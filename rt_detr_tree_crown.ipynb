{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNKO1hIXsUiH6+FBj8GU6T9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeliasporto/rt_detr_tree_crown/blob/main/rt_detr_tree_crown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkdeSb-igB1Q",
        "outputId": "5d2b1cee-bbb2-4241-db8d-595cae3e1c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RT-DETR'...\n",
            "remote: Enumerating objects: 990, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 990 (delta 2), reused 6 (delta 1), pack-reused 978 (from 1)\u001b[K\n",
            "Receiving objects: 100% (990/990), 622.02 KiB | 5.50 MiB/s, done.\n",
            "Resolving deltas: 100% (460/460), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lyuwenyu/RT-DETR.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('individual_urban_tree_crown_detection'):\n",
        "  !git clone https://github.com/pedrozamboni/individual_urban_tree_crown_detection.git\n",
        "  !mkdir -p /content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection\n",
        "\n",
        "%cd /content\n",
        "\n",
        "path = '/content/individual_urban_tree_crown_detection/rgb'\n",
        "\n",
        "!mv {path}/* /content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection\n",
        "print(f'arquivos movidos de {path} para /content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz7dNKsDgD3B",
        "outputId": "72867ab2-e5ce-4345-80c8-a4e9c66886a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'individual_urban_tree_crown_detection'...\n",
            "remote: Enumerating objects: 696, done.\u001b[K\n",
            "remote: Total 696 (delta 0), reused 0 (delta 0), pack-reused 696 (from 1)\u001b[K\n",
            "Receiving objects: 100% (696/696), 184.86 MiB | 55.82 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Updating files: 100% (677/677), done.\n",
            "/content\n",
            "arquivos movidos de /content/individual_urban_tree_crown_detection/rgb para /content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYEPlsWJsjFE",
        "outputId": "7d4c617f-7480-43ba-b94d-60b01082d33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def separar_imagens(path, txt_train, txt_val, txt_test):\n",
        "    os.makedirs(os.path.join(path, 'train'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(path, 'val'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(path, 'test'), exist_ok=True)\n",
        "\n",
        "    # Função para ler o conteúdo de um arquivo txt e retornar os nomes das imagens\n",
        "    def ler_imagens(txt_file):\n",
        "        with open(txt_file, 'r') as f:\n",
        "            return [line.strip() for line in f.readlines()]  # Remove as quebras de linha\n",
        "\n",
        "    # Ler os arquivos .txt\n",
        "    imagens_train = ler_imagens(txt_train)\n",
        "    imagens_val = ler_imagens(txt_val)\n",
        "    imagens_test = ler_imagens(txt_test)\n",
        "\n",
        "    # Função para mover as imagens para a pasta de destino apropriada\n",
        "    def mover_imagens(imagens, destino):\n",
        "        for imagem in imagens:\n",
        "            origem_imagem = os.path.join(path, imagem)\n",
        "            if os.path.exists(origem_imagem):\n",
        "                shutil.move(origem_imagem, os.path.join(path, destino, imagem))\n",
        "            else:\n",
        "                print(f\"A imagem {imagem} não foi encontrada na pasta de origem.\")\n",
        "\n",
        "    # Mover as imagens para as pastas apropriadas\n",
        "    mover_imagens(imagens_train, 'train')\n",
        "    mover_imagens(imagens_val, 'val')\n",
        "    mover_imagens(imagens_test, 'test')\n",
        "\n",
        "# Caminho para a pasta original onde as imagens estão\n",
        "path = '/content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection'\n",
        "\n",
        "# Caminhos dos arquivos .txt com a lista das imagens para cada categoria\n",
        "txt_train = '/content/individual_urban_tree_crown_detection/img_list/4/train.txt'\n",
        "txt_val = '/content/individual_urban_tree_crown_detection/img_list/4/val.txt'\n",
        "txt_test = '/content/individual_urban_tree_crown_detection/img_list/4/test.txt'\n",
        "\n",
        "# Chama a função para separar as imagens\n",
        "separar_imagens(path, txt_train, txt_val, txt_test)\n"
      ],
      "metadata": {
        "id": "7zKBGTjJ2Exv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c061c57c-024f-4ff7-81ad-2678e9c5bc9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A imagem 192.png não foi encontrada na pasta de origem.\n",
            "A imagem 125.png não foi encontrada na pasta de origem.\n",
            "A imagem 19.png não foi encontrada na pasta de origem.\n",
            "A imagem 215.png não foi encontrada na pasta de origem.\n",
            "A imagem 53.png não foi encontrada na pasta de origem.\n",
            "A imagem 163.png não foi encontrada na pasta de origem.\n",
            "A imagem 155.png não foi encontrada na pasta de origem.\n",
            "A imagem 89.png não foi encontrada na pasta de origem.\n",
            "A imagem 22.png não foi encontrada na pasta de origem.\n",
            "A imagem 93.png não foi encontrada na pasta de origem.\n",
            "A imagem 43.png não foi encontrada na pasta de origem.\n",
            "A imagem 103.png não foi encontrada na pasta de origem.\n",
            "A imagem 130.png não foi encontrada na pasta de origem.\n",
            "A imagem 200.png não foi encontrada na pasta de origem.\n",
            "A imagem 95.png não foi encontrada na pasta de origem.\n",
            "A imagem 105.png não foi encontrada na pasta de origem.\n",
            "A imagem 153.png não foi encontrada na pasta de origem.\n",
            "A imagem 109.png não foi encontrada na pasta de origem.\n",
            "A imagem 45.png não foi encontrada na pasta de origem.\n",
            "A imagem 3.png não foi encontrada na pasta de origem.\n",
            "A imagem 133.png não foi encontrada na pasta de origem.\n",
            "A imagem 28.png não foi encontrada na pasta de origem.\n",
            "A imagem 123.png não foi encontrada na pasta de origem.\n",
            "A imagem 83.png não foi encontrada na pasta de origem.\n",
            "A imagem 181.png não foi encontrada na pasta de origem.\n",
            "A imagem 101.png não foi encontrada na pasta de origem.\n",
            "A imagem 34.png não foi encontrada na pasta de origem.\n",
            "A imagem 151.png não foi encontrada na pasta de origem.\n",
            "A imagem 124.png não foi encontrada na pasta de origem.\n",
            "A imagem 185.png não foi encontrada na pasta de origem.\n",
            "A imagem 111.png não foi encontrada na pasta de origem.\n",
            "A imagem 126.png não foi encontrada na pasta de origem.\n",
            "A imagem 99.png não foi encontrada na pasta de origem.\n",
            "A imagem 16.png não foi encontrada na pasta de origem.\n",
            "A imagem 15.png não foi encontrada na pasta de origem.\n",
            "A imagem 24.png não foi encontrada na pasta de origem.\n",
            "A imagem 116.png não foi encontrada na pasta de origem.\n",
            "A imagem 0.png não foi encontrada na pasta de origem.\n",
            "A imagem 108.png não foi encontrada na pasta de origem.\n",
            "A imagem 218.png não foi encontrada na pasta de origem.\n",
            "A imagem 11.png não foi encontrada na pasta de origem.\n",
            "A imagem 6.png não foi encontrada na pasta de origem.\n",
            "A imagem 118.png não foi encontrada na pasta de origem.\n",
            "A imagem 9.png não foi encontrada na pasta de origem.\n",
            "A imagem 20.png não foi encontrada na pasta de origem.\n",
            "A imagem 131.png não foi encontrada na pasta de origem.\n",
            "A imagem 77.png não foi encontrada na pasta de origem.\n",
            "A imagem 137.png não foi encontrada na pasta de origem.\n",
            "A imagem 191.png não foi encontrada na pasta de origem.\n",
            "A imagem 216.png não foi encontrada na pasta de origem.\n",
            "A imagem 2.png não foi encontrada na pasta de origem.\n",
            "A imagem 143.png não foi encontrada na pasta de origem.\n",
            "A imagem 74.png não foi encontrada na pasta de origem.\n",
            "A imagem 119.png não foi encontrada na pasta de origem.\n",
            "A imagem 76.png não foi encontrada na pasta de origem.\n",
            "A imagem 134.png não foi encontrada na pasta de origem.\n",
            "A imagem 206.png não foi encontrada na pasta de origem.\n",
            "A imagem 39.png não foi encontrada na pasta de origem.\n",
            "A imagem 8.png não foi encontrada na pasta de origem.\n",
            "A imagem 90.png não foi encontrada na pasta de origem.\n",
            "A imagem 190.png não foi encontrada na pasta de origem.\n",
            "A imagem 41.png não foi encontrada na pasta de origem.\n",
            "A imagem 32.png não foi encontrada na pasta de origem.\n",
            "A imagem 29.png não foi encontrada na pasta de origem.\n",
            "A imagem 14.png não foi encontrada na pasta de origem.\n",
            "A imagem 102.png não foi encontrada na pasta de origem.\n",
            "A imagem 62.png não foi encontrada na pasta de origem.\n",
            "A imagem 205.png não foi encontrada na pasta de origem.\n",
            "A imagem 142.png não foi encontrada na pasta de origem.\n",
            "A imagem 179.png não foi encontrada na pasta de origem.\n",
            "A imagem 171.png não foi encontrada na pasta de origem.\n",
            "A imagem 157.png não foi encontrada na pasta de origem.\n",
            "A imagem 60.png não foi encontrada na pasta de origem.\n",
            "A imagem 12.png não foi encontrada na pasta de origem.\n",
            "A imagem 148.png não foi encontrada na pasta de origem.\n",
            "A imagem 58.png não foi encontrada na pasta de origem.\n",
            "A imagem 136.png não foi encontrada na pasta de origem.\n",
            "A imagem 46.png não foi encontrada na pasta de origem.\n",
            "A imagem 211.png não foi encontrada na pasta de origem.\n",
            "A imagem 219.png não foi encontrada na pasta de origem.\n",
            "A imagem 94.png não foi encontrada na pasta de origem.\n",
            "A imagem 146.png não foi encontrada na pasta de origem.\n",
            "A imagem 64.png não foi encontrada na pasta de origem.\n",
            "A imagem 177.png não foi encontrada na pasta de origem.\n",
            "A imagem 106.png não foi encontrada na pasta de origem.\n",
            "A imagem 214.png não foi encontrada na pasta de origem.\n",
            "A imagem 68.png não foi encontrada na pasta de origem.\n",
            "A imagem 61.png não foi encontrada na pasta de origem.\n",
            "A imagem 149.png não foi encontrada na pasta de origem.\n",
            "A imagem 38.png não foi encontrada na pasta de origem.\n",
            "A imagem 165.png não foi encontrada na pasta de origem.\n",
            "A imagem 51.png não foi encontrada na pasta de origem.\n",
            "A imagem 160.png não foi encontrada na pasta de origem.\n",
            "A imagem 110.png não foi encontrada na pasta de origem.\n",
            "A imagem 156.png não foi encontrada na pasta de origem.\n",
            "A imagem 26.png não foi encontrada na pasta de origem.\n",
            "A imagem 10.png não foi encontrada na pasta de origem.\n",
            "A imagem 120.png não foi encontrada na pasta de origem.\n",
            "A imagem 107.png não foi encontrada na pasta de origem.\n",
            "A imagem 164.png não foi encontrada na pasta de origem.\n",
            "A imagem 150.png não foi encontrada na pasta de origem.\n",
            "A imagem 207.png não foi encontrada na pasta de origem.\n",
            "A imagem 127.png não foi encontrada na pasta de origem.\n",
            "A imagem 82.png não foi encontrada na pasta de origem.\n",
            "A imagem 176.png não foi encontrada na pasta de origem.\n",
            "A imagem 67.png não foi encontrada na pasta de origem.\n",
            "A imagem 23.png não foi encontrada na pasta de origem.\n",
            "A imagem 98.png não foi encontrada na pasta de origem.\n",
            "A imagem 197.png não foi encontrada na pasta de origem.\n",
            "A imagem 162.png não foi encontrada na pasta de origem.\n",
            "A imagem 59.png não foi encontrada na pasta de origem.\n",
            "A imagem 117.png não foi encontrada na pasta de origem.\n",
            "A imagem 84.png não foi encontrada na pasta de origem.\n",
            "A imagem 175.png não foi encontrada na pasta de origem.\n",
            "A imagem 184.png não foi encontrada na pasta de origem.\n",
            "A imagem 140.png não foi encontrada na pasta de origem.\n",
            "A imagem 65.png não foi encontrada na pasta de origem.\n",
            "A imagem 212.png não foi encontrada na pasta de origem.\n",
            "A imagem 47.png não foi encontrada na pasta de origem.\n",
            "A imagem 37.png não foi encontrada na pasta de origem.\n",
            "A imagem 159.png não foi encontrada na pasta de origem.\n",
            "A imagem 75.png não foi encontrada na pasta de origem.\n",
            "A imagem 180.png não foi encontrada na pasta de origem.\n",
            "A imagem 132.png não foi encontrada na pasta de origem.\n",
            "A imagem 79.png não foi encontrada na pasta de origem.\n",
            "A imagem 198.png não foi encontrada na pasta de origem.\n",
            "A imagem 199.png não foi encontrada na pasta de origem.\n",
            "A imagem 193.png não foi encontrada na pasta de origem.\n",
            "A imagem 203.png não foi encontrada na pasta de origem.\n",
            "A imagem 204.png não foi encontrada na pasta de origem.\n",
            "A imagem 189.png não foi encontrada na pasta de origem.\n",
            "A imagem 71.png não foi encontrada na pasta de origem.\n",
            "A imagem 169.png não foi encontrada na pasta de origem.\n",
            "A imagem 40.png não foi encontrada na pasta de origem.\n",
            "A imagem 122.png não foi encontrada na pasta de origem.\n",
            "A imagem 1.png não foi encontrada na pasta de origem.\n",
            "A imagem 42.png não foi encontrada na pasta de origem.\n",
            "A imagem 49.png não foi encontrada na pasta de origem.\n",
            "A imagem 13.png não foi encontrada na pasta de origem.\n",
            "A imagem 72.png não foi encontrada na pasta de origem.\n",
            "A imagem 139.png não foi encontrada na pasta de origem.\n",
            "A imagem 80.png não foi encontrada na pasta de origem.\n",
            "A imagem 56.png não foi encontrada na pasta de origem.\n",
            "A imagem 44.png não foi encontrada na pasta de origem.\n",
            "A imagem 48.png não foi encontrada na pasta de origem.\n",
            "A imagem 18.png não foi encontrada na pasta de origem.\n",
            "A imagem 173.png não foi encontrada na pasta de origem.\n",
            "A imagem 52.png não foi encontrada na pasta de origem.\n",
            "A imagem 183.png não foi encontrada na pasta de origem.\n",
            "A imagem 158.png não foi encontrada na pasta de origem.\n",
            "A imagem 5.png não foi encontrada na pasta de origem.\n",
            "A imagem 69.png não foi encontrada na pasta de origem.\n",
            "A imagem 201.png não foi encontrada na pasta de origem.\n",
            "A imagem 167.png não foi encontrada na pasta de origem.\n",
            "A imagem 50.png não foi encontrada na pasta de origem.\n",
            "A imagem 114.png não foi encontrada na pasta de origem.\n",
            "A imagem 70.png não foi encontrada na pasta de origem.\n",
            "A imagem 86.png não foi encontrada na pasta de origem.\n",
            "A imagem 172.png não foi encontrada na pasta de origem.\n",
            "A imagem 154.png não foi encontrada na pasta de origem.\n",
            "A imagem 194.png não foi encontrada na pasta de origem.\n",
            "A imagem 141.png não foi encontrada na pasta de origem.\n",
            "A imagem 168.png não foi encontrada na pasta de origem.\n",
            "A imagem 208.png não foi encontrada na pasta de origem.\n",
            "A imagem 92.png não foi encontrada na pasta de origem.\n",
            "A imagem 147.png não foi encontrada na pasta de origem.\n",
            "A imagem 88.png não foi encontrada na pasta de origem.\n",
            "A imagem 178.png não foi encontrada na pasta de origem.\n",
            "A imagem 27.png não foi encontrada na pasta de origem.\n",
            "A imagem 135.png não foi encontrada na pasta de origem.\n",
            "A imagem 121.png não foi encontrada na pasta de origem.\n",
            "A imagem 17.png não foi encontrada na pasta de origem.\n",
            "A imagem 186.png não foi encontrada na pasta de origem.\n",
            "A imagem 87.png não foi encontrada na pasta de origem.\n",
            "A imagem 30.png não foi encontrada na pasta de origem.\n",
            "A imagem 217.png não foi encontrada na pasta de origem.\n",
            "A imagem 100.png não foi encontrada na pasta de origem.\n",
            "A imagem 35.png não foi encontrada na pasta de origem.\n",
            "A imagem 161.png não foi encontrada na pasta de origem.\n",
            "A imagem 145.png não foi encontrada na pasta de origem.\n",
            "A imagem 174.png não foi encontrada na pasta de origem.\n",
            "A imagem 112.png não foi encontrada na pasta de origem.\n",
            "A imagem 144.png não foi encontrada na pasta de origem.\n",
            "A imagem 202.png não foi encontrada na pasta de origem.\n",
            "A imagem 128.png não foi encontrada na pasta de origem.\n",
            "A imagem 187.png não foi encontrada na pasta de origem.\n",
            "A imagem 36.png não foi encontrada na pasta de origem.\n",
            "A imagem 25.png não foi encontrada na pasta de origem.\n",
            "A imagem 91.png não foi encontrada na pasta de origem.\n",
            "A imagem 73.png não foi encontrada na pasta de origem.\n",
            "A imagem 166.png não foi encontrada na pasta de origem.\n",
            "A imagem 113.png não foi encontrada na pasta de origem.\n",
            "A imagem 170.png não foi encontrada na pasta de origem.\n",
            "A imagem 33.png não foi encontrada na pasta de origem.\n",
            "A imagem 195.png não foi encontrada na pasta de origem.\n",
            "A imagem 209.png não foi encontrada na pasta de origem.\n",
            "A imagem 115.png não foi encontrada na pasta de origem.\n",
            "A imagem 213.png não foi encontrada na pasta de origem.\n",
            "A imagem 7.png não foi encontrada na pasta de origem.\n",
            "A imagem 66.png não foi encontrada na pasta de origem.\n",
            "A imagem 57.png não foi encontrada na pasta de origem.\n",
            "A imagem 78.png não foi encontrada na pasta de origem.\n",
            "A imagem 152.png não foi encontrada na pasta de origem.\n",
            "A imagem 55.png não foi encontrada na pasta de origem.\n",
            "A imagem 210.png não foi encontrada na pasta de origem.\n",
            "A imagem 31.png não foi encontrada na pasta de origem.\n",
            "A imagem 129.png não foi encontrada na pasta de origem.\n",
            "A imagem 4.png não foi encontrada na pasta de origem.\n",
            "A imagem 81.png não foi encontrada na pasta de origem.\n",
            "A imagem 21.png não foi encontrada na pasta de origem.\n",
            "A imagem 96.png não foi encontrada na pasta de origem.\n",
            "A imagem 138.png não foi encontrada na pasta de origem.\n",
            "A imagem 104.png não foi encontrada na pasta de origem.\n",
            "A imagem 196.png não foi encontrada na pasta de origem.\n",
            "A imagem 54.png não foi encontrada na pasta de origem.\n",
            "A imagem 188.png não foi encontrada na pasta de origem.\n",
            "A imagem 63.png não foi encontrada na pasta de origem.\n",
            "A imagem 182.png não foi encontrada na pasta de origem.\n",
            "A imagem 85.png não foi encontrada na pasta de origem.\n",
            "A imagem 97.png não foi encontrada na pasta de origem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def parse_bbox_file(bbox_file, image_width, image_height):\n",
        "    with open(bbox_file, 'r') as file:\n",
        "        annotations = []\n",
        "        for line in file:\n",
        "            coordinates = list(map(float, line.split()))  # Leitura de coordenadas (x_min, y_min, x_max, y_max)\n",
        "            x_min, y_min, x_max, y_max = coordinates\n",
        "\n",
        "            # Garantir que as coordenadas estão dentro dos limites\n",
        "            x_min = max(0, min(x_min, image_width - 1))\n",
        "            y_min = max(0, min(y_min, image_height - 1))\n",
        "            x_max = max(0, min(x_max, image_width - 1))\n",
        "            y_max = max(0, min(y_max, image_height - 1))\n",
        "\n",
        "            # Calcular largura, altura e área\n",
        "            bbox_width = x_max - x_min\n",
        "            bbox_height = y_max - y_min\n",
        "            area = bbox_width * bbox_height\n",
        "\n",
        "            if bbox_width > 0 and bbox_height > 0:\n",
        "                annotations.append({\n",
        "                    \"bbox\": [x_min, y_min, bbox_width, bbox_height],\n",
        "                    \"area\": area,\n",
        "                    \"iscrowd\": 0\n",
        "                })\n",
        "        return annotations\n",
        "\n",
        "def create_coco_annotations(img_list_dir, bbox_list_dir, output_path, category_name=\"Tree Crown\"):\n",
        "    images = []\n",
        "    annotations = []\n",
        "    categories = [{\"id\": 0, \"name\": category_name, \"supercategory\": \"none\"}]\n",
        "\n",
        "    annotation_id = 1\n",
        "    for image_id, image_name in enumerate(os.listdir(img_list_dir), 1):\n",
        "        if image_name.endswith(\".png\"):  # Filtrar arquivos de imagem\n",
        "            image_path = os.path.join(img_list_dir, image_name)\n",
        "            bbox_file = os.path.join(bbox_list_dir, image_name.replace('.png', '.txt'))\n",
        "\n",
        "            # Obter dimensões da imagem\n",
        "            with Image.open(image_path) as img:\n",
        "                width, height = img.size\n",
        "\n",
        "            images.append({\n",
        "                \"id\": image_id,\n",
        "                \"file_name\": image_name,\n",
        "                \"width\": width,\n",
        "                \"height\": height\n",
        "            })\n",
        "\n",
        "            if os.path.exists(bbox_file):\n",
        "                bboxes = parse_bbox_file(bbox_file, width, height)\n",
        "                for bbox in bboxes:\n",
        "                    annotations.append({\n",
        "                        \"id\": annotation_id,\n",
        "                        \"image_id\": image_id,\n",
        "                        \"category_id\": 0,\n",
        "                        \"bbox\": bbox[\"bbox\"],\n",
        "                        \"area\": bbox[\"area\"],\n",
        "                        \"iscrowd\": bbox[\"iscrowd\"]\n",
        "                    })\n",
        "                    annotation_id += 1\n",
        "\n",
        "    coco_format = {\n",
        "        \"images\": images,\n",
        "        \"annotations\": annotations,\n",
        "        \"categories\": categories\n",
        "    }\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    with open(output_path, 'w') as json_file:\n",
        "        json.dump(coco_format, json_file, indent=4)\n",
        "    print(f\"Arquivo JSON gerado: {output_path}\")\n",
        "\n",
        "# Diretórios e caminhos\n",
        "img_list_dir_train = '/content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection/train/'\n",
        "img_list_dir_val = '/content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection/val/'\n",
        "img_list_dir_test = '/content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection/test/'\n",
        "\n",
        "bbox_list_dir = '/content/individual_urban_tree_crown_detection/bbox_txt'\n",
        "\n",
        "output_path_train = '/content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection/annotations/instances_train.json'\n",
        "output_path_val = '/content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection/annotations/instances_val.json'\n",
        "output_path_test = '/content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection/annotations/instances_test.json'\n",
        "\n",
        "# Gerar arquivos JSON\n",
        "create_coco_annotations(img_list_dir_train, bbox_list_dir, output_path_train)\n",
        "create_coco_annotations(img_list_dir_val, bbox_list_dir, output_path_val)\n",
        "create_coco_annotations(img_list_dir_test, bbox_list_dir, output_path_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "6LTd5McGxTea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d9a99f-49ff-4722-d71b-0416903b0b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo JSON gerado: /content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection/annotations/instances_train.json\n",
            "Arquivo JSON gerado: /content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection/annotations/instances_val.json\n",
            "Arquivo JSON gerado: /content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection/annotations/instances_test.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "%cd /content\n",
        "git_repo_url = 'https://github.com/lyuwenyu/RT-DETR.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "!pip install torch==2.0.1\n",
        "!pip install torchvision==0.15.2\n",
        "!pip install onnx==1.14.0\n",
        "!pip install onnxruntime==1.15.1\n",
        "!pip install pycocotools\n",
        "!pip install PyYAML\n",
        "!pip install scipy\n",
        "import sys\n",
        "sys.path.append(project_name)"
      ],
      "metadata": {
        "id": "J-CIvuIwgJZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c0df15-4ce4-42eb-8979-d95b75c23b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.5)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n",
            "Collecting torchvision==0.15.2\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision==0.15.2) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision==0.15.2) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision==0.15.2) (3.30.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision==0.15.2) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision==0.15.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision==0.15.2) (1.3.0)\n",
            "Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "Successfully installed torchvision-0.15.2\n",
            "Collecting onnx==1.14.0\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx==1.14.0) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx==1.14.0) (4.25.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx==1.14.0) (4.12.2)\n",
            "Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.14.0\n",
            "Collecting onnxruntime==1.15.1\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime==1.15.1)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.1) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.1) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.1) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.1) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.1) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.15.1)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.15.1) (1.3.0)\n",
            "Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.15.1\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ED-CZH87YzI",
        "outputId": "0a6d511e-91e3-4395-bcaf-7a9df6132449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.0.1\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, jinja2, networkx, nvidia-cublas-cu11, nvidia-cuda-cupti-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-runtime-cu11, nvidia-cudnn-cu11, nvidia-cufft-cu11, nvidia-curand-cu11, nvidia-cusolver-cu11, nvidia-cusparse-cu11, nvidia-nccl-cu11, nvidia-nvtx-cu11, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchvision, triton\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/RT-DETR/rtdetr_pytorch/tools/train.py -c /content/RT-DETR/rtdetr_pytorch/configs/rtdetr/rtdetr_r101vd_6x_coco.yml"
      ],
      "metadata": {
        "id": "GbwgV_66gMFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c1024a-6cec-4164-8a9d-ba43cb62fbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-15 13:51:49.449338: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-15 13:51:49.466356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-15 13:51:49.487619: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-15 13:51:49.494142: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-15 13:51:49.509415: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-15 13:51:50.611571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Not init distributed mode.\n",
            "Start training\n",
            "Downloading: \"https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet101_vd_ssld_pretrained_from_paddle.pth\" to /root/.cache/torch/hub/checkpoints/ResNet101_vd_ssld_pretrained_from_paddle.pth\n",
            "100% 163M/163M [00:00<00:00, 203MB/s]\n",
            "Load PResNet101 state_dict\n",
            "Initial lr:  [1e-06, 0.0001]\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "number of params: 76365411\n",
            "Epoch: [0]  [ 0/33]  eta: 0:01:17  lr: 0.000001  loss: 41.1817 (41.1817)  loss_vfl: 0.3247 (0.3247)  loss_bbox: 1.0138 (1.0138)  loss_giou: 2.2543 (2.2543)  loss_vfl_aux_0: 0.3335 (0.3335)  loss_bbox_aux_0: 1.0217 (1.0217)  loss_giou_aux_0: 2.2503 (2.2503)  loss_vfl_aux_1: 0.3230 (0.3230)  loss_bbox_aux_1: 1.0268 (1.0268)  loss_giou_aux_1: 2.2620 (2.2620)  loss_vfl_aux_2: 0.3155 (0.3155)  loss_bbox_aux_2: 0.9940 (0.9940)  loss_giou_aux_2: 2.2608 (2.2608)  loss_vfl_aux_3: 0.3156 (0.3156)  loss_bbox_aux_3: 1.0213 (1.0213)  loss_giou_aux_3: 2.2409 (2.2409)  loss_vfl_aux_4: 0.3476 (0.3476)  loss_bbox_aux_4: 1.0466 (1.0466)  loss_giou_aux_4: 2.2515 (2.2515)  loss_vfl_aux_5: 0.2627 (0.2627)  loss_bbox_aux_5: 1.0158 (1.0158)  loss_giou_aux_5: 2.2411 (2.2411)  loss_vfl_dn_0: 0.7711 (0.7711)  loss_bbox_dn_0: 0.4521 (0.4521)  loss_giou_dn_0: 1.3623 (1.3623)  loss_vfl_dn_1: 0.9179 (0.9179)  loss_bbox_dn_1: 0.4521 (0.4521)  loss_giou_dn_1: 1.3623 (1.3623)  loss_vfl_dn_2: 0.8344 (0.8344)  loss_bbox_dn_2: 0.4521 (0.4521)  loss_giou_dn_2: 1.3623 (1.3623)  loss_vfl_dn_3: 0.8793 (0.8793)  loss_bbox_dn_3: 0.4521 (0.4521)  loss_giou_dn_3: 1.3623 (1.3623)  loss_vfl_dn_4: 0.9298 (0.9298)  loss_bbox_dn_4: 0.4521 (0.4521)  loss_giou_dn_4: 1.3623 (1.3623)  loss_vfl_dn_5: 0.8395 (0.8395)  loss_bbox_dn_5: 0.4521 (0.4521)  loss_giou_dn_5: 1.3623 (1.3623)  time: 2.3408  data: 0.4535  max mem: 6374\n",
            "Epoch: [0]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 28.4546 (30.5188)  loss_vfl: 0.5833 (0.5757)  loss_bbox: 0.4863 (0.5932)  loss_giou: 1.2248 (1.3505)  loss_vfl_aux_0: 0.5202 (0.5208)  loss_bbox_aux_0: 0.5087 (0.6007)  loss_giou_aux_0: 1.2545 (1.3608)  loss_vfl_aux_1: 0.5617 (0.5385)  loss_bbox_aux_1: 0.4899 (0.5962)  loss_giou_aux_1: 1.2493 (1.3589)  loss_vfl_aux_2: 0.5827 (0.5669)  loss_bbox_aux_2: 0.4905 (0.5937)  loss_giou_aux_2: 1.2419 (1.3527)  loss_vfl_aux_3: 0.6021 (0.5619)  loss_bbox_aux_3: 0.4888 (0.5905)  loss_giou_aux_3: 1.2339 (1.3520)  loss_vfl_aux_4: 0.6269 (0.5650)  loss_bbox_aux_4: 0.4926 (0.5932)  loss_giou_aux_4: 1.2267 (1.3515)  loss_vfl_aux_5: 0.4921 (0.4775)  loss_bbox_aux_5: 0.5711 (0.6269)  loss_giou_aux_5: 1.2730 (1.3675)  loss_vfl_dn_0: 0.3145 (0.3733)  loss_bbox_dn_0: 0.4085 (0.4415)  loss_giou_dn_0: 1.3608 (1.3644)  loss_vfl_dn_1: 0.3194 (0.3766)  loss_bbox_dn_1: 0.4074 (0.4407)  loss_giou_dn_1: 1.3637 (1.3648)  loss_vfl_dn_2: 0.3187 (0.3562)  loss_bbox_dn_2: 0.4070 (0.4399)  loss_giou_dn_2: 1.3636 (1.3660)  loss_vfl_dn_3: 0.3237 (0.3606)  loss_bbox_dn_3: 0.4057 (0.4388)  loss_giou_dn_3: 1.3579 (1.3659)  loss_vfl_dn_4: 0.3230 (0.3651)  loss_bbox_dn_4: 0.4037 (0.4379)  loss_giou_dn_4: 1.3569 (1.3661)  loss_vfl_dn_5: 0.3316 (0.3610)  loss_bbox_dn_5: 0.4023 (0.4374)  loss_giou_dn_5: 1.3608 (1.3679)  time: 0.3455  data: 0.0140  max mem: 7772\n",
            "Epoch: [0] Total time: 0:00:14 (0.4438 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 28.4546 (30.5188)  loss_vfl: 0.5833 (0.5757)  loss_bbox: 0.4863 (0.5932)  loss_giou: 1.2248 (1.3505)  loss_vfl_aux_0: 0.5202 (0.5208)  loss_bbox_aux_0: 0.5087 (0.6007)  loss_giou_aux_0: 1.2545 (1.3608)  loss_vfl_aux_1: 0.5617 (0.5385)  loss_bbox_aux_1: 0.4899 (0.5962)  loss_giou_aux_1: 1.2493 (1.3589)  loss_vfl_aux_2: 0.5827 (0.5669)  loss_bbox_aux_2: 0.4905 (0.5937)  loss_giou_aux_2: 1.2419 (1.3527)  loss_vfl_aux_3: 0.6021 (0.5619)  loss_bbox_aux_3: 0.4888 (0.5905)  loss_giou_aux_3: 1.2339 (1.3520)  loss_vfl_aux_4: 0.6269 (0.5650)  loss_bbox_aux_4: 0.4926 (0.5932)  loss_giou_aux_4: 1.2267 (1.3515)  loss_vfl_aux_5: 0.4921 (0.4775)  loss_bbox_aux_5: 0.5711 (0.6269)  loss_giou_aux_5: 1.2730 (1.3675)  loss_vfl_dn_0: 0.3145 (0.3733)  loss_bbox_dn_0: 0.4085 (0.4415)  loss_giou_dn_0: 1.3608 (1.3644)  loss_vfl_dn_1: 0.3194 (0.3766)  loss_bbox_dn_1: 0.4074 (0.4407)  loss_giou_dn_1: 1.3637 (1.3648)  loss_vfl_dn_2: 0.3187 (0.3562)  loss_bbox_dn_2: 0.4070 (0.4399)  loss_giou_dn_2: 1.3636 (1.3660)  loss_vfl_dn_3: 0.3237 (0.3606)  loss_bbox_dn_3: 0.4057 (0.4388)  loss_giou_dn_3: 1.3579 (1.3659)  loss_vfl_dn_4: 0.3230 (0.3651)  loss_bbox_dn_4: 0.4037 (0.4379)  loss_giou_dn_4: 1.3569 (1.3661)  loss_vfl_dn_5: 0.3316 (0.3610)  loss_bbox_dn_5: 0.4023 (0.4374)  loss_giou_dn_5: 1.3608 (1.3679)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9857  data: 0.5656  max mem: 7772\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4169  data: 0.1085  max mem: 7772\n",
            "Test: Total time: 0:00:02 (0.4291 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
            "best_stat:  {'epoch': 0, 'coco_eval_bbox': 0.0068128287747728595}\n",
            "Epoch: [1]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 27.3157 (27.3157)  loss_vfl: 0.4775 (0.4775)  loss_bbox: 0.4416 (0.4416)  loss_giou: 1.2228 (1.2228)  loss_vfl_aux_0: 0.4622 (0.4622)  loss_bbox_aux_0: 0.4554 (0.4554)  loss_giou_aux_0: 1.2466 (1.2466)  loss_vfl_aux_1: 0.4528 (0.4528)  loss_bbox_aux_1: 0.4491 (0.4491)  loss_giou_aux_1: 1.2377 (1.2377)  loss_vfl_aux_2: 0.4579 (0.4579)  loss_bbox_aux_2: 0.4414 (0.4414)  loss_giou_aux_2: 1.2243 (1.2243)  loss_vfl_aux_3: 0.4708 (0.4708)  loss_bbox_aux_3: 0.4439 (0.4439)  loss_giou_aux_3: 1.2218 (1.2218)  loss_vfl_aux_4: 0.4850 (0.4850)  loss_bbox_aux_4: 0.4438 (0.4438)  loss_giou_aux_4: 1.2344 (1.2344)  loss_vfl_aux_5: 0.4197 (0.4197)  loss_bbox_aux_5: 0.4655 (0.4655)  loss_giou_aux_5: 1.2695 (1.2695)  loss_vfl_dn_0: 0.3081 (0.3081)  loss_bbox_dn_0: 0.3791 (0.3791)  loss_giou_dn_0: 1.3628 (1.3628)  loss_vfl_dn_1: 0.3090 (0.3090)  loss_bbox_dn_1: 0.3762 (0.3762)  loss_giou_dn_1: 1.3576 (1.3576)  loss_vfl_dn_2: 0.3217 (0.3217)  loss_bbox_dn_2: 0.3735 (0.3735)  loss_giou_dn_2: 1.3535 (1.3535)  loss_vfl_dn_3: 0.3330 (0.3330)  loss_bbox_dn_3: 0.3692 (0.3692)  loss_giou_dn_3: 1.3424 (1.3424)  loss_vfl_dn_4: 0.3414 (0.3414)  loss_bbox_dn_4: 0.3673 (0.3673)  loss_giou_dn_4: 1.3409 (1.3409)  loss_vfl_dn_5: 0.3476 (0.3476)  loss_bbox_dn_5: 0.3663 (0.3663)  loss_giou_dn_5: 1.3425 (1.3425)  time: 0.9789  data: 0.6097  max mem: 7772\n",
            "Epoch: [1]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 26.6090 (27.3429)  loss_vfl: 0.6604 (0.7079)  loss_bbox: 0.3373 (0.3975)  loss_giou: 1.1142 (1.0929)  loss_vfl_aux_0: 0.5399 (0.5704)  loss_bbox_aux_0: 0.3612 (0.4140)  loss_giou_aux_0: 1.1246 (1.1257)  loss_vfl_aux_1: 0.5716 (0.6051)  loss_bbox_aux_1: 0.3543 (0.4084)  loss_giou_aux_1: 1.1169 (1.1114)  loss_vfl_aux_2: 0.5892 (0.6293)  loss_bbox_aux_2: 0.3465 (0.4045)  loss_giou_aux_2: 1.1110 (1.1062)  loss_vfl_aux_3: 0.6261 (0.6579)  loss_bbox_aux_3: 0.3459 (0.4031)  loss_giou_aux_3: 1.1121 (1.0986)  loss_vfl_aux_4: 0.6439 (0.6868)  loss_bbox_aux_4: 0.3378 (0.3985)  loss_giou_aux_4: 1.1129 (1.0933)  loss_vfl_aux_5: 0.5132 (0.5285)  loss_bbox_aux_5: 0.3711 (0.4288)  loss_giou_aux_5: 1.1650 (1.1535)  loss_vfl_dn_0: 0.3260 (0.3217)  loss_bbox_dn_0: 0.3965 (0.4210)  loss_giou_dn_0: 1.3197 (1.3265)  loss_vfl_dn_1: 0.3313 (0.3293)  loss_bbox_dn_1: 0.3879 (0.4134)  loss_giou_dn_1: 1.2923 (1.3104)  loss_vfl_dn_2: 0.3382 (0.3376)  loss_bbox_dn_2: 0.3844 (0.4091)  loss_giou_dn_2: 1.2841 (1.3044)  loss_vfl_dn_3: 0.3378 (0.3396)  loss_bbox_dn_3: 0.3821 (0.4046)  loss_giou_dn_3: 1.2865 (1.3020)  loss_vfl_dn_4: 0.3349 (0.3438)  loss_bbox_dn_4: 0.3802 (0.4024)  loss_giou_dn_4: 1.2829 (1.3014)  loss_vfl_dn_5: 0.3442 (0.3517)  loss_bbox_dn_5: 0.3781 (0.4008)  loss_giou_dn_5: 1.2771 (1.3009)  time: 0.3346  data: 0.0146  max mem: 7772\n",
            "Epoch: [1] Total time: 0:00:11 (0.3529 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 26.6090 (27.3429)  loss_vfl: 0.6604 (0.7079)  loss_bbox: 0.3373 (0.3975)  loss_giou: 1.1142 (1.0929)  loss_vfl_aux_0: 0.5399 (0.5704)  loss_bbox_aux_0: 0.3612 (0.4140)  loss_giou_aux_0: 1.1246 (1.1257)  loss_vfl_aux_1: 0.5716 (0.6051)  loss_bbox_aux_1: 0.3543 (0.4084)  loss_giou_aux_1: 1.1169 (1.1114)  loss_vfl_aux_2: 0.5892 (0.6293)  loss_bbox_aux_2: 0.3465 (0.4045)  loss_giou_aux_2: 1.1110 (1.1062)  loss_vfl_aux_3: 0.6261 (0.6579)  loss_bbox_aux_3: 0.3459 (0.4031)  loss_giou_aux_3: 1.1121 (1.0986)  loss_vfl_aux_4: 0.6439 (0.6868)  loss_bbox_aux_4: 0.3378 (0.3985)  loss_giou_aux_4: 1.1129 (1.0933)  loss_vfl_aux_5: 0.5132 (0.5285)  loss_bbox_aux_5: 0.3711 (0.4288)  loss_giou_aux_5: 1.1650 (1.1535)  loss_vfl_dn_0: 0.3260 (0.3217)  loss_bbox_dn_0: 0.3965 (0.4210)  loss_giou_dn_0: 1.3197 (1.3265)  loss_vfl_dn_1: 0.3313 (0.3293)  loss_bbox_dn_1: 0.3879 (0.4134)  loss_giou_dn_1: 1.2923 (1.3104)  loss_vfl_dn_2: 0.3382 (0.3376)  loss_bbox_dn_2: 0.3844 (0.4091)  loss_giou_dn_2: 1.2841 (1.3044)  loss_vfl_dn_3: 0.3378 (0.3396)  loss_bbox_dn_3: 0.3821 (0.4046)  loss_giou_dn_3: 1.2865 (1.3020)  loss_vfl_dn_4: 0.3349 (0.3438)  loss_bbox_dn_4: 0.3802 (0.4024)  loss_giou_dn_4: 1.2829 (1.3014)  loss_vfl_dn_5: 0.3442 (0.3517)  loss_bbox_dn_5: 0.3781 (0.4008)  loss_giou_dn_5: 1.2771 (1.3009)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9335  data: 0.5702  max mem: 7772\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4147  data: 0.1098  max mem: 7772\n",
            "Test: Total time: 0:00:02 (0.4273 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.017\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.064\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306\n",
            "best_stat:  {'epoch': 1, 'coco_eval_bbox': 0.056553326114776356}\n",
            "Epoch: [2]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 24.9304 (24.9304)  loss_vfl: 0.7274 (0.7274)  loss_bbox: 0.2942 (0.2942)  loss_giou: 0.9327 (0.9327)  loss_vfl_aux_0: 0.6078 (0.6078)  loss_bbox_aux_0: 0.3297 (0.3297)  loss_giou_aux_0: 1.0036 (1.0036)  loss_vfl_aux_1: 0.6111 (0.6111)  loss_bbox_aux_1: 0.3283 (0.3283)  loss_giou_aux_1: 0.9837 (0.9837)  loss_vfl_aux_2: 0.6654 (0.6654)  loss_bbox_aux_2: 0.3097 (0.3097)  loss_giou_aux_2: 0.9669 (0.9669)  loss_vfl_aux_3: 0.6880 (0.6880)  loss_bbox_aux_3: 0.3133 (0.3133)  loss_giou_aux_3: 0.9590 (0.9590)  loss_vfl_aux_4: 0.6994 (0.6994)  loss_bbox_aux_4: 0.3002 (0.3002)  loss_giou_aux_4: 0.9430 (0.9430)  loss_vfl_aux_5: 0.5907 (0.5907)  loss_bbox_aux_5: 0.3378 (0.3378)  loss_giou_aux_5: 1.0227 (1.0227)  loss_vfl_dn_0: 0.3346 (0.3346)  loss_bbox_dn_0: 0.3506 (0.3506)  loss_giou_dn_0: 1.2511 (1.2511)  loss_vfl_dn_1: 0.3491 (0.3491)  loss_bbox_dn_1: 0.3353 (0.3353)  loss_giou_dn_1: 1.2096 (1.2096)  loss_vfl_dn_2: 0.3550 (0.3550)  loss_bbox_dn_2: 0.3280 (0.3280)  loss_giou_dn_2: 1.1938 (1.1938)  loss_vfl_dn_3: 0.3563 (0.3563)  loss_bbox_dn_3: 0.3218 (0.3218)  loss_giou_dn_3: 1.1868 (1.1868)  loss_vfl_dn_4: 0.3688 (0.3688)  loss_bbox_dn_4: 0.3186 (0.3186)  loss_giou_dn_4: 1.1854 (1.1854)  loss_vfl_dn_5: 0.3711 (0.3711)  loss_bbox_dn_5: 0.3169 (0.3169)  loss_giou_dn_5: 1.1828 (1.1828)  time: 0.9845  data: 0.6005  max mem: 7772\n",
            "Epoch: [2]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 25.8044 (26.6120)  loss_vfl: 0.8000 (0.7764)  loss_bbox: 0.2790 (0.3557)  loss_giou: 0.9196 (0.9894)  loss_vfl_aux_0: 0.6217 (0.5880)  loss_bbox_aux_0: 0.3516 (0.4156)  loss_giou_aux_0: 1.0341 (1.0740)  loss_vfl_aux_1: 0.6638 (0.6403)  loss_bbox_aux_1: 0.3424 (0.3995)  loss_giou_aux_1: 1.0056 (1.0492)  loss_vfl_aux_2: 0.6972 (0.6833)  loss_bbox_aux_2: 0.3000 (0.3807)  loss_giou_aux_2: 0.9843 (1.0296)  loss_vfl_aux_3: 0.7472 (0.7233)  loss_bbox_aux_3: 0.2861 (0.3712)  loss_giou_aux_3: 0.9510 (1.0107)  loss_vfl_aux_4: 0.7891 (0.7630)  loss_bbox_aux_4: 0.2796 (0.3614)  loss_giou_aux_4: 0.9367 (0.9996)  loss_vfl_aux_5: 0.5884 (0.5638)  loss_bbox_aux_5: 0.3553 (0.4302)  loss_giou_aux_5: 1.0727 (1.1127)  loss_vfl_dn_0: 0.3405 (0.3356)  loss_bbox_dn_0: 0.4136 (0.4218)  loss_giou_dn_0: 1.2619 (1.2684)  loss_vfl_dn_1: 0.3480 (0.3414)  loss_bbox_dn_1: 0.3981 (0.4072)  loss_giou_dn_1: 1.2310 (1.2453)  loss_vfl_dn_2: 0.3524 (0.3463)  loss_bbox_dn_2: 0.3927 (0.3998)  loss_giou_dn_2: 1.2077 (1.2328)  loss_vfl_dn_3: 0.3573 (0.3499)  loss_bbox_dn_3: 0.3852 (0.3930)  loss_giou_dn_3: 1.1867 (1.2243)  loss_vfl_dn_4: 0.3601 (0.3581)  loss_bbox_dn_4: 0.3790 (0.3896)  loss_giou_dn_4: 1.1732 (1.2184)  loss_vfl_dn_5: 0.3640 (0.3601)  loss_bbox_dn_5: 0.3728 (0.3876)  loss_giou_dn_5: 1.1681 (1.2147)  time: 0.3318  data: 0.0144  max mem: 7779\n",
            "Epoch: [2] Total time: 0:00:11 (0.3491 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 25.8044 (26.6120)  loss_vfl: 0.8000 (0.7764)  loss_bbox: 0.2790 (0.3557)  loss_giou: 0.9196 (0.9894)  loss_vfl_aux_0: 0.6217 (0.5880)  loss_bbox_aux_0: 0.3516 (0.4156)  loss_giou_aux_0: 1.0341 (1.0740)  loss_vfl_aux_1: 0.6638 (0.6403)  loss_bbox_aux_1: 0.3424 (0.3995)  loss_giou_aux_1: 1.0056 (1.0492)  loss_vfl_aux_2: 0.6972 (0.6833)  loss_bbox_aux_2: 0.3000 (0.3807)  loss_giou_aux_2: 0.9843 (1.0296)  loss_vfl_aux_3: 0.7472 (0.7233)  loss_bbox_aux_3: 0.2861 (0.3712)  loss_giou_aux_3: 0.9510 (1.0107)  loss_vfl_aux_4: 0.7891 (0.7630)  loss_bbox_aux_4: 0.2796 (0.3614)  loss_giou_aux_4: 0.9367 (0.9996)  loss_vfl_aux_5: 0.5884 (0.5638)  loss_bbox_aux_5: 0.3553 (0.4302)  loss_giou_aux_5: 1.0727 (1.1127)  loss_vfl_dn_0: 0.3405 (0.3356)  loss_bbox_dn_0: 0.4136 (0.4218)  loss_giou_dn_0: 1.2619 (1.2684)  loss_vfl_dn_1: 0.3480 (0.3414)  loss_bbox_dn_1: 0.3981 (0.4072)  loss_giou_dn_1: 1.2310 (1.2453)  loss_vfl_dn_2: 0.3524 (0.3463)  loss_bbox_dn_2: 0.3927 (0.3998)  loss_giou_dn_2: 1.2077 (1.2328)  loss_vfl_dn_3: 0.3573 (0.3499)  loss_bbox_dn_3: 0.3852 (0.3930)  loss_giou_dn_3: 1.1867 (1.2243)  loss_vfl_dn_4: 0.3601 (0.3581)  loss_bbox_dn_4: 0.3790 (0.3896)  loss_giou_dn_4: 1.1732 (1.2184)  loss_vfl_dn_5: 0.3640 (0.3601)  loss_bbox_dn_5: 0.3728 (0.3876)  loss_giou_dn_5: 1.1681 (1.2147)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8849  data: 0.5577  max mem: 7779\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3943  data: 0.1118  max mem: 7779\n",
            "Test: Total time: 0:00:02 (0.4074 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.228\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.184\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.139\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
            "best_stat:  {'epoch': 2, 'coco_eval_bbox': 0.09886680878453323}\n",
            "Epoch: [3]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 29.1195 (29.1195)  loss_vfl: 0.9455 (0.9455)  loss_bbox: 0.4351 (0.4351)  loss_giou: 0.9016 (0.9016)  loss_vfl_aux_0: 0.6800 (0.6800)  loss_bbox_aux_0: 0.5833 (0.5833)  loss_giou_aux_0: 0.9993 (0.9993)  loss_vfl_aux_1: 0.8347 (0.8347)  loss_bbox_aux_1: 0.5543 (0.5543)  loss_giou_aux_1: 0.9773 (0.9773)  loss_vfl_aux_2: 0.9042 (0.9042)  loss_bbox_aux_2: 0.5093 (0.5093)  loss_giou_aux_2: 0.9263 (0.9263)  loss_vfl_aux_3: 0.9929 (0.9929)  loss_bbox_aux_3: 0.4791 (0.4791)  loss_giou_aux_3: 0.9084 (0.9084)  loss_vfl_aux_4: 1.0532 (1.0532)  loss_bbox_aux_4: 0.4363 (0.4363)  loss_giou_aux_4: 0.9040 (0.9040)  loss_vfl_aux_5: 0.5654 (0.5654)  loss_bbox_aux_5: 0.6056 (0.6056)  loss_giou_aux_5: 1.0707 (1.0707)  loss_vfl_dn_0: 0.3422 (0.3422)  loss_bbox_dn_0: 0.6391 (0.6391)  loss_giou_dn_0: 1.2575 (1.2575)  loss_vfl_dn_1: 0.3510 (0.3510)  loss_bbox_dn_1: 0.6093 (0.6093)  loss_giou_dn_1: 1.2158 (1.2158)  loss_vfl_dn_2: 0.3535 (0.3535)  loss_bbox_dn_2: 0.5923 (0.5923)  loss_giou_dn_2: 1.1874 (1.1874)  loss_vfl_dn_3: 0.3640 (0.3640)  loss_bbox_dn_3: 0.5800 (0.5800)  loss_giou_dn_3: 1.1661 (1.1661)  loss_vfl_dn_4: 0.3721 (0.3721)  loss_bbox_dn_4: 0.5747 (0.5747)  loss_giou_dn_4: 1.1533 (1.1533)  loss_vfl_dn_5: 0.3841 (0.3841)  loss_bbox_dn_5: 0.5701 (0.5701)  loss_giou_dn_5: 1.1408 (1.1408)  time: 0.9677  data: 0.5440  max mem: 7779\n",
            "Epoch: [3]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 24.7863 (25.8411)  loss_vfl: 0.7671 (0.8087)  loss_bbox: 0.2526 (0.3007)  loss_giou: 0.9447 (0.9625)  loss_vfl_aux_0: 0.5633 (0.5600)  loss_bbox_aux_0: 0.3051 (0.3833)  loss_giou_aux_0: 1.0180 (1.0752)  loss_vfl_aux_1: 0.6190 (0.6431)  loss_bbox_aux_1: 0.2737 (0.3500)  loss_giou_aux_1: 1.0059 (1.0239)  loss_vfl_aux_2: 0.7173 (0.7125)  loss_bbox_aux_2: 0.2640 (0.3304)  loss_giou_aux_2: 0.9665 (0.9969)  loss_vfl_aux_3: 0.7775 (0.7598)  loss_bbox_aux_3: 0.2624 (0.3160)  loss_giou_aux_3: 0.9540 (0.9763)  loss_vfl_aux_4: 0.7346 (0.7877)  loss_bbox_aux_4: 0.2510 (0.3067)  loss_giou_aux_4: 0.9491 (0.9687)  loss_vfl_aux_5: 0.5366 (0.5151)  loss_bbox_aux_5: 0.3416 (0.4191)  loss_giou_aux_5: 1.0861 (1.1422)  loss_vfl_dn_0: 0.3407 (0.3403)  loss_bbox_dn_0: 0.3659 (0.3810)  loss_giou_dn_0: 1.2345 (1.2634)  loss_vfl_dn_1: 0.3573 (0.3449)  loss_bbox_dn_1: 0.3419 (0.3617)  loss_giou_dn_1: 1.1849 (1.2316)  loss_vfl_dn_2: 0.3643 (0.3519)  loss_bbox_dn_2: 0.3327 (0.3530)  loss_giou_dn_2: 1.1460 (1.2098)  loss_vfl_dn_3: 0.3769 (0.3590)  loss_bbox_dn_3: 0.3231 (0.3461)  loss_giou_dn_3: 1.1186 (1.1893)  loss_vfl_dn_4: 0.3815 (0.3649)  loss_bbox_dn_4: 0.3216 (0.3444)  loss_giou_dn_4: 1.1080 (1.1785)  loss_vfl_dn_5: 0.3797 (0.3660)  loss_bbox_dn_5: 0.3242 (0.3444)  loss_giou_dn_5: 1.0981 (1.1720)  time: 0.3190  data: 0.0139  max mem: 7779\n",
            "Epoch: [3] Total time: 0:00:11 (0.3439 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 24.7863 (25.8411)  loss_vfl: 0.7671 (0.8087)  loss_bbox: 0.2526 (0.3007)  loss_giou: 0.9447 (0.9625)  loss_vfl_aux_0: 0.5633 (0.5600)  loss_bbox_aux_0: 0.3051 (0.3833)  loss_giou_aux_0: 1.0180 (1.0752)  loss_vfl_aux_1: 0.6190 (0.6431)  loss_bbox_aux_1: 0.2737 (0.3500)  loss_giou_aux_1: 1.0059 (1.0239)  loss_vfl_aux_2: 0.7173 (0.7125)  loss_bbox_aux_2: 0.2640 (0.3304)  loss_giou_aux_2: 0.9665 (0.9969)  loss_vfl_aux_3: 0.7775 (0.7598)  loss_bbox_aux_3: 0.2624 (0.3160)  loss_giou_aux_3: 0.9540 (0.9763)  loss_vfl_aux_4: 0.7346 (0.7877)  loss_bbox_aux_4: 0.2510 (0.3067)  loss_giou_aux_4: 0.9491 (0.9687)  loss_vfl_aux_5: 0.5366 (0.5151)  loss_bbox_aux_5: 0.3416 (0.4191)  loss_giou_aux_5: 1.0861 (1.1422)  loss_vfl_dn_0: 0.3407 (0.3403)  loss_bbox_dn_0: 0.3659 (0.3810)  loss_giou_dn_0: 1.2345 (1.2634)  loss_vfl_dn_1: 0.3573 (0.3449)  loss_bbox_dn_1: 0.3419 (0.3617)  loss_giou_dn_1: 1.1849 (1.2316)  loss_vfl_dn_2: 0.3643 (0.3519)  loss_bbox_dn_2: 0.3327 (0.3530)  loss_giou_dn_2: 1.1460 (1.2098)  loss_vfl_dn_3: 0.3769 (0.3590)  loss_bbox_dn_3: 0.3231 (0.3461)  loss_giou_dn_3: 1.1186 (1.1893)  loss_vfl_dn_4: 0.3815 (0.3649)  loss_bbox_dn_4: 0.3216 (0.3444)  loss_giou_dn_4: 1.1080 (1.1785)  loss_vfl_dn_5: 0.3797 (0.3660)  loss_bbox_dn_5: 0.3242 (0.3444)  loss_giou_dn_5: 1.0981 (1.1720)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8842  data: 0.5415  max mem: 7779\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4063  data: 0.1166  max mem: 7779\n",
            "Test: Total time: 0:00:02 (0.4186 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.132\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\n",
            "best_stat:  {'epoch': 2, 'coco_eval_bbox': 0.09886680878453323}\n",
            "Epoch: [4]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 25.6851 (25.6851)  loss_vfl: 1.0626 (1.0626)  loss_bbox: 0.3056 (0.3056)  loss_giou: 0.6400 (0.6400)  loss_vfl_aux_0: 0.6953 (0.6953)  loss_bbox_aux_0: 0.4814 (0.4814)  loss_giou_aux_0: 0.8410 (0.8410)  loss_vfl_aux_1: 0.8115 (0.8115)  loss_bbox_aux_1: 0.4502 (0.4502)  loss_giou_aux_1: 0.8036 (0.8036)  loss_vfl_aux_2: 0.8419 (0.8419)  loss_bbox_aux_2: 0.3786 (0.3786)  loss_giou_aux_2: 0.7567 (0.7567)  loss_vfl_aux_3: 0.8961 (0.8961)  loss_bbox_aux_3: 0.3479 (0.3479)  loss_giou_aux_3: 0.7030 (0.7030)  loss_vfl_aux_4: 1.0287 (1.0287)  loss_bbox_aux_4: 0.3169 (0.3169)  loss_giou_aux_4: 0.6508 (0.6508)  loss_vfl_aux_5: 0.6368 (0.6368)  loss_bbox_aux_5: 0.5108 (0.5108)  loss_giou_aux_5: 0.9424 (0.9424)  loss_vfl_dn_0: 0.3738 (0.3738)  loss_bbox_dn_0: 0.5979 (0.5979)  loss_giou_dn_0: 1.1647 (1.1647)  loss_vfl_dn_1: 0.4083 (0.4083)  loss_bbox_dn_1: 0.5558 (0.5558)  loss_giou_dn_1: 1.0526 (1.0526)  loss_vfl_dn_2: 0.4193 (0.4193)  loss_bbox_dn_2: 0.5314 (0.5314)  loss_giou_dn_2: 0.9772 (0.9772)  loss_vfl_dn_3: 0.4345 (0.4345)  loss_bbox_dn_3: 0.5137 (0.5137)  loss_giou_dn_3: 0.9143 (0.9143)  loss_vfl_dn_4: 0.4459 (0.4459)  loss_bbox_dn_4: 0.5065 (0.5065)  loss_giou_dn_4: 0.8772 (0.8772)  loss_vfl_dn_5: 0.4476 (0.4476)  loss_bbox_dn_5: 0.5060 (0.5060)  loss_giou_dn_5: 0.8566 (0.8566)  time: 0.9633  data: 0.5948  max mem: 7779\n",
            "Epoch: [4]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 24.0552 (24.8064)  loss_vfl: 0.8997 (0.8879)  loss_bbox: 0.2166 (0.2467)  loss_giou: 0.8589 (0.8449)  loss_vfl_aux_0: 0.6304 (0.6357)  loss_bbox_aux_0: 0.2305 (0.3265)  loss_giou_aux_0: 0.9706 (0.9728)  loss_vfl_aux_1: 0.7533 (0.7343)  loss_bbox_aux_1: 0.2266 (0.2916)  loss_giou_aux_1: 0.9019 (0.9073)  loss_vfl_aux_2: 0.8132 (0.7912)  loss_bbox_aux_2: 0.2226 (0.2700)  loss_giou_aux_2: 0.8663 (0.8747)  loss_vfl_aux_3: 0.8155 (0.8328)  loss_bbox_aux_3: 0.2158 (0.2580)  loss_giou_aux_3: 0.8654 (0.8567)  loss_vfl_aux_4: 0.8860 (0.8771)  loss_bbox_aux_4: 0.2106 (0.2502)  loss_giou_aux_4: 0.8517 (0.8471)  loss_vfl_aux_5: 0.5428 (0.5476)  loss_bbox_aux_5: 0.2834 (0.3803)  loss_giou_aux_5: 1.0925 (1.0837)  loss_vfl_dn_0: 0.3488 (0.3515)  loss_bbox_dn_0: 0.2874 (0.3766)  loss_giou_dn_0: 1.2274 (1.2299)  loss_vfl_dn_1: 0.3703 (0.3672)  loss_bbox_dn_1: 0.2564 (0.3506)  loss_giou_dn_1: 1.1462 (1.1555)  loss_vfl_dn_2: 0.3887 (0.3802)  loss_bbox_dn_2: 0.2524 (0.3425)  loss_giou_dn_2: 1.1016 (1.1137)  loss_vfl_dn_3: 0.3871 (0.3881)  loss_bbox_dn_3: 0.2514 (0.3371)  loss_giou_dn_3: 1.0703 (1.0877)  loss_vfl_dn_4: 0.3960 (0.3949)  loss_bbox_dn_4: 0.2483 (0.3366)  loss_giou_dn_4: 1.0584 (1.0756)  loss_vfl_dn_5: 0.3957 (0.3943)  loss_bbox_dn_5: 0.2471 (0.3373)  loss_giou_dn_5: 1.0556 (1.0700)  time: 0.3187  data: 0.0139  max mem: 7779\n",
            "Epoch: [4] Total time: 0:00:11 (0.3427 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 24.0552 (24.8064)  loss_vfl: 0.8997 (0.8879)  loss_bbox: 0.2166 (0.2467)  loss_giou: 0.8589 (0.8449)  loss_vfl_aux_0: 0.6304 (0.6357)  loss_bbox_aux_0: 0.2305 (0.3265)  loss_giou_aux_0: 0.9706 (0.9728)  loss_vfl_aux_1: 0.7533 (0.7343)  loss_bbox_aux_1: 0.2266 (0.2916)  loss_giou_aux_1: 0.9019 (0.9073)  loss_vfl_aux_2: 0.8132 (0.7912)  loss_bbox_aux_2: 0.2226 (0.2700)  loss_giou_aux_2: 0.8663 (0.8747)  loss_vfl_aux_3: 0.8155 (0.8328)  loss_bbox_aux_3: 0.2158 (0.2580)  loss_giou_aux_3: 0.8654 (0.8567)  loss_vfl_aux_4: 0.8860 (0.8771)  loss_bbox_aux_4: 0.2106 (0.2502)  loss_giou_aux_4: 0.8517 (0.8471)  loss_vfl_aux_5: 0.5428 (0.5476)  loss_bbox_aux_5: 0.2834 (0.3803)  loss_giou_aux_5: 1.0925 (1.0837)  loss_vfl_dn_0: 0.3488 (0.3515)  loss_bbox_dn_0: 0.2874 (0.3766)  loss_giou_dn_0: 1.2274 (1.2299)  loss_vfl_dn_1: 0.3703 (0.3672)  loss_bbox_dn_1: 0.2564 (0.3506)  loss_giou_dn_1: 1.1462 (1.1555)  loss_vfl_dn_2: 0.3887 (0.3802)  loss_bbox_dn_2: 0.2524 (0.3425)  loss_giou_dn_2: 1.1016 (1.1137)  loss_vfl_dn_3: 0.3871 (0.3881)  loss_bbox_dn_3: 0.2514 (0.3371)  loss_giou_dn_3: 1.0703 (1.0877)  loss_vfl_dn_4: 0.3960 (0.3949)  loss_bbox_dn_4: 0.2483 (0.3366)  loss_giou_dn_4: 1.0584 (1.0756)  loss_vfl_dn_5: 0.3957 (0.3943)  loss_bbox_dn_5: 0.2471 (0.3373)  loss_giou_dn_5: 1.0556 (1.0700)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9192  data: 0.5918  max mem: 7779\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4462  data: 0.1100  max mem: 7779\n",
            "Test: Total time: 0:00:02 (0.4596 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.076\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.146\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.222\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
            "best_stat:  {'epoch': 2, 'coco_eval_bbox': 0.09886680878453323}\n",
            "Epoch: [5]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 27.1503 (27.1503)  loss_vfl: 1.0289 (1.0289)  loss_bbox: 0.3955 (0.3955)  loss_giou: 0.8581 (0.8581)  loss_vfl_aux_0: 0.7598 (0.7598)  loss_bbox_aux_0: 0.5024 (0.5024)  loss_giou_aux_0: 0.9204 (0.9204)  loss_vfl_aux_1: 0.8411 (0.8411)  loss_bbox_aux_1: 0.4470 (0.4470)  loss_giou_aux_1: 0.8949 (0.8949)  loss_vfl_aux_2: 0.8807 (0.8807)  loss_bbox_aux_2: 0.4249 (0.4249)  loss_giou_aux_2: 0.8907 (0.8907)  loss_vfl_aux_3: 0.9635 (0.9635)  loss_bbox_aux_3: 0.4125 (0.4125)  loss_giou_aux_3: 0.8715 (0.8715)  loss_vfl_aux_4: 1.0341 (1.0341)  loss_bbox_aux_4: 0.4091 (0.4091)  loss_giou_aux_4: 0.8636 (0.8636)  loss_vfl_aux_5: 0.7128 (0.7128)  loss_bbox_aux_5: 0.5502 (0.5502)  loss_giou_aux_5: 0.9660 (0.9660)  loss_vfl_dn_0: 0.3518 (0.3518)  loss_bbox_dn_0: 0.5251 (0.5251)  loss_giou_dn_0: 1.2043 (1.2043)  loss_vfl_dn_1: 0.3827 (0.3827)  loss_bbox_dn_1: 0.4799 (0.4799)  loss_giou_dn_1: 1.0819 (1.0819)  loss_vfl_dn_2: 0.3942 (0.3942)  loss_bbox_dn_2: 0.4677 (0.4677)  loss_giou_dn_2: 1.0403 (1.0403)  loss_vfl_dn_3: 0.3977 (0.3977)  loss_bbox_dn_3: 0.4622 (0.4622)  loss_giou_dn_3: 1.0108 (1.0108)  loss_vfl_dn_4: 0.4016 (0.4016)  loss_bbox_dn_4: 0.4640 (0.4640)  loss_giou_dn_4: 0.9987 (0.9987)  loss_vfl_dn_5: 0.3973 (0.3973)  loss_bbox_dn_5: 0.4660 (0.4660)  loss_giou_dn_5: 0.9964 (0.9964)  time: 0.9555  data: 0.5263  max mem: 7779\n",
            "Epoch: [5]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 23.9963 (24.2003)  loss_vfl: 0.9530 (0.9302)  loss_bbox: 0.2122 (0.2394)  loss_giou: 0.7610 (0.7983)  loss_vfl_aux_0: 0.7009 (0.6890)  loss_bbox_aux_0: 0.2656 (0.3087)  loss_giou_aux_0: 0.8570 (0.9001)  loss_vfl_aux_1: 0.8046 (0.7695)  loss_bbox_aux_1: 0.2458 (0.2759)  loss_giou_aux_1: 0.8014 (0.8544)  loss_vfl_aux_2: 0.8394 (0.8175)  loss_bbox_aux_2: 0.2339 (0.2633)  loss_giou_aux_2: 0.7785 (0.8328)  loss_vfl_aux_3: 0.8529 (0.8674)  loss_bbox_aux_3: 0.2152 (0.2520)  loss_giou_aux_3: 0.7809 (0.8159)  loss_vfl_aux_4: 0.9043 (0.9129)  loss_bbox_aux_4: 0.2078 (0.2440)  loss_giou_aux_4: 0.7664 (0.8042)  loss_vfl_aux_5: 0.6101 (0.6053)  loss_bbox_aux_5: 0.3263 (0.3681)  loss_giou_aux_5: 0.9939 (1.0132)  loss_vfl_dn_0: 0.3693 (0.3671)  loss_bbox_dn_0: 0.3446 (0.3848)  loss_giou_dn_0: 1.1577 (1.1680)  loss_vfl_dn_1: 0.3967 (0.3921)  loss_bbox_dn_1: 0.3138 (0.3471)  loss_giou_dn_1: 1.0171 (1.0563)  loss_vfl_dn_2: 0.4057 (0.4039)  loss_bbox_dn_2: 0.3085 (0.3380)  loss_giou_dn_2: 0.9779 (1.0118)  loss_vfl_dn_3: 0.4100 (0.4097)  loss_bbox_dn_3: 0.3028 (0.3332)  loss_giou_dn_3: 0.9526 (0.9868)  loss_vfl_dn_4: 0.4209 (0.4155)  loss_bbox_dn_4: 0.3019 (0.3319)  loss_giou_dn_4: 0.9339 (0.9757)  loss_vfl_dn_5: 0.4199 (0.4154)  loss_bbox_dn_5: 0.3001 (0.3311)  loss_giou_dn_5: 0.9337 (0.9697)  time: 0.3121  data: 0.0136  max mem: 7779\n",
            "Epoch: [5] Total time: 0:00:11 (0.3375 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 23.9963 (24.2003)  loss_vfl: 0.9530 (0.9302)  loss_bbox: 0.2122 (0.2394)  loss_giou: 0.7610 (0.7983)  loss_vfl_aux_0: 0.7009 (0.6890)  loss_bbox_aux_0: 0.2656 (0.3087)  loss_giou_aux_0: 0.8570 (0.9001)  loss_vfl_aux_1: 0.8046 (0.7695)  loss_bbox_aux_1: 0.2458 (0.2759)  loss_giou_aux_1: 0.8014 (0.8544)  loss_vfl_aux_2: 0.8394 (0.8175)  loss_bbox_aux_2: 0.2339 (0.2633)  loss_giou_aux_2: 0.7785 (0.8328)  loss_vfl_aux_3: 0.8529 (0.8674)  loss_bbox_aux_3: 0.2152 (0.2520)  loss_giou_aux_3: 0.7809 (0.8159)  loss_vfl_aux_4: 0.9043 (0.9129)  loss_bbox_aux_4: 0.2078 (0.2440)  loss_giou_aux_4: 0.7664 (0.8042)  loss_vfl_aux_5: 0.6101 (0.6053)  loss_bbox_aux_5: 0.3263 (0.3681)  loss_giou_aux_5: 0.9939 (1.0132)  loss_vfl_dn_0: 0.3693 (0.3671)  loss_bbox_dn_0: 0.3446 (0.3848)  loss_giou_dn_0: 1.1577 (1.1680)  loss_vfl_dn_1: 0.3967 (0.3921)  loss_bbox_dn_1: 0.3138 (0.3471)  loss_giou_dn_1: 1.0171 (1.0563)  loss_vfl_dn_2: 0.4057 (0.4039)  loss_bbox_dn_2: 0.3085 (0.3380)  loss_giou_dn_2: 0.9779 (1.0118)  loss_vfl_dn_3: 0.4100 (0.4097)  loss_bbox_dn_3: 0.3028 (0.3332)  loss_giou_dn_3: 0.9526 (0.9868)  loss_vfl_dn_4: 0.4209 (0.4155)  loss_bbox_dn_4: 0.3019 (0.3319)  loss_giou_dn_4: 0.9339 (0.9757)  loss_vfl_dn_5: 0.4199 (0.4154)  loss_bbox_dn_5: 0.3001 (0.3311)  loss_giou_dn_5: 0.9337 (0.9697)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9508  data: 0.6102  max mem: 7779\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4097  data: 0.1136  max mem: 7779\n",
            "Test: Total time: 0:00:02 (0.4223 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.145\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.086\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.575\n",
            "best_stat:  {'epoch': 2, 'coco_eval_bbox': 0.09886680878453323}\n",
            "Epoch: [6]  [ 0/33]  eta: 0:00:40  lr: 0.000001  loss: 23.0479 (23.0479)  loss_vfl: 0.8676 (0.8676)  loss_bbox: 0.1645 (0.1645)  loss_giou: 0.8024 (0.8024)  loss_vfl_aux_0: 0.7484 (0.7484)  loss_bbox_aux_0: 0.1853 (0.1853)  loss_giou_aux_0: 0.8938 (0.8938)  loss_vfl_aux_1: 0.8010 (0.8010)  loss_bbox_aux_1: 0.1693 (0.1693)  loss_giou_aux_1: 0.8420 (0.8420)  loss_vfl_aux_2: 0.8724 (0.8724)  loss_bbox_aux_2: 0.1687 (0.1687)  loss_giou_aux_2: 0.8169 (0.8169)  loss_vfl_aux_3: 0.9017 (0.9017)  loss_bbox_aux_3: 0.1641 (0.1641)  loss_giou_aux_3: 0.8132 (0.8132)  loss_vfl_aux_4: 0.8994 (0.8994)  loss_bbox_aux_4: 0.1661 (0.1661)  loss_giou_aux_4: 0.8152 (0.8152)  loss_vfl_aux_5: 0.7609 (0.7609)  loss_bbox_aux_5: 0.2488 (0.2488)  loss_giou_aux_5: 0.9715 (0.9715)  loss_vfl_dn_0: 0.3675 (0.3675)  loss_bbox_dn_0: 0.2724 (0.2724)  loss_giou_dn_0: 1.1654 (1.1654)  loss_vfl_dn_1: 0.3893 (0.3893)  loss_bbox_dn_1: 0.2494 (0.2494)  loss_giou_dn_1: 1.0583 (1.0583)  loss_vfl_dn_2: 0.4049 (0.4049)  loss_bbox_dn_2: 0.2382 (0.2382)  loss_giou_dn_2: 1.0051 (1.0051)  loss_vfl_dn_3: 0.4055 (0.4055)  loss_bbox_dn_3: 0.2329 (0.2329)  loss_giou_dn_3: 0.9832 (0.9832)  loss_vfl_dn_4: 0.4077 (0.4077)  loss_bbox_dn_4: 0.2301 (0.2301)  loss_giou_dn_4: 0.9690 (0.9690)  loss_vfl_dn_5: 0.4114 (0.4114)  loss_bbox_dn_5: 0.2272 (0.2272)  loss_giou_dn_5: 0.9573 (0.9573)  time: 1.2285  data: 0.5205  max mem: 7779\n",
            "Epoch: [6]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 23.3129 (24.1609)  loss_vfl: 0.9256 (0.9665)  loss_bbox: 0.2122 (0.2373)  loss_giou: 0.7512 (0.7584)  loss_vfl_aux_0: 0.7247 (0.7212)  loss_bbox_aux_0: 0.2666 (0.3092)  loss_giou_aux_0: 0.8491 (0.8711)  loss_vfl_aux_1: 0.7643 (0.8010)  loss_bbox_aux_1: 0.2491 (0.2749)  loss_giou_aux_1: 0.8110 (0.8123)  loss_vfl_aux_2: 0.8018 (0.8505)  loss_bbox_aux_2: 0.2391 (0.2601)  loss_giou_aux_2: 0.7913 (0.7874)  loss_vfl_aux_3: 0.8618 (0.8958)  loss_bbox_aux_3: 0.2250 (0.2507)  loss_giou_aux_3: 0.7738 (0.7760)  loss_vfl_aux_4: 0.9121 (0.9417)  loss_bbox_aux_4: 0.2128 (0.2440)  loss_giou_aux_4: 0.7687 (0.7651)  loss_vfl_aux_5: 0.6033 (0.6091)  loss_bbox_aux_5: 0.3254 (0.3833)  loss_giou_aux_5: 0.9559 (1.0048)  loss_vfl_dn_0: 0.3811 (0.3761)  loss_bbox_dn_0: 0.3159 (0.3975)  loss_giou_dn_0: 1.1151 (1.1434)  loss_vfl_dn_1: 0.4015 (0.3987)  loss_bbox_dn_1: 0.2872 (0.3650)  loss_giou_dn_1: 1.0037 (1.0323)  loss_vfl_dn_2: 0.4130 (0.4081)  loss_bbox_dn_2: 0.2923 (0.3577)  loss_giou_dn_2: 0.9618 (0.9888)  loss_vfl_dn_3: 0.4144 (0.4116)  loss_bbox_dn_3: 0.2948 (0.3537)  loss_giou_dn_3: 0.9399 (0.9661)  loss_vfl_dn_4: 0.4171 (0.4157)  loss_bbox_dn_4: 0.3008 (0.3525)  loss_giou_dn_4: 0.9311 (0.9559)  loss_vfl_dn_5: 0.4155 (0.4153)  loss_bbox_dn_5: 0.3040 (0.3519)  loss_giou_dn_5: 0.9269 (0.9502)  time: 0.3220  data: 0.0144  max mem: 7780\n",
            "Epoch: [6] Total time: 0:00:11 (0.3529 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 23.3129 (24.1609)  loss_vfl: 0.9256 (0.9665)  loss_bbox: 0.2122 (0.2373)  loss_giou: 0.7512 (0.7584)  loss_vfl_aux_0: 0.7247 (0.7212)  loss_bbox_aux_0: 0.2666 (0.3092)  loss_giou_aux_0: 0.8491 (0.8711)  loss_vfl_aux_1: 0.7643 (0.8010)  loss_bbox_aux_1: 0.2491 (0.2749)  loss_giou_aux_1: 0.8110 (0.8123)  loss_vfl_aux_2: 0.8018 (0.8505)  loss_bbox_aux_2: 0.2391 (0.2601)  loss_giou_aux_2: 0.7913 (0.7874)  loss_vfl_aux_3: 0.8618 (0.8958)  loss_bbox_aux_3: 0.2250 (0.2507)  loss_giou_aux_3: 0.7738 (0.7760)  loss_vfl_aux_4: 0.9121 (0.9417)  loss_bbox_aux_4: 0.2128 (0.2440)  loss_giou_aux_4: 0.7687 (0.7651)  loss_vfl_aux_5: 0.6033 (0.6091)  loss_bbox_aux_5: 0.3254 (0.3833)  loss_giou_aux_5: 0.9559 (1.0048)  loss_vfl_dn_0: 0.3811 (0.3761)  loss_bbox_dn_0: 0.3159 (0.3975)  loss_giou_dn_0: 1.1151 (1.1434)  loss_vfl_dn_1: 0.4015 (0.3987)  loss_bbox_dn_1: 0.2872 (0.3650)  loss_giou_dn_1: 1.0037 (1.0323)  loss_vfl_dn_2: 0.4130 (0.4081)  loss_bbox_dn_2: 0.2923 (0.3577)  loss_giou_dn_2: 0.9618 (0.9888)  loss_vfl_dn_3: 0.4144 (0.4116)  loss_bbox_dn_3: 0.2948 (0.3537)  loss_giou_dn_3: 0.9399 (0.9661)  loss_vfl_dn_4: 0.4171 (0.4157)  loss_bbox_dn_4: 0.3008 (0.3525)  loss_giou_dn_4: 0.9311 (0.9559)  loss_vfl_dn_5: 0.4155 (0.4153)  loss_bbox_dn_5: 0.3040 (0.3519)  loss_giou_dn_5: 0.9269 (0.9502)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9084  data: 0.5742  max mem: 7780\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3933  data: 0.1083  max mem: 7780\n",
            "Test: Total time: 0:00:02 (0.4072 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n",
            "best_stat:  {'epoch': 2, 'coco_eval_bbox': 0.09886680878453323}\n",
            "Epoch: [7]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 21.6013 (21.6013)  loss_vfl: 0.9777 (0.9777)  loss_bbox: 0.1497 (0.1497)  loss_giou: 0.6948 (0.6948)  loss_vfl_aux_0: 0.6436 (0.6436)  loss_bbox_aux_0: 0.2290 (0.2290)  loss_giou_aux_0: 0.8511 (0.8511)  loss_vfl_aux_1: 0.7784 (0.7784)  loss_bbox_aux_1: 0.1844 (0.1844)  loss_giou_aux_1: 0.7742 (0.7742)  loss_vfl_aux_2: 0.8423 (0.8423)  loss_bbox_aux_2: 0.1680 (0.1680)  loss_giou_aux_2: 0.7325 (0.7325)  loss_vfl_aux_3: 0.8293 (0.8293)  loss_bbox_aux_3: 0.1642 (0.1642)  loss_giou_aux_3: 0.7291 (0.7291)  loss_vfl_aux_4: 0.9082 (0.9082)  loss_bbox_aux_4: 0.1530 (0.1530)  loss_giou_aux_4: 0.7010 (0.7010)  loss_vfl_aux_5: 0.5226 (0.5226)  loss_bbox_aux_5: 0.2519 (0.2519)  loss_giou_aux_5: 1.0017 (1.0017)  loss_vfl_dn_0: 0.3985 (0.3985)  loss_bbox_dn_0: 0.2892 (0.2892)  loss_giou_dn_0: 1.0492 (1.0492)  loss_vfl_dn_1: 0.4180 (0.4180)  loss_bbox_dn_1: 0.2443 (0.2443)  loss_giou_dn_1: 0.9243 (0.9243)  loss_vfl_dn_2: 0.4291 (0.4291)  loss_bbox_dn_2: 0.2294 (0.2294)  loss_giou_dn_2: 0.8691 (0.8691)  loss_vfl_dn_3: 0.4375 (0.4375)  loss_bbox_dn_3: 0.2205 (0.2205)  loss_giou_dn_3: 0.8431 (0.8431)  loss_vfl_dn_4: 0.4415 (0.4415)  loss_bbox_dn_4: 0.2150 (0.2150)  loss_giou_dn_4: 0.8258 (0.8258)  loss_vfl_dn_5: 0.4471 (0.4471)  loss_bbox_dn_5: 0.2117 (0.2117)  loss_giou_dn_5: 0.8213 (0.8213)  time: 1.0667  data: 0.7028  max mem: 7780\n",
            "Epoch: [7]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 23.3755 (23.4409)  loss_vfl: 0.8859 (0.8921)  loss_bbox: 0.2127 (0.2100)  loss_giou: 0.7884 (0.8109)  loss_vfl_aux_0: 0.6886 (0.6931)  loss_bbox_aux_0: 0.2483 (0.2569)  loss_giou_aux_0: 0.8588 (0.9052)  loss_vfl_aux_1: 0.7470 (0.7620)  loss_bbox_aux_1: 0.2201 (0.2351)  loss_giou_aux_1: 0.8257 (0.8605)  loss_vfl_aux_2: 0.7563 (0.7868)  loss_bbox_aux_2: 0.2281 (0.2262)  loss_giou_aux_2: 0.8279 (0.8443)  loss_vfl_aux_3: 0.7934 (0.8189)  loss_bbox_aux_3: 0.2234 (0.2217)  loss_giou_aux_3: 0.8104 (0.8318)  loss_vfl_aux_4: 0.8494 (0.8594)  loss_bbox_aux_4: 0.2147 (0.2132)  loss_giou_aux_4: 0.7946 (0.8185)  loss_vfl_aux_5: 0.6129 (0.6083)  loss_bbox_aux_5: 0.3202 (0.3110)  loss_giou_aux_5: 0.9751 (1.0189)  loss_vfl_dn_0: 0.3761 (0.3763)  loss_bbox_dn_0: 0.3384 (0.3325)  loss_giou_dn_0: 1.1184 (1.1317)  loss_vfl_dn_1: 0.3997 (0.3973)  loss_bbox_dn_1: 0.3075 (0.3048)  loss_giou_dn_1: 1.0152 (1.0300)  loss_vfl_dn_2: 0.4126 (0.4063)  loss_bbox_dn_2: 0.2926 (0.2966)  loss_giou_dn_2: 0.9730 (0.9880)  loss_vfl_dn_3: 0.4164 (0.4095)  loss_bbox_dn_3: 0.2912 (0.2923)  loss_giou_dn_3: 0.9672 (0.9698)  loss_vfl_dn_4: 0.4132 (0.4100)  loss_bbox_dn_4: 0.2890 (0.2905)  loss_giou_dn_4: 0.9615 (0.9617)  loss_vfl_dn_5: 0.4147 (0.4108)  loss_bbox_dn_5: 0.2860 (0.2893)  loss_giou_dn_5: 0.9615 (0.9585)  time: 0.3151  data: 0.0135  max mem: 7780\n",
            "Epoch: [7] Total time: 0:00:11 (0.3522 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 23.3755 (23.4409)  loss_vfl: 0.8859 (0.8921)  loss_bbox: 0.2127 (0.2100)  loss_giou: 0.7884 (0.8109)  loss_vfl_aux_0: 0.6886 (0.6931)  loss_bbox_aux_0: 0.2483 (0.2569)  loss_giou_aux_0: 0.8588 (0.9052)  loss_vfl_aux_1: 0.7470 (0.7620)  loss_bbox_aux_1: 0.2201 (0.2351)  loss_giou_aux_1: 0.8257 (0.8605)  loss_vfl_aux_2: 0.7563 (0.7868)  loss_bbox_aux_2: 0.2281 (0.2262)  loss_giou_aux_2: 0.8279 (0.8443)  loss_vfl_aux_3: 0.7934 (0.8189)  loss_bbox_aux_3: 0.2234 (0.2217)  loss_giou_aux_3: 0.8104 (0.8318)  loss_vfl_aux_4: 0.8494 (0.8594)  loss_bbox_aux_4: 0.2147 (0.2132)  loss_giou_aux_4: 0.7946 (0.8185)  loss_vfl_aux_5: 0.6129 (0.6083)  loss_bbox_aux_5: 0.3202 (0.3110)  loss_giou_aux_5: 0.9751 (1.0189)  loss_vfl_dn_0: 0.3761 (0.3763)  loss_bbox_dn_0: 0.3384 (0.3325)  loss_giou_dn_0: 1.1184 (1.1317)  loss_vfl_dn_1: 0.3997 (0.3973)  loss_bbox_dn_1: 0.3075 (0.3048)  loss_giou_dn_1: 1.0152 (1.0300)  loss_vfl_dn_2: 0.4126 (0.4063)  loss_bbox_dn_2: 0.2926 (0.2966)  loss_giou_dn_2: 0.9730 (0.9880)  loss_vfl_dn_3: 0.4164 (0.4095)  loss_bbox_dn_3: 0.2912 (0.2923)  loss_giou_dn_3: 0.9672 (0.9698)  loss_vfl_dn_4: 0.4132 (0.4100)  loss_bbox_dn_4: 0.2890 (0.2905)  loss_giou_dn_4: 0.9615 (0.9617)  loss_vfl_dn_5: 0.4147 (0.4108)  loss_bbox_dn_5: 0.2860 (0.2893)  loss_giou_dn_5: 0.9615 (0.9585)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8874  data: 0.5590  max mem: 7780\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3957  data: 0.1083  max mem: 7780\n",
            "Test: Total time: 0:00:02 (0.4093 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.129\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            "best_stat:  {'epoch': 2, 'coco_eval_bbox': 0.09886680878453323}\n",
            "Epoch: [8]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 23.2701 (23.2701)  loss_vfl: 0.9494 (0.9494)  loss_bbox: 0.2658 (0.2658)  loss_giou: 0.7217 (0.7217)  loss_vfl_aux_0: 0.7707 (0.7707)  loss_bbox_aux_0: 0.3221 (0.3221)  loss_giou_aux_0: 0.8425 (0.8425)  loss_vfl_aux_1: 0.8503 (0.8503)  loss_bbox_aux_1: 0.3012 (0.3012)  loss_giou_aux_1: 0.7787 (0.7787)  loss_vfl_aux_2: 0.8027 (0.8027)  loss_bbox_aux_2: 0.3071 (0.3071)  loss_giou_aux_2: 0.8173 (0.8173)  loss_vfl_aux_3: 0.8008 (0.8008)  loss_bbox_aux_3: 0.2940 (0.2940)  loss_giou_aux_3: 0.7852 (0.7852)  loss_vfl_aux_4: 0.8745 (0.8745)  loss_bbox_aux_4: 0.2847 (0.2847)  loss_giou_aux_4: 0.7632 (0.7632)  loss_vfl_aux_5: 0.7903 (0.7903)  loss_bbox_aux_5: 0.3837 (0.3837)  loss_giou_aux_5: 0.9341 (0.9341)  loss_vfl_dn_0: 0.4056 (0.4056)  loss_bbox_dn_0: 0.3547 (0.3547)  loss_giou_dn_0: 1.0630 (1.0630)  loss_vfl_dn_1: 0.4360 (0.4360)  loss_bbox_dn_1: 0.3122 (0.3122)  loss_giou_dn_1: 0.9144 (0.9144)  loss_vfl_dn_2: 0.4294 (0.4294)  loss_bbox_dn_2: 0.2982 (0.2982)  loss_giou_dn_2: 0.8483 (0.8483)  loss_vfl_dn_3: 0.4283 (0.4283)  loss_bbox_dn_3: 0.2915 (0.2915)  loss_giou_dn_3: 0.8191 (0.8191)  loss_vfl_dn_4: 0.4249 (0.4249)  loss_bbox_dn_4: 0.2899 (0.2899)  loss_giou_dn_4: 0.8044 (0.8044)  loss_vfl_dn_5: 0.4262 (0.4262)  loss_bbox_dn_5: 0.2882 (0.2882)  loss_giou_dn_5: 0.7956 (0.7956)  time: 0.9814  data: 0.5809  max mem: 7780\n",
            "Epoch: [8]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 23.0860 (23.2149)  loss_vfl: 0.9910 (0.9686)  loss_bbox: 0.2220 (0.2209)  loss_giou: 0.6569 (0.7170)  loss_vfl_aux_0: 0.7838 (0.7685)  loss_bbox_aux_0: 0.2567 (0.2702)  loss_giou_aux_0: 0.7769 (0.8026)  loss_vfl_aux_1: 0.8187 (0.8208)  loss_bbox_aux_1: 0.2314 (0.2494)  loss_giou_aux_1: 0.7292 (0.7640)  loss_vfl_aux_2: 0.8637 (0.8302)  loss_bbox_aux_2: 0.2377 (0.2466)  loss_giou_aux_2: 0.7112 (0.7573)  loss_vfl_aux_3: 0.8959 (0.8750)  loss_bbox_aux_3: 0.2300 (0.2375)  loss_giou_aux_3: 0.6855 (0.7406)  loss_vfl_aux_4: 0.9445 (0.9191)  loss_bbox_aux_4: 0.2284 (0.2301)  loss_giou_aux_4: 0.6621 (0.7280)  loss_vfl_aux_5: 0.6826 (0.6835)  loss_bbox_aux_5: 0.3357 (0.3428)  loss_giou_aux_5: 0.8951 (0.9259)  loss_vfl_dn_0: 0.3971 (0.3934)  loss_bbox_dn_0: 0.4045 (0.3880)  loss_giou_dn_0: 1.0744 (1.0854)  loss_vfl_dn_1: 0.4164 (0.4134)  loss_bbox_dn_1: 0.3586 (0.3491)  loss_giou_dn_1: 0.9363 (0.9597)  loss_vfl_dn_2: 0.4249 (0.4217)  loss_bbox_dn_2: 0.3427 (0.3344)  loss_giou_dn_2: 0.8882 (0.9049)  loss_vfl_dn_3: 0.4241 (0.4243)  loss_bbox_dn_3: 0.3339 (0.3274)  loss_giou_dn_3: 0.8689 (0.8801)  loss_vfl_dn_4: 0.4273 (0.4238)  loss_bbox_dn_4: 0.3298 (0.3244)  loss_giou_dn_4: 0.8623 (0.8714)  loss_vfl_dn_5: 0.4280 (0.4252)  loss_bbox_dn_5: 0.3273 (0.3225)  loss_giou_dn_5: 0.8601 (0.8675)  time: 0.3332  data: 0.0143  max mem: 7788\n",
            "Epoch: [8] Total time: 0:00:11 (0.3517 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 23.0860 (23.2149)  loss_vfl: 0.9910 (0.9686)  loss_bbox: 0.2220 (0.2209)  loss_giou: 0.6569 (0.7170)  loss_vfl_aux_0: 0.7838 (0.7685)  loss_bbox_aux_0: 0.2567 (0.2702)  loss_giou_aux_0: 0.7769 (0.8026)  loss_vfl_aux_1: 0.8187 (0.8208)  loss_bbox_aux_1: 0.2314 (0.2494)  loss_giou_aux_1: 0.7292 (0.7640)  loss_vfl_aux_2: 0.8637 (0.8302)  loss_bbox_aux_2: 0.2377 (0.2466)  loss_giou_aux_2: 0.7112 (0.7573)  loss_vfl_aux_3: 0.8959 (0.8750)  loss_bbox_aux_3: 0.2300 (0.2375)  loss_giou_aux_3: 0.6855 (0.7406)  loss_vfl_aux_4: 0.9445 (0.9191)  loss_bbox_aux_4: 0.2284 (0.2301)  loss_giou_aux_4: 0.6621 (0.7280)  loss_vfl_aux_5: 0.6826 (0.6835)  loss_bbox_aux_5: 0.3357 (0.3428)  loss_giou_aux_5: 0.8951 (0.9259)  loss_vfl_dn_0: 0.3971 (0.3934)  loss_bbox_dn_0: 0.4045 (0.3880)  loss_giou_dn_0: 1.0744 (1.0854)  loss_vfl_dn_1: 0.4164 (0.4134)  loss_bbox_dn_1: 0.3586 (0.3491)  loss_giou_dn_1: 0.9363 (0.9597)  loss_vfl_dn_2: 0.4249 (0.4217)  loss_bbox_dn_2: 0.3427 (0.3344)  loss_giou_dn_2: 0.8882 (0.9049)  loss_vfl_dn_3: 0.4241 (0.4243)  loss_bbox_dn_3: 0.3339 (0.3274)  loss_giou_dn_3: 0.8689 (0.8801)  loss_vfl_dn_4: 0.4273 (0.4238)  loss_bbox_dn_4: 0.3298 (0.3244)  loss_giou_dn_4: 0.8623 (0.8714)  loss_vfl_dn_5: 0.4280 (0.4252)  loss_bbox_dn_5: 0.3273 (0.3225)  loss_giou_dn_5: 0.8601 (0.8675)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8422  data: 0.5203  max mem: 7788\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4030  data: 0.1081  max mem: 7788\n",
            "Test: Total time: 0:00:02 (0.4169 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.113\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.245\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.173\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
            "best_stat:  {'epoch': 8, 'coco_eval_bbox': 0.11269043706233156}\n",
            "Epoch: [9]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 21.4157 (21.4157)  loss_vfl: 0.9093 (0.9093)  loss_bbox: 0.1735 (0.1735)  loss_giou: 0.7281 (0.7281)  loss_vfl_aux_0: 0.7359 (0.7359)  loss_bbox_aux_0: 0.2170 (0.2170)  loss_giou_aux_0: 0.8482 (0.8482)  loss_vfl_aux_1: 0.7843 (0.7843)  loss_bbox_aux_1: 0.1988 (0.1988)  loss_giou_aux_1: 0.7836 (0.7836)  loss_vfl_aux_2: 0.7698 (0.7698)  loss_bbox_aux_2: 0.1839 (0.1839)  loss_giou_aux_2: 0.7535 (0.7535)  loss_vfl_aux_3: 0.7593 (0.7593)  loss_bbox_aux_3: 0.1806 (0.1806)  loss_giou_aux_3: 0.7460 (0.7460)  loss_vfl_aux_4: 0.8588 (0.8588)  loss_bbox_aux_4: 0.1736 (0.1736)  loss_giou_aux_4: 0.7309 (0.7309)  loss_vfl_aux_5: 0.7207 (0.7207)  loss_bbox_aux_5: 0.2355 (0.2355)  loss_giou_aux_5: 0.9187 (0.9187)  loss_vfl_dn_0: 0.4033 (0.4033)  loss_bbox_dn_0: 0.2523 (0.2523)  loss_giou_dn_0: 1.0394 (1.0394)  loss_vfl_dn_1: 0.4273 (0.4273)  loss_bbox_dn_1: 0.2200 (0.2200)  loss_giou_dn_1: 0.8932 (0.8932)  loss_vfl_dn_2: 0.4344 (0.4344)  loss_bbox_dn_2: 0.2089 (0.2089)  loss_giou_dn_2: 0.8238 (0.8238)  loss_vfl_dn_3: 0.4381 (0.4381)  loss_bbox_dn_3: 0.2042 (0.2042)  loss_giou_dn_3: 0.7959 (0.7959)  loss_vfl_dn_4: 0.4356 (0.4356)  loss_bbox_dn_4: 0.2039 (0.2039)  loss_giou_dn_4: 0.7916 (0.7916)  loss_vfl_dn_5: 0.4344 (0.4344)  loss_bbox_dn_5: 0.2054 (0.2054)  loss_giou_dn_5: 0.7937 (0.7937)  time: 1.0146  data: 0.6003  max mem: 7788\n",
            "Epoch: [9]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 22.5367 (22.6101)  loss_vfl: 0.8542 (0.8742)  loss_bbox: 0.2352 (0.2074)  loss_giou: 0.7868 (0.7751)  loss_vfl_aux_0: 0.6961 (0.7116)  loss_bbox_aux_0: 0.2461 (0.2497)  loss_giou_aux_0: 0.8613 (0.8566)  loss_vfl_aux_1: 0.7473 (0.7484)  loss_bbox_aux_1: 0.2471 (0.2330)  loss_giou_aux_1: 0.8342 (0.8180)  loss_vfl_aux_2: 0.7496 (0.7565)  loss_bbox_aux_2: 0.2389 (0.2278)  loss_giou_aux_2: 0.8083 (0.8144)  loss_vfl_aux_3: 0.7551 (0.7847)  loss_bbox_aux_3: 0.2447 (0.2232)  loss_giou_aux_3: 0.7996 (0.8008)  loss_vfl_aux_4: 0.7943 (0.8180)  loss_bbox_aux_4: 0.2339 (0.2150)  loss_giou_aux_4: 0.7913 (0.7910)  loss_vfl_aux_5: 0.6017 (0.6399)  loss_bbox_aux_5: 0.2833 (0.2965)  loss_giou_aux_5: 0.9629 (0.9584)  loss_vfl_dn_0: 0.3916 (0.3892)  loss_bbox_dn_0: 0.3182 (0.3131)  loss_giou_dn_0: 1.0805 (1.0836)  loss_vfl_dn_1: 0.4120 (0.4068)  loss_bbox_dn_1: 0.2834 (0.2817)  loss_giou_dn_1: 0.9456 (0.9666)  loss_vfl_dn_2: 0.4179 (0.4149)  loss_bbox_dn_2: 0.2648 (0.2716)  loss_giou_dn_2: 0.9085 (0.9232)  loss_vfl_dn_3: 0.4174 (0.4168)  loss_bbox_dn_3: 0.2603 (0.2686)  loss_giou_dn_3: 0.8985 (0.9071)  loss_vfl_dn_4: 0.4166 (0.4172)  loss_bbox_dn_4: 0.2584 (0.2673)  loss_giou_dn_4: 0.8853 (0.8998)  loss_vfl_dn_5: 0.4197 (0.4185)  loss_bbox_dn_5: 0.2567 (0.2669)  loss_giou_dn_5: 0.8775 (0.8970)  time: 0.3156  data: 0.0136  max mem: 7788\n",
            "Epoch: [9] Total time: 0:00:11 (0.3416 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 22.5367 (22.6101)  loss_vfl: 0.8542 (0.8742)  loss_bbox: 0.2352 (0.2074)  loss_giou: 0.7868 (0.7751)  loss_vfl_aux_0: 0.6961 (0.7116)  loss_bbox_aux_0: 0.2461 (0.2497)  loss_giou_aux_0: 0.8613 (0.8566)  loss_vfl_aux_1: 0.7473 (0.7484)  loss_bbox_aux_1: 0.2471 (0.2330)  loss_giou_aux_1: 0.8342 (0.8180)  loss_vfl_aux_2: 0.7496 (0.7565)  loss_bbox_aux_2: 0.2389 (0.2278)  loss_giou_aux_2: 0.8083 (0.8144)  loss_vfl_aux_3: 0.7551 (0.7847)  loss_bbox_aux_3: 0.2447 (0.2232)  loss_giou_aux_3: 0.7996 (0.8008)  loss_vfl_aux_4: 0.7943 (0.8180)  loss_bbox_aux_4: 0.2339 (0.2150)  loss_giou_aux_4: 0.7913 (0.7910)  loss_vfl_aux_5: 0.6017 (0.6399)  loss_bbox_aux_5: 0.2833 (0.2965)  loss_giou_aux_5: 0.9629 (0.9584)  loss_vfl_dn_0: 0.3916 (0.3892)  loss_bbox_dn_0: 0.3182 (0.3131)  loss_giou_dn_0: 1.0805 (1.0836)  loss_vfl_dn_1: 0.4120 (0.4068)  loss_bbox_dn_1: 0.2834 (0.2817)  loss_giou_dn_1: 0.9456 (0.9666)  loss_vfl_dn_2: 0.4179 (0.4149)  loss_bbox_dn_2: 0.2648 (0.2716)  loss_giou_dn_2: 0.9085 (0.9232)  loss_vfl_dn_3: 0.4174 (0.4168)  loss_bbox_dn_3: 0.2603 (0.2686)  loss_giou_dn_3: 0.8985 (0.9071)  loss_vfl_dn_4: 0.4166 (0.4172)  loss_bbox_dn_4: 0.2584 (0.2673)  loss_giou_dn_4: 0.8853 (0.8998)  loss_vfl_dn_5: 0.4197 (0.4185)  loss_bbox_dn_5: 0.2567 (0.2669)  loss_giou_dn_5: 0.8775 (0.8970)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8454  data: 0.5160  max mem: 7788\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3928  data: 0.1088  max mem: 7788\n",
            "Test: Total time: 0:00:02 (0.4064 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.132\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.591\n",
            "best_stat:  {'epoch': 9, 'coco_eval_bbox': 0.16392706905329865}\n",
            "Epoch: [10]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 25.9534 (25.9534)  loss_vfl: 1.1755 (1.1755)  loss_bbox: 0.3089 (0.3089)  loss_giou: 0.6977 (0.6977)  loss_vfl_aux_0: 0.9704 (0.9704)  loss_bbox_aux_0: 0.4109 (0.4109)  loss_giou_aux_0: 0.7862 (0.7862)  loss_vfl_aux_1: 1.0291 (1.0291)  loss_bbox_aux_1: 0.3817 (0.3817)  loss_giou_aux_1: 0.7331 (0.7331)  loss_vfl_aux_2: 1.0087 (1.0087)  loss_bbox_aux_2: 0.3659 (0.3659)  loss_giou_aux_2: 0.7251 (0.7251)  loss_vfl_aux_3: 1.0641 (1.0641)  loss_bbox_aux_3: 0.3239 (0.3239)  loss_giou_aux_3: 0.7134 (0.7134)  loss_vfl_aux_4: 1.0620 (1.0620)  loss_bbox_aux_4: 0.3212 (0.3212)  loss_giou_aux_4: 0.7112 (0.7112)  loss_vfl_aux_5: 0.8928 (0.8928)  loss_bbox_aux_5: 0.4510 (0.4510)  loss_giou_aux_5: 0.8857 (0.8857)  loss_vfl_dn_0: 0.4124 (0.4124)  loss_bbox_dn_0: 0.5497 (0.5497)  loss_giou_dn_0: 1.0364 (1.0364)  loss_vfl_dn_1: 0.4244 (0.4244)  loss_bbox_dn_1: 0.5033 (0.5033)  loss_giou_dn_1: 0.9287 (0.9287)  loss_vfl_dn_2: 0.4322 (0.4322)  loss_bbox_dn_2: 0.4902 (0.4902)  loss_giou_dn_2: 0.8774 (0.8774)  loss_vfl_dn_3: 0.4304 (0.4304)  loss_bbox_dn_3: 0.4818 (0.4818)  loss_giou_dn_3: 0.8491 (0.8491)  loss_vfl_dn_4: 0.4381 (0.4381)  loss_bbox_dn_4: 0.4785 (0.4785)  loss_giou_dn_4: 0.8432 (0.8432)  loss_vfl_dn_5: 0.4405 (0.4405)  loss_bbox_dn_5: 0.4774 (0.4774)  loss_giou_dn_5: 0.8409 (0.8409)  time: 0.9315  data: 0.5146  max mem: 7788\n",
            "Epoch: [10]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 21.9145 (22.4841)  loss_vfl: 0.8735 (0.8867)  loss_bbox: 0.2123 (0.2264)  loss_giou: 0.6659 (0.7074)  loss_vfl_aux_0: 0.7729 (0.7544)  loss_bbox_aux_0: 0.2451 (0.2646)  loss_giou_aux_0: 0.7610 (0.7735)  loss_vfl_aux_1: 0.7889 (0.7865)  loss_bbox_aux_1: 0.2320 (0.2489)  loss_giou_aux_1: 0.7271 (0.7440)  loss_vfl_aux_2: 0.8094 (0.7979)  loss_bbox_aux_2: 0.2251 (0.2436)  loss_giou_aux_2: 0.7014 (0.7361)  loss_vfl_aux_3: 0.8150 (0.8176)  loss_bbox_aux_3: 0.2209 (0.2383)  loss_giou_aux_3: 0.6783 (0.7271)  loss_vfl_aux_4: 0.8567 (0.8461)  loss_bbox_aux_4: 0.2160 (0.2342)  loss_giou_aux_4: 0.6659 (0.7194)  loss_vfl_aux_5: 0.6587 (0.6570)  loss_bbox_aux_5: 0.3040 (0.3302)  loss_giou_aux_5: 0.8817 (0.9081)  loss_vfl_dn_0: 0.4014 (0.4030)  loss_bbox_dn_0: 0.3643 (0.3741)  loss_giou_dn_0: 1.0405 (1.0438)  loss_vfl_dn_1: 0.4247 (0.4238)  loss_bbox_dn_1: 0.3288 (0.3348)  loss_giou_dn_1: 0.9143 (0.9072)  loss_vfl_dn_2: 0.4306 (0.4307)  loss_bbox_dn_2: 0.3199 (0.3211)  loss_giou_dn_2: 0.8527 (0.8569)  loss_vfl_dn_3: 0.4404 (0.4345)  loss_bbox_dn_3: 0.3127 (0.3163)  loss_giou_dn_3: 0.8369 (0.8379)  loss_vfl_dn_4: 0.4373 (0.4338)  loss_bbox_dn_4: 0.3112 (0.3148)  loss_giou_dn_4: 0.8241 (0.8301)  loss_vfl_dn_5: 0.4383 (0.4331)  loss_bbox_dn_5: 0.3100 (0.3141)  loss_giou_dn_5: 0.8237 (0.8264)  time: 0.3265  data: 0.0145  max mem: 7788\n",
            "Epoch: [10] Total time: 0:00:11 (0.3504 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 21.9145 (22.4841)  loss_vfl: 0.8735 (0.8867)  loss_bbox: 0.2123 (0.2264)  loss_giou: 0.6659 (0.7074)  loss_vfl_aux_0: 0.7729 (0.7544)  loss_bbox_aux_0: 0.2451 (0.2646)  loss_giou_aux_0: 0.7610 (0.7735)  loss_vfl_aux_1: 0.7889 (0.7865)  loss_bbox_aux_1: 0.2320 (0.2489)  loss_giou_aux_1: 0.7271 (0.7440)  loss_vfl_aux_2: 0.8094 (0.7979)  loss_bbox_aux_2: 0.2251 (0.2436)  loss_giou_aux_2: 0.7014 (0.7361)  loss_vfl_aux_3: 0.8150 (0.8176)  loss_bbox_aux_3: 0.2209 (0.2383)  loss_giou_aux_3: 0.6783 (0.7271)  loss_vfl_aux_4: 0.8567 (0.8461)  loss_bbox_aux_4: 0.2160 (0.2342)  loss_giou_aux_4: 0.6659 (0.7194)  loss_vfl_aux_5: 0.6587 (0.6570)  loss_bbox_aux_5: 0.3040 (0.3302)  loss_giou_aux_5: 0.8817 (0.9081)  loss_vfl_dn_0: 0.4014 (0.4030)  loss_bbox_dn_0: 0.3643 (0.3741)  loss_giou_dn_0: 1.0405 (1.0438)  loss_vfl_dn_1: 0.4247 (0.4238)  loss_bbox_dn_1: 0.3288 (0.3348)  loss_giou_dn_1: 0.9143 (0.9072)  loss_vfl_dn_2: 0.4306 (0.4307)  loss_bbox_dn_2: 0.3199 (0.3211)  loss_giou_dn_2: 0.8527 (0.8569)  loss_vfl_dn_3: 0.4404 (0.4345)  loss_bbox_dn_3: 0.3127 (0.3163)  loss_giou_dn_3: 0.8369 (0.8379)  loss_vfl_dn_4: 0.4373 (0.4338)  loss_bbox_dn_4: 0.3112 (0.3148)  loss_giou_dn_4: 0.8241 (0.8301)  loss_vfl_dn_5: 0.4383 (0.4331)  loss_bbox_dn_5: 0.3100 (0.3141)  loss_giou_dn_5: 0.8237 (0.8264)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8792  data: 0.5582  max mem: 7788\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4383  data: 0.1076  max mem: 7788\n",
            "Test: Total time: 0:00:02 (0.4528 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.202\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.363\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.505\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "best_stat:  {'epoch': 10, 'coco_eval_bbox': 0.18996398734135134}\n",
            "Epoch: [11]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 20.7333 (20.7333)  loss_vfl: 0.7608 (0.7608)  loss_bbox: 0.1846 (0.1846)  loss_giou: 0.6605 (0.6605)  loss_vfl_aux_0: 0.6840 (0.6840)  loss_bbox_aux_0: 0.2535 (0.2535)  loss_giou_aux_0: 0.8167 (0.8167)  loss_vfl_aux_1: 0.7355 (0.7355)  loss_bbox_aux_1: 0.2042 (0.2042)  loss_giou_aux_1: 0.6978 (0.6978)  loss_vfl_aux_2: 0.7277 (0.7277)  loss_bbox_aux_2: 0.2000 (0.2000)  loss_giou_aux_2: 0.6803 (0.6803)  loss_vfl_aux_3: 0.7095 (0.7095)  loss_bbox_aux_3: 0.1968 (0.1968)  loss_giou_aux_3: 0.6917 (0.6917)  loss_vfl_aux_4: 0.7027 (0.7027)  loss_bbox_aux_4: 0.1919 (0.1919)  loss_giou_aux_4: 0.6845 (0.6845)  loss_vfl_aux_5: 0.6016 (0.6016)  loss_bbox_aux_5: 0.3525 (0.3525)  loss_giou_aux_5: 1.0422 (1.0422)  loss_vfl_dn_0: 0.4015 (0.4015)  loss_bbox_dn_0: 0.3124 (0.3124)  loss_giou_dn_0: 0.9952 (0.9952)  loss_vfl_dn_1: 0.4205 (0.4205)  loss_bbox_dn_1: 0.2652 (0.2652)  loss_giou_dn_1: 0.8388 (0.8388)  loss_vfl_dn_2: 0.4210 (0.4210)  loss_bbox_dn_2: 0.2504 (0.2504)  loss_giou_dn_2: 0.7805 (0.7805)  loss_vfl_dn_3: 0.4238 (0.4238)  loss_bbox_dn_3: 0.2481 (0.2481)  loss_giou_dn_3: 0.7627 (0.7627)  loss_vfl_dn_4: 0.4228 (0.4228)  loss_bbox_dn_4: 0.2458 (0.2458)  loss_giou_dn_4: 0.7536 (0.7536)  loss_vfl_dn_5: 0.4207 (0.4207)  loss_bbox_dn_5: 0.2441 (0.2441)  loss_giou_dn_5: 0.7475 (0.7475)  time: 1.0227  data: 0.5980  max mem: 7788\n",
            "Epoch: [11]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 22.2957 (22.0234)  loss_vfl: 0.8052 (0.8410)  loss_bbox: 0.2236 (0.2049)  loss_giou: 0.7349 (0.7395)  loss_vfl_aux_0: 0.7250 (0.7227)  loss_bbox_aux_0: 0.2556 (0.2379)  loss_giou_aux_0: 0.8093 (0.8075)  loss_vfl_aux_1: 0.7343 (0.7426)  loss_bbox_aux_1: 0.2362 (0.2233)  loss_giou_aux_1: 0.7899 (0.7798)  loss_vfl_aux_2: 0.7515 (0.7679)  loss_bbox_aux_2: 0.2369 (0.2185)  loss_giou_aux_2: 0.7694 (0.7648)  loss_vfl_aux_3: 0.7672 (0.7796)  loss_bbox_aux_3: 0.2298 (0.2153)  loss_giou_aux_3: 0.7531 (0.7567)  loss_vfl_aux_4: 0.7690 (0.7998)  loss_bbox_aux_4: 0.2227 (0.2123)  loss_giou_aux_4: 0.7485 (0.7501)  loss_vfl_aux_5: 0.6265 (0.6234)  loss_bbox_aux_5: 0.3394 (0.3087)  loss_giou_aux_5: 0.9620 (0.9540)  loss_vfl_dn_0: 0.3967 (0.3974)  loss_bbox_dn_0: 0.3408 (0.3173)  loss_giou_dn_0: 1.0502 (1.0512)  loss_vfl_dn_1: 0.4189 (0.4176)  loss_bbox_dn_1: 0.2958 (0.2814)  loss_giou_dn_1: 0.9005 (0.9175)  loss_vfl_dn_2: 0.4302 (0.4251)  loss_bbox_dn_2: 0.2832 (0.2703)  loss_giou_dn_2: 0.8583 (0.8718)  loss_vfl_dn_3: 0.4222 (0.4260)  loss_bbox_dn_3: 0.2787 (0.2663)  loss_giou_dn_3: 0.8446 (0.8550)  loss_vfl_dn_4: 0.4190 (0.4247)  loss_bbox_dn_4: 0.2748 (0.2647)  loss_giou_dn_4: 0.8443 (0.8496)  loss_vfl_dn_5: 0.4204 (0.4262)  loss_bbox_dn_5: 0.2724 (0.2640)  loss_giou_dn_5: 0.8437 (0.8470)  time: 0.3163  data: 0.0136  max mem: 7790\n",
            "Epoch: [11] Total time: 0:00:11 (0.3448 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 22.2957 (22.0234)  loss_vfl: 0.8052 (0.8410)  loss_bbox: 0.2236 (0.2049)  loss_giou: 0.7349 (0.7395)  loss_vfl_aux_0: 0.7250 (0.7227)  loss_bbox_aux_0: 0.2556 (0.2379)  loss_giou_aux_0: 0.8093 (0.8075)  loss_vfl_aux_1: 0.7343 (0.7426)  loss_bbox_aux_1: 0.2362 (0.2233)  loss_giou_aux_1: 0.7899 (0.7798)  loss_vfl_aux_2: 0.7515 (0.7679)  loss_bbox_aux_2: 0.2369 (0.2185)  loss_giou_aux_2: 0.7694 (0.7648)  loss_vfl_aux_3: 0.7672 (0.7796)  loss_bbox_aux_3: 0.2298 (0.2153)  loss_giou_aux_3: 0.7531 (0.7567)  loss_vfl_aux_4: 0.7690 (0.7998)  loss_bbox_aux_4: 0.2227 (0.2123)  loss_giou_aux_4: 0.7485 (0.7501)  loss_vfl_aux_5: 0.6265 (0.6234)  loss_bbox_aux_5: 0.3394 (0.3087)  loss_giou_aux_5: 0.9620 (0.9540)  loss_vfl_dn_0: 0.3967 (0.3974)  loss_bbox_dn_0: 0.3408 (0.3173)  loss_giou_dn_0: 1.0502 (1.0512)  loss_vfl_dn_1: 0.4189 (0.4176)  loss_bbox_dn_1: 0.2958 (0.2814)  loss_giou_dn_1: 0.9005 (0.9175)  loss_vfl_dn_2: 0.4302 (0.4251)  loss_bbox_dn_2: 0.2832 (0.2703)  loss_giou_dn_2: 0.8583 (0.8718)  loss_vfl_dn_3: 0.4222 (0.4260)  loss_bbox_dn_3: 0.2787 (0.2663)  loss_giou_dn_3: 0.8446 (0.8550)  loss_vfl_dn_4: 0.4190 (0.4247)  loss_bbox_dn_4: 0.2748 (0.2647)  loss_giou_dn_4: 0.8443 (0.8496)  loss_vfl_dn_5: 0.4204 (0.4262)  loss_bbox_dn_5: 0.2724 (0.2640)  loss_giou_dn_5: 0.8437 (0.8470)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8873  data: 0.5690  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4377  data: 0.1108  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4524 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.232\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.227\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "best_stat:  {'epoch': 11, 'coco_eval_bbox': 0.20261313356616867}\n",
            "Epoch: [12]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 20.9220 (20.9220)  loss_vfl: 0.7895 (0.7895)  loss_bbox: 0.1681 (0.1681)  loss_giou: 0.7029 (0.7029)  loss_vfl_aux_0: 0.6926 (0.6926)  loss_bbox_aux_0: 0.1942 (0.1942)  loss_giou_aux_0: 0.7954 (0.7954)  loss_vfl_aux_1: 0.7237 (0.7237)  loss_bbox_aux_1: 0.1882 (0.1882)  loss_giou_aux_1: 0.7660 (0.7660)  loss_vfl_aux_2: 0.7564 (0.7564)  loss_bbox_aux_2: 0.1834 (0.1834)  loss_giou_aux_2: 0.7324 (0.7324)  loss_vfl_aux_3: 0.7577 (0.7577)  loss_bbox_aux_3: 0.1747 (0.1747)  loss_giou_aux_3: 0.7245 (0.7245)  loss_vfl_aux_4: 0.7800 (0.7800)  loss_bbox_aux_4: 0.1721 (0.1721)  loss_giou_aux_4: 0.7032 (0.7032)  loss_vfl_aux_5: 0.6353 (0.6353)  loss_bbox_aux_5: 0.2504 (0.2504)  loss_giou_aux_5: 1.0207 (1.0207)  loss_vfl_dn_0: 0.3894 (0.3894)  loss_bbox_dn_0: 0.2330 (0.2330)  loss_giou_dn_0: 1.0563 (1.0563)  loss_vfl_dn_1: 0.4200 (0.4200)  loss_bbox_dn_1: 0.2083 (0.2083)  loss_giou_dn_1: 0.9063 (0.9063)  loss_vfl_dn_2: 0.4320 (0.4320)  loss_bbox_dn_2: 0.2018 (0.2018)  loss_giou_dn_2: 0.8341 (0.8341)  loss_vfl_dn_3: 0.4368 (0.4368)  loss_bbox_dn_3: 0.2011 (0.2011)  loss_giou_dn_3: 0.8099 (0.8099)  loss_vfl_dn_4: 0.4367 (0.4367)  loss_bbox_dn_4: 0.2015 (0.2015)  loss_giou_dn_4: 0.8044 (0.8044)  loss_vfl_dn_5: 0.4387 (0.4387)  loss_bbox_dn_5: 0.2023 (0.2023)  loss_giou_dn_5: 0.7983 (0.7983)  time: 1.0689  data: 0.6548  max mem: 7790\n",
            "Epoch: [12]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 21.8722 (22.0719)  loss_vfl: 0.7401 (0.7776)  loss_bbox: 0.1947 (0.2162)  loss_giou: 0.7456 (0.7624)  loss_vfl_aux_0: 0.6882 (0.7125)  loss_bbox_aux_0: 0.2241 (0.2545)  loss_giou_aux_0: 0.8346 (0.8303)  loss_vfl_aux_1: 0.6932 (0.7240)  loss_bbox_aux_1: 0.2080 (0.2355)  loss_giou_aux_1: 0.7778 (0.7935)  loss_vfl_aux_2: 0.6919 (0.7326)  loss_bbox_aux_2: 0.2013 (0.2286)  loss_giou_aux_2: 0.7431 (0.7805)  loss_vfl_aux_3: 0.6911 (0.7422)  loss_bbox_aux_3: 0.2032 (0.2240)  loss_giou_aux_3: 0.7482 (0.7752)  loss_vfl_aux_4: 0.7149 (0.7579)  loss_bbox_aux_4: 0.2020 (0.2210)  loss_giou_aux_4: 0.7451 (0.7683)  loss_vfl_aux_5: 0.5819 (0.6053)  loss_bbox_aux_5: 0.2804 (0.3278)  loss_giou_aux_5: 0.9865 (0.9852)  loss_vfl_dn_0: 0.3921 (0.3963)  loss_bbox_dn_0: 0.2774 (0.3299)  loss_giou_dn_0: 1.0491 (1.0402)  loss_vfl_dn_1: 0.4149 (0.4137)  loss_bbox_dn_1: 0.2491 (0.2931)  loss_giou_dn_1: 0.9250 (0.9131)  loss_vfl_dn_2: 0.4137 (0.4186)  loss_bbox_dn_2: 0.2450 (0.2810)  loss_giou_dn_2: 0.8950 (0.8713)  loss_vfl_dn_3: 0.4242 (0.4209)  loss_bbox_dn_3: 0.2442 (0.2773)  loss_giou_dn_3: 0.8781 (0.8580)  loss_vfl_dn_4: 0.4206 (0.4217)  loss_bbox_dn_4: 0.2409 (0.2757)  loss_giou_dn_4: 0.8809 (0.8542)  loss_vfl_dn_5: 0.4162 (0.4233)  loss_bbox_dn_5: 0.2394 (0.2751)  loss_giou_dn_5: 0.8772 (0.8531)  time: 0.3259  data: 0.0146  max mem: 7790\n",
            "Epoch: [12] Total time: 0:00:11 (0.3495 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 21.8722 (22.0719)  loss_vfl: 0.7401 (0.7776)  loss_bbox: 0.1947 (0.2162)  loss_giou: 0.7456 (0.7624)  loss_vfl_aux_0: 0.6882 (0.7125)  loss_bbox_aux_0: 0.2241 (0.2545)  loss_giou_aux_0: 0.8346 (0.8303)  loss_vfl_aux_1: 0.6932 (0.7240)  loss_bbox_aux_1: 0.2080 (0.2355)  loss_giou_aux_1: 0.7778 (0.7935)  loss_vfl_aux_2: 0.6919 (0.7326)  loss_bbox_aux_2: 0.2013 (0.2286)  loss_giou_aux_2: 0.7431 (0.7805)  loss_vfl_aux_3: 0.6911 (0.7422)  loss_bbox_aux_3: 0.2032 (0.2240)  loss_giou_aux_3: 0.7482 (0.7752)  loss_vfl_aux_4: 0.7149 (0.7579)  loss_bbox_aux_4: 0.2020 (0.2210)  loss_giou_aux_4: 0.7451 (0.7683)  loss_vfl_aux_5: 0.5819 (0.6053)  loss_bbox_aux_5: 0.2804 (0.3278)  loss_giou_aux_5: 0.9865 (0.9852)  loss_vfl_dn_0: 0.3921 (0.3963)  loss_bbox_dn_0: 0.2774 (0.3299)  loss_giou_dn_0: 1.0491 (1.0402)  loss_vfl_dn_1: 0.4149 (0.4137)  loss_bbox_dn_1: 0.2491 (0.2931)  loss_giou_dn_1: 0.9250 (0.9131)  loss_vfl_dn_2: 0.4137 (0.4186)  loss_bbox_dn_2: 0.2450 (0.2810)  loss_giou_dn_2: 0.8950 (0.8713)  loss_vfl_dn_3: 0.4242 (0.4209)  loss_bbox_dn_3: 0.2442 (0.2773)  loss_giou_dn_3: 0.8781 (0.8580)  loss_vfl_dn_4: 0.4206 (0.4217)  loss_bbox_dn_4: 0.2409 (0.2757)  loss_giou_dn_4: 0.8809 (0.8542)  loss_vfl_dn_5: 0.4162 (0.4233)  loss_bbox_dn_5: 0.2394 (0.2751)  loss_giou_dn_5: 0.8772 (0.8531)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8575  data: 0.5431  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3849  data: 0.1080  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3998 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.467\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.232\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "best_stat:  {'epoch': 12, 'coco_eval_bbox': 0.2279869801708274}\n",
            "Epoch: [13]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 21.0566 (21.0566)  loss_vfl: 0.8114 (0.8114)  loss_bbox: 0.1481 (0.1481)  loss_giou: 0.6884 (0.6884)  loss_vfl_aux_0: 0.7055 (0.7055)  loss_bbox_aux_0: 0.1976 (0.1976)  loss_giou_aux_0: 0.8036 (0.8036)  loss_vfl_aux_1: 0.7345 (0.7345)  loss_bbox_aux_1: 0.1672 (0.1672)  loss_giou_aux_1: 0.7382 (0.7382)  loss_vfl_aux_2: 0.7641 (0.7641)  loss_bbox_aux_2: 0.1477 (0.1477)  loss_giou_aux_2: 0.6927 (0.6927)  loss_vfl_aux_3: 0.7526 (0.7526)  loss_bbox_aux_3: 0.1528 (0.1528)  loss_giou_aux_3: 0.6903 (0.6903)  loss_vfl_aux_4: 0.7769 (0.7769)  loss_bbox_aux_4: 0.1450 (0.1450)  loss_giou_aux_4: 0.6869 (0.6869)  loss_vfl_aux_5: 0.6205 (0.6205)  loss_bbox_aux_5: 0.2895 (0.2895)  loss_giou_aux_5: 1.0274 (1.0274)  loss_vfl_dn_0: 0.3939 (0.3939)  loss_bbox_dn_0: 0.3017 (0.3017)  loss_giou_dn_0: 1.0447 (1.0447)  loss_vfl_dn_1: 0.4169 (0.4169)  loss_bbox_dn_1: 0.2640 (0.2640)  loss_giou_dn_1: 0.9017 (0.9017)  loss_vfl_dn_2: 0.4217 (0.4217)  loss_bbox_dn_2: 0.2492 (0.2492)  loss_giou_dn_2: 0.8530 (0.8530)  loss_vfl_dn_3: 0.4237 (0.4237)  loss_bbox_dn_3: 0.2446 (0.2446)  loss_giou_dn_3: 0.8329 (0.8329)  loss_vfl_dn_4: 0.4227 (0.4227)  loss_bbox_dn_4: 0.2400 (0.2400)  loss_giou_dn_4: 0.8282 (0.8282)  loss_vfl_dn_5: 0.4179 (0.4179)  loss_bbox_dn_5: 0.2369 (0.2369)  loss_giou_dn_5: 0.8221 (0.8221)  time: 1.0122  data: 0.5746  max mem: 7790\n",
            "Epoch: [13]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 20.6710 (21.1361)  loss_vfl: 0.7635 (0.7932)  loss_bbox: 0.1784 (0.1890)  loss_giou: 0.6913 (0.7168)  loss_vfl_aux_0: 0.7297 (0.7350)  loss_bbox_aux_0: 0.2091 (0.2097)  loss_giou_aux_0: 0.7640 (0.7686)  loss_vfl_aux_1: 0.7380 (0.7449)  loss_bbox_aux_1: 0.1967 (0.2010)  loss_giou_aux_1: 0.7200 (0.7431)  loss_vfl_aux_2: 0.7201 (0.7502)  loss_bbox_aux_2: 0.1879 (0.1963)  loss_giou_aux_2: 0.7136 (0.7325)  loss_vfl_aux_3: 0.7285 (0.7580)  loss_bbox_aux_3: 0.1847 (0.1947)  loss_giou_aux_3: 0.7056 (0.7292)  loss_vfl_aux_4: 0.7339 (0.7746)  loss_bbox_aux_4: 0.1777 (0.1914)  loss_giou_aux_4: 0.7049 (0.7226)  loss_vfl_aux_5: 0.6559 (0.6514)  loss_bbox_aux_5: 0.2389 (0.2704)  loss_giou_aux_5: 0.8969 (0.9108)  loss_vfl_dn_0: 0.3980 (0.4027)  loss_bbox_dn_0: 0.2633 (0.2870)  loss_giou_dn_0: 1.0066 (1.0140)  loss_vfl_dn_1: 0.4216 (0.4218)  loss_bbox_dn_1: 0.2188 (0.2501)  loss_giou_dn_1: 0.8675 (0.8741)  loss_vfl_dn_2: 0.4255 (0.4277)  loss_bbox_dn_2: 0.2048 (0.2392)  loss_giou_dn_2: 0.8283 (0.8261)  loss_vfl_dn_3: 0.4306 (0.4286)  loss_bbox_dn_3: 0.2091 (0.2364)  loss_giou_dn_3: 0.8068 (0.8103)  loss_vfl_dn_4: 0.4328 (0.4302)  loss_bbox_dn_4: 0.2064 (0.2353)  loss_giou_dn_4: 0.7991 (0.8035)  loss_vfl_dn_5: 0.4332 (0.4307)  loss_bbox_dn_5: 0.2028 (0.2346)  loss_giou_dn_5: 0.7948 (0.8003)  time: 0.3242  data: 0.0151  max mem: 7790\n",
            "Epoch: [13] Total time: 0:00:11 (0.3594 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 20.6710 (21.1361)  loss_vfl: 0.7635 (0.7932)  loss_bbox: 0.1784 (0.1890)  loss_giou: 0.6913 (0.7168)  loss_vfl_aux_0: 0.7297 (0.7350)  loss_bbox_aux_0: 0.2091 (0.2097)  loss_giou_aux_0: 0.7640 (0.7686)  loss_vfl_aux_1: 0.7380 (0.7449)  loss_bbox_aux_1: 0.1967 (0.2010)  loss_giou_aux_1: 0.7200 (0.7431)  loss_vfl_aux_2: 0.7201 (0.7502)  loss_bbox_aux_2: 0.1879 (0.1963)  loss_giou_aux_2: 0.7136 (0.7325)  loss_vfl_aux_3: 0.7285 (0.7580)  loss_bbox_aux_3: 0.1847 (0.1947)  loss_giou_aux_3: 0.7056 (0.7292)  loss_vfl_aux_4: 0.7339 (0.7746)  loss_bbox_aux_4: 0.1777 (0.1914)  loss_giou_aux_4: 0.7049 (0.7226)  loss_vfl_aux_5: 0.6559 (0.6514)  loss_bbox_aux_5: 0.2389 (0.2704)  loss_giou_aux_5: 0.8969 (0.9108)  loss_vfl_dn_0: 0.3980 (0.4027)  loss_bbox_dn_0: 0.2633 (0.2870)  loss_giou_dn_0: 1.0066 (1.0140)  loss_vfl_dn_1: 0.4216 (0.4218)  loss_bbox_dn_1: 0.2188 (0.2501)  loss_giou_dn_1: 0.8675 (0.8741)  loss_vfl_dn_2: 0.4255 (0.4277)  loss_bbox_dn_2: 0.2048 (0.2392)  loss_giou_dn_2: 0.8283 (0.8261)  loss_vfl_dn_3: 0.4306 (0.4286)  loss_bbox_dn_3: 0.2091 (0.2364)  loss_giou_dn_3: 0.8068 (0.8103)  loss_vfl_dn_4: 0.4328 (0.4302)  loss_bbox_dn_4: 0.2064 (0.2353)  loss_giou_dn_4: 0.7991 (0.8035)  loss_vfl_dn_5: 0.4332 (0.4307)  loss_bbox_dn_5: 0.2028 (0.2346)  loss_giou_dn_5: 0.7948 (0.8003)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9024  data: 0.5906  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3834  data: 0.1098  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3970 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.514\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.227\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "best_stat:  {'epoch': 13, 'coco_eval_bbox': 0.25235081992687897}\n",
            "Epoch: [14]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 21.0523 (21.0523)  loss_vfl: 0.8377 (0.8377)  loss_bbox: 0.1943 (0.1943)  loss_giou: 0.6255 (0.6255)  loss_vfl_aux_0: 0.7545 (0.7545)  loss_bbox_aux_0: 0.1915 (0.1915)  loss_giou_aux_0: 0.6997 (0.6997)  loss_vfl_aux_1: 0.7722 (0.7722)  loss_bbox_aux_1: 0.1837 (0.1837)  loss_giou_aux_1: 0.6399 (0.6399)  loss_vfl_aux_2: 0.7635 (0.7635)  loss_bbox_aux_2: 0.1950 (0.1950)  loss_giou_aux_2: 0.6447 (0.6447)  loss_vfl_aux_3: 0.7864 (0.7864)  loss_bbox_aux_3: 0.1896 (0.1896)  loss_giou_aux_3: 0.6215 (0.6215)  loss_vfl_aux_4: 0.7937 (0.7937)  loss_bbox_aux_4: 0.1929 (0.1929)  loss_giou_aux_4: 0.6216 (0.6216)  loss_vfl_aux_5: 0.8234 (0.8234)  loss_bbox_aux_5: 0.2858 (0.2858)  loss_giou_aux_5: 0.8382 (0.8382)  loss_vfl_dn_0: 0.4314 (0.4314)  loss_bbox_dn_0: 0.3403 (0.3403)  loss_giou_dn_0: 0.9941 (0.9941)  loss_vfl_dn_1: 0.4605 (0.4605)  loss_bbox_dn_1: 0.2758 (0.2758)  loss_giou_dn_1: 0.8460 (0.8460)  loss_vfl_dn_2: 0.4602 (0.4602)  loss_bbox_dn_2: 0.2671 (0.2671)  loss_giou_dn_2: 0.8042 (0.8042)  loss_vfl_dn_3: 0.4591 (0.4591)  loss_bbox_dn_3: 0.2625 (0.2625)  loss_giou_dn_3: 0.7882 (0.7882)  loss_vfl_dn_4: 0.4569 (0.4569)  loss_bbox_dn_4: 0.2634 (0.2634)  loss_giou_dn_4: 0.7852 (0.7852)  loss_vfl_dn_5: 0.4559 (0.4559)  loss_bbox_dn_5: 0.2623 (0.2623)  loss_giou_dn_5: 0.7840 (0.7840)  time: 1.0609  data: 0.6337  max mem: 7790\n",
            "Epoch: [14]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 21.0411 (21.4347)  loss_vfl: 0.7179 (0.7565)  loss_bbox: 0.1840 (0.2147)  loss_giou: 0.7275 (0.7296)  loss_vfl_aux_0: 0.6971 (0.7082)  loss_bbox_aux_0: 0.2165 (0.2353)  loss_giou_aux_0: 0.7635 (0.7803)  loss_vfl_aux_1: 0.6623 (0.7214)  loss_bbox_aux_1: 0.1945 (0.2256)  loss_giou_aux_1: 0.7411 (0.7545)  loss_vfl_aux_2: 0.6847 (0.7250)  loss_bbox_aux_2: 0.1939 (0.2212)  loss_giou_aux_2: 0.7547 (0.7438)  loss_vfl_aux_3: 0.6846 (0.7291)  loss_bbox_aux_3: 0.1886 (0.2186)  loss_giou_aux_3: 0.7374 (0.7380)  loss_vfl_aux_4: 0.6958 (0.7429)  loss_bbox_aux_4: 0.1832 (0.2177)  loss_giou_aux_4: 0.7225 (0.7333)  loss_vfl_aux_5: 0.6489 (0.6178)  loss_bbox_aux_5: 0.2685 (0.3148)  loss_giou_aux_5: 0.9257 (0.9361)  loss_vfl_dn_0: 0.4008 (0.4039)  loss_bbox_dn_0: 0.3048 (0.3300)  loss_giou_dn_0: 1.0040 (1.0106)  loss_vfl_dn_1: 0.4195 (0.4199)  loss_bbox_dn_1: 0.2551 (0.2869)  loss_giou_dn_1: 0.8733 (0.8753)  loss_vfl_dn_2: 0.4235 (0.4248)  loss_bbox_dn_2: 0.2443 (0.2740)  loss_giou_dn_2: 0.8303 (0.8295)  loss_vfl_dn_3: 0.4223 (0.4280)  loss_bbox_dn_3: 0.2425 (0.2698)  loss_giou_dn_3: 0.8063 (0.8119)  loss_vfl_dn_4: 0.4257 (0.4291)  loss_bbox_dn_4: 0.2448 (0.2685)  loss_giou_dn_4: 0.7990 (0.8059)  loss_vfl_dn_5: 0.4246 (0.4295)  loss_bbox_dn_5: 0.2413 (0.2681)  loss_giou_dn_5: 0.7990 (0.8046)  time: 0.3407  data: 0.0148  max mem: 7790\n",
            "Epoch: [14] Total time: 0:00:11 (0.3570 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 21.0411 (21.4347)  loss_vfl: 0.7179 (0.7565)  loss_bbox: 0.1840 (0.2147)  loss_giou: 0.7275 (0.7296)  loss_vfl_aux_0: 0.6971 (0.7082)  loss_bbox_aux_0: 0.2165 (0.2353)  loss_giou_aux_0: 0.7635 (0.7803)  loss_vfl_aux_1: 0.6623 (0.7214)  loss_bbox_aux_1: 0.1945 (0.2256)  loss_giou_aux_1: 0.7411 (0.7545)  loss_vfl_aux_2: 0.6847 (0.7250)  loss_bbox_aux_2: 0.1939 (0.2212)  loss_giou_aux_2: 0.7547 (0.7438)  loss_vfl_aux_3: 0.6846 (0.7291)  loss_bbox_aux_3: 0.1886 (0.2186)  loss_giou_aux_3: 0.7374 (0.7380)  loss_vfl_aux_4: 0.6958 (0.7429)  loss_bbox_aux_4: 0.1832 (0.2177)  loss_giou_aux_4: 0.7225 (0.7333)  loss_vfl_aux_5: 0.6489 (0.6178)  loss_bbox_aux_5: 0.2685 (0.3148)  loss_giou_aux_5: 0.9257 (0.9361)  loss_vfl_dn_0: 0.4008 (0.4039)  loss_bbox_dn_0: 0.3048 (0.3300)  loss_giou_dn_0: 1.0040 (1.0106)  loss_vfl_dn_1: 0.4195 (0.4199)  loss_bbox_dn_1: 0.2551 (0.2869)  loss_giou_dn_1: 0.8733 (0.8753)  loss_vfl_dn_2: 0.4235 (0.4248)  loss_bbox_dn_2: 0.2443 (0.2740)  loss_giou_dn_2: 0.8303 (0.8295)  loss_vfl_dn_3: 0.4223 (0.4280)  loss_bbox_dn_3: 0.2425 (0.2698)  loss_giou_dn_3: 0.8063 (0.8119)  loss_vfl_dn_4: 0.4257 (0.4291)  loss_bbox_dn_4: 0.2448 (0.2685)  loss_giou_dn_4: 0.7990 (0.8059)  loss_vfl_dn_5: 0.4246 (0.4295)  loss_bbox_dn_5: 0.2413 (0.2681)  loss_giou_dn_5: 0.7990 (0.8046)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9223  data: 0.6077  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3901  data: 0.1126  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4043 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.481\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.381\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.236\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 13, 'coco_eval_bbox': 0.25235081992687897}\n",
            "Epoch: [15]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 20.1954 (20.1954)  loss_vfl: 0.8054 (0.8054)  loss_bbox: 0.1810 (0.1810)  loss_giou: 0.7315 (0.7315)  loss_vfl_aux_0: 0.6433 (0.6433)  loss_bbox_aux_0: 0.1790 (0.1790)  loss_giou_aux_0: 0.7692 (0.7692)  loss_vfl_aux_1: 0.6905 (0.6905)  loss_bbox_aux_1: 0.1759 (0.1759)  loss_giou_aux_1: 0.7323 (0.7323)  loss_vfl_aux_2: 0.7127 (0.7127)  loss_bbox_aux_2: 0.1600 (0.1600)  loss_giou_aux_2: 0.7161 (0.7161)  loss_vfl_aux_3: 0.7511 (0.7511)  loss_bbox_aux_3: 0.1780 (0.1780)  loss_giou_aux_3: 0.7284 (0.7284)  loss_vfl_aux_4: 0.7643 (0.7643)  loss_bbox_aux_4: 0.1737 (0.1737)  loss_giou_aux_4: 0.7170 (0.7170)  loss_vfl_aux_5: 0.5776 (0.5776)  loss_bbox_aux_5: 0.2378 (0.2378)  loss_giou_aux_5: 0.9090 (0.9090)  loss_vfl_dn_0: 0.4143 (0.4143)  loss_bbox_dn_0: 0.2546 (0.2546)  loss_giou_dn_0: 0.9849 (0.9849)  loss_vfl_dn_1: 0.4284 (0.4284)  loss_bbox_dn_1: 0.1996 (0.1996)  loss_giou_dn_1: 0.8257 (0.8257)  loss_vfl_dn_2: 0.4266 (0.4266)  loss_bbox_dn_2: 0.1847 (0.1847)  loss_giou_dn_2: 0.7862 (0.7862)  loss_vfl_dn_3: 0.4338 (0.4338)  loss_bbox_dn_3: 0.1835 (0.1835)  loss_giou_dn_3: 0.7660 (0.7660)  loss_vfl_dn_4: 0.4379 (0.4379)  loss_bbox_dn_4: 0.1809 (0.1809)  loss_giou_dn_4: 0.7619 (0.7619)  loss_vfl_dn_5: 0.4442 (0.4442)  loss_bbox_dn_5: 0.1807 (0.1807)  loss_giou_dn_5: 0.7674 (0.7674)  time: 0.9337  data: 0.5767  max mem: 7790\n",
            "Epoch: [15]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 21.0001 (21.3741)  loss_vfl: 0.7841 (0.7927)  loss_bbox: 0.1901 (0.2111)  loss_giou: 0.6802 (0.7098)  loss_vfl_aux_0: 0.7166 (0.7345)  loss_bbox_aux_0: 0.2210 (0.2365)  loss_giou_aux_0: 0.7163 (0.7691)  loss_vfl_aux_1: 0.7573 (0.7539)  loss_bbox_aux_1: 0.2222 (0.2220)  loss_giou_aux_1: 0.6911 (0.7345)  loss_vfl_aux_2: 0.7399 (0.7484)  loss_bbox_aux_2: 0.2173 (0.2188)  loss_giou_aux_2: 0.6754 (0.7276)  loss_vfl_aux_3: 0.7346 (0.7500)  loss_bbox_aux_3: 0.2025 (0.2184)  loss_giou_aux_3: 0.6875 (0.7248)  loss_vfl_aux_4: 0.7503 (0.7643)  loss_bbox_aux_4: 0.1982 (0.2141)  loss_giou_aux_4: 0.6881 (0.7169)  loss_vfl_aux_5: 0.6373 (0.6372)  loss_bbox_aux_5: 0.3171 (0.3132)  loss_giou_aux_5: 0.9139 (0.9258)  loss_vfl_dn_0: 0.4081 (0.4081)  loss_bbox_dn_0: 0.3320 (0.3257)  loss_giou_dn_0: 0.9926 (1.0028)  loss_vfl_dn_1: 0.4238 (0.4240)  loss_bbox_dn_1: 0.2589 (0.2783)  loss_giou_dn_1: 0.8536 (0.8637)  loss_vfl_dn_2: 0.4319 (0.4298)  loss_bbox_dn_2: 0.2342 (0.2641)  loss_giou_dn_2: 0.7778 (0.8134)  loss_vfl_dn_3: 0.4314 (0.4308)  loss_bbox_dn_3: 0.2325 (0.2597)  loss_giou_dn_3: 0.7608 (0.7961)  loss_vfl_dn_4: 0.4336 (0.4317)  loss_bbox_dn_4: 0.2320 (0.2576)  loss_giou_dn_4: 0.7562 (0.7886)  loss_vfl_dn_5: 0.4366 (0.4325)  loss_bbox_dn_5: 0.2292 (0.2572)  loss_giou_dn_5: 0.7537 (0.7859)  time: 0.3258  data: 0.0146  max mem: 7790\n",
            "Epoch: [15] Total time: 0:00:11 (0.3458 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 21.0001 (21.3741)  loss_vfl: 0.7841 (0.7927)  loss_bbox: 0.1901 (0.2111)  loss_giou: 0.6802 (0.7098)  loss_vfl_aux_0: 0.7166 (0.7345)  loss_bbox_aux_0: 0.2210 (0.2365)  loss_giou_aux_0: 0.7163 (0.7691)  loss_vfl_aux_1: 0.7573 (0.7539)  loss_bbox_aux_1: 0.2222 (0.2220)  loss_giou_aux_1: 0.6911 (0.7345)  loss_vfl_aux_2: 0.7399 (0.7484)  loss_bbox_aux_2: 0.2173 (0.2188)  loss_giou_aux_2: 0.6754 (0.7276)  loss_vfl_aux_3: 0.7346 (0.7500)  loss_bbox_aux_3: 0.2025 (0.2184)  loss_giou_aux_3: 0.6875 (0.7248)  loss_vfl_aux_4: 0.7503 (0.7643)  loss_bbox_aux_4: 0.1982 (0.2141)  loss_giou_aux_4: 0.6881 (0.7169)  loss_vfl_aux_5: 0.6373 (0.6372)  loss_bbox_aux_5: 0.3171 (0.3132)  loss_giou_aux_5: 0.9139 (0.9258)  loss_vfl_dn_0: 0.4081 (0.4081)  loss_bbox_dn_0: 0.3320 (0.3257)  loss_giou_dn_0: 0.9926 (1.0028)  loss_vfl_dn_1: 0.4238 (0.4240)  loss_bbox_dn_1: 0.2589 (0.2783)  loss_giou_dn_1: 0.8536 (0.8637)  loss_vfl_dn_2: 0.4319 (0.4298)  loss_bbox_dn_2: 0.2342 (0.2641)  loss_giou_dn_2: 0.7778 (0.8134)  loss_vfl_dn_3: 0.4314 (0.4308)  loss_bbox_dn_3: 0.2325 (0.2597)  loss_giou_dn_3: 0.7608 (0.7961)  loss_vfl_dn_4: 0.4336 (0.4317)  loss_bbox_dn_4: 0.2320 (0.2576)  loss_giou_dn_4: 0.7562 (0.7886)  loss_vfl_dn_5: 0.4366 (0.4325)  loss_bbox_dn_5: 0.2292 (0.2572)  loss_giou_dn_5: 0.7537 (0.7859)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8547  data: 0.5415  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3812  data: 0.1082  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3933 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.505\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.363\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n",
            "best_stat:  {'epoch': 15, 'coco_eval_bbox': 0.25408714636848434}\n",
            "Epoch: [16]  [ 0/33]  eta: 0:00:36  lr: 0.000001  loss: 21.8464 (21.8464)  loss_vfl: 0.6103 (0.6103)  loss_bbox: 0.1623 (0.1623)  loss_giou: 0.9377 (0.9377)  loss_vfl_aux_0: 0.5552 (0.5552)  loss_bbox_aux_0: 0.1929 (0.1929)  loss_giou_aux_0: 1.0157 (1.0157)  loss_vfl_aux_1: 0.5411 (0.5411)  loss_bbox_aux_1: 0.1814 (0.1814)  loss_giou_aux_1: 0.9927 (0.9927)  loss_vfl_aux_2: 0.5497 (0.5497)  loss_bbox_aux_2: 0.1748 (0.1748)  loss_giou_aux_2: 0.9729 (0.9729)  loss_vfl_aux_3: 0.5568 (0.5568)  loss_bbox_aux_3: 0.1773 (0.1773)  loss_giou_aux_3: 0.9818 (0.9818)  loss_vfl_aux_4: 0.5856 (0.5856)  loss_bbox_aux_4: 0.1744 (0.1744)  loss_giou_aux_4: 0.9563 (0.9563)  loss_vfl_aux_5: 0.4584 (0.4584)  loss_bbox_aux_5: 0.2297 (0.2297)  loss_giou_aux_5: 1.1037 (1.1037)  loss_vfl_dn_0: 0.3909 (0.3909)  loss_bbox_dn_0: 0.1665 (0.1665)  loss_giou_dn_0: 1.1192 (1.1192)  loss_vfl_dn_1: 0.3967 (0.3967)  loss_bbox_dn_1: 0.1600 (0.1600)  loss_giou_dn_1: 1.0635 (1.0635)  loss_vfl_dn_2: 0.3949 (0.3949)  loss_bbox_dn_2: 0.1603 (0.1603)  loss_giou_dn_2: 1.0557 (1.0557)  loss_vfl_dn_3: 0.3922 (0.3922)  loss_bbox_dn_3: 0.1605 (0.1605)  loss_giou_dn_3: 1.0567 (1.0567)  loss_vfl_dn_4: 0.3890 (0.3890)  loss_bbox_dn_4: 0.1621 (0.1621)  loss_giou_dn_4: 1.0574 (1.0574)  loss_vfl_dn_5: 0.3926 (0.3926)  loss_bbox_dn_5: 0.1624 (0.1624)  loss_giou_dn_5: 1.0552 (1.0552)  time: 1.1017  data: 0.7206  max mem: 7790\n",
            "Epoch: [16]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 21.2224 (21.3145)  loss_vfl: 0.7970 (0.7838)  loss_bbox: 0.1977 (0.2046)  loss_giou: 0.6787 (0.7052)  loss_vfl_aux_0: 0.7690 (0.7460)  loss_bbox_aux_0: 0.2149 (0.2249)  loss_giou_aux_0: 0.7088 (0.7521)  loss_vfl_aux_1: 0.7450 (0.7468)  loss_bbox_aux_1: 0.2035 (0.2161)  loss_giou_aux_1: 0.6739 (0.7285)  loss_vfl_aux_2: 0.7513 (0.7557)  loss_bbox_aux_2: 0.2098 (0.2127)  loss_giou_aux_2: 0.6863 (0.7200)  loss_vfl_aux_3: 0.7574 (0.7560)  loss_bbox_aux_3: 0.2039 (0.2118)  loss_giou_aux_3: 0.6748 (0.7184)  loss_vfl_aux_4: 0.7638 (0.7664)  loss_bbox_aux_4: 0.1995 (0.2099)  loss_giou_aux_4: 0.6743 (0.7124)  loss_vfl_aux_5: 0.6619 (0.6546)  loss_bbox_aux_5: 0.2949 (0.3097)  loss_giou_aux_5: 0.8955 (0.9198)  loss_vfl_dn_0: 0.4163 (0.4082)  loss_bbox_dn_0: 0.3231 (0.3291)  loss_giou_dn_0: 0.9545 (0.9988)  loss_vfl_dn_1: 0.4330 (0.4255)  loss_bbox_dn_1: 0.2593 (0.2827)  loss_giou_dn_1: 0.8041 (0.8559)  loss_vfl_dn_2: 0.4361 (0.4297)  loss_bbox_dn_2: 0.2455 (0.2689)  loss_giou_dn_2: 0.7552 (0.8084)  loss_vfl_dn_3: 0.4364 (0.4315)  loss_bbox_dn_3: 0.2407 (0.2649)  loss_giou_dn_3: 0.7439 (0.7916)  loss_vfl_dn_4: 0.4364 (0.4333)  loss_bbox_dn_4: 0.2398 (0.2633)  loss_giou_dn_4: 0.7296 (0.7865)  loss_vfl_dn_5: 0.4386 (0.4333)  loss_bbox_dn_5: 0.2393 (0.2627)  loss_giou_dn_5: 0.7284 (0.7846)  time: 0.3196  data: 0.0145  max mem: 7790\n",
            "Epoch: [16] Total time: 0:00:11 (0.3501 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 21.2224 (21.3145)  loss_vfl: 0.7970 (0.7838)  loss_bbox: 0.1977 (0.2046)  loss_giou: 0.6787 (0.7052)  loss_vfl_aux_0: 0.7690 (0.7460)  loss_bbox_aux_0: 0.2149 (0.2249)  loss_giou_aux_0: 0.7088 (0.7521)  loss_vfl_aux_1: 0.7450 (0.7468)  loss_bbox_aux_1: 0.2035 (0.2161)  loss_giou_aux_1: 0.6739 (0.7285)  loss_vfl_aux_2: 0.7513 (0.7557)  loss_bbox_aux_2: 0.2098 (0.2127)  loss_giou_aux_2: 0.6863 (0.7200)  loss_vfl_aux_3: 0.7574 (0.7560)  loss_bbox_aux_3: 0.2039 (0.2118)  loss_giou_aux_3: 0.6748 (0.7184)  loss_vfl_aux_4: 0.7638 (0.7664)  loss_bbox_aux_4: 0.1995 (0.2099)  loss_giou_aux_4: 0.6743 (0.7124)  loss_vfl_aux_5: 0.6619 (0.6546)  loss_bbox_aux_5: 0.2949 (0.3097)  loss_giou_aux_5: 0.8955 (0.9198)  loss_vfl_dn_0: 0.4163 (0.4082)  loss_bbox_dn_0: 0.3231 (0.3291)  loss_giou_dn_0: 0.9545 (0.9988)  loss_vfl_dn_1: 0.4330 (0.4255)  loss_bbox_dn_1: 0.2593 (0.2827)  loss_giou_dn_1: 0.8041 (0.8559)  loss_vfl_dn_2: 0.4361 (0.4297)  loss_bbox_dn_2: 0.2455 (0.2689)  loss_giou_dn_2: 0.7552 (0.8084)  loss_vfl_dn_3: 0.4364 (0.4315)  loss_bbox_dn_3: 0.2407 (0.2649)  loss_giou_dn_3: 0.7439 (0.7916)  loss_vfl_dn_4: 0.4364 (0.4333)  loss_bbox_dn_4: 0.2398 (0.2633)  loss_giou_dn_4: 0.7296 (0.7865)  loss_vfl_dn_5: 0.4386 (0.4333)  loss_bbox_dn_5: 0.2393 (0.2627)  loss_giou_dn_5: 0.7284 (0.7846)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9132  data: 0.5801  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4091  data: 0.1138  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4264 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.222\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.241\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "best_stat:  {'epoch': 15, 'coco_eval_bbox': 0.25408714636848434}\n",
            "Epoch: [17]  [ 0/33]  eta: 0:00:27  lr: 0.000001  loss: 25.1383 (25.1383)  loss_vfl: 0.7270 (0.7270)  loss_bbox: 0.3065 (0.3065)  loss_giou: 0.9048 (0.9048)  loss_vfl_aux_0: 0.6376 (0.6376)  loss_bbox_aux_0: 0.4266 (0.4266)  loss_giou_aux_0: 0.9964 (0.9964)  loss_vfl_aux_1: 0.6686 (0.6686)  loss_bbox_aux_1: 0.3825 (0.3825)  loss_giou_aux_1: 0.9534 (0.9534)  loss_vfl_aux_2: 0.7172 (0.7172)  loss_bbox_aux_2: 0.3601 (0.3601)  loss_giou_aux_2: 0.9314 (0.9314)  loss_vfl_aux_3: 0.7330 (0.7330)  loss_bbox_aux_3: 0.3216 (0.3216)  loss_giou_aux_3: 0.9242 (0.9242)  loss_vfl_aux_4: 0.7199 (0.7199)  loss_bbox_aux_4: 0.3217 (0.3217)  loss_giou_aux_4: 0.9252 (0.9252)  loss_vfl_aux_5: 0.5206 (0.5206)  loss_bbox_aux_5: 0.6059 (0.6059)  loss_giou_aux_5: 1.1817 (1.1817)  loss_vfl_dn_0: 0.3853 (0.3853)  loss_bbox_dn_0: 0.4861 (0.4861)  loss_giou_dn_0: 1.0639 (1.0639)  loss_vfl_dn_1: 0.3834 (0.3834)  loss_bbox_dn_1: 0.4293 (0.4293)  loss_giou_dn_1: 0.9904 (0.9904)  loss_vfl_dn_2: 0.3842 (0.3842)  loss_bbox_dn_2: 0.4184 (0.4184)  loss_giou_dn_2: 0.9748 (0.9748)  loss_vfl_dn_3: 0.3802 (0.3802)  loss_bbox_dn_3: 0.4193 (0.4193)  loss_giou_dn_3: 0.9838 (0.9838)  loss_vfl_dn_4: 0.3773 (0.3773)  loss_bbox_dn_4: 0.4187 (0.4187)  loss_giou_dn_4: 0.9882 (0.9882)  loss_vfl_dn_5: 0.3725 (0.3725)  loss_bbox_dn_5: 0.4184 (0.4184)  loss_giou_dn_5: 0.9981 (0.9981)  time: 0.8423  data: 0.4797  max mem: 7790\n",
            "Epoch: [17]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 21.0796 (21.2986)  loss_vfl: 0.7495 (0.7534)  loss_bbox: 0.1929 (0.2187)  loss_giou: 0.6633 (0.7142)  loss_vfl_aux_0: 0.7304 (0.7334)  loss_bbox_aux_0: 0.2258 (0.2414)  loss_giou_aux_0: 0.7409 (0.7646)  loss_vfl_aux_1: 0.7173 (0.7290)  loss_bbox_aux_1: 0.2103 (0.2285)  loss_giou_aux_1: 0.6910 (0.7344)  loss_vfl_aux_2: 0.7320 (0.7371)  loss_bbox_aux_2: 0.2085 (0.2238)  loss_giou_aux_2: 0.6971 (0.7248)  loss_vfl_aux_3: 0.7183 (0.7383)  loss_bbox_aux_3: 0.2026 (0.2207)  loss_giou_aux_3: 0.6813 (0.7215)  loss_vfl_aux_4: 0.7177 (0.7471)  loss_bbox_aux_4: 0.1994 (0.2203)  loss_giou_aux_4: 0.6706 (0.7173)  loss_vfl_aux_5: 0.6563 (0.6450)  loss_bbox_aux_5: 0.3146 (0.3237)  loss_giou_aux_5: 0.8933 (0.9230)  loss_vfl_dn_0: 0.4176 (0.4117)  loss_bbox_dn_0: 0.3218 (0.3287)  loss_giou_dn_0: 0.9585 (0.9840)  loss_vfl_dn_1: 0.4367 (0.4257)  loss_bbox_dn_1: 0.2690 (0.2829)  loss_giou_dn_1: 0.8131 (0.8481)  loss_vfl_dn_2: 0.4388 (0.4294)  loss_bbox_dn_2: 0.2607 (0.2709)  loss_giou_dn_2: 0.7811 (0.8032)  loss_vfl_dn_3: 0.4410 (0.4316)  loss_bbox_dn_3: 0.2455 (0.2673)  loss_giou_dn_3: 0.7675 (0.7888)  loss_vfl_dn_4: 0.4395 (0.4333)  loss_bbox_dn_4: 0.2446 (0.2662)  loss_giou_dn_4: 0.7719 (0.7844)  loss_vfl_dn_5: 0.4404 (0.4334)  loss_bbox_dn_5: 0.2464 (0.2662)  loss_giou_dn_5: 0.7731 (0.7827)  time: 0.3205  data: 0.0138  max mem: 7790\n",
            "Epoch: [17] Total time: 0:00:11 (0.3414 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 21.0796 (21.2986)  loss_vfl: 0.7495 (0.7534)  loss_bbox: 0.1929 (0.2187)  loss_giou: 0.6633 (0.7142)  loss_vfl_aux_0: 0.7304 (0.7334)  loss_bbox_aux_0: 0.2258 (0.2414)  loss_giou_aux_0: 0.7409 (0.7646)  loss_vfl_aux_1: 0.7173 (0.7290)  loss_bbox_aux_1: 0.2103 (0.2285)  loss_giou_aux_1: 0.6910 (0.7344)  loss_vfl_aux_2: 0.7320 (0.7371)  loss_bbox_aux_2: 0.2085 (0.2238)  loss_giou_aux_2: 0.6971 (0.7248)  loss_vfl_aux_3: 0.7183 (0.7383)  loss_bbox_aux_3: 0.2026 (0.2207)  loss_giou_aux_3: 0.6813 (0.7215)  loss_vfl_aux_4: 0.7177 (0.7471)  loss_bbox_aux_4: 0.1994 (0.2203)  loss_giou_aux_4: 0.6706 (0.7173)  loss_vfl_aux_5: 0.6563 (0.6450)  loss_bbox_aux_5: 0.3146 (0.3237)  loss_giou_aux_5: 0.8933 (0.9230)  loss_vfl_dn_0: 0.4176 (0.4117)  loss_bbox_dn_0: 0.3218 (0.3287)  loss_giou_dn_0: 0.9585 (0.9840)  loss_vfl_dn_1: 0.4367 (0.4257)  loss_bbox_dn_1: 0.2690 (0.2829)  loss_giou_dn_1: 0.8131 (0.8481)  loss_vfl_dn_2: 0.4388 (0.4294)  loss_bbox_dn_2: 0.2607 (0.2709)  loss_giou_dn_2: 0.7811 (0.8032)  loss_vfl_dn_3: 0.4410 (0.4316)  loss_bbox_dn_3: 0.2455 (0.2673)  loss_giou_dn_3: 0.7675 (0.7888)  loss_vfl_dn_4: 0.4395 (0.4333)  loss_bbox_dn_4: 0.2446 (0.2662)  loss_giou_dn_4: 0.7719 (0.7844)  loss_vfl_dn_5: 0.4404 (0.4334)  loss_bbox_dn_5: 0.2464 (0.2662)  loss_giou_dn_5: 0.7731 (0.7827)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8504  data: 0.5385  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4323  data: 0.1097  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4454 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.536\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "best_stat:  {'epoch': 17, 'coco_eval_bbox': 0.26258013047175033}\n",
            "Epoch: [18]  [ 0/33]  eta: 0:00:29  lr: 0.000001  loss: 22.1583 (22.1583)  loss_vfl: 0.7562 (0.7562)  loss_bbox: 0.1889 (0.1889)  loss_giou: 0.8215 (0.8215)  loss_vfl_aux_0: 0.6710 (0.6710)  loss_bbox_aux_0: 0.2281 (0.2281)  loss_giou_aux_0: 0.8852 (0.8852)  loss_vfl_aux_1: 0.6826 (0.6826)  loss_bbox_aux_1: 0.2038 (0.2038)  loss_giou_aux_1: 0.8424 (0.8424)  loss_vfl_aux_2: 0.7012 (0.7012)  loss_bbox_aux_2: 0.2117 (0.2117)  loss_giou_aux_2: 0.8449 (0.8449)  loss_vfl_aux_3: 0.7321 (0.7321)  loss_bbox_aux_3: 0.2158 (0.2158)  loss_giou_aux_3: 0.8520 (0.8520)  loss_vfl_aux_4: 0.7273 (0.7273)  loss_bbox_aux_4: 0.2218 (0.2218)  loss_giou_aux_4: 0.8566 (0.8566)  loss_vfl_aux_5: 0.5718 (0.5718)  loss_bbox_aux_5: 0.2987 (0.2987)  loss_giou_aux_5: 1.0039 (1.0039)  loss_vfl_dn_0: 0.4008 (0.4008)  loss_bbox_dn_0: 0.2795 (0.2795)  loss_giou_dn_0: 1.0837 (1.0837)  loss_vfl_dn_1: 0.4150 (0.4150)  loss_bbox_dn_1: 0.2375 (0.2375)  loss_giou_dn_1: 0.9650 (0.9650)  loss_vfl_dn_2: 0.4344 (0.4344)  loss_bbox_dn_2: 0.2340 (0.2340)  loss_giou_dn_2: 0.9046 (0.9046)  loss_vfl_dn_3: 0.4393 (0.4393)  loss_bbox_dn_3: 0.2306 (0.2306)  loss_giou_dn_3: 0.8963 (0.8963)  loss_vfl_dn_4: 0.4429 (0.4429)  loss_bbox_dn_4: 0.2287 (0.2287)  loss_giou_dn_4: 0.8905 (0.8905)  loss_vfl_dn_5: 0.4344 (0.4344)  loss_bbox_dn_5: 0.2276 (0.2276)  loss_giou_dn_5: 0.8961 (0.8961)  time: 0.9046  data: 0.5278  max mem: 7790\n",
            "Epoch: [18]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 20.7746 (20.9067)  loss_vfl: 0.7337 (0.7369)  loss_bbox: 0.1976 (0.2014)  loss_giou: 0.7038 (0.7201)  loss_vfl_aux_0: 0.6970 (0.7108)  loss_bbox_aux_0: 0.2244 (0.2240)  loss_giou_aux_0: 0.7521 (0.7747)  loss_vfl_aux_1: 0.6973 (0.7201)  loss_bbox_aux_1: 0.2000 (0.2085)  loss_giou_aux_1: 0.7163 (0.7443)  loss_vfl_aux_2: 0.6997 (0.7187)  loss_bbox_aux_2: 0.2130 (0.2049)  loss_giou_aux_2: 0.7160 (0.7322)  loss_vfl_aux_3: 0.7239 (0.7201)  loss_bbox_aux_3: 0.1958 (0.2040)  loss_giou_aux_3: 0.7070 (0.7280)  loss_vfl_aux_4: 0.7418 (0.7269)  loss_bbox_aux_4: 0.1978 (0.2040)  loss_giou_aux_4: 0.6976 (0.7239)  loss_vfl_aux_5: 0.6276 (0.6325)  loss_bbox_aux_5: 0.2622 (0.2840)  loss_giou_aux_5: 0.9019 (0.9173)  loss_vfl_dn_0: 0.4172 (0.4114)  loss_bbox_dn_0: 0.2879 (0.2894)  loss_giou_dn_0: 0.9728 (0.9929)  loss_vfl_dn_1: 0.4296 (0.4255)  loss_bbox_dn_1: 0.2353 (0.2488)  loss_giou_dn_1: 0.8183 (0.8523)  loss_vfl_dn_2: 0.4337 (0.4287)  loss_bbox_dn_2: 0.2252 (0.2382)  loss_giou_dn_2: 0.7719 (0.8088)  loss_vfl_dn_3: 0.4327 (0.4286)  loss_bbox_dn_3: 0.2200 (0.2351)  loss_giou_dn_3: 0.7542 (0.7965)  loss_vfl_dn_4: 0.4325 (0.4295)  loss_bbox_dn_4: 0.2206 (0.2342)  loss_giou_dn_4: 0.7512 (0.7926)  loss_vfl_dn_5: 0.4318 (0.4304)  loss_bbox_dn_5: 0.2215 (0.2342)  loss_giou_dn_5: 0.7506 (0.7924)  time: 0.3171  data: 0.0136  max mem: 7790\n",
            "Epoch: [18] Total time: 0:00:11 (0.3404 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 20.7746 (20.9067)  loss_vfl: 0.7337 (0.7369)  loss_bbox: 0.1976 (0.2014)  loss_giou: 0.7038 (0.7201)  loss_vfl_aux_0: 0.6970 (0.7108)  loss_bbox_aux_0: 0.2244 (0.2240)  loss_giou_aux_0: 0.7521 (0.7747)  loss_vfl_aux_1: 0.6973 (0.7201)  loss_bbox_aux_1: 0.2000 (0.2085)  loss_giou_aux_1: 0.7163 (0.7443)  loss_vfl_aux_2: 0.6997 (0.7187)  loss_bbox_aux_2: 0.2130 (0.2049)  loss_giou_aux_2: 0.7160 (0.7322)  loss_vfl_aux_3: 0.7239 (0.7201)  loss_bbox_aux_3: 0.1958 (0.2040)  loss_giou_aux_3: 0.7070 (0.7280)  loss_vfl_aux_4: 0.7418 (0.7269)  loss_bbox_aux_4: 0.1978 (0.2040)  loss_giou_aux_4: 0.6976 (0.7239)  loss_vfl_aux_5: 0.6276 (0.6325)  loss_bbox_aux_5: 0.2622 (0.2840)  loss_giou_aux_5: 0.9019 (0.9173)  loss_vfl_dn_0: 0.4172 (0.4114)  loss_bbox_dn_0: 0.2879 (0.2894)  loss_giou_dn_0: 0.9728 (0.9929)  loss_vfl_dn_1: 0.4296 (0.4255)  loss_bbox_dn_1: 0.2353 (0.2488)  loss_giou_dn_1: 0.8183 (0.8523)  loss_vfl_dn_2: 0.4337 (0.4287)  loss_bbox_dn_2: 0.2252 (0.2382)  loss_giou_dn_2: 0.7719 (0.8088)  loss_vfl_dn_3: 0.4327 (0.4286)  loss_bbox_dn_3: 0.2200 (0.2351)  loss_giou_dn_3: 0.7542 (0.7965)  loss_vfl_dn_4: 0.4325 (0.4295)  loss_bbox_dn_4: 0.2206 (0.2342)  loss_giou_dn_4: 0.7512 (0.7926)  loss_vfl_dn_5: 0.4318 (0.4304)  loss_bbox_dn_5: 0.2215 (0.2342)  loss_giou_dn_5: 0.7506 (0.7924)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8712  data: 0.5588  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4380  data: 0.1087  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4517 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.553\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            "best_stat:  {'epoch': 18, 'coco_eval_bbox': 0.2634608624189968}\n",
            "Epoch: [19]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 20.2598 (20.2598)  loss_vfl: 0.8333 (0.8333)  loss_bbox: 0.1899 (0.1899)  loss_giou: 0.5113 (0.5113)  loss_vfl_aux_0: 0.8261 (0.8261)  loss_bbox_aux_0: 0.2411 (0.2411)  loss_giou_aux_0: 0.6359 (0.6359)  loss_vfl_aux_1: 0.7804 (0.7804)  loss_bbox_aux_1: 0.2187 (0.2187)  loss_giou_aux_1: 0.5888 (0.5888)  loss_vfl_aux_2: 0.7748 (0.7748)  loss_bbox_aux_2: 0.2063 (0.2063)  loss_giou_aux_2: 0.5619 (0.5619)  loss_vfl_aux_3: 0.7876 (0.7876)  loss_bbox_aux_3: 0.2012 (0.2012)  loss_giou_aux_3: 0.5420 (0.5420)  loss_vfl_aux_4: 0.8069 (0.8069)  loss_bbox_aux_4: 0.1946 (0.1946)  loss_giou_aux_4: 0.5261 (0.5261)  loss_vfl_aux_5: 0.6968 (0.6968)  loss_bbox_aux_5: 0.3265 (0.3265)  loss_giou_aux_5: 0.8112 (0.8112)  loss_vfl_dn_0: 0.4331 (0.4331)  loss_bbox_dn_0: 0.4003 (0.4003)  loss_giou_dn_0: 0.9099 (0.9099)  loss_vfl_dn_1: 0.4451 (0.4451)  loss_bbox_dn_1: 0.3477 (0.3477)  loss_giou_dn_1: 0.7524 (0.7524)  loss_vfl_dn_2: 0.4403 (0.4403)  loss_bbox_dn_2: 0.3285 (0.3285)  loss_giou_dn_2: 0.6961 (0.6961)  loss_vfl_dn_3: 0.4413 (0.4413)  loss_bbox_dn_3: 0.3167 (0.3167)  loss_giou_dn_3: 0.6676 (0.6676)  loss_vfl_dn_4: 0.4368 (0.4368)  loss_bbox_dn_4: 0.3146 (0.3146)  loss_giou_dn_4: 0.6600 (0.6600)  loss_vfl_dn_5: 0.4399 (0.4399)  loss_bbox_dn_5: 0.3130 (0.3130)  loss_giou_dn_5: 0.6549 (0.6549)  time: 1.0767  data: 0.7159  max mem: 7790\n",
            "Epoch: [19]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 20.0989 (20.4458)  loss_vfl: 0.7203 (0.7292)  loss_bbox: 0.1676 (0.1827)  loss_giou: 0.6956 (0.6986)  loss_vfl_aux_0: 0.7384 (0.7183)  loss_bbox_aux_0: 0.1807 (0.2027)  loss_giou_aux_0: 0.7719 (0.7489)  loss_vfl_aux_1: 0.7047 (0.7123)  loss_bbox_aux_1: 0.1752 (0.1935)  loss_giou_aux_1: 0.7233 (0.7223)  loss_vfl_aux_2: 0.6828 (0.7077)  loss_bbox_aux_2: 0.1736 (0.1891)  loss_giou_aux_2: 0.7164 (0.7125)  loss_vfl_aux_3: 0.6963 (0.7138)  loss_bbox_aux_3: 0.1662 (0.1855)  loss_giou_aux_3: 0.7008 (0.7045)  loss_vfl_aux_4: 0.7159 (0.7184)  loss_bbox_aux_4: 0.1662 (0.1834)  loss_giou_aux_4: 0.7055 (0.7008)  loss_vfl_aux_5: 0.6452 (0.6458)  loss_bbox_aux_5: 0.2413 (0.2635)  loss_giou_aux_5: 0.8905 (0.8966)  loss_vfl_dn_0: 0.4107 (0.4089)  loss_bbox_dn_0: 0.2470 (0.2823)  loss_giou_dn_0: 0.9829 (0.9795)  loss_vfl_dn_1: 0.4185 (0.4232)  loss_bbox_dn_1: 0.2050 (0.2415)  loss_giou_dn_1: 0.8384 (0.8395)  loss_vfl_dn_2: 0.4243 (0.4271)  loss_bbox_dn_2: 0.1948 (0.2297)  loss_giou_dn_2: 0.7756 (0.7965)  loss_vfl_dn_3: 0.4232 (0.4300)  loss_bbox_dn_3: 0.1996 (0.2256)  loss_giou_dn_3: 0.7530 (0.7781)  loss_vfl_dn_4: 0.4304 (0.4303)  loss_bbox_dn_4: 0.1977 (0.2248)  loss_giou_dn_4: 0.7433 (0.7725)  loss_vfl_dn_5: 0.4322 (0.4309)  loss_bbox_dn_5: 0.1980 (0.2245)  loss_giou_dn_5: 0.7380 (0.7710)  time: 0.3218  data: 0.0144  max mem: 7790\n",
            "Epoch: [19] Total time: 0:00:11 (0.3489 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 20.0989 (20.4458)  loss_vfl: 0.7203 (0.7292)  loss_bbox: 0.1676 (0.1827)  loss_giou: 0.6956 (0.6986)  loss_vfl_aux_0: 0.7384 (0.7183)  loss_bbox_aux_0: 0.1807 (0.2027)  loss_giou_aux_0: 0.7719 (0.7489)  loss_vfl_aux_1: 0.7047 (0.7123)  loss_bbox_aux_1: 0.1752 (0.1935)  loss_giou_aux_1: 0.7233 (0.7223)  loss_vfl_aux_2: 0.6828 (0.7077)  loss_bbox_aux_2: 0.1736 (0.1891)  loss_giou_aux_2: 0.7164 (0.7125)  loss_vfl_aux_3: 0.6963 (0.7138)  loss_bbox_aux_3: 0.1662 (0.1855)  loss_giou_aux_3: 0.7008 (0.7045)  loss_vfl_aux_4: 0.7159 (0.7184)  loss_bbox_aux_4: 0.1662 (0.1834)  loss_giou_aux_4: 0.7055 (0.7008)  loss_vfl_aux_5: 0.6452 (0.6458)  loss_bbox_aux_5: 0.2413 (0.2635)  loss_giou_aux_5: 0.8905 (0.8966)  loss_vfl_dn_0: 0.4107 (0.4089)  loss_bbox_dn_0: 0.2470 (0.2823)  loss_giou_dn_0: 0.9829 (0.9795)  loss_vfl_dn_1: 0.4185 (0.4232)  loss_bbox_dn_1: 0.2050 (0.2415)  loss_giou_dn_1: 0.8384 (0.8395)  loss_vfl_dn_2: 0.4243 (0.4271)  loss_bbox_dn_2: 0.1948 (0.2297)  loss_giou_dn_2: 0.7756 (0.7965)  loss_vfl_dn_3: 0.4232 (0.4300)  loss_bbox_dn_3: 0.1996 (0.2256)  loss_giou_dn_3: 0.7530 (0.7781)  loss_vfl_dn_4: 0.4304 (0.4303)  loss_bbox_dn_4: 0.1977 (0.2248)  loss_giou_dn_4: 0.7433 (0.7725)  loss_vfl_dn_5: 0.4322 (0.4309)  loss_bbox_dn_5: 0.1980 (0.2245)  loss_giou_dn_5: 0.7380 (0.7710)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8605  data: 0.5477  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3776  data: 0.1056  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3907 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.526\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 18, 'coco_eval_bbox': 0.2634608624189968}\n",
            "Epoch: [20]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 18.2976 (18.2976)  loss_vfl: 0.6809 (0.6809)  loss_bbox: 0.1019 (0.1019)  loss_giou: 0.6958 (0.6958)  loss_vfl_aux_0: 0.6366 (0.6366)  loss_bbox_aux_0: 0.1588 (0.1588)  loss_giou_aux_0: 0.7908 (0.7908)  loss_vfl_aux_1: 0.6326 (0.6326)  loss_bbox_aux_1: 0.1216 (0.1216)  loss_giou_aux_1: 0.7477 (0.7477)  loss_vfl_aux_2: 0.6022 (0.6022)  loss_bbox_aux_2: 0.1158 (0.1158)  loss_giou_aux_2: 0.7394 (0.7394)  loss_vfl_aux_3: 0.6295 (0.6295)  loss_bbox_aux_3: 0.1102 (0.1102)  loss_giou_aux_3: 0.7253 (0.7253)  loss_vfl_aux_4: 0.6680 (0.6680)  loss_bbox_aux_4: 0.1071 (0.1071)  loss_giou_aux_4: 0.6975 (0.6975)  loss_vfl_aux_5: 0.5930 (0.5930)  loss_bbox_aux_5: 0.1840 (0.1840)  loss_giou_aux_5: 0.8864 (0.8864)  loss_vfl_dn_0: 0.4163 (0.4163)  loss_bbox_dn_0: 0.1832 (0.1832)  loss_giou_dn_0: 0.8938 (0.8938)  loss_vfl_dn_1: 0.4115 (0.4115)  loss_bbox_dn_1: 0.1355 (0.1355)  loss_giou_dn_1: 0.7667 (0.7667)  loss_vfl_dn_2: 0.4041 (0.4041)  loss_bbox_dn_2: 0.1184 (0.1184)  loss_giou_dn_2: 0.7197 (0.7197)  loss_vfl_dn_3: 0.3991 (0.3991)  loss_bbox_dn_3: 0.1131 (0.1131)  loss_giou_dn_3: 0.7076 (0.7076)  loss_vfl_dn_4: 0.3983 (0.3983)  loss_bbox_dn_4: 0.1107 (0.1107)  loss_giou_dn_4: 0.6964 (0.6964)  loss_vfl_dn_5: 0.3954 (0.3954)  loss_bbox_dn_5: 0.1087 (0.1087)  loss_giou_dn_5: 0.6939 (0.6939)  time: 0.9658  data: 0.5838  max mem: 7790\n",
            "Epoch: [20]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 20.1539 (20.5577)  loss_vfl: 0.7314 (0.7409)  loss_bbox: 0.1668 (0.1774)  loss_giou: 0.6737 (0.7139)  loss_vfl_aux_0: 0.6987 (0.7024)  loss_bbox_aux_0: 0.1877 (0.1982)  loss_giou_aux_0: 0.6988 (0.7671)  loss_vfl_aux_1: 0.6976 (0.7127)  loss_bbox_aux_1: 0.1759 (0.1882)  loss_giou_aux_1: 0.7026 (0.7381)  loss_vfl_aux_2: 0.7091 (0.7037)  loss_bbox_aux_2: 0.1732 (0.1863)  loss_giou_aux_2: 0.6707 (0.7336)  loss_vfl_aux_3: 0.7188 (0.7146)  loss_bbox_aux_3: 0.1721 (0.1828)  loss_giou_aux_3: 0.6728 (0.7251)  loss_vfl_aux_4: 0.7224 (0.7251)  loss_bbox_aux_4: 0.1735 (0.1805)  loss_giou_aux_4: 0.6809 (0.7216)  loss_vfl_aux_5: 0.6208 (0.6426)  loss_bbox_aux_5: 0.2452 (0.2540)  loss_giou_aux_5: 0.9104 (0.9044)  loss_vfl_dn_0: 0.4129 (0.4121)  loss_bbox_dn_0: 0.2631 (0.2769)  loss_giou_dn_0: 0.9746 (0.9856)  loss_vfl_dn_1: 0.4271 (0.4290)  loss_bbox_dn_1: 0.2195 (0.2366)  loss_giou_dn_1: 0.8290 (0.8459)  loss_vfl_dn_2: 0.4279 (0.4307)  loss_bbox_dn_2: 0.2070 (0.2246)  loss_giou_dn_2: 0.7806 (0.8014)  loss_vfl_dn_3: 0.4332 (0.4303)  loss_bbox_dn_3: 0.2014 (0.2210)  loss_giou_dn_3: 0.7627 (0.7864)  loss_vfl_dn_4: 0.4368 (0.4313)  loss_bbox_dn_4: 0.2033 (0.2200)  loss_giou_dn_4: 0.7630 (0.7820)  loss_vfl_dn_5: 0.4388 (0.4305)  loss_bbox_dn_5: 0.2022 (0.2195)  loss_giou_dn_5: 0.7543 (0.7808)  time: 0.3211  data: 0.0153  max mem: 7790\n",
            "Epoch: [20] Total time: 0:00:11 (0.3534 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 20.1539 (20.5577)  loss_vfl: 0.7314 (0.7409)  loss_bbox: 0.1668 (0.1774)  loss_giou: 0.6737 (0.7139)  loss_vfl_aux_0: 0.6987 (0.7024)  loss_bbox_aux_0: 0.1877 (0.1982)  loss_giou_aux_0: 0.6988 (0.7671)  loss_vfl_aux_1: 0.6976 (0.7127)  loss_bbox_aux_1: 0.1759 (0.1882)  loss_giou_aux_1: 0.7026 (0.7381)  loss_vfl_aux_2: 0.7091 (0.7037)  loss_bbox_aux_2: 0.1732 (0.1863)  loss_giou_aux_2: 0.6707 (0.7336)  loss_vfl_aux_3: 0.7188 (0.7146)  loss_bbox_aux_3: 0.1721 (0.1828)  loss_giou_aux_3: 0.6728 (0.7251)  loss_vfl_aux_4: 0.7224 (0.7251)  loss_bbox_aux_4: 0.1735 (0.1805)  loss_giou_aux_4: 0.6809 (0.7216)  loss_vfl_aux_5: 0.6208 (0.6426)  loss_bbox_aux_5: 0.2452 (0.2540)  loss_giou_aux_5: 0.9104 (0.9044)  loss_vfl_dn_0: 0.4129 (0.4121)  loss_bbox_dn_0: 0.2631 (0.2769)  loss_giou_dn_0: 0.9746 (0.9856)  loss_vfl_dn_1: 0.4271 (0.4290)  loss_bbox_dn_1: 0.2195 (0.2366)  loss_giou_dn_1: 0.8290 (0.8459)  loss_vfl_dn_2: 0.4279 (0.4307)  loss_bbox_dn_2: 0.2070 (0.2246)  loss_giou_dn_2: 0.7806 (0.8014)  loss_vfl_dn_3: 0.4332 (0.4303)  loss_bbox_dn_3: 0.2014 (0.2210)  loss_giou_dn_3: 0.7627 (0.7864)  loss_vfl_dn_4: 0.4368 (0.4313)  loss_bbox_dn_4: 0.2033 (0.2200)  loss_giou_dn_4: 0.7630 (0.7820)  loss_vfl_dn_5: 0.4388 (0.4305)  loss_bbox_dn_5: 0.2022 (0.2195)  loss_giou_dn_5: 0.7543 (0.7808)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9030  data: 0.5803  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3874  data: 0.1115  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4027 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.569\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641\n",
            "best_stat:  {'epoch': 20, 'coco_eval_bbox': 0.2738383829622292}\n",
            "Epoch: [21]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 21.2758 (21.2758)  loss_vfl: 0.6051 (0.6051)  loss_bbox: 0.1346 (0.1346)  loss_giou: 0.9822 (0.9822)  loss_vfl_aux_0: 0.6144 (0.6144)  loss_bbox_aux_0: 0.1388 (0.1388)  loss_giou_aux_0: 0.9947 (0.9947)  loss_vfl_aux_1: 0.6251 (0.6251)  loss_bbox_aux_1: 0.1347 (0.1347)  loss_giou_aux_1: 0.9731 (0.9731)  loss_vfl_aux_2: 0.5822 (0.5822)  loss_bbox_aux_2: 0.1394 (0.1394)  loss_giou_aux_2: 0.9852 (0.9852)  loss_vfl_aux_3: 0.5970 (0.5970)  loss_bbox_aux_3: 0.1361 (0.1361)  loss_giou_aux_3: 0.9857 (0.9857)  loss_vfl_aux_4: 0.6059 (0.6059)  loss_bbox_aux_4: 0.1345 (0.1345)  loss_giou_aux_4: 0.9756 (0.9756)  loss_vfl_aux_5: 0.4666 (0.4666)  loss_bbox_aux_5: 0.1786 (0.1786)  loss_giou_aux_5: 1.1254 (1.1254)  loss_vfl_dn_0: 0.3881 (0.3881)  loss_bbox_dn_0: 0.1509 (0.1509)  loss_giou_dn_0: 1.1166 (1.1166)  loss_vfl_dn_1: 0.3979 (0.3979)  loss_bbox_dn_1: 0.1359 (0.1359)  loss_giou_dn_1: 0.9977 (0.9977)  loss_vfl_dn_2: 0.4008 (0.4008)  loss_bbox_dn_2: 0.1343 (0.1343)  loss_giou_dn_2: 0.9535 (0.9535)  loss_vfl_dn_3: 0.4041 (0.4041)  loss_bbox_dn_3: 0.1355 (0.1355)  loss_giou_dn_3: 0.9462 (0.9462)  loss_vfl_dn_4: 0.4069 (0.4069)  loss_bbox_dn_4: 0.1374 (0.1374)  loss_giou_dn_4: 0.9506 (0.9506)  loss_vfl_dn_5: 0.4128 (0.4128)  loss_bbox_dn_5: 0.1389 (0.1389)  loss_giou_dn_5: 0.9527 (0.9527)  time: 1.0784  data: 0.6916  max mem: 7790\n",
            "Epoch: [21]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 20.0563 (20.2412)  loss_vfl: 0.7229 (0.7372)  loss_bbox: 0.1840 (0.1867)  loss_giou: 0.6300 (0.6823)  loss_vfl_aux_0: 0.7271 (0.7172)  loss_bbox_aux_0: 0.1867 (0.2099)  loss_giou_aux_0: 0.6807 (0.7308)  loss_vfl_aux_1: 0.6875 (0.6992)  loss_bbox_aux_1: 0.1913 (0.1991)  loss_giou_aux_1: 0.6683 (0.7102)  loss_vfl_aux_2: 0.6944 (0.7032)  loss_bbox_aux_2: 0.1870 (0.1947)  loss_giou_aux_2: 0.6476 (0.6984)  loss_vfl_aux_3: 0.6897 (0.7216)  loss_bbox_aux_3: 0.1860 (0.1906)  loss_giou_aux_3: 0.6451 (0.6898)  loss_vfl_aux_4: 0.7232 (0.7306)  loss_bbox_aux_4: 0.1875 (0.1877)  loss_giou_aux_4: 0.6370 (0.6834)  loss_vfl_aux_5: 0.6684 (0.6383)  loss_bbox_aux_5: 0.2525 (0.2713)  loss_giou_aux_5: 0.8082 (0.8781)  loss_vfl_dn_0: 0.4242 (0.4192)  loss_bbox_dn_0: 0.2971 (0.2934)  loss_giou_dn_0: 0.9179 (0.9423)  loss_vfl_dn_1: 0.4346 (0.4305)  loss_bbox_dn_1: 0.2570 (0.2496)  loss_giou_dn_1: 0.7718 (0.7985)  loss_vfl_dn_2: 0.4342 (0.4321)  loss_bbox_dn_2: 0.2481 (0.2380)  loss_giou_dn_2: 0.7396 (0.7539)  loss_vfl_dn_3: 0.4374 (0.4347)  loss_bbox_dn_3: 0.2474 (0.2351)  loss_giou_dn_3: 0.7300 (0.7412)  loss_vfl_dn_4: 0.4391 (0.4357)  loss_bbox_dn_4: 0.2437 (0.2341)  loss_giou_dn_4: 0.7251 (0.7364)  loss_vfl_dn_5: 0.4448 (0.4372)  loss_bbox_dn_5: 0.2408 (0.2341)  loss_giou_dn_5: 0.7227 (0.7349)  time: 0.3343  data: 0.0148  max mem: 7790\n",
            "Epoch: [21] Total time: 0:00:11 (0.3578 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 20.0563 (20.2412)  loss_vfl: 0.7229 (0.7372)  loss_bbox: 0.1840 (0.1867)  loss_giou: 0.6300 (0.6823)  loss_vfl_aux_0: 0.7271 (0.7172)  loss_bbox_aux_0: 0.1867 (0.2099)  loss_giou_aux_0: 0.6807 (0.7308)  loss_vfl_aux_1: 0.6875 (0.6992)  loss_bbox_aux_1: 0.1913 (0.1991)  loss_giou_aux_1: 0.6683 (0.7102)  loss_vfl_aux_2: 0.6944 (0.7032)  loss_bbox_aux_2: 0.1870 (0.1947)  loss_giou_aux_2: 0.6476 (0.6984)  loss_vfl_aux_3: 0.6897 (0.7216)  loss_bbox_aux_3: 0.1860 (0.1906)  loss_giou_aux_3: 0.6451 (0.6898)  loss_vfl_aux_4: 0.7232 (0.7306)  loss_bbox_aux_4: 0.1875 (0.1877)  loss_giou_aux_4: 0.6370 (0.6834)  loss_vfl_aux_5: 0.6684 (0.6383)  loss_bbox_aux_5: 0.2525 (0.2713)  loss_giou_aux_5: 0.8082 (0.8781)  loss_vfl_dn_0: 0.4242 (0.4192)  loss_bbox_dn_0: 0.2971 (0.2934)  loss_giou_dn_0: 0.9179 (0.9423)  loss_vfl_dn_1: 0.4346 (0.4305)  loss_bbox_dn_1: 0.2570 (0.2496)  loss_giou_dn_1: 0.7718 (0.7985)  loss_vfl_dn_2: 0.4342 (0.4321)  loss_bbox_dn_2: 0.2481 (0.2380)  loss_giou_dn_2: 0.7396 (0.7539)  loss_vfl_dn_3: 0.4374 (0.4347)  loss_bbox_dn_3: 0.2474 (0.2351)  loss_giou_dn_3: 0.7300 (0.7412)  loss_vfl_dn_4: 0.4391 (0.4357)  loss_bbox_dn_4: 0.2437 (0.2341)  loss_giou_dn_4: 0.7251 (0.7364)  loss_vfl_dn_5: 0.4448 (0.4372)  loss_bbox_dn_5: 0.2408 (0.2341)  loss_giou_dn_5: 0.7227 (0.7349)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9037  data: 0.5879  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3847  data: 0.1096  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3971 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.266\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.536\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.240\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n",
            "best_stat:  {'epoch': 20, 'coco_eval_bbox': 0.2738383829622292}\n",
            "Epoch: [22]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 22.9276 (22.9276)  loss_vfl: 0.9190 (0.9190)  loss_bbox: 0.2472 (0.2472)  loss_giou: 0.7793 (0.7793)  loss_vfl_aux_0: 0.8340 (0.8340)  loss_bbox_aux_0: 0.3647 (0.3647)  loss_giou_aux_0: 0.9456 (0.9456)  loss_vfl_aux_1: 0.8290 (0.8290)  loss_bbox_aux_1: 0.2372 (0.2372)  loss_giou_aux_1: 0.8280 (0.8280)  loss_vfl_aux_2: 0.8152 (0.8152)  loss_bbox_aux_2: 0.2478 (0.2478)  loss_giou_aux_2: 0.7954 (0.7954)  loss_vfl_aux_3: 0.8591 (0.8591)  loss_bbox_aux_3: 0.2385 (0.2385)  loss_giou_aux_3: 0.7762 (0.7762)  loss_vfl_aux_4: 0.8913 (0.8913)  loss_bbox_aux_4: 0.2291 (0.2291)  loss_giou_aux_4: 0.7659 (0.7659)  loss_vfl_aux_5: 0.7350 (0.7350)  loss_bbox_aux_5: 0.3592 (0.3592)  loss_giou_aux_5: 1.0521 (1.0521)  loss_vfl_dn_0: 0.4066 (0.4066)  loss_bbox_dn_0: 0.3186 (0.3186)  loss_giou_dn_0: 0.9866 (0.9866)  loss_vfl_dn_1: 0.4115 (0.4115)  loss_bbox_dn_1: 0.2768 (0.2768)  loss_giou_dn_1: 0.8557 (0.8557)  loss_vfl_dn_2: 0.4126 (0.4126)  loss_bbox_dn_2: 0.2642 (0.2642)  loss_giou_dn_2: 0.8075 (0.8075)  loss_vfl_dn_3: 0.4132 (0.4132)  loss_bbox_dn_3: 0.2627 (0.2627)  loss_giou_dn_3: 0.8001 (0.8001)  loss_vfl_dn_4: 0.4138 (0.4138)  loss_bbox_dn_4: 0.2629 (0.2629)  loss_giou_dn_4: 0.8005 (0.8005)  loss_vfl_dn_5: 0.4184 (0.4184)  loss_bbox_dn_5: 0.2633 (0.2633)  loss_giou_dn_5: 0.8035 (0.8035)  time: 0.9751  data: 0.5700  max mem: 7790\n",
            "Epoch: [22]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 20.3260 (20.5115)  loss_vfl: 0.7538 (0.7657)  loss_bbox: 0.2070 (0.2023)  loss_giou: 0.6440 (0.6614)  loss_vfl_aux_0: 0.7167 (0.7360)  loss_bbox_aux_0: 0.2244 (0.2233)  loss_giou_aux_0: 0.7190 (0.7154)  loss_vfl_aux_1: 0.7322 (0.7240)  loss_bbox_aux_1: 0.2211 (0.2113)  loss_giou_aux_1: 0.6546 (0.6920)  loss_vfl_aux_2: 0.7227 (0.7397)  loss_bbox_aux_2: 0.2036 (0.2037)  loss_giou_aux_2: 0.6503 (0.6759)  loss_vfl_aux_3: 0.7313 (0.7501)  loss_bbox_aux_3: 0.1988 (0.2014)  loss_giou_aux_3: 0.6439 (0.6661)  loss_vfl_aux_4: 0.7514 (0.7608)  loss_bbox_aux_4: 0.2095 (0.2005)  loss_giou_aux_4: 0.6461 (0.6618)  loss_vfl_aux_5: 0.6687 (0.6760)  loss_bbox_aux_5: 0.2931 (0.2855)  loss_giou_aux_5: 0.8303 (0.8506)  loss_vfl_dn_0: 0.4251 (0.4207)  loss_bbox_dn_0: 0.3419 (0.3280)  loss_giou_dn_0: 0.9270 (0.9402)  loss_vfl_dn_1: 0.4358 (0.4318)  loss_bbox_dn_1: 0.2825 (0.2770)  loss_giou_dn_1: 0.7963 (0.7975)  loss_vfl_dn_2: 0.4337 (0.4337)  loss_bbox_dn_2: 0.2671 (0.2621)  loss_giou_dn_2: 0.7482 (0.7524)  loss_vfl_dn_3: 0.4372 (0.4367)  loss_bbox_dn_3: 0.2617 (0.2565)  loss_giou_dn_3: 0.7367 (0.7350)  loss_vfl_dn_4: 0.4382 (0.4370)  loss_bbox_dn_4: 0.2591 (0.2542)  loss_giou_dn_4: 0.7247 (0.7281)  loss_vfl_dn_5: 0.4399 (0.4376)  loss_bbox_dn_5: 0.2557 (0.2535)  loss_giou_dn_5: 0.7226 (0.7257)  time: 0.3237  data: 0.0136  max mem: 7790\n",
            "Epoch: [22] Total time: 0:00:11 (0.3484 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 20.3260 (20.5115)  loss_vfl: 0.7538 (0.7657)  loss_bbox: 0.2070 (0.2023)  loss_giou: 0.6440 (0.6614)  loss_vfl_aux_0: 0.7167 (0.7360)  loss_bbox_aux_0: 0.2244 (0.2233)  loss_giou_aux_0: 0.7190 (0.7154)  loss_vfl_aux_1: 0.7322 (0.7240)  loss_bbox_aux_1: 0.2211 (0.2113)  loss_giou_aux_1: 0.6546 (0.6920)  loss_vfl_aux_2: 0.7227 (0.7397)  loss_bbox_aux_2: 0.2036 (0.2037)  loss_giou_aux_2: 0.6503 (0.6759)  loss_vfl_aux_3: 0.7313 (0.7501)  loss_bbox_aux_3: 0.1988 (0.2014)  loss_giou_aux_3: 0.6439 (0.6661)  loss_vfl_aux_4: 0.7514 (0.7608)  loss_bbox_aux_4: 0.2095 (0.2005)  loss_giou_aux_4: 0.6461 (0.6618)  loss_vfl_aux_5: 0.6687 (0.6760)  loss_bbox_aux_5: 0.2931 (0.2855)  loss_giou_aux_5: 0.8303 (0.8506)  loss_vfl_dn_0: 0.4251 (0.4207)  loss_bbox_dn_0: 0.3419 (0.3280)  loss_giou_dn_0: 0.9270 (0.9402)  loss_vfl_dn_1: 0.4358 (0.4318)  loss_bbox_dn_1: 0.2825 (0.2770)  loss_giou_dn_1: 0.7963 (0.7975)  loss_vfl_dn_2: 0.4337 (0.4337)  loss_bbox_dn_2: 0.2671 (0.2621)  loss_giou_dn_2: 0.7482 (0.7524)  loss_vfl_dn_3: 0.4372 (0.4367)  loss_bbox_dn_3: 0.2617 (0.2565)  loss_giou_dn_3: 0.7367 (0.7350)  loss_vfl_dn_4: 0.4382 (0.4370)  loss_bbox_dn_4: 0.2591 (0.2542)  loss_giou_dn_4: 0.7247 (0.7281)  loss_vfl_dn_5: 0.4399 (0.4376)  loss_bbox_dn_5: 0.2557 (0.2535)  loss_giou_dn_5: 0.7226 (0.7257)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8571  data: 0.5423  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3890  data: 0.1130  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4039 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.535\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
            "best_stat:  {'epoch': 20, 'coco_eval_bbox': 0.2738383829622292}\n",
            "Epoch: [23]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 24.1273 (24.1273)  loss_vfl: 0.9908 (0.9908)  loss_bbox: 0.3590 (0.3590)  loss_giou: 0.6357 (0.6357)  loss_vfl_aux_0: 0.8765 (0.8765)  loss_bbox_aux_0: 0.3607 (0.3607)  loss_giou_aux_0: 0.6693 (0.6693)  loss_vfl_aux_1: 0.8974 (0.8974)  loss_bbox_aux_1: 0.3675 (0.3675)  loss_giou_aux_1: 0.6579 (0.6579)  loss_vfl_aux_2: 0.9570 (0.9570)  loss_bbox_aux_2: 0.3585 (0.3585)  loss_giou_aux_2: 0.6437 (0.6437)  loss_vfl_aux_3: 0.9567 (0.9567)  loss_bbox_aux_3: 0.3676 (0.3676)  loss_giou_aux_3: 0.6490 (0.6490)  loss_vfl_aux_4: 0.9798 (0.9798)  loss_bbox_aux_4: 0.3602 (0.3602)  loss_giou_aux_4: 0.6406 (0.6406)  loss_vfl_aux_5: 0.8429 (0.8429)  loss_bbox_aux_5: 0.4238 (0.4238)  loss_giou_aux_5: 0.7138 (0.7138)  loss_vfl_dn_0: 0.4390 (0.4390)  loss_bbox_dn_0: 0.5440 (0.5440)  loss_giou_dn_0: 0.9412 (0.9412)  loss_vfl_dn_1: 0.4729 (0.4729)  loss_bbox_dn_1: 0.4813 (0.4813)  loss_giou_dn_1: 0.8028 (0.8028)  loss_vfl_dn_2: 0.4736 (0.4736)  loss_bbox_dn_2: 0.4602 (0.4602)  loss_giou_dn_2: 0.7697 (0.7697)  loss_vfl_dn_3: 0.4684 (0.4684)  loss_bbox_dn_3: 0.4528 (0.4528)  loss_giou_dn_3: 0.7548 (0.7548)  loss_vfl_dn_4: 0.4776 (0.4776)  loss_bbox_dn_4: 0.4521 (0.4521)  loss_giou_dn_4: 0.7472 (0.7472)  loss_vfl_dn_5: 0.4860 (0.4860)  loss_bbox_dn_5: 0.4518 (0.4518)  loss_giou_dn_5: 0.7436 (0.7436)  time: 1.0502  data: 0.6499  max mem: 7790\n",
            "Epoch: [23]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 19.8384 (20.3422)  loss_vfl: 0.7166 (0.7313)  loss_bbox: 0.1688 (0.1900)  loss_giou: 0.6861 (0.6948)  loss_vfl_aux_0: 0.7048 (0.7053)  loss_bbox_aux_0: 0.1801 (0.2027)  loss_giou_aux_0: 0.7321 (0.7353)  loss_vfl_aux_1: 0.6885 (0.7105)  loss_bbox_aux_1: 0.1740 (0.1964)  loss_giou_aux_1: 0.7007 (0.7163)  loss_vfl_aux_2: 0.7065 (0.7125)  loss_bbox_aux_2: 0.1816 (0.1936)  loss_giou_aux_2: 0.6976 (0.7077)  loss_vfl_aux_3: 0.7121 (0.7181)  loss_bbox_aux_3: 0.1726 (0.1896)  loss_giou_aux_3: 0.6838 (0.7002)  loss_vfl_aux_4: 0.7080 (0.7258)  loss_bbox_aux_4: 0.1730 (0.1899)  loss_giou_aux_4: 0.6870 (0.6968)  loss_vfl_aux_5: 0.6460 (0.6537)  loss_bbox_aux_5: 0.2272 (0.2505)  loss_giou_aux_5: 0.8211 (0.8537)  loss_vfl_dn_0: 0.4193 (0.4176)  loss_bbox_dn_0: 0.2620 (0.2825)  loss_giou_dn_0: 0.9488 (0.9568)  loss_vfl_dn_1: 0.4292 (0.4313)  loss_bbox_dn_1: 0.2243 (0.2395)  loss_giou_dn_1: 0.8176 (0.8195)  loss_vfl_dn_2: 0.4371 (0.4352)  loss_bbox_dn_2: 0.2074 (0.2297)  loss_giou_dn_2: 0.7699 (0.7801)  loss_vfl_dn_3: 0.4363 (0.4339)  loss_bbox_dn_3: 0.2026 (0.2267)  loss_giou_dn_3: 0.7537 (0.7677)  loss_vfl_dn_4: 0.4405 (0.4358)  loss_bbox_dn_4: 0.1973 (0.2264)  loss_giou_dn_4: 0.7537 (0.7625)  loss_vfl_dn_5: 0.4385 (0.4349)  loss_bbox_dn_5: 0.1971 (0.2261)  loss_giou_dn_5: 0.7606 (0.7614)  time: 0.3261  data: 0.0139  max mem: 7790\n",
            "Epoch: [23] Total time: 0:00:11 (0.3505 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 19.8384 (20.3422)  loss_vfl: 0.7166 (0.7313)  loss_bbox: 0.1688 (0.1900)  loss_giou: 0.6861 (0.6948)  loss_vfl_aux_0: 0.7048 (0.7053)  loss_bbox_aux_0: 0.1801 (0.2027)  loss_giou_aux_0: 0.7321 (0.7353)  loss_vfl_aux_1: 0.6885 (0.7105)  loss_bbox_aux_1: 0.1740 (0.1964)  loss_giou_aux_1: 0.7007 (0.7163)  loss_vfl_aux_2: 0.7065 (0.7125)  loss_bbox_aux_2: 0.1816 (0.1936)  loss_giou_aux_2: 0.6976 (0.7077)  loss_vfl_aux_3: 0.7121 (0.7181)  loss_bbox_aux_3: 0.1726 (0.1896)  loss_giou_aux_3: 0.6838 (0.7002)  loss_vfl_aux_4: 0.7080 (0.7258)  loss_bbox_aux_4: 0.1730 (0.1899)  loss_giou_aux_4: 0.6870 (0.6968)  loss_vfl_aux_5: 0.6460 (0.6537)  loss_bbox_aux_5: 0.2272 (0.2505)  loss_giou_aux_5: 0.8211 (0.8537)  loss_vfl_dn_0: 0.4193 (0.4176)  loss_bbox_dn_0: 0.2620 (0.2825)  loss_giou_dn_0: 0.9488 (0.9568)  loss_vfl_dn_1: 0.4292 (0.4313)  loss_bbox_dn_1: 0.2243 (0.2395)  loss_giou_dn_1: 0.8176 (0.8195)  loss_vfl_dn_2: 0.4371 (0.4352)  loss_bbox_dn_2: 0.2074 (0.2297)  loss_giou_dn_2: 0.7699 (0.7801)  loss_vfl_dn_3: 0.4363 (0.4339)  loss_bbox_dn_3: 0.2026 (0.2267)  loss_giou_dn_3: 0.7537 (0.7677)  loss_vfl_dn_4: 0.4405 (0.4358)  loss_bbox_dn_4: 0.1973 (0.2264)  loss_giou_dn_4: 0.7537 (0.7625)  loss_vfl_dn_5: 0.4385 (0.4349)  loss_bbox_dn_5: 0.1971 (0.2261)  loss_giou_dn_5: 0.7606 (0.7614)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8611  data: 0.5401  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3951  data: 0.1130  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4075 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.551\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.225\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.386\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641\n",
            "best_stat:  {'epoch': 20, 'coco_eval_bbox': 0.2738383829622292}\n",
            "Epoch: [24]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 20.9990 (20.9990)  loss_vfl: 0.8085 (0.8085)  loss_bbox: 0.2641 (0.2641)  loss_giou: 0.6647 (0.6647)  loss_vfl_aux_0: 0.8098 (0.8098)  loss_bbox_aux_0: 0.2840 (0.2840)  loss_giou_aux_0: 0.7262 (0.7262)  loss_vfl_aux_1: 0.7798 (0.7798)  loss_bbox_aux_1: 0.2693 (0.2693)  loss_giou_aux_1: 0.6658 (0.6658)  loss_vfl_aux_2: 0.7827 (0.7827)  loss_bbox_aux_2: 0.2635 (0.2635)  loss_giou_aux_2: 0.6601 (0.6601)  loss_vfl_aux_3: 0.7895 (0.7895)  loss_bbox_aux_3: 0.2575 (0.2575)  loss_giou_aux_3: 0.6575 (0.6575)  loss_vfl_aux_4: 0.8030 (0.8030)  loss_bbox_aux_4: 0.2663 (0.2663)  loss_giou_aux_4: 0.6658 (0.6658)  loss_vfl_aux_5: 0.6821 (0.6821)  loss_bbox_aux_5: 0.4023 (0.4023)  loss_giou_aux_5: 0.9024 (0.9024)  loss_vfl_dn_0: 0.4126 (0.4126)  loss_bbox_dn_0: 0.4033 (0.4033)  loss_giou_dn_0: 0.9255 (0.9255)  loss_vfl_dn_1: 0.4266 (0.4266)  loss_bbox_dn_1: 0.3180 (0.3180)  loss_giou_dn_1: 0.7407 (0.7407)  loss_vfl_dn_2: 0.4318 (0.4318)  loss_bbox_dn_2: 0.2851 (0.2851)  loss_giou_dn_2: 0.6609 (0.6609)  loss_vfl_dn_3: 0.4317 (0.4317)  loss_bbox_dn_3: 0.2741 (0.2741)  loss_giou_dn_3: 0.6371 (0.6371)  loss_vfl_dn_4: 0.4312 (0.4312)  loss_bbox_dn_4: 0.2672 (0.2672)  loss_giou_dn_4: 0.6250 (0.6250)  loss_vfl_dn_5: 0.4323 (0.4323)  loss_bbox_dn_5: 0.2661 (0.2661)  loss_giou_dn_5: 0.6247 (0.6247)  time: 0.9831  data: 0.5869  max mem: 7790\n",
            "Epoch: [24]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 20.0659 (20.1861)  loss_vfl: 0.7424 (0.7426)  loss_bbox: 0.1769 (0.1958)  loss_giou: 0.6539 (0.6548)  loss_vfl_aux_0: 0.7342 (0.7298)  loss_bbox_aux_0: 0.1903 (0.2078)  loss_giou_aux_0: 0.6756 (0.6925)  loss_vfl_aux_1: 0.7275 (0.7238)  loss_bbox_aux_1: 0.1771 (0.1986)  loss_giou_aux_1: 0.6455 (0.6713)  loss_vfl_aux_2: 0.7242 (0.7280)  loss_bbox_aux_2: 0.1726 (0.1944)  loss_giou_aux_2: 0.6454 (0.6622)  loss_vfl_aux_3: 0.7189 (0.7317)  loss_bbox_aux_3: 0.1815 (0.1974)  loss_giou_aux_3: 0.6439 (0.6618)  loss_vfl_aux_4: 0.7355 (0.7385)  loss_bbox_aux_4: 0.1749 (0.1973)  loss_giou_aux_4: 0.6527 (0.6578)  loss_vfl_aux_5: 0.6866 (0.6807)  loss_bbox_aux_5: 0.2549 (0.2662)  loss_giou_aux_5: 0.7645 (0.8152)  loss_vfl_dn_0: 0.4153 (0.4214)  loss_bbox_dn_0: 0.3034 (0.3146)  loss_giou_dn_0: 0.9120 (0.9353)  loss_vfl_dn_1: 0.4284 (0.4326)  loss_bbox_dn_1: 0.2575 (0.2652)  loss_giou_dn_1: 0.7671 (0.7913)  loss_vfl_dn_2: 0.4345 (0.4354)  loss_bbox_dn_2: 0.2493 (0.2521)  loss_giou_dn_2: 0.7528 (0.7456)  loss_vfl_dn_3: 0.4335 (0.4365)  loss_bbox_dn_3: 0.2488 (0.2489)  loss_giou_dn_3: 0.7385 (0.7345)  loss_vfl_dn_4: 0.4324 (0.4378)  loss_bbox_dn_4: 0.2491 (0.2475)  loss_giou_dn_4: 0.7289 (0.7288)  loss_vfl_dn_5: 0.4330 (0.4367)  loss_bbox_dn_5: 0.2472 (0.2471)  loss_giou_dn_5: 0.7246 (0.7267)  time: 0.3250  data: 0.0152  max mem: 7790\n",
            "Epoch: [24] Total time: 0:00:11 (0.3494 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 20.0659 (20.1861)  loss_vfl: 0.7424 (0.7426)  loss_bbox: 0.1769 (0.1958)  loss_giou: 0.6539 (0.6548)  loss_vfl_aux_0: 0.7342 (0.7298)  loss_bbox_aux_0: 0.1903 (0.2078)  loss_giou_aux_0: 0.6756 (0.6925)  loss_vfl_aux_1: 0.7275 (0.7238)  loss_bbox_aux_1: 0.1771 (0.1986)  loss_giou_aux_1: 0.6455 (0.6713)  loss_vfl_aux_2: 0.7242 (0.7280)  loss_bbox_aux_2: 0.1726 (0.1944)  loss_giou_aux_2: 0.6454 (0.6622)  loss_vfl_aux_3: 0.7189 (0.7317)  loss_bbox_aux_3: 0.1815 (0.1974)  loss_giou_aux_3: 0.6439 (0.6618)  loss_vfl_aux_4: 0.7355 (0.7385)  loss_bbox_aux_4: 0.1749 (0.1973)  loss_giou_aux_4: 0.6527 (0.6578)  loss_vfl_aux_5: 0.6866 (0.6807)  loss_bbox_aux_5: 0.2549 (0.2662)  loss_giou_aux_5: 0.7645 (0.8152)  loss_vfl_dn_0: 0.4153 (0.4214)  loss_bbox_dn_0: 0.3034 (0.3146)  loss_giou_dn_0: 0.9120 (0.9353)  loss_vfl_dn_1: 0.4284 (0.4326)  loss_bbox_dn_1: 0.2575 (0.2652)  loss_giou_dn_1: 0.7671 (0.7913)  loss_vfl_dn_2: 0.4345 (0.4354)  loss_bbox_dn_2: 0.2493 (0.2521)  loss_giou_dn_2: 0.7528 (0.7456)  loss_vfl_dn_3: 0.4335 (0.4365)  loss_bbox_dn_3: 0.2488 (0.2489)  loss_giou_dn_3: 0.7385 (0.7345)  loss_vfl_dn_4: 0.4324 (0.4378)  loss_bbox_dn_4: 0.2491 (0.2475)  loss_giou_dn_4: 0.7289 (0.7288)  loss_vfl_dn_5: 0.4330 (0.4367)  loss_bbox_dn_5: 0.2472 (0.2471)  loss_giou_dn_5: 0.7246 (0.7267)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8770  data: 0.5643  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4498  data: 0.1128  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4634 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.563\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.247\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.440\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            "best_stat:  {'epoch': 24, 'coco_eval_bbox': 0.27527456550247376}\n",
            "Epoch: [25]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 19.7098 (19.7098)  loss_vfl: 0.7494 (0.7494)  loss_bbox: 0.2044 (0.2044)  loss_giou: 0.5551 (0.5551)  loss_vfl_aux_0: 0.7810 (0.7810)  loss_bbox_aux_0: 0.2139 (0.2139)  loss_giou_aux_0: 0.6032 (0.6032)  loss_vfl_aux_1: 0.7415 (0.7415)  loss_bbox_aux_1: 0.2147 (0.2147)  loss_giou_aux_1: 0.5976 (0.5976)  loss_vfl_aux_2: 0.7368 (0.7368)  loss_bbox_aux_2: 0.2155 (0.2155)  loss_giou_aux_2: 0.5867 (0.5867)  loss_vfl_aux_3: 0.7167 (0.7167)  loss_bbox_aux_3: 0.2128 (0.2128)  loss_giou_aux_3: 0.5769 (0.5769)  loss_vfl_aux_4: 0.7505 (0.7505)  loss_bbox_aux_4: 0.2074 (0.2074)  loss_giou_aux_4: 0.5549 (0.5549)  loss_vfl_aux_5: 0.6999 (0.6999)  loss_bbox_aux_5: 0.2495 (0.2495)  loss_giou_aux_5: 0.7103 (0.7103)  loss_vfl_dn_0: 0.4297 (0.4297)  loss_bbox_dn_0: 0.3174 (0.3174)  loss_giou_dn_0: 0.9167 (0.9167)  loss_vfl_dn_1: 0.4416 (0.4416)  loss_bbox_dn_1: 0.2842 (0.2842)  loss_giou_dn_1: 0.7712 (0.7712)  loss_vfl_dn_2: 0.4470 (0.4470)  loss_bbox_dn_2: 0.2726 (0.2726)  loss_giou_dn_2: 0.7226 (0.7226)  loss_vfl_dn_3: 0.4514 (0.4514)  loss_bbox_dn_3: 0.2669 (0.2669)  loss_giou_dn_3: 0.6962 (0.6962)  loss_vfl_dn_4: 0.4581 (0.4581)  loss_bbox_dn_4: 0.2657 (0.2657)  loss_giou_dn_4: 0.6841 (0.6841)  loss_vfl_dn_5: 0.4626 (0.4626)  loss_bbox_dn_5: 0.2649 (0.2649)  loss_giou_dn_5: 0.6781 (0.6781)  time: 1.0233  data: 0.6271  max mem: 7790\n",
            "Epoch: [25]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 19.6333 (19.6844)  loss_vfl: 0.6989 (0.7183)  loss_bbox: 0.1621 (0.1789)  loss_giou: 0.5990 (0.6367)  loss_vfl_aux_0: 0.7071 (0.7225)  loss_bbox_aux_0: 0.1783 (0.1929)  loss_giou_aux_0: 0.6594 (0.6908)  loss_vfl_aux_1: 0.6980 (0.7011)  loss_bbox_aux_1: 0.1721 (0.1856)  loss_giou_aux_1: 0.6221 (0.6677)  loss_vfl_aux_2: 0.6903 (0.7034)  loss_bbox_aux_2: 0.1699 (0.1827)  loss_giou_aux_2: 0.6222 (0.6495)  loss_vfl_aux_3: 0.6981 (0.7000)  loss_bbox_aux_3: 0.1679 (0.1829)  loss_giou_aux_3: 0.6035 (0.6439)  loss_vfl_aux_4: 0.6988 (0.7114)  loss_bbox_aux_4: 0.1619 (0.1813)  loss_giou_aux_4: 0.5901 (0.6398)  loss_vfl_aux_5: 0.6657 (0.6862)  loss_bbox_aux_5: 0.2370 (0.2481)  loss_giou_aux_5: 0.7926 (0.8073)  loss_vfl_dn_0: 0.4222 (0.4202)  loss_bbox_dn_0: 0.2831 (0.2873)  loss_giou_dn_0: 0.9061 (0.9390)  loss_vfl_dn_1: 0.4322 (0.4326)  loss_bbox_dn_1: 0.2328 (0.2455)  loss_giou_dn_1: 0.7538 (0.7887)  loss_vfl_dn_2: 0.4369 (0.4351)  loss_bbox_dn_2: 0.2165 (0.2334)  loss_giou_dn_2: 0.7013 (0.7337)  loss_vfl_dn_3: 0.4357 (0.4359)  loss_bbox_dn_3: 0.2113 (0.2302)  loss_giou_dn_3: 0.6832 (0.7143)  loss_vfl_dn_4: 0.4381 (0.4381)  loss_bbox_dn_4: 0.2089 (0.2300)  loss_giou_dn_4: 0.6768 (0.7110)  loss_vfl_dn_5: 0.4376 (0.4393)  loss_bbox_dn_5: 0.2093 (0.2298)  loss_giou_dn_5: 0.6738 (0.7091)  time: 0.3395  data: 0.0154  max mem: 7790\n",
            "Epoch: [25] Total time: 0:00:11 (0.3600 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 19.6333 (19.6844)  loss_vfl: 0.6989 (0.7183)  loss_bbox: 0.1621 (0.1789)  loss_giou: 0.5990 (0.6367)  loss_vfl_aux_0: 0.7071 (0.7225)  loss_bbox_aux_0: 0.1783 (0.1929)  loss_giou_aux_0: 0.6594 (0.6908)  loss_vfl_aux_1: 0.6980 (0.7011)  loss_bbox_aux_1: 0.1721 (0.1856)  loss_giou_aux_1: 0.6221 (0.6677)  loss_vfl_aux_2: 0.6903 (0.7034)  loss_bbox_aux_2: 0.1699 (0.1827)  loss_giou_aux_2: 0.6222 (0.6495)  loss_vfl_aux_3: 0.6981 (0.7000)  loss_bbox_aux_3: 0.1679 (0.1829)  loss_giou_aux_3: 0.6035 (0.6439)  loss_vfl_aux_4: 0.6988 (0.7114)  loss_bbox_aux_4: 0.1619 (0.1813)  loss_giou_aux_4: 0.5901 (0.6398)  loss_vfl_aux_5: 0.6657 (0.6862)  loss_bbox_aux_5: 0.2370 (0.2481)  loss_giou_aux_5: 0.7926 (0.8073)  loss_vfl_dn_0: 0.4222 (0.4202)  loss_bbox_dn_0: 0.2831 (0.2873)  loss_giou_dn_0: 0.9061 (0.9390)  loss_vfl_dn_1: 0.4322 (0.4326)  loss_bbox_dn_1: 0.2328 (0.2455)  loss_giou_dn_1: 0.7538 (0.7887)  loss_vfl_dn_2: 0.4369 (0.4351)  loss_bbox_dn_2: 0.2165 (0.2334)  loss_giou_dn_2: 0.7013 (0.7337)  loss_vfl_dn_3: 0.4357 (0.4359)  loss_bbox_dn_3: 0.2113 (0.2302)  loss_giou_dn_3: 0.6832 (0.7143)  loss_vfl_dn_4: 0.4381 (0.4381)  loss_bbox_dn_4: 0.2089 (0.2300)  loss_giou_dn_4: 0.6768 (0.7110)  loss_vfl_dn_5: 0.4376 (0.4393)  loss_bbox_dn_5: 0.2093 (0.2298)  loss_giou_dn_5: 0.6738 (0.7091)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8560  data: 0.5427  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3834  data: 0.1108  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3967 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.554\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.361\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n",
            "best_stat:  {'epoch': 24, 'coco_eval_bbox': 0.27527456550247376}\n",
            "Epoch: [26]  [ 0/33]  eta: 0:00:52  lr: 0.000001  loss: 19.2208 (19.2208)  loss_vfl: 0.6728 (0.6728)  loss_bbox: 0.1378 (0.1378)  loss_giou: 0.6659 (0.6659)  loss_vfl_aux_0: 0.6625 (0.6625)  loss_bbox_aux_0: 0.1775 (0.1775)  loss_giou_aux_0: 0.7485 (0.7485)  loss_vfl_aux_1: 0.6782 (0.6782)  loss_bbox_aux_1: 0.1474 (0.1474)  loss_giou_aux_1: 0.6920 (0.6920)  loss_vfl_aux_2: 0.6934 (0.6934)  loss_bbox_aux_2: 0.1407 (0.1407)  loss_giou_aux_2: 0.6526 (0.6526)  loss_vfl_aux_3: 0.6836 (0.6836)  loss_bbox_aux_3: 0.1383 (0.1383)  loss_giou_aux_3: 0.6582 (0.6582)  loss_vfl_aux_4: 0.6775 (0.6775)  loss_bbox_aux_4: 0.1382 (0.1382)  loss_giou_aux_4: 0.6605 (0.6605)  loss_vfl_aux_5: 0.6239 (0.6239)  loss_bbox_aux_5: 0.2005 (0.2005)  loss_giou_aux_5: 0.8693 (0.8693)  loss_vfl_dn_0: 0.4175 (0.4175)  loss_bbox_dn_0: 0.2243 (0.2243)  loss_giou_dn_0: 0.9644 (0.9644)  loss_vfl_dn_1: 0.4479 (0.4479)  loss_bbox_dn_1: 0.1844 (0.1844)  loss_giou_dn_1: 0.8003 (0.8003)  loss_vfl_dn_2: 0.4557 (0.4557)  loss_bbox_dn_2: 0.1759 (0.1759)  loss_giou_dn_2: 0.7382 (0.7382)  loss_vfl_dn_3: 0.4577 (0.4577)  loss_bbox_dn_3: 0.1738 (0.1738)  loss_giou_dn_3: 0.7350 (0.7350)  loss_vfl_dn_4: 0.4576 (0.4576)  loss_bbox_dn_4: 0.1745 (0.1745)  loss_giou_dn_4: 0.7325 (0.7325)  loss_vfl_dn_5: 0.4541 (0.4541)  loss_bbox_dn_5: 0.1750 (0.1750)  loss_giou_dn_5: 0.7325 (0.7325)  time: 1.5820  data: 1.1540  max mem: 7790\n",
            "Epoch: [26]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 19.3661 (19.8898)  loss_vfl: 0.6890 (0.7173)  loss_bbox: 0.1620 (0.1921)  loss_giou: 0.7076 (0.6724)  loss_vfl_aux_0: 0.7020 (0.6991)  loss_bbox_aux_0: 0.1781 (0.2032)  loss_giou_aux_0: 0.7199 (0.7168)  loss_vfl_aux_1: 0.6713 (0.6887)  loss_bbox_aux_1: 0.1676 (0.1923)  loss_giou_aux_1: 0.6929 (0.6942)  loss_vfl_aux_2: 0.6673 (0.6967)  loss_bbox_aux_2: 0.1674 (0.1936)  loss_giou_aux_2: 0.6735 (0.6824)  loss_vfl_aux_3: 0.6729 (0.6972)  loss_bbox_aux_3: 0.1605 (0.1919)  loss_giou_aux_3: 0.6696 (0.6775)  loss_vfl_aux_4: 0.6891 (0.7137)  loss_bbox_aux_4: 0.1618 (0.1906)  loss_giou_aux_4: 0.6980 (0.6734)  loss_vfl_aux_5: 0.6456 (0.6571)  loss_bbox_aux_5: 0.2223 (0.2580)  loss_giou_aux_5: 0.8329 (0.8386)  loss_vfl_dn_0: 0.4221 (0.4214)  loss_bbox_dn_0: 0.2416 (0.2910)  loss_giou_dn_0: 0.9353 (0.9294)  loss_vfl_dn_1: 0.4315 (0.4318)  loss_bbox_dn_1: 0.2024 (0.2430)  loss_giou_dn_1: 0.7650 (0.7872)  loss_vfl_dn_2: 0.4337 (0.4348)  loss_bbox_dn_2: 0.1920 (0.2285)  loss_giou_dn_2: 0.7258 (0.7400)  loss_vfl_dn_3: 0.4359 (0.4360)  loss_bbox_dn_3: 0.1890 (0.2237)  loss_giou_dn_3: 0.7150 (0.7241)  loss_vfl_dn_4: 0.4371 (0.4367)  loss_bbox_dn_4: 0.1877 (0.2221)  loss_giou_dn_4: 0.7100 (0.7186)  loss_vfl_dn_5: 0.4359 (0.4365)  loss_bbox_dn_5: 0.1872 (0.2213)  loss_giou_dn_5: 0.7041 (0.7166)  time: 0.3243  data: 0.0160  max mem: 7790\n",
            "Epoch: [26] Total time: 0:00:12 (0.3638 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 19.3661 (19.8898)  loss_vfl: 0.6890 (0.7173)  loss_bbox: 0.1620 (0.1921)  loss_giou: 0.7076 (0.6724)  loss_vfl_aux_0: 0.7020 (0.6991)  loss_bbox_aux_0: 0.1781 (0.2032)  loss_giou_aux_0: 0.7199 (0.7168)  loss_vfl_aux_1: 0.6713 (0.6887)  loss_bbox_aux_1: 0.1676 (0.1923)  loss_giou_aux_1: 0.6929 (0.6942)  loss_vfl_aux_2: 0.6673 (0.6967)  loss_bbox_aux_2: 0.1674 (0.1936)  loss_giou_aux_2: 0.6735 (0.6824)  loss_vfl_aux_3: 0.6729 (0.6972)  loss_bbox_aux_3: 0.1605 (0.1919)  loss_giou_aux_3: 0.6696 (0.6775)  loss_vfl_aux_4: 0.6891 (0.7137)  loss_bbox_aux_4: 0.1618 (0.1906)  loss_giou_aux_4: 0.6980 (0.6734)  loss_vfl_aux_5: 0.6456 (0.6571)  loss_bbox_aux_5: 0.2223 (0.2580)  loss_giou_aux_5: 0.8329 (0.8386)  loss_vfl_dn_0: 0.4221 (0.4214)  loss_bbox_dn_0: 0.2416 (0.2910)  loss_giou_dn_0: 0.9353 (0.9294)  loss_vfl_dn_1: 0.4315 (0.4318)  loss_bbox_dn_1: 0.2024 (0.2430)  loss_giou_dn_1: 0.7650 (0.7872)  loss_vfl_dn_2: 0.4337 (0.4348)  loss_bbox_dn_2: 0.1920 (0.2285)  loss_giou_dn_2: 0.7258 (0.7400)  loss_vfl_dn_3: 0.4359 (0.4360)  loss_bbox_dn_3: 0.1890 (0.2237)  loss_giou_dn_3: 0.7150 (0.7241)  loss_vfl_dn_4: 0.4371 (0.4367)  loss_bbox_dn_4: 0.1877 (0.2221)  loss_giou_dn_4: 0.7100 (0.7186)  loss_vfl_dn_5: 0.4359 (0.4365)  loss_bbox_dn_5: 0.1872 (0.2213)  loss_giou_dn_5: 0.7041 (0.7166)\n",
            "Test:  [0/6]  eta: 0:00:26    time: 4.4356  data: 4.1252  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.9752  data: 0.6993  max mem: 7790\n",
            "Test: Total time: 0:00:05 (0.9889 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.541\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.451\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684\n",
            "best_stat:  {'epoch': 24, 'coco_eval_bbox': 0.27527456550247376}\n",
            "Epoch: [27]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 20.9395 (20.9395)  loss_vfl: 0.5823 (0.5823)  loss_bbox: 0.1461 (0.1461)  loss_giou: 0.8995 (0.8995)  loss_vfl_aux_0: 0.5872 (0.5872)  loss_bbox_aux_0: 0.1570 (0.1570)  loss_giou_aux_0: 0.9092 (0.9092)  loss_vfl_aux_1: 0.5659 (0.5659)  loss_bbox_aux_1: 0.1489 (0.1489)  loss_giou_aux_1: 0.9197 (0.9197)  loss_vfl_aux_2: 0.5702 (0.5702)  loss_bbox_aux_2: 0.1444 (0.1444)  loss_giou_aux_2: 0.8913 (0.8913)  loss_vfl_aux_3: 0.5578 (0.5578)  loss_bbox_aux_3: 0.1468 (0.1468)  loss_giou_aux_3: 0.9129 (0.9129)  loss_vfl_aux_4: 0.5785 (0.5785)  loss_bbox_aux_4: 0.1482 (0.1482)  loss_giou_aux_4: 0.9045 (0.9045)  loss_vfl_aux_5: 0.5688 (0.5688)  loss_bbox_aux_5: 0.1710 (0.1710)  loss_giou_aux_5: 0.9800 (0.9800)  loss_vfl_dn_0: 0.3879 (0.3879)  loss_bbox_dn_0: 0.1767 (0.1767)  loss_giou_dn_0: 1.0869 (1.0869)  loss_vfl_dn_1: 0.4023 (0.4023)  loss_bbox_dn_1: 0.1587 (0.1587)  loss_giou_dn_1: 1.0161 (1.0161)  loss_vfl_dn_2: 0.4090 (0.4090)  loss_bbox_dn_2: 0.1534 (0.1534)  loss_giou_dn_2: 0.9991 (0.9991)  loss_vfl_dn_3: 0.4131 (0.4131)  loss_bbox_dn_3: 0.1538 (0.1538)  loss_giou_dn_3: 0.9878 (0.9878)  loss_vfl_dn_4: 0.4079 (0.4079)  loss_bbox_dn_4: 0.1549 (0.1549)  loss_giou_dn_4: 0.9876 (0.9876)  loss_vfl_dn_5: 0.4138 (0.4138)  loss_bbox_dn_5: 0.1553 (0.1553)  loss_giou_dn_5: 0.9848 (0.9848)  time: 1.0071  data: 0.6148  max mem: 7790\n",
            "Epoch: [27]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 19.1227 (19.8198)  loss_vfl: 0.7063 (0.7514)  loss_bbox: 0.1398 (0.1698)  loss_giou: 0.6209 (0.6511)  loss_vfl_aux_0: 0.7090 (0.7171)  loss_bbox_aux_0: 0.1675 (0.1928)  loss_giou_aux_0: 0.6584 (0.7050)  loss_vfl_aux_1: 0.6676 (0.7220)  loss_bbox_aux_1: 0.1545 (0.1786)  loss_giou_aux_1: 0.6332 (0.6758)  loss_vfl_aux_2: 0.6927 (0.7239)  loss_bbox_aux_2: 0.1427 (0.1743)  loss_giou_aux_2: 0.6271 (0.6629)  loss_vfl_aux_3: 0.6879 (0.7344)  loss_bbox_aux_3: 0.1444 (0.1692)  loss_giou_aux_3: 0.6174 (0.6561)  loss_vfl_aux_4: 0.6906 (0.7412)  loss_bbox_aux_4: 0.1422 (0.1699)  loss_giou_aux_4: 0.6134 (0.6533)  loss_vfl_aux_5: 0.6468 (0.6753)  loss_bbox_aux_5: 0.2098 (0.2451)  loss_giou_aux_5: 0.8370 (0.8399)  loss_vfl_dn_0: 0.4240 (0.4194)  loss_bbox_dn_0: 0.2509 (0.2852)  loss_giou_dn_0: 0.9012 (0.9310)  loss_vfl_dn_1: 0.4372 (0.4304)  loss_bbox_dn_1: 0.1963 (0.2356)  loss_giou_dn_1: 0.7333 (0.7867)  loss_vfl_dn_2: 0.4385 (0.4310)  loss_bbox_dn_2: 0.1877 (0.2219)  loss_giou_dn_2: 0.6879 (0.7417)  loss_vfl_dn_3: 0.4399 (0.4319)  loss_bbox_dn_3: 0.1915 (0.2181)  loss_giou_dn_3: 0.6736 (0.7286)  loss_vfl_dn_4: 0.4412 (0.4336)  loss_bbox_dn_4: 0.1948 (0.2169)  loss_giou_dn_4: 0.6693 (0.7241)  loss_vfl_dn_5: 0.4424 (0.4349)  loss_bbox_dn_5: 0.1958 (0.2164)  loss_giou_dn_5: 0.6619 (0.7231)  time: 0.3386  data: 0.0148  max mem: 7790\n",
            "Epoch: [27] Total time: 0:00:11 (0.3608 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 19.1227 (19.8198)  loss_vfl: 0.7063 (0.7514)  loss_bbox: 0.1398 (0.1698)  loss_giou: 0.6209 (0.6511)  loss_vfl_aux_0: 0.7090 (0.7171)  loss_bbox_aux_0: 0.1675 (0.1928)  loss_giou_aux_0: 0.6584 (0.7050)  loss_vfl_aux_1: 0.6676 (0.7220)  loss_bbox_aux_1: 0.1545 (0.1786)  loss_giou_aux_1: 0.6332 (0.6758)  loss_vfl_aux_2: 0.6927 (0.7239)  loss_bbox_aux_2: 0.1427 (0.1743)  loss_giou_aux_2: 0.6271 (0.6629)  loss_vfl_aux_3: 0.6879 (0.7344)  loss_bbox_aux_3: 0.1444 (0.1692)  loss_giou_aux_3: 0.6174 (0.6561)  loss_vfl_aux_4: 0.6906 (0.7412)  loss_bbox_aux_4: 0.1422 (0.1699)  loss_giou_aux_4: 0.6134 (0.6533)  loss_vfl_aux_5: 0.6468 (0.6753)  loss_bbox_aux_5: 0.2098 (0.2451)  loss_giou_aux_5: 0.8370 (0.8399)  loss_vfl_dn_0: 0.4240 (0.4194)  loss_bbox_dn_0: 0.2509 (0.2852)  loss_giou_dn_0: 0.9012 (0.9310)  loss_vfl_dn_1: 0.4372 (0.4304)  loss_bbox_dn_1: 0.1963 (0.2356)  loss_giou_dn_1: 0.7333 (0.7867)  loss_vfl_dn_2: 0.4385 (0.4310)  loss_bbox_dn_2: 0.1877 (0.2219)  loss_giou_dn_2: 0.6879 (0.7417)  loss_vfl_dn_3: 0.4399 (0.4319)  loss_bbox_dn_3: 0.1915 (0.2181)  loss_giou_dn_3: 0.6736 (0.7286)  loss_vfl_dn_4: 0.4412 (0.4336)  loss_bbox_dn_4: 0.1948 (0.2169)  loss_giou_dn_4: 0.6693 (0.7241)  loss_vfl_dn_5: 0.4424 (0.4349)  loss_bbox_dn_5: 0.1958 (0.2164)  loss_giou_dn_5: 0.6619 (0.7231)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8984  data: 0.5872  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3826  data: 0.1097  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3945 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.572\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.395\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.381\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.597\n",
            "best_stat:  {'epoch': 27, 'coco_eval_bbox': 0.2866406688493229}\n",
            "Epoch: [28]  [ 0/33]  eta: 0:00:29  lr: 0.000001  loss: 18.4629 (18.4629)  loss_vfl: 0.7156 (0.7156)  loss_bbox: 0.1705 (0.1705)  loss_giou: 0.5178 (0.5178)  loss_vfl_aux_0: 0.7289 (0.7289)  loss_bbox_aux_0: 0.1906 (0.1906)  loss_giou_aux_0: 0.5460 (0.5460)  loss_vfl_aux_1: 0.7123 (0.7123)  loss_bbox_aux_1: 0.1830 (0.1830)  loss_giou_aux_1: 0.5452 (0.5452)  loss_vfl_aux_2: 0.7321 (0.7321)  loss_bbox_aux_2: 0.1862 (0.1862)  loss_giou_aux_2: 0.5344 (0.5344)  loss_vfl_aux_3: 0.7220 (0.7220)  loss_bbox_aux_3: 0.1766 (0.1766)  loss_giou_aux_3: 0.5275 (0.5275)  loss_vfl_aux_4: 0.7164 (0.7164)  loss_bbox_aux_4: 0.1739 (0.1739)  loss_giou_aux_4: 0.5221 (0.5221)  loss_vfl_aux_5: 0.7142 (0.7142)  loss_bbox_aux_5: 0.2291 (0.2291)  loss_giou_aux_5: 0.6617 (0.6617)  loss_vfl_dn_0: 0.4319 (0.4319)  loss_bbox_dn_0: 0.3217 (0.3217)  loss_giou_dn_0: 0.8973 (0.8973)  loss_vfl_dn_1: 0.4507 (0.4507)  loss_bbox_dn_1: 0.2554 (0.2554)  loss_giou_dn_1: 0.7056 (0.7056)  loss_vfl_dn_2: 0.4470 (0.4470)  loss_bbox_dn_2: 0.2356 (0.2356)  loss_giou_dn_2: 0.6355 (0.6355)  loss_vfl_dn_3: 0.4523 (0.4523)  loss_bbox_dn_3: 0.2292 (0.2292)  loss_giou_dn_3: 0.6159 (0.6159)  loss_vfl_dn_4: 0.4566 (0.4566)  loss_bbox_dn_4: 0.2286 (0.2286)  loss_giou_dn_4: 0.6052 (0.6052)  loss_vfl_dn_5: 0.4542 (0.4542)  loss_bbox_dn_5: 0.2294 (0.2294)  loss_giou_dn_5: 0.6048 (0.6048)  time: 0.8937  data: 0.4475  max mem: 7790\n",
            "Epoch: [28]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 19.4815 (19.6785)  loss_vfl: 0.6918 (0.7069)  loss_bbox: 0.1733 (0.1778)  loss_giou: 0.6503 (0.6643)  loss_vfl_aux_0: 0.6670 (0.6969)  loss_bbox_aux_0: 0.1723 (0.1934)  loss_giou_aux_0: 0.6851 (0.7067)  loss_vfl_aux_1: 0.6704 (0.6901)  loss_bbox_aux_1: 0.1794 (0.1834)  loss_giou_aux_1: 0.6533 (0.6842)  loss_vfl_aux_2: 0.6836 (0.6901)  loss_bbox_aux_2: 0.1781 (0.1798)  loss_giou_aux_2: 0.6588 (0.6742)  loss_vfl_aux_3: 0.6887 (0.6925)  loss_bbox_aux_3: 0.1714 (0.1786)  loss_giou_aux_3: 0.6649 (0.6690)  loss_vfl_aux_4: 0.6891 (0.6949)  loss_bbox_aux_4: 0.1708 (0.1780)  loss_giou_aux_4: 0.6516 (0.6667)  loss_vfl_aux_5: 0.6415 (0.6582)  loss_bbox_aux_5: 0.2347 (0.2478)  loss_giou_aux_5: 0.7996 (0.8331)  loss_vfl_dn_0: 0.4196 (0.4212)  loss_bbox_dn_0: 0.2669 (0.2812)  loss_giou_dn_0: 0.9088 (0.9221)  loss_vfl_dn_1: 0.4271 (0.4294)  loss_bbox_dn_1: 0.2200 (0.2380)  loss_giou_dn_1: 0.7627 (0.7828)  loss_vfl_dn_2: 0.4337 (0.4306)  loss_bbox_dn_2: 0.2114 (0.2266)  loss_giou_dn_2: 0.7133 (0.7411)  loss_vfl_dn_3: 0.4380 (0.4314)  loss_bbox_dn_3: 0.2082 (0.2230)  loss_giou_dn_3: 0.6961 (0.7289)  loss_vfl_dn_4: 0.4392 (0.4325)  loss_bbox_dn_4: 0.2068 (0.2219)  loss_giou_dn_4: 0.6901 (0.7242)  loss_vfl_dn_5: 0.4399 (0.4329)  loss_bbox_dn_5: 0.2065 (0.2213)  loss_giou_dn_5: 0.6844 (0.7225)  time: 0.3239  data: 0.0152  max mem: 7790\n",
            "Epoch: [28] Total time: 0:00:11 (0.3447 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 19.4815 (19.6785)  loss_vfl: 0.6918 (0.7069)  loss_bbox: 0.1733 (0.1778)  loss_giou: 0.6503 (0.6643)  loss_vfl_aux_0: 0.6670 (0.6969)  loss_bbox_aux_0: 0.1723 (0.1934)  loss_giou_aux_0: 0.6851 (0.7067)  loss_vfl_aux_1: 0.6704 (0.6901)  loss_bbox_aux_1: 0.1794 (0.1834)  loss_giou_aux_1: 0.6533 (0.6842)  loss_vfl_aux_2: 0.6836 (0.6901)  loss_bbox_aux_2: 0.1781 (0.1798)  loss_giou_aux_2: 0.6588 (0.6742)  loss_vfl_aux_3: 0.6887 (0.6925)  loss_bbox_aux_3: 0.1714 (0.1786)  loss_giou_aux_3: 0.6649 (0.6690)  loss_vfl_aux_4: 0.6891 (0.6949)  loss_bbox_aux_4: 0.1708 (0.1780)  loss_giou_aux_4: 0.6516 (0.6667)  loss_vfl_aux_5: 0.6415 (0.6582)  loss_bbox_aux_5: 0.2347 (0.2478)  loss_giou_aux_5: 0.7996 (0.8331)  loss_vfl_dn_0: 0.4196 (0.4212)  loss_bbox_dn_0: 0.2669 (0.2812)  loss_giou_dn_0: 0.9088 (0.9221)  loss_vfl_dn_1: 0.4271 (0.4294)  loss_bbox_dn_1: 0.2200 (0.2380)  loss_giou_dn_1: 0.7627 (0.7828)  loss_vfl_dn_2: 0.4337 (0.4306)  loss_bbox_dn_2: 0.2114 (0.2266)  loss_giou_dn_2: 0.7133 (0.7411)  loss_vfl_dn_3: 0.4380 (0.4314)  loss_bbox_dn_3: 0.2082 (0.2230)  loss_giou_dn_3: 0.6961 (0.7289)  loss_vfl_dn_4: 0.4392 (0.4325)  loss_bbox_dn_4: 0.2068 (0.2219)  loss_giou_dn_4: 0.6901 (0.7242)  loss_vfl_dn_5: 0.4399 (0.4329)  loss_bbox_dn_5: 0.2065 (0.2213)  loss_giou_dn_5: 0.6844 (0.7225)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9639  data: 0.6478  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3997  data: 0.1230  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4144 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.555\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.261\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.374\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.553\n",
            "best_stat:  {'epoch': 27, 'coco_eval_bbox': 0.2866406688493229}\n",
            "Epoch: [29]  [ 0/33]  eta: 0:00:36  lr: 0.000001  loss: 25.0456 (25.0456)  loss_vfl: 1.0174 (1.0174)  loss_bbox: 0.3742 (0.3742)  loss_giou: 0.5247 (0.5247)  loss_vfl_aux_0: 1.3190 (1.3190)  loss_bbox_aux_0: 0.3996 (0.3996)  loss_giou_aux_0: 0.6041 (0.6041)  loss_vfl_aux_1: 1.1829 (1.1829)  loss_bbox_aux_1: 0.4075 (0.4075)  loss_giou_aux_1: 0.5751 (0.5751)  loss_vfl_aux_2: 1.1796 (1.1796)  loss_bbox_aux_2: 0.3878 (0.3878)  loss_giou_aux_2: 0.5583 (0.5583)  loss_vfl_aux_3: 1.1064 (1.1064)  loss_bbox_aux_3: 0.3743 (0.3743)  loss_giou_aux_3: 0.5375 (0.5375)  loss_vfl_aux_4: 1.0841 (1.0841)  loss_bbox_aux_4: 0.3763 (0.3763)  loss_giou_aux_4: 0.5368 (0.5368)  loss_vfl_aux_5: 1.2023 (1.2023)  loss_bbox_aux_5: 0.5194 (0.5194)  loss_giou_aux_5: 0.6988 (0.6988)  loss_vfl_dn_0: 0.4267 (0.4267)  loss_bbox_dn_0: 0.6085 (0.6085)  loss_giou_dn_0: 0.8830 (0.8830)  loss_vfl_dn_1: 0.4307 (0.4307)  loss_bbox_dn_1: 0.5528 (0.5528)  loss_giou_dn_1: 0.7550 (0.7550)  loss_vfl_dn_2: 0.4288 (0.4288)  loss_bbox_dn_2: 0.5241 (0.5241)  loss_giou_dn_2: 0.6979 (0.6979)  loss_vfl_dn_3: 0.4304 (0.4304)  loss_bbox_dn_3: 0.5040 (0.5040)  loss_giou_dn_3: 0.6681 (0.6681)  loss_vfl_dn_4: 0.4377 (0.4377)  loss_bbox_dn_4: 0.4944 (0.4944)  loss_giou_dn_4: 0.6571 (0.6571)  loss_vfl_dn_5: 0.4374 (0.4374)  loss_bbox_dn_5: 0.4898 (0.4898)  loss_giou_dn_5: 0.6534 (0.6534)  time: 1.0999  data: 0.6653  max mem: 7790\n",
            "Epoch: [29]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 19.5354 (19.7500)  loss_vfl: 0.7232 (0.7375)  loss_bbox: 0.1808 (0.1875)  loss_giou: 0.6316 (0.6329)  loss_vfl_aux_0: 0.7090 (0.7286)  loss_bbox_aux_0: 0.1847 (0.2010)  loss_giou_aux_0: 0.6830 (0.6869)  loss_vfl_aux_1: 0.7221 (0.7330)  loss_bbox_aux_1: 0.1857 (0.1923)  loss_giou_aux_1: 0.6397 (0.6580)  loss_vfl_aux_2: 0.7085 (0.7261)  loss_bbox_aux_2: 0.1797 (0.1909)  loss_giou_aux_2: 0.6268 (0.6469)  loss_vfl_aux_3: 0.7033 (0.7277)  loss_bbox_aux_3: 0.1785 (0.1904)  loss_giou_aux_3: 0.6357 (0.6405)  loss_vfl_aux_4: 0.7201 (0.7353)  loss_bbox_aux_4: 0.1803 (0.1856)  loss_giou_aux_4: 0.6322 (0.6349)  loss_vfl_aux_5: 0.6559 (0.7075)  loss_bbox_aux_5: 0.2417 (0.2589)  loss_giou_aux_5: 0.7620 (0.8078)  loss_vfl_dn_0: 0.4331 (0.4251)  loss_bbox_dn_0: 0.2901 (0.3029)  loss_giou_dn_0: 0.9124 (0.9115)  loss_vfl_dn_1: 0.4410 (0.4349)  loss_bbox_dn_1: 0.2317 (0.2478)  loss_giou_dn_1: 0.7679 (0.7637)  loss_vfl_dn_2: 0.4449 (0.4355)  loss_bbox_dn_2: 0.2242 (0.2320)  loss_giou_dn_2: 0.7258 (0.7147)  loss_vfl_dn_3: 0.4450 (0.4376)  loss_bbox_dn_3: 0.2229 (0.2267)  loss_giou_dn_3: 0.7096 (0.6975)  loss_vfl_dn_4: 0.4473 (0.4393)  loss_bbox_dn_4: 0.2214 (0.2249)  loss_giou_dn_4: 0.7055 (0.6915)  loss_vfl_dn_5: 0.4468 (0.4401)  loss_bbox_dn_5: 0.2209 (0.2243)  loss_giou_dn_5: 0.7015 (0.6898)  time: 0.3264  data: 0.0158  max mem: 7790\n",
            "Epoch: [29] Total time: 0:00:11 (0.3548 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 19.5354 (19.7500)  loss_vfl: 0.7232 (0.7375)  loss_bbox: 0.1808 (0.1875)  loss_giou: 0.6316 (0.6329)  loss_vfl_aux_0: 0.7090 (0.7286)  loss_bbox_aux_0: 0.1847 (0.2010)  loss_giou_aux_0: 0.6830 (0.6869)  loss_vfl_aux_1: 0.7221 (0.7330)  loss_bbox_aux_1: 0.1857 (0.1923)  loss_giou_aux_1: 0.6397 (0.6580)  loss_vfl_aux_2: 0.7085 (0.7261)  loss_bbox_aux_2: 0.1797 (0.1909)  loss_giou_aux_2: 0.6268 (0.6469)  loss_vfl_aux_3: 0.7033 (0.7277)  loss_bbox_aux_3: 0.1785 (0.1904)  loss_giou_aux_3: 0.6357 (0.6405)  loss_vfl_aux_4: 0.7201 (0.7353)  loss_bbox_aux_4: 0.1803 (0.1856)  loss_giou_aux_4: 0.6322 (0.6349)  loss_vfl_aux_5: 0.6559 (0.7075)  loss_bbox_aux_5: 0.2417 (0.2589)  loss_giou_aux_5: 0.7620 (0.8078)  loss_vfl_dn_0: 0.4331 (0.4251)  loss_bbox_dn_0: 0.2901 (0.3029)  loss_giou_dn_0: 0.9124 (0.9115)  loss_vfl_dn_1: 0.4410 (0.4349)  loss_bbox_dn_1: 0.2317 (0.2478)  loss_giou_dn_1: 0.7679 (0.7637)  loss_vfl_dn_2: 0.4449 (0.4355)  loss_bbox_dn_2: 0.2242 (0.2320)  loss_giou_dn_2: 0.7258 (0.7147)  loss_vfl_dn_3: 0.4450 (0.4376)  loss_bbox_dn_3: 0.2229 (0.2267)  loss_giou_dn_3: 0.7096 (0.6975)  loss_vfl_dn_4: 0.4473 (0.4393)  loss_bbox_dn_4: 0.2214 (0.2249)  loss_giou_dn_4: 0.7055 (0.6915)  loss_vfl_dn_5: 0.4468 (0.4401)  loss_bbox_dn_5: 0.2209 (0.2243)  loss_giou_dn_5: 0.7015 (0.6898)\n",
            "Test:  [0/6]  eta: 0:00:24    time: 4.0647  data: 3.7564  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.9181  data: 0.6445  max mem: 7790\n",
            "Test: Total time: 0:00:05 (0.9323 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.562\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.265\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "best_stat:  {'epoch': 27, 'coco_eval_bbox': 0.2866406688493229}\n",
            "Epoch: [30]  [ 0/33]  eta: 0:00:38  lr: 0.000001  loss: 19.9691 (19.9691)  loss_vfl: 0.6944 (0.6944)  loss_bbox: 0.2306 (0.2306)  loss_giou: 0.7079 (0.7079)  loss_vfl_aux_0: 0.6342 (0.6342)  loss_bbox_aux_0: 0.2321 (0.2321)  loss_giou_aux_0: 0.7646 (0.7646)  loss_vfl_aux_1: 0.6504 (0.6504)  loss_bbox_aux_1: 0.2294 (0.2294)  loss_giou_aux_1: 0.7322 (0.7322)  loss_vfl_aux_2: 0.6604 (0.6604)  loss_bbox_aux_2: 0.2261 (0.2261)  loss_giou_aux_2: 0.7333 (0.7333)  loss_vfl_aux_3: 0.6791 (0.6791)  loss_bbox_aux_3: 0.2358 (0.2358)  loss_giou_aux_3: 0.7242 (0.7242)  loss_vfl_aux_4: 0.6811 (0.6811)  loss_bbox_aux_4: 0.2391 (0.2391)  loss_giou_aux_4: 0.7220 (0.7220)  loss_vfl_aux_5: 0.6680 (0.6680)  loss_bbox_aux_5: 0.2607 (0.2607)  loss_giou_aux_5: 0.8381 (0.8381)  loss_vfl_dn_0: 0.4372 (0.4372)  loss_bbox_dn_0: 0.2991 (0.2991)  loss_giou_dn_0: 0.8720 (0.8720)  loss_vfl_dn_1: 0.4508 (0.4508)  loss_bbox_dn_1: 0.2596 (0.2596)  loss_giou_dn_1: 0.7253 (0.7253)  loss_vfl_dn_2: 0.4475 (0.4475)  loss_bbox_dn_2: 0.2413 (0.2413)  loss_giou_dn_2: 0.6726 (0.6726)  loss_vfl_dn_3: 0.4467 (0.4467)  loss_bbox_dn_3: 0.2355 (0.2355)  loss_giou_dn_3: 0.6612 (0.6612)  loss_vfl_dn_4: 0.4478 (0.4478)  loss_bbox_dn_4: 0.2344 (0.2344)  loss_giou_dn_4: 0.6572 (0.6572)  loss_vfl_dn_5: 0.4495 (0.4495)  loss_bbox_dn_5: 0.2330 (0.2330)  loss_giou_dn_5: 0.6547 (0.6547)  time: 1.1586  data: 0.7112  max mem: 7790\n",
            "Epoch: [30]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 19.4139 (19.6535)  loss_vfl: 0.6903 (0.7091)  loss_bbox: 0.1745 (0.1933)  loss_giou: 0.6272 (0.6523)  loss_vfl_aux_0: 0.6835 (0.6974)  loss_bbox_aux_0: 0.1882 (0.2033)  loss_giou_aux_0: 0.6761 (0.6835)  loss_vfl_aux_1: 0.6908 (0.6969)  loss_bbox_aux_1: 0.1868 (0.1967)  loss_giou_aux_1: 0.6461 (0.6661)  loss_vfl_aux_2: 0.6925 (0.7081)  loss_bbox_aux_2: 0.1754 (0.1949)  loss_giou_aux_2: 0.6233 (0.6584)  loss_vfl_aux_3: 0.6752 (0.7064)  loss_bbox_aux_3: 0.1834 (0.1948)  loss_giou_aux_3: 0.6285 (0.6546)  loss_vfl_aux_4: 0.6915 (0.7027)  loss_bbox_aux_4: 0.1797 (0.1957)  loss_giou_aux_4: 0.6286 (0.6560)  loss_vfl_aux_5: 0.6783 (0.6894)  loss_bbox_aux_5: 0.2465 (0.2447)  loss_giou_aux_5: 0.7871 (0.7817)  loss_vfl_dn_0: 0.4240 (0.4265)  loss_bbox_dn_0: 0.3036 (0.2985)  loss_giou_dn_0: 0.8952 (0.9005)  loss_vfl_dn_1: 0.4296 (0.4338)  loss_bbox_dn_1: 0.2453 (0.2494)  loss_giou_dn_1: 0.7441 (0.7598)  loss_vfl_dn_2: 0.4317 (0.4355)  loss_bbox_dn_2: 0.2286 (0.2366)  loss_giou_dn_2: 0.6940 (0.7164)  loss_vfl_dn_3: 0.4307 (0.4374)  loss_bbox_dn_3: 0.2205 (0.2327)  loss_giou_dn_3: 0.6841 (0.7027)  loss_vfl_dn_4: 0.4323 (0.4389)  loss_bbox_dn_4: 0.2173 (0.2317)  loss_giou_dn_4: 0.6798 (0.6982)  loss_vfl_dn_5: 0.4331 (0.4400)  loss_bbox_dn_5: 0.2160 (0.2314)  loss_giou_dn_5: 0.6764 (0.6971)  time: 0.3202  data: 0.0140  max mem: 7790\n",
            "Epoch: [30] Total time: 0:00:11 (0.3478 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 19.4139 (19.6535)  loss_vfl: 0.6903 (0.7091)  loss_bbox: 0.1745 (0.1933)  loss_giou: 0.6272 (0.6523)  loss_vfl_aux_0: 0.6835 (0.6974)  loss_bbox_aux_0: 0.1882 (0.2033)  loss_giou_aux_0: 0.6761 (0.6835)  loss_vfl_aux_1: 0.6908 (0.6969)  loss_bbox_aux_1: 0.1868 (0.1967)  loss_giou_aux_1: 0.6461 (0.6661)  loss_vfl_aux_2: 0.6925 (0.7081)  loss_bbox_aux_2: 0.1754 (0.1949)  loss_giou_aux_2: 0.6233 (0.6584)  loss_vfl_aux_3: 0.6752 (0.7064)  loss_bbox_aux_3: 0.1834 (0.1948)  loss_giou_aux_3: 0.6285 (0.6546)  loss_vfl_aux_4: 0.6915 (0.7027)  loss_bbox_aux_4: 0.1797 (0.1957)  loss_giou_aux_4: 0.6286 (0.6560)  loss_vfl_aux_5: 0.6783 (0.6894)  loss_bbox_aux_5: 0.2465 (0.2447)  loss_giou_aux_5: 0.7871 (0.7817)  loss_vfl_dn_0: 0.4240 (0.4265)  loss_bbox_dn_0: 0.3036 (0.2985)  loss_giou_dn_0: 0.8952 (0.9005)  loss_vfl_dn_1: 0.4296 (0.4338)  loss_bbox_dn_1: 0.2453 (0.2494)  loss_giou_dn_1: 0.7441 (0.7598)  loss_vfl_dn_2: 0.4317 (0.4355)  loss_bbox_dn_2: 0.2286 (0.2366)  loss_giou_dn_2: 0.6940 (0.7164)  loss_vfl_dn_3: 0.4307 (0.4374)  loss_bbox_dn_3: 0.2205 (0.2327)  loss_giou_dn_3: 0.6841 (0.7027)  loss_vfl_dn_4: 0.4323 (0.4389)  loss_bbox_dn_4: 0.2173 (0.2317)  loss_giou_dn_4: 0.6798 (0.6982)  loss_vfl_dn_5: 0.4331 (0.4400)  loss_bbox_dn_5: 0.2160 (0.2314)  loss_giou_dn_5: 0.6764 (0.6971)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9025  data: 0.5782  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4385  data: 0.1123  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4526 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.584\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
            "best_stat:  {'epoch': 30, 'coco_eval_bbox': 0.2881207466823741}\n",
            "Epoch: [31]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 17.9309 (17.9309)  loss_vfl: 0.6162 (0.6162)  loss_bbox: 0.1181 (0.1181)  loss_giou: 0.7007 (0.7007)  loss_vfl_aux_0: 0.6584 (0.6584)  loss_bbox_aux_0: 0.1212 (0.1212)  loss_giou_aux_0: 0.6906 (0.6906)  loss_vfl_aux_1: 0.6278 (0.6278)  loss_bbox_aux_1: 0.1157 (0.1157)  loss_giou_aux_1: 0.6730 (0.6730)  loss_vfl_aux_2: 0.6062 (0.6062)  loss_bbox_aux_2: 0.1160 (0.1160)  loss_giou_aux_2: 0.6993 (0.6993)  loss_vfl_aux_3: 0.6192 (0.6192)  loss_bbox_aux_3: 0.1142 (0.1142)  loss_giou_aux_3: 0.6865 (0.6865)  loss_vfl_aux_4: 0.6164 (0.6164)  loss_bbox_aux_4: 0.1137 (0.1137)  loss_giou_aux_4: 0.6855 (0.6855)  loss_vfl_aux_5: 0.6253 (0.6253)  loss_bbox_aux_5: 0.1662 (0.1662)  loss_giou_aux_5: 0.8209 (0.8209)  loss_vfl_dn_0: 0.4256 (0.4256)  loss_bbox_dn_0: 0.1392 (0.1392)  loss_giou_dn_0: 0.9041 (0.9041)  loss_vfl_dn_1: 0.4338 (0.4338)  loss_bbox_dn_1: 0.1180 (0.1180)  loss_giou_dn_1: 0.7523 (0.7523)  loss_vfl_dn_2: 0.4342 (0.4342)  loss_bbox_dn_2: 0.1120 (0.1120)  loss_giou_dn_2: 0.7121 (0.7121)  loss_vfl_dn_3: 0.4316 (0.4316)  loss_bbox_dn_3: 0.1107 (0.1107)  loss_giou_dn_3: 0.6943 (0.6943)  loss_vfl_dn_4: 0.4282 (0.4282)  loss_bbox_dn_4: 0.1107 (0.1107)  loss_giou_dn_4: 0.6958 (0.6958)  loss_vfl_dn_5: 0.4260 (0.4260)  loss_bbox_dn_5: 0.1114 (0.1114)  loss_giou_dn_5: 0.7000 (0.7000)  time: 0.9804  data: 0.5500  max mem: 7790\n",
            "Epoch: [31]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.3960 (19.2757)  loss_vfl: 0.6874 (0.7064)  loss_bbox: 0.1668 (0.1738)  loss_giou: 0.5656 (0.6333)  loss_vfl_aux_0: 0.6821 (0.7150)  loss_bbox_aux_0: 0.1777 (0.1828)  loss_giou_aux_0: 0.6122 (0.6720)  loss_vfl_aux_1: 0.6800 (0.6964)  loss_bbox_aux_1: 0.1708 (0.1775)  loss_giou_aux_1: 0.5771 (0.6496)  loss_vfl_aux_2: 0.6714 (0.7031)  loss_bbox_aux_2: 0.1654 (0.1718)  loss_giou_aux_2: 0.5633 (0.6407)  loss_vfl_aux_3: 0.6669 (0.6977)  loss_bbox_aux_3: 0.1657 (0.1746)  loss_giou_aux_3: 0.5683 (0.6371)  loss_vfl_aux_4: 0.6644 (0.6982)  loss_bbox_aux_4: 0.1667 (0.1752)  loss_giou_aux_4: 0.5684 (0.6366)  loss_vfl_aux_5: 0.6856 (0.7113)  loss_bbox_aux_5: 0.2126 (0.2248)  loss_giou_aux_5: 0.7140 (0.7680)  loss_vfl_dn_0: 0.4318 (0.4274)  loss_bbox_dn_0: 0.2436 (0.2852)  loss_giou_dn_0: 0.8646 (0.8948)  loss_vfl_dn_1: 0.4366 (0.4344)  loss_bbox_dn_1: 0.1931 (0.2391)  loss_giou_dn_1: 0.6979 (0.7504)  loss_vfl_dn_2: 0.4321 (0.4351)  loss_bbox_dn_2: 0.1819 (0.2251)  loss_giou_dn_2: 0.6406 (0.7060)  loss_vfl_dn_3: 0.4323 (0.4352)  loss_bbox_dn_3: 0.1813 (0.2206)  loss_giou_dn_3: 0.6186 (0.6922)  loss_vfl_dn_4: 0.4347 (0.4367)  loss_bbox_dn_4: 0.1798 (0.2189)  loss_giou_dn_4: 0.6161 (0.6877)  loss_vfl_dn_5: 0.4354 (0.4364)  loss_bbox_dn_5: 0.1803 (0.2181)  loss_giou_dn_5: 0.6148 (0.6863)  time: 0.3227  data: 0.0142  max mem: 7790\n",
            "Epoch: [31] Total time: 0:00:11 (0.3460 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.3960 (19.2757)  loss_vfl: 0.6874 (0.7064)  loss_bbox: 0.1668 (0.1738)  loss_giou: 0.5656 (0.6333)  loss_vfl_aux_0: 0.6821 (0.7150)  loss_bbox_aux_0: 0.1777 (0.1828)  loss_giou_aux_0: 0.6122 (0.6720)  loss_vfl_aux_1: 0.6800 (0.6964)  loss_bbox_aux_1: 0.1708 (0.1775)  loss_giou_aux_1: 0.5771 (0.6496)  loss_vfl_aux_2: 0.6714 (0.7031)  loss_bbox_aux_2: 0.1654 (0.1718)  loss_giou_aux_2: 0.5633 (0.6407)  loss_vfl_aux_3: 0.6669 (0.6977)  loss_bbox_aux_3: 0.1657 (0.1746)  loss_giou_aux_3: 0.5683 (0.6371)  loss_vfl_aux_4: 0.6644 (0.6982)  loss_bbox_aux_4: 0.1667 (0.1752)  loss_giou_aux_4: 0.5684 (0.6366)  loss_vfl_aux_5: 0.6856 (0.7113)  loss_bbox_aux_5: 0.2126 (0.2248)  loss_giou_aux_5: 0.7140 (0.7680)  loss_vfl_dn_0: 0.4318 (0.4274)  loss_bbox_dn_0: 0.2436 (0.2852)  loss_giou_dn_0: 0.8646 (0.8948)  loss_vfl_dn_1: 0.4366 (0.4344)  loss_bbox_dn_1: 0.1931 (0.2391)  loss_giou_dn_1: 0.6979 (0.7504)  loss_vfl_dn_2: 0.4321 (0.4351)  loss_bbox_dn_2: 0.1819 (0.2251)  loss_giou_dn_2: 0.6406 (0.7060)  loss_vfl_dn_3: 0.4323 (0.4352)  loss_bbox_dn_3: 0.1813 (0.2206)  loss_giou_dn_3: 0.6186 (0.6922)  loss_vfl_dn_4: 0.4347 (0.4367)  loss_bbox_dn_4: 0.1798 (0.2189)  loss_giou_dn_4: 0.6161 (0.6877)  loss_vfl_dn_5: 0.4354 (0.4364)  loss_bbox_dn_5: 0.1803 (0.2181)  loss_giou_dn_5: 0.6148 (0.6863)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9066  data: 0.5851  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4464  data: 0.1132  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4606 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.597\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.273\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.380\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            "best_stat:  {'epoch': 31, 'coco_eval_bbox': 0.30855451581566173}\n",
            "Epoch: [32]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 18.4967 (18.4967)  loss_vfl: 0.6832 (0.6832)  loss_bbox: 0.1650 (0.1650)  loss_giou: 0.5901 (0.5901)  loss_vfl_aux_0: 0.6354 (0.6354)  loss_bbox_aux_0: 0.1970 (0.1970)  loss_giou_aux_0: 0.6315 (0.6315)  loss_vfl_aux_1: 0.6279 (0.6279)  loss_bbox_aux_1: 0.1827 (0.1827)  loss_giou_aux_1: 0.6244 (0.6244)  loss_vfl_aux_2: 0.6416 (0.6416)  loss_bbox_aux_2: 0.1702 (0.1702)  loss_giou_aux_2: 0.6105 (0.6105)  loss_vfl_aux_3: 0.6658 (0.6658)  loss_bbox_aux_3: 0.1645 (0.1645)  loss_giou_aux_3: 0.5936 (0.5936)  loss_vfl_aux_4: 0.6926 (0.6926)  loss_bbox_aux_4: 0.1556 (0.1556)  loss_giou_aux_4: 0.5781 (0.5781)  loss_vfl_aux_5: 0.6079 (0.6079)  loss_bbox_aux_5: 0.2794 (0.2794)  loss_giou_aux_5: 0.8519 (0.8519)  loss_vfl_dn_0: 0.4284 (0.4284)  loss_bbox_dn_0: 0.2783 (0.2783)  loss_giou_dn_0: 0.8832 (0.8832)  loss_vfl_dn_1: 0.4253 (0.4253)  loss_bbox_dn_1: 0.2301 (0.2301)  loss_giou_dn_1: 0.7372 (0.7372)  loss_vfl_dn_2: 0.4235 (0.4235)  loss_bbox_dn_2: 0.2185 (0.2185)  loss_giou_dn_2: 0.6757 (0.6757)  loss_vfl_dn_3: 0.4190 (0.4190)  loss_bbox_dn_3: 0.2135 (0.2135)  loss_giou_dn_3: 0.6579 (0.6579)  loss_vfl_dn_4: 0.4212 (0.4212)  loss_bbox_dn_4: 0.2097 (0.2097)  loss_giou_dn_4: 0.6482 (0.6482)  loss_vfl_dn_5: 0.4249 (0.4249)  loss_bbox_dn_5: 0.2085 (0.2085)  loss_giou_dn_5: 0.6446 (0.6446)  time: 0.9204  data: 0.5229  max mem: 7790\n",
            "Epoch: [32]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.8056 (18.9969)  loss_vfl: 0.7064 (0.7067)  loss_bbox: 0.1635 (0.1587)  loss_giou: 0.5819 (0.6383)  loss_vfl_aux_0: 0.6952 (0.6992)  loss_bbox_aux_0: 0.1727 (0.1772)  loss_giou_aux_0: 0.6355 (0.6861)  loss_vfl_aux_1: 0.6896 (0.6957)  loss_bbox_aux_1: 0.1559 (0.1674)  loss_giou_aux_1: 0.6098 (0.6525)  loss_vfl_aux_2: 0.6772 (0.6966)  loss_bbox_aux_2: 0.1677 (0.1599)  loss_giou_aux_2: 0.5903 (0.6434)  loss_vfl_aux_3: 0.6893 (0.6964)  loss_bbox_aux_3: 0.1670 (0.1589)  loss_giou_aux_3: 0.5859 (0.6419)  loss_vfl_aux_4: 0.6984 (0.7012)  loss_bbox_aux_4: 0.1663 (0.1582)  loss_giou_aux_4: 0.5840 (0.6410)  loss_vfl_aux_5: 0.6464 (0.6612)  loss_bbox_aux_5: 0.2169 (0.2213)  loss_giou_aux_5: 0.7810 (0.8078)  loss_vfl_dn_0: 0.4283 (0.4279)  loss_bbox_dn_0: 0.2562 (0.2559)  loss_giou_dn_0: 0.8522 (0.8871)  loss_vfl_dn_1: 0.4349 (0.4339)  loss_bbox_dn_1: 0.1868 (0.2103)  loss_giou_dn_1: 0.6903 (0.7419)  loss_vfl_dn_2: 0.4378 (0.4351)  loss_bbox_dn_2: 0.1673 (0.1961)  loss_giou_dn_2: 0.6566 (0.7006)  loss_vfl_dn_3: 0.4408 (0.4347)  loss_bbox_dn_3: 0.1644 (0.1919)  loss_giou_dn_3: 0.6485 (0.6893)  loss_vfl_dn_4: 0.4400 (0.4364)  loss_bbox_dn_4: 0.1646 (0.1905)  loss_giou_dn_4: 0.6500 (0.6855)  loss_vfl_dn_5: 0.4395 (0.4365)  loss_bbox_dn_5: 0.1653 (0.1898)  loss_giou_dn_5: 0.6461 (0.6840)  time: 0.3173  data: 0.0137  max mem: 7790\n",
            "Epoch: [32] Total time: 0:00:11 (0.3442 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.8056 (18.9969)  loss_vfl: 0.7064 (0.7067)  loss_bbox: 0.1635 (0.1587)  loss_giou: 0.5819 (0.6383)  loss_vfl_aux_0: 0.6952 (0.6992)  loss_bbox_aux_0: 0.1727 (0.1772)  loss_giou_aux_0: 0.6355 (0.6861)  loss_vfl_aux_1: 0.6896 (0.6957)  loss_bbox_aux_1: 0.1559 (0.1674)  loss_giou_aux_1: 0.6098 (0.6525)  loss_vfl_aux_2: 0.6772 (0.6966)  loss_bbox_aux_2: 0.1677 (0.1599)  loss_giou_aux_2: 0.5903 (0.6434)  loss_vfl_aux_3: 0.6893 (0.6964)  loss_bbox_aux_3: 0.1670 (0.1589)  loss_giou_aux_3: 0.5859 (0.6419)  loss_vfl_aux_4: 0.6984 (0.7012)  loss_bbox_aux_4: 0.1663 (0.1582)  loss_giou_aux_4: 0.5840 (0.6410)  loss_vfl_aux_5: 0.6464 (0.6612)  loss_bbox_aux_5: 0.2169 (0.2213)  loss_giou_aux_5: 0.7810 (0.8078)  loss_vfl_dn_0: 0.4283 (0.4279)  loss_bbox_dn_0: 0.2562 (0.2559)  loss_giou_dn_0: 0.8522 (0.8871)  loss_vfl_dn_1: 0.4349 (0.4339)  loss_bbox_dn_1: 0.1868 (0.2103)  loss_giou_dn_1: 0.6903 (0.7419)  loss_vfl_dn_2: 0.4378 (0.4351)  loss_bbox_dn_2: 0.1673 (0.1961)  loss_giou_dn_2: 0.6566 (0.7006)  loss_vfl_dn_3: 0.4408 (0.4347)  loss_bbox_dn_3: 0.1644 (0.1919)  loss_giou_dn_3: 0.6485 (0.6893)  loss_vfl_dn_4: 0.4400 (0.4364)  loss_bbox_dn_4: 0.1646 (0.1905)  loss_giou_dn_4: 0.6500 (0.6855)  loss_vfl_dn_5: 0.4395 (0.4365)  loss_bbox_dn_5: 0.1653 (0.1898)  loss_giou_dn_5: 0.6461 (0.6840)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8623  data: 0.5543  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3800  data: 0.1102  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3928 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
            "best_stat:  {'epoch': 31, 'coco_eval_bbox': 0.30855451581566173}\n",
            "Epoch: [33]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 18.2361 (18.2361)  loss_vfl: 0.7194 (0.7194)  loss_bbox: 0.1716 (0.1716)  loss_giou: 0.4576 (0.4576)  loss_vfl_aux_0: 0.7601 (0.7601)  loss_bbox_aux_0: 0.1876 (0.1876)  loss_giou_aux_0: 0.4960 (0.4960)  loss_vfl_aux_1: 0.7752 (0.7752)  loss_bbox_aux_1: 0.1777 (0.1777)  loss_giou_aux_1: 0.4578 (0.4578)  loss_vfl_aux_2: 0.7223 (0.7223)  loss_bbox_aux_2: 0.1784 (0.1784)  loss_giou_aux_2: 0.4629 (0.4629)  loss_vfl_aux_3: 0.7141 (0.7141)  loss_bbox_aux_3: 0.1859 (0.1859)  loss_giou_aux_3: 0.4740 (0.4740)  loss_vfl_aux_4: 0.7412 (0.7412)  loss_bbox_aux_4: 0.1727 (0.1727)  loss_giou_aux_4: 0.4595 (0.4595)  loss_vfl_aux_5: 0.7744 (0.7744)  loss_bbox_aux_5: 0.2520 (0.2520)  loss_giou_aux_5: 0.6240 (0.6240)  loss_vfl_dn_0: 0.4328 (0.4328)  loss_bbox_dn_0: 0.3529 (0.3529)  loss_giou_dn_0: 0.8262 (0.8262)  loss_vfl_dn_1: 0.4354 (0.4354)  loss_bbox_dn_1: 0.3021 (0.3021)  loss_giou_dn_1: 0.6556 (0.6556)  loss_vfl_dn_2: 0.4377 (0.4377)  loss_bbox_dn_2: 0.2906 (0.2906)  loss_giou_dn_2: 0.6064 (0.6064)  loss_vfl_dn_3: 0.4384 (0.4384)  loss_bbox_dn_3: 0.2905 (0.2905)  loss_giou_dn_3: 0.5914 (0.5914)  loss_vfl_dn_4: 0.4360 (0.4360)  loss_bbox_dn_4: 0.2878 (0.2878)  loss_giou_dn_4: 0.5841 (0.5841)  loss_vfl_dn_5: 0.4341 (0.4341)  loss_bbox_dn_5: 0.2882 (0.2882)  loss_giou_dn_5: 0.5814 (0.5814)  time: 0.9844  data: 0.5731  max mem: 7790\n",
            "Epoch: [33]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.9330 (19.1952)  loss_vfl: 0.6605 (0.6816)  loss_bbox: 0.1625 (0.1760)  loss_giou: 0.6245 (0.6435)  loss_vfl_aux_0: 0.6656 (0.6870)  loss_bbox_aux_0: 0.1733 (0.1850)  loss_giou_aux_0: 0.6956 (0.6863)  loss_vfl_aux_1: 0.6651 (0.6764)  loss_bbox_aux_1: 0.1639 (0.1818)  loss_giou_aux_1: 0.6494 (0.6651)  loss_vfl_aux_2: 0.6637 (0.6734)  loss_bbox_aux_2: 0.1614 (0.1782)  loss_giou_aux_2: 0.6335 (0.6536)  loss_vfl_aux_3: 0.6534 (0.6757)  loss_bbox_aux_3: 0.1636 (0.1764)  loss_giou_aux_3: 0.6327 (0.6482)  loss_vfl_aux_4: 0.6601 (0.6795)  loss_bbox_aux_4: 0.1632 (0.1760)  loss_giou_aux_4: 0.6246 (0.6454)  loss_vfl_aux_5: 0.6423 (0.6615)  loss_bbox_aux_5: 0.2067 (0.2350)  loss_giou_aux_5: 0.8215 (0.8202)  loss_vfl_dn_0: 0.4220 (0.4217)  loss_bbox_dn_0: 0.2550 (0.2704)  loss_giou_dn_0: 0.9165 (0.9123)  loss_vfl_dn_1: 0.4299 (0.4321)  loss_bbox_dn_1: 0.2033 (0.2234)  loss_giou_dn_1: 0.7466 (0.7612)  loss_vfl_dn_2: 0.4327 (0.4334)  loss_bbox_dn_2: 0.1904 (0.2111)  loss_giou_dn_2: 0.6906 (0.7148)  loss_vfl_dn_3: 0.4341 (0.4334)  loss_bbox_dn_3: 0.1884 (0.2068)  loss_giou_dn_3: 0.6701 (0.6991)  loss_vfl_dn_4: 0.4317 (0.4346)  loss_bbox_dn_4: 0.1889 (0.2059)  loss_giou_dn_4: 0.6625 (0.6952)  loss_vfl_dn_5: 0.4291 (0.4345)  loss_bbox_dn_5: 0.1893 (0.2055)  loss_giou_dn_5: 0.6648 (0.6938)  time: 0.3370  data: 0.0157  max mem: 7790\n",
            "Epoch: [33] Total time: 0:00:11 (0.3553 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.9330 (19.1952)  loss_vfl: 0.6605 (0.6816)  loss_bbox: 0.1625 (0.1760)  loss_giou: 0.6245 (0.6435)  loss_vfl_aux_0: 0.6656 (0.6870)  loss_bbox_aux_0: 0.1733 (0.1850)  loss_giou_aux_0: 0.6956 (0.6863)  loss_vfl_aux_1: 0.6651 (0.6764)  loss_bbox_aux_1: 0.1639 (0.1818)  loss_giou_aux_1: 0.6494 (0.6651)  loss_vfl_aux_2: 0.6637 (0.6734)  loss_bbox_aux_2: 0.1614 (0.1782)  loss_giou_aux_2: 0.6335 (0.6536)  loss_vfl_aux_3: 0.6534 (0.6757)  loss_bbox_aux_3: 0.1636 (0.1764)  loss_giou_aux_3: 0.6327 (0.6482)  loss_vfl_aux_4: 0.6601 (0.6795)  loss_bbox_aux_4: 0.1632 (0.1760)  loss_giou_aux_4: 0.6246 (0.6454)  loss_vfl_aux_5: 0.6423 (0.6615)  loss_bbox_aux_5: 0.2067 (0.2350)  loss_giou_aux_5: 0.8215 (0.8202)  loss_vfl_dn_0: 0.4220 (0.4217)  loss_bbox_dn_0: 0.2550 (0.2704)  loss_giou_dn_0: 0.9165 (0.9123)  loss_vfl_dn_1: 0.4299 (0.4321)  loss_bbox_dn_1: 0.2033 (0.2234)  loss_giou_dn_1: 0.7466 (0.7612)  loss_vfl_dn_2: 0.4327 (0.4334)  loss_bbox_dn_2: 0.1904 (0.2111)  loss_giou_dn_2: 0.6906 (0.7148)  loss_vfl_dn_3: 0.4341 (0.4334)  loss_bbox_dn_3: 0.1884 (0.2068)  loss_giou_dn_3: 0.6701 (0.6991)  loss_vfl_dn_4: 0.4317 (0.4346)  loss_bbox_dn_4: 0.1889 (0.2059)  loss_giou_dn_4: 0.6625 (0.6952)  loss_vfl_dn_5: 0.4291 (0.4345)  loss_bbox_dn_5: 0.1893 (0.2055)  loss_giou_dn_5: 0.6648 (0.6938)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8546  data: 0.5404  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3850  data: 0.1116  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3976 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.588\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 31, 'coco_eval_bbox': 0.30855451581566173}\n",
            "Epoch: [34]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 17.7998 (17.7998)  loss_vfl: 0.6872 (0.6872)  loss_bbox: 0.1764 (0.1764)  loss_giou: 0.5259 (0.5259)  loss_vfl_aux_0: 0.7351 (0.7351)  loss_bbox_aux_0: 0.1924 (0.1924)  loss_giou_aux_0: 0.5755 (0.5755)  loss_vfl_aux_1: 0.7133 (0.7133)  loss_bbox_aux_1: 0.1800 (0.1800)  loss_giou_aux_1: 0.5374 (0.5374)  loss_vfl_aux_2: 0.7171 (0.7171)  loss_bbox_aux_2: 0.1804 (0.1804)  loss_giou_aux_2: 0.5245 (0.5245)  loss_vfl_aux_3: 0.6929 (0.6929)  loss_bbox_aux_3: 0.1763 (0.1763)  loss_giou_aux_3: 0.5317 (0.5317)  loss_vfl_aux_4: 0.6926 (0.6926)  loss_bbox_aux_4: 0.1756 (0.1756)  loss_giou_aux_4: 0.5250 (0.5250)  loss_vfl_aux_5: 0.7074 (0.7074)  loss_bbox_aux_5: 0.1908 (0.1908)  loss_giou_aux_5: 0.6181 (0.6181)  loss_vfl_dn_0: 0.4479 (0.4479)  loss_bbox_dn_0: 0.2681 (0.2681)  loss_giou_dn_0: 0.8003 (0.8003)  loss_vfl_dn_1: 0.4582 (0.4582)  loss_bbox_dn_1: 0.2234 (0.2234)  loss_giou_dn_1: 0.6330 (0.6330)  loss_vfl_dn_2: 0.4458 (0.4458)  loss_bbox_dn_2: 0.2135 (0.2135)  loss_giou_dn_2: 0.5859 (0.5859)  loss_vfl_dn_3: 0.4403 (0.4403)  loss_bbox_dn_3: 0.2096 (0.2096)  loss_giou_dn_3: 0.5707 (0.5707)  loss_vfl_dn_4: 0.4381 (0.4381)  loss_bbox_dn_4: 0.2113 (0.2113)  loss_giou_dn_4: 0.5720 (0.5720)  loss_vfl_dn_5: 0.4404 (0.4404)  loss_bbox_dn_5: 0.2122 (0.2122)  loss_giou_dn_5: 0.5737 (0.5737)  time: 1.0617  data: 0.6097  max mem: 7790\n",
            "Epoch: [34]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 19.0007 (19.3052)  loss_vfl: 0.6883 (0.7099)  loss_bbox: 0.1624 (0.1748)  loss_giou: 0.6398 (0.6491)  loss_vfl_aux_0: 0.6963 (0.6980)  loss_bbox_aux_0: 0.1715 (0.1923)  loss_giou_aux_0: 0.6726 (0.6893)  loss_vfl_aux_1: 0.6828 (0.6940)  loss_bbox_aux_1: 0.1655 (0.1831)  loss_giou_aux_1: 0.6315 (0.6662)  loss_vfl_aux_2: 0.6669 (0.6919)  loss_bbox_aux_2: 0.1631 (0.1786)  loss_giou_aux_2: 0.6190 (0.6547)  loss_vfl_aux_3: 0.6718 (0.6952)  loss_bbox_aux_3: 0.1618 (0.1777)  loss_giou_aux_3: 0.6231 (0.6534)  loss_vfl_aux_4: 0.6737 (0.7034)  loss_bbox_aux_4: 0.1614 (0.1733)  loss_giou_aux_4: 0.6182 (0.6485)  loss_vfl_aux_5: 0.6638 (0.6709)  loss_bbox_aux_5: 0.2232 (0.2415)  loss_giou_aux_5: 0.7864 (0.8146)  loss_vfl_dn_0: 0.4243 (0.4229)  loss_bbox_dn_0: 0.2505 (0.2702)  loss_giou_dn_0: 0.8859 (0.9008)  loss_vfl_dn_1: 0.4354 (0.4324)  loss_bbox_dn_1: 0.1952 (0.2260)  loss_giou_dn_1: 0.7326 (0.7491)  loss_vfl_dn_2: 0.4329 (0.4311)  loss_bbox_dn_2: 0.1773 (0.2139)  loss_giou_dn_2: 0.6939 (0.7041)  loss_vfl_dn_3: 0.4361 (0.4323)  loss_bbox_dn_3: 0.1725 (0.2113)  loss_giou_dn_3: 0.6846 (0.6913)  loss_vfl_dn_4: 0.4371 (0.4329)  loss_bbox_dn_4: 0.1719 (0.2104)  loss_giou_dn_4: 0.6849 (0.6865)  loss_vfl_dn_5: 0.4380 (0.4330)  loss_bbox_dn_5: 0.1716 (0.2103)  loss_giou_dn_5: 0.6860 (0.6861)  time: 0.3333  data: 0.0139  max mem: 7790\n",
            "Epoch: [34] Total time: 0:00:11 (0.3580 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 19.0007 (19.3052)  loss_vfl: 0.6883 (0.7099)  loss_bbox: 0.1624 (0.1748)  loss_giou: 0.6398 (0.6491)  loss_vfl_aux_0: 0.6963 (0.6980)  loss_bbox_aux_0: 0.1715 (0.1923)  loss_giou_aux_0: 0.6726 (0.6893)  loss_vfl_aux_1: 0.6828 (0.6940)  loss_bbox_aux_1: 0.1655 (0.1831)  loss_giou_aux_1: 0.6315 (0.6662)  loss_vfl_aux_2: 0.6669 (0.6919)  loss_bbox_aux_2: 0.1631 (0.1786)  loss_giou_aux_2: 0.6190 (0.6547)  loss_vfl_aux_3: 0.6718 (0.6952)  loss_bbox_aux_3: 0.1618 (0.1777)  loss_giou_aux_3: 0.6231 (0.6534)  loss_vfl_aux_4: 0.6737 (0.7034)  loss_bbox_aux_4: 0.1614 (0.1733)  loss_giou_aux_4: 0.6182 (0.6485)  loss_vfl_aux_5: 0.6638 (0.6709)  loss_bbox_aux_5: 0.2232 (0.2415)  loss_giou_aux_5: 0.7864 (0.8146)  loss_vfl_dn_0: 0.4243 (0.4229)  loss_bbox_dn_0: 0.2505 (0.2702)  loss_giou_dn_0: 0.8859 (0.9008)  loss_vfl_dn_1: 0.4354 (0.4324)  loss_bbox_dn_1: 0.1952 (0.2260)  loss_giou_dn_1: 0.7326 (0.7491)  loss_vfl_dn_2: 0.4329 (0.4311)  loss_bbox_dn_2: 0.1773 (0.2139)  loss_giou_dn_2: 0.6939 (0.7041)  loss_vfl_dn_3: 0.4361 (0.4323)  loss_bbox_dn_3: 0.1725 (0.2113)  loss_giou_dn_3: 0.6846 (0.6913)  loss_vfl_dn_4: 0.4371 (0.4329)  loss_bbox_dn_4: 0.1719 (0.2104)  loss_giou_dn_4: 0.6849 (0.6865)  loss_vfl_dn_5: 0.4380 (0.4330)  loss_bbox_dn_5: 0.1716 (0.2103)  loss_giou_dn_5: 0.6860 (0.6861)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8931  data: 0.5615  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3990  data: 0.1118  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4112 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.579\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659\n",
            "best_stat:  {'epoch': 31, 'coco_eval_bbox': 0.30855451581566173}\n",
            "Epoch: [35]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 18.8946 (18.8946)  loss_vfl: 0.6933 (0.6933)  loss_bbox: 0.1623 (0.1623)  loss_giou: 0.7131 (0.7131)  loss_vfl_aux_0: 0.5706 (0.5706)  loss_bbox_aux_0: 0.1531 (0.1531)  loss_giou_aux_0: 0.7857 (0.7857)  loss_vfl_aux_1: 0.6163 (0.6163)  loss_bbox_aux_1: 0.1649 (0.1649)  loss_giou_aux_1: 0.7414 (0.7414)  loss_vfl_aux_2: 0.6335 (0.6335)  loss_bbox_aux_2: 0.1629 (0.1629)  loss_giou_aux_2: 0.7328 (0.7328)  loss_vfl_aux_3: 0.6822 (0.6822)  loss_bbox_aux_3: 0.1594 (0.1594)  loss_giou_aux_3: 0.7132 (0.7132)  loss_vfl_aux_4: 0.6746 (0.6746)  loss_bbox_aux_4: 0.1636 (0.1636)  loss_giou_aux_4: 0.7208 (0.7208)  loss_vfl_aux_5: 0.5907 (0.5907)  loss_bbox_aux_5: 0.1817 (0.1817)  loss_giou_aux_5: 0.8732 (0.8732)  loss_vfl_dn_0: 0.4236 (0.4236)  loss_bbox_dn_0: 0.1716 (0.1716)  loss_giou_dn_0: 0.8836 (0.8836)  loss_vfl_dn_1: 0.4405 (0.4405)  loss_bbox_dn_1: 0.1420 (0.1420)  loss_giou_dn_1: 0.7507 (0.7507)  loss_vfl_dn_2: 0.4456 (0.4456)  loss_bbox_dn_2: 0.1395 (0.1395)  loss_giou_dn_2: 0.7169 (0.7169)  loss_vfl_dn_3: 0.4419 (0.4419)  loss_bbox_dn_3: 0.1393 (0.1393)  loss_giou_dn_3: 0.7102 (0.7102)  loss_vfl_dn_4: 0.4481 (0.4481)  loss_bbox_dn_4: 0.1402 (0.1402)  loss_giou_dn_4: 0.7088 (0.7088)  loss_vfl_dn_5: 0.4497 (0.4497)  loss_bbox_dn_5: 0.1408 (0.1408)  loss_giou_dn_5: 0.7123 (0.7123)  time: 0.9296  data: 0.5317  max mem: 7790\n",
            "Epoch: [35]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 19.1669 (18.9444)  loss_vfl: 0.6992 (0.7069)  loss_bbox: 0.1396 (0.1596)  loss_giou: 0.6144 (0.6229)  loss_vfl_aux_0: 0.6851 (0.6854)  loss_bbox_aux_0: 0.1596 (0.1766)  loss_giou_aux_0: 0.6533 (0.6750)  loss_vfl_aux_1: 0.6754 (0.6884)  loss_bbox_aux_1: 0.1513 (0.1654)  loss_giou_aux_1: 0.6336 (0.6457)  loss_vfl_aux_2: 0.6948 (0.7002)  loss_bbox_aux_2: 0.1440 (0.1619)  loss_giou_aux_2: 0.6086 (0.6288)  loss_vfl_aux_3: 0.6894 (0.7028)  loss_bbox_aux_3: 0.1422 (0.1603)  loss_giou_aux_3: 0.6171 (0.6258)  loss_vfl_aux_4: 0.6944 (0.7038)  loss_bbox_aux_4: 0.1454 (0.1597)  loss_giou_aux_4: 0.6115 (0.6250)  loss_vfl_aux_5: 0.6563 (0.6672)  loss_bbox_aux_5: 0.2121 (0.2289)  loss_giou_aux_5: 0.7962 (0.8018)  loss_vfl_dn_0: 0.4293 (0.4294)  loss_bbox_dn_0: 0.2576 (0.2629)  loss_giou_dn_0: 0.8939 (0.8851)  loss_vfl_dn_1: 0.4377 (0.4364)  loss_bbox_dn_1: 0.1997 (0.2137)  loss_giou_dn_1: 0.7248 (0.7349)  loss_vfl_dn_2: 0.4310 (0.4379)  loss_bbox_dn_2: 0.1864 (0.2027)  loss_giou_dn_2: 0.6750 (0.6943)  loss_vfl_dn_3: 0.4324 (0.4381)  loss_bbox_dn_3: 0.1831 (0.1995)  loss_giou_dn_3: 0.6632 (0.6832)  loss_vfl_dn_4: 0.4390 (0.4397)  loss_bbox_dn_4: 0.1829 (0.1983)  loss_giou_dn_4: 0.6585 (0.6797)  loss_vfl_dn_5: 0.4386 (0.4408)  loss_bbox_dn_5: 0.1819 (0.1977)  loss_giou_dn_5: 0.6583 (0.6781)  time: 0.3280  data: 0.0153  max mem: 7790\n",
            "Epoch: [35] Total time: 0:00:11 (0.3533 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 19.1669 (18.9444)  loss_vfl: 0.6992 (0.7069)  loss_bbox: 0.1396 (0.1596)  loss_giou: 0.6144 (0.6229)  loss_vfl_aux_0: 0.6851 (0.6854)  loss_bbox_aux_0: 0.1596 (0.1766)  loss_giou_aux_0: 0.6533 (0.6750)  loss_vfl_aux_1: 0.6754 (0.6884)  loss_bbox_aux_1: 0.1513 (0.1654)  loss_giou_aux_1: 0.6336 (0.6457)  loss_vfl_aux_2: 0.6948 (0.7002)  loss_bbox_aux_2: 0.1440 (0.1619)  loss_giou_aux_2: 0.6086 (0.6288)  loss_vfl_aux_3: 0.6894 (0.7028)  loss_bbox_aux_3: 0.1422 (0.1603)  loss_giou_aux_3: 0.6171 (0.6258)  loss_vfl_aux_4: 0.6944 (0.7038)  loss_bbox_aux_4: 0.1454 (0.1597)  loss_giou_aux_4: 0.6115 (0.6250)  loss_vfl_aux_5: 0.6563 (0.6672)  loss_bbox_aux_5: 0.2121 (0.2289)  loss_giou_aux_5: 0.7962 (0.8018)  loss_vfl_dn_0: 0.4293 (0.4294)  loss_bbox_dn_0: 0.2576 (0.2629)  loss_giou_dn_0: 0.8939 (0.8851)  loss_vfl_dn_1: 0.4377 (0.4364)  loss_bbox_dn_1: 0.1997 (0.2137)  loss_giou_dn_1: 0.7248 (0.7349)  loss_vfl_dn_2: 0.4310 (0.4379)  loss_bbox_dn_2: 0.1864 (0.2027)  loss_giou_dn_2: 0.6750 (0.6943)  loss_vfl_dn_3: 0.4324 (0.4381)  loss_bbox_dn_3: 0.1831 (0.1995)  loss_giou_dn_3: 0.6632 (0.6832)  loss_vfl_dn_4: 0.4390 (0.4397)  loss_bbox_dn_4: 0.1829 (0.1983)  loss_giou_dn_4: 0.6585 (0.6797)  loss_vfl_dn_5: 0.4386 (0.4408)  loss_bbox_dn_5: 0.1819 (0.1977)  loss_giou_dn_5: 0.6583 (0.6781)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8987  data: 0.5907  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3882  data: 0.1137  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4012 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.604\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.266\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            "best_stat:  {'epoch': 31, 'coco_eval_bbox': 0.30855451581566173}\n",
            "Epoch: [36]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 19.4740 (19.4740)  loss_vfl: 0.7462 (0.7462)  loss_bbox: 0.2325 (0.2325)  loss_giou: 0.5046 (0.5046)  loss_vfl_aux_0: 0.7919 (0.7919)  loss_bbox_aux_0: 0.2184 (0.2184)  loss_giou_aux_0: 0.4926 (0.4926)  loss_vfl_aux_1: 0.7773 (0.7773)  loss_bbox_aux_1: 0.2267 (0.2267)  loss_giou_aux_1: 0.4962 (0.4962)  loss_vfl_aux_2: 0.8187 (0.8187)  loss_bbox_aux_2: 0.2074 (0.2074)  loss_giou_aux_2: 0.4642 (0.4642)  loss_vfl_aux_3: 0.7361 (0.7361)  loss_bbox_aux_3: 0.2359 (0.2359)  loss_giou_aux_3: 0.5044 (0.5044)  loss_vfl_aux_4: 0.7261 (0.7261)  loss_bbox_aux_4: 0.2314 (0.2314)  loss_giou_aux_4: 0.5058 (0.5058)  loss_vfl_aux_5: 0.7265 (0.7265)  loss_bbox_aux_5: 0.3219 (0.3219)  loss_giou_aux_5: 0.6598 (0.6598)  loss_vfl_dn_0: 0.4307 (0.4307)  loss_bbox_dn_0: 0.4581 (0.4581)  loss_giou_dn_0: 0.8913 (0.8913)  loss_vfl_dn_1: 0.4488 (0.4488)  loss_bbox_dn_1: 0.3582 (0.3582)  loss_giou_dn_1: 0.6876 (0.6876)  loss_vfl_dn_2: 0.4512 (0.4512)  loss_bbox_dn_2: 0.3359 (0.3359)  loss_giou_dn_2: 0.6257 (0.6257)  loss_vfl_dn_3: 0.4498 (0.4498)  loss_bbox_dn_3: 0.3322 (0.3322)  loss_giou_dn_3: 0.6069 (0.6069)  loss_vfl_dn_4: 0.4505 (0.4505)  loss_bbox_dn_4: 0.3335 (0.3335)  loss_giou_dn_4: 0.6018 (0.6018)  loss_vfl_dn_5: 0.4518 (0.4518)  loss_bbox_dn_5: 0.3345 (0.3345)  loss_giou_dn_5: 0.6011 (0.6011)  time: 0.9656  data: 0.5844  max mem: 7790\n",
            "Epoch: [36]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.6838 (18.6640)  loss_vfl: 0.6646 (0.6792)  loss_bbox: 0.1544 (0.1669)  loss_giou: 0.5680 (0.6030)  loss_vfl_aux_0: 0.6789 (0.6904)  loss_bbox_aux_0: 0.1690 (0.1836)  loss_giou_aux_0: 0.6240 (0.6485)  loss_vfl_aux_1: 0.6636 (0.6777)  loss_bbox_aux_1: 0.1596 (0.1735)  loss_giou_aux_1: 0.5806 (0.6205)  loss_vfl_aux_2: 0.6593 (0.6693)  loss_bbox_aux_2: 0.1629 (0.1722)  loss_giou_aux_2: 0.5824 (0.6121)  loss_vfl_aux_3: 0.6601 (0.6672)  loss_bbox_aux_3: 0.1587 (0.1710)  loss_giou_aux_3: 0.5700 (0.6094)  loss_vfl_aux_4: 0.6495 (0.6744)  loss_bbox_aux_4: 0.1588 (0.1691)  loss_giou_aux_4: 0.5657 (0.6048)  loss_vfl_aux_5: 0.6429 (0.6938)  loss_bbox_aux_5: 0.2272 (0.2315)  loss_giou_aux_5: 0.7593 (0.7619)  loss_vfl_dn_0: 0.4299 (0.4276)  loss_bbox_dn_0: 0.2670 (0.2805)  loss_giou_dn_0: 0.8642 (0.8721)  loss_vfl_dn_1: 0.4327 (0.4313)  loss_bbox_dn_1: 0.2238 (0.2279)  loss_giou_dn_1: 0.6986 (0.7229)  loss_vfl_dn_2: 0.4337 (0.4314)  loss_bbox_dn_2: 0.2113 (0.2130)  loss_giou_dn_2: 0.6488 (0.6789)  loss_vfl_dn_3: 0.4302 (0.4308)  loss_bbox_dn_3: 0.2054 (0.2089)  loss_giou_dn_3: 0.6353 (0.6648)  loss_vfl_dn_4: 0.4328 (0.4316)  loss_bbox_dn_4: 0.1995 (0.2073)  loss_giou_dn_4: 0.6264 (0.6592)  loss_vfl_dn_5: 0.4320 (0.4315)  loss_bbox_dn_5: 0.1973 (0.2068)  loss_giou_dn_5: 0.6231 (0.6573)  time: 0.3240  data: 0.0159  max mem: 7790\n",
            "Epoch: [36] Total time: 0:00:11 (0.3467 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.6838 (18.6640)  loss_vfl: 0.6646 (0.6792)  loss_bbox: 0.1544 (0.1669)  loss_giou: 0.5680 (0.6030)  loss_vfl_aux_0: 0.6789 (0.6904)  loss_bbox_aux_0: 0.1690 (0.1836)  loss_giou_aux_0: 0.6240 (0.6485)  loss_vfl_aux_1: 0.6636 (0.6777)  loss_bbox_aux_1: 0.1596 (0.1735)  loss_giou_aux_1: 0.5806 (0.6205)  loss_vfl_aux_2: 0.6593 (0.6693)  loss_bbox_aux_2: 0.1629 (0.1722)  loss_giou_aux_2: 0.5824 (0.6121)  loss_vfl_aux_3: 0.6601 (0.6672)  loss_bbox_aux_3: 0.1587 (0.1710)  loss_giou_aux_3: 0.5700 (0.6094)  loss_vfl_aux_4: 0.6495 (0.6744)  loss_bbox_aux_4: 0.1588 (0.1691)  loss_giou_aux_4: 0.5657 (0.6048)  loss_vfl_aux_5: 0.6429 (0.6938)  loss_bbox_aux_5: 0.2272 (0.2315)  loss_giou_aux_5: 0.7593 (0.7619)  loss_vfl_dn_0: 0.4299 (0.4276)  loss_bbox_dn_0: 0.2670 (0.2805)  loss_giou_dn_0: 0.8642 (0.8721)  loss_vfl_dn_1: 0.4327 (0.4313)  loss_bbox_dn_1: 0.2238 (0.2279)  loss_giou_dn_1: 0.6986 (0.7229)  loss_vfl_dn_2: 0.4337 (0.4314)  loss_bbox_dn_2: 0.2113 (0.2130)  loss_giou_dn_2: 0.6488 (0.6789)  loss_vfl_dn_3: 0.4302 (0.4308)  loss_bbox_dn_3: 0.2054 (0.2089)  loss_giou_dn_3: 0.6353 (0.6648)  loss_vfl_dn_4: 0.4328 (0.4316)  loss_bbox_dn_4: 0.1995 (0.2073)  loss_giou_dn_4: 0.6264 (0.6592)  loss_vfl_dn_5: 0.4320 (0.4315)  loss_bbox_dn_5: 0.1973 (0.2068)  loss_giou_dn_5: 0.6231 (0.6573)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9003  data: 0.5921  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4389  data: 0.1101  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4528 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.588\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.343\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "best_stat:  {'epoch': 31, 'coco_eval_bbox': 0.30855451581566173}\n",
            "Epoch: [37]  [ 0/33]  eta: 0:00:36  lr: 0.000001  loss: 19.5181 (19.5181)  loss_vfl: 0.8830 (0.8830)  loss_bbox: 0.1474 (0.1474)  loss_giou: 0.5541 (0.5541)  loss_vfl_aux_0: 0.8393 (0.8393)  loss_bbox_aux_0: 0.2140 (0.2140)  loss_giou_aux_0: 0.6843 (0.6843)  loss_vfl_aux_1: 0.8736 (0.8736)  loss_bbox_aux_1: 0.1573 (0.1573)  loss_giou_aux_1: 0.5870 (0.5870)  loss_vfl_aux_2: 0.8683 (0.8683)  loss_bbox_aux_2: 0.1512 (0.1512)  loss_giou_aux_2: 0.5681 (0.5681)  loss_vfl_aux_3: 0.8629 (0.8629)  loss_bbox_aux_3: 0.1514 (0.1514)  loss_giou_aux_3: 0.5650 (0.5650)  loss_vfl_aux_4: 0.8369 (0.8369)  loss_bbox_aux_4: 0.1462 (0.1462)  loss_giou_aux_4: 0.5533 (0.5533)  loss_vfl_aux_5: 0.7949 (0.7949)  loss_bbox_aux_5: 0.2304 (0.2304)  loss_giou_aux_5: 0.7633 (0.7633)  loss_vfl_dn_0: 0.4272 (0.4272)  loss_bbox_dn_0: 0.2963 (0.2963)  loss_giou_dn_0: 0.8407 (0.8407)  loss_vfl_dn_1: 0.4412 (0.4412)  loss_bbox_dn_1: 0.2381 (0.2381)  loss_giou_dn_1: 0.6551 (0.6551)  loss_vfl_dn_2: 0.4361 (0.4361)  loss_bbox_dn_2: 0.2392 (0.2392)  loss_giou_dn_2: 0.6269 (0.6269)  loss_vfl_dn_3: 0.4360 (0.4360)  loss_bbox_dn_3: 0.2416 (0.2416)  loss_giou_dn_3: 0.6160 (0.6160)  loss_vfl_dn_4: 0.4297 (0.4297)  loss_bbox_dn_4: 0.2453 (0.2453)  loss_giou_dn_4: 0.6139 (0.6139)  loss_vfl_dn_5: 0.4387 (0.4387)  loss_bbox_dn_5: 0.2474 (0.2474)  loss_giou_dn_5: 0.6168 (0.6168)  time: 1.1202  data: 0.7623  max mem: 7790\n",
            "Epoch: [37]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.7860 (18.9271)  loss_vfl: 0.6906 (0.7168)  loss_bbox: 0.1491 (0.1648)  loss_giou: 0.5718 (0.5972)  loss_vfl_aux_0: 0.6723 (0.6992)  loss_bbox_aux_0: 0.1749 (0.1833)  loss_giou_aux_0: 0.6509 (0.6578)  loss_vfl_aux_1: 0.6690 (0.6912)  loss_bbox_aux_1: 0.1583 (0.1762)  loss_giou_aux_1: 0.5956 (0.6283)  loss_vfl_aux_2: 0.6389 (0.6988)  loss_bbox_aux_2: 0.1559 (0.1719)  loss_giou_aux_2: 0.5696 (0.6121)  loss_vfl_aux_3: 0.6721 (0.7073)  loss_bbox_aux_3: 0.1532 (0.1686)  loss_giou_aux_3: 0.5596 (0.6035)  loss_vfl_aux_4: 0.6866 (0.7128)  loss_bbox_aux_4: 0.1540 (0.1661)  loss_giou_aux_4: 0.5623 (0.5984)  loss_vfl_aux_5: 0.6764 (0.6791)  loss_bbox_aux_5: 0.2070 (0.2254)  loss_giou_aux_5: 0.7497 (0.7709)  loss_vfl_dn_0: 0.4261 (0.4295)  loss_bbox_dn_0: 0.2527 (0.2769)  loss_giou_dn_0: 0.9038 (0.8876)  loss_vfl_dn_1: 0.4347 (0.4385)  loss_bbox_dn_1: 0.2176 (0.2289)  loss_giou_dn_1: 0.7585 (0.7297)  loss_vfl_dn_2: 0.4397 (0.4394)  loss_bbox_dn_2: 0.2076 (0.2164)  loss_giou_dn_2: 0.7217 (0.6871)  loss_vfl_dn_3: 0.4399 (0.4409)  loss_bbox_dn_3: 0.2035 (0.2130)  loss_giou_dn_3: 0.7105 (0.6704)  loss_vfl_dn_4: 0.4397 (0.4423)  loss_bbox_dn_4: 0.2031 (0.2119)  loss_giou_dn_4: 0.7005 (0.6655)  loss_vfl_dn_5: 0.4447 (0.4434)  loss_bbox_dn_5: 0.2026 (0.2116)  loss_giou_dn_5: 0.6989 (0.6640)  time: 0.3186  data: 0.0150  max mem: 7790\n",
            "Epoch: [37] Total time: 0:00:11 (0.3471 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.7860 (18.9271)  loss_vfl: 0.6906 (0.7168)  loss_bbox: 0.1491 (0.1648)  loss_giou: 0.5718 (0.5972)  loss_vfl_aux_0: 0.6723 (0.6992)  loss_bbox_aux_0: 0.1749 (0.1833)  loss_giou_aux_0: 0.6509 (0.6578)  loss_vfl_aux_1: 0.6690 (0.6912)  loss_bbox_aux_1: 0.1583 (0.1762)  loss_giou_aux_1: 0.5956 (0.6283)  loss_vfl_aux_2: 0.6389 (0.6988)  loss_bbox_aux_2: 0.1559 (0.1719)  loss_giou_aux_2: 0.5696 (0.6121)  loss_vfl_aux_3: 0.6721 (0.7073)  loss_bbox_aux_3: 0.1532 (0.1686)  loss_giou_aux_3: 0.5596 (0.6035)  loss_vfl_aux_4: 0.6866 (0.7128)  loss_bbox_aux_4: 0.1540 (0.1661)  loss_giou_aux_4: 0.5623 (0.5984)  loss_vfl_aux_5: 0.6764 (0.6791)  loss_bbox_aux_5: 0.2070 (0.2254)  loss_giou_aux_5: 0.7497 (0.7709)  loss_vfl_dn_0: 0.4261 (0.4295)  loss_bbox_dn_0: 0.2527 (0.2769)  loss_giou_dn_0: 0.9038 (0.8876)  loss_vfl_dn_1: 0.4347 (0.4385)  loss_bbox_dn_1: 0.2176 (0.2289)  loss_giou_dn_1: 0.7585 (0.7297)  loss_vfl_dn_2: 0.4397 (0.4394)  loss_bbox_dn_2: 0.2076 (0.2164)  loss_giou_dn_2: 0.7217 (0.6871)  loss_vfl_dn_3: 0.4399 (0.4409)  loss_bbox_dn_3: 0.2035 (0.2130)  loss_giou_dn_3: 0.7105 (0.6704)  loss_vfl_dn_4: 0.4397 (0.4423)  loss_bbox_dn_4: 0.2031 (0.2119)  loss_giou_dn_4: 0.7005 (0.6655)  loss_vfl_dn_5: 0.4447 (0.4434)  loss_bbox_dn_5: 0.2026 (0.2116)  loss_giou_dn_5: 0.6989 (0.6640)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8660  data: 0.5540  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4433  data: 0.1111  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4573 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.598\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n",
            "best_stat:  {'epoch': 31, 'coco_eval_bbox': 0.30855451581566173}\n",
            "Epoch: [38]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 22.0067 (22.0067)  loss_vfl: 0.7350 (0.7350)  loss_bbox: 0.2692 (0.2692)  loss_giou: 0.7874 (0.7874)  loss_vfl_aux_0: 0.8545 (0.8545)  loss_bbox_aux_0: 0.2609 (0.2609)  loss_giou_aux_0: 0.7552 (0.7552)  loss_vfl_aux_1: 0.8600 (0.8600)  loss_bbox_aux_1: 0.2418 (0.2418)  loss_giou_aux_1: 0.7416 (0.7416)  loss_vfl_aux_2: 0.8018 (0.8018)  loss_bbox_aux_2: 0.2584 (0.2584)  loss_giou_aux_2: 0.7685 (0.7685)  loss_vfl_aux_3: 0.7833 (0.7833)  loss_bbox_aux_3: 0.2664 (0.2664)  loss_giou_aux_3: 0.7896 (0.7896)  loss_vfl_aux_4: 0.8222 (0.8222)  loss_bbox_aux_4: 0.2621 (0.2621)  loss_giou_aux_4: 0.7456 (0.7456)  loss_vfl_aux_5: 0.7756 (0.7756)  loss_bbox_aux_5: 0.3450 (0.3450)  loss_giou_aux_5: 0.9198 (0.9198)  loss_vfl_dn_0: 0.4186 (0.4186)  loss_bbox_dn_0: 0.3433 (0.3433)  loss_giou_dn_0: 0.9243 (0.9243)  loss_vfl_dn_1: 0.4261 (0.4261)  loss_bbox_dn_1: 0.2836 (0.2836)  loss_giou_dn_1: 0.8165 (0.8165)  loss_vfl_dn_2: 0.4215 (0.4215)  loss_bbox_dn_2: 0.2606 (0.2606)  loss_giou_dn_2: 0.7652 (0.7652)  loss_vfl_dn_3: 0.4214 (0.4214)  loss_bbox_dn_3: 0.2532 (0.2532)  loss_giou_dn_3: 0.7616 (0.7616)  loss_vfl_dn_4: 0.4197 (0.4197)  loss_bbox_dn_4: 0.2552 (0.2552)  loss_giou_dn_4: 0.7579 (0.7579)  loss_vfl_dn_5: 0.4209 (0.4209)  loss_bbox_dn_5: 0.2563 (0.2563)  loss_giou_dn_5: 0.7569 (0.7569)  time: 0.9947  data: 0.5567  max mem: 7790\n",
            "Epoch: [38]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.4190 (18.6884)  loss_vfl: 0.6619 (0.7034)  loss_bbox: 0.1358 (0.1618)  loss_giou: 0.5750 (0.6076)  loss_vfl_aux_0: 0.6723 (0.7045)  loss_bbox_aux_0: 0.1466 (0.1768)  loss_giou_aux_0: 0.6303 (0.6463)  loss_vfl_aux_1: 0.6685 (0.6950)  loss_bbox_aux_1: 0.1459 (0.1689)  loss_giou_aux_1: 0.6140 (0.6288)  loss_vfl_aux_2: 0.6578 (0.6927)  loss_bbox_aux_2: 0.1272 (0.1639)  loss_giou_aux_2: 0.5878 (0.6157)  loss_vfl_aux_3: 0.6648 (0.6943)  loss_bbox_aux_3: 0.1330 (0.1626)  loss_giou_aux_3: 0.5760 (0.6087)  loss_vfl_aux_4: 0.6635 (0.7030)  loss_bbox_aux_4: 0.1310 (0.1607)  loss_giou_aux_4: 0.5770 (0.6051)  loss_vfl_aux_5: 0.6487 (0.6930)  loss_bbox_aux_5: 0.1866 (0.2212)  loss_giou_aux_5: 0.7205 (0.7545)  loss_vfl_dn_0: 0.4305 (0.4298)  loss_bbox_dn_0: 0.2185 (0.2632)  loss_giou_dn_0: 0.8567 (0.8618)  loss_vfl_dn_1: 0.4337 (0.4353)  loss_bbox_dn_1: 0.1890 (0.2171)  loss_giou_dn_1: 0.7024 (0.7161)  loss_vfl_dn_2: 0.4344 (0.4359)  loss_bbox_dn_2: 0.1720 (0.2036)  loss_giou_dn_2: 0.6528 (0.6728)  loss_vfl_dn_3: 0.4363 (0.4357)  loss_bbox_dn_3: 0.1626 (0.2002)  loss_giou_dn_3: 0.6429 (0.6602)  loss_vfl_dn_4: 0.4352 (0.4366)  loss_bbox_dn_4: 0.1587 (0.1993)  loss_giou_dn_4: 0.6428 (0.6568)  loss_vfl_dn_5: 0.4376 (0.4394)  loss_bbox_dn_5: 0.1588 (0.1994)  loss_giou_dn_5: 0.6435 (0.6564)  time: 0.3360  data: 0.0150  max mem: 7790\n",
            "Epoch: [38] Total time: 0:00:11 (0.3607 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.4190 (18.6884)  loss_vfl: 0.6619 (0.7034)  loss_bbox: 0.1358 (0.1618)  loss_giou: 0.5750 (0.6076)  loss_vfl_aux_0: 0.6723 (0.7045)  loss_bbox_aux_0: 0.1466 (0.1768)  loss_giou_aux_0: 0.6303 (0.6463)  loss_vfl_aux_1: 0.6685 (0.6950)  loss_bbox_aux_1: 0.1459 (0.1689)  loss_giou_aux_1: 0.6140 (0.6288)  loss_vfl_aux_2: 0.6578 (0.6927)  loss_bbox_aux_2: 0.1272 (0.1639)  loss_giou_aux_2: 0.5878 (0.6157)  loss_vfl_aux_3: 0.6648 (0.6943)  loss_bbox_aux_3: 0.1330 (0.1626)  loss_giou_aux_3: 0.5760 (0.6087)  loss_vfl_aux_4: 0.6635 (0.7030)  loss_bbox_aux_4: 0.1310 (0.1607)  loss_giou_aux_4: 0.5770 (0.6051)  loss_vfl_aux_5: 0.6487 (0.6930)  loss_bbox_aux_5: 0.1866 (0.2212)  loss_giou_aux_5: 0.7205 (0.7545)  loss_vfl_dn_0: 0.4305 (0.4298)  loss_bbox_dn_0: 0.2185 (0.2632)  loss_giou_dn_0: 0.8567 (0.8618)  loss_vfl_dn_1: 0.4337 (0.4353)  loss_bbox_dn_1: 0.1890 (0.2171)  loss_giou_dn_1: 0.7024 (0.7161)  loss_vfl_dn_2: 0.4344 (0.4359)  loss_bbox_dn_2: 0.1720 (0.2036)  loss_giou_dn_2: 0.6528 (0.6728)  loss_vfl_dn_3: 0.4363 (0.4357)  loss_bbox_dn_3: 0.1626 (0.2002)  loss_giou_dn_3: 0.6429 (0.6602)  loss_vfl_dn_4: 0.4352 (0.4366)  loss_bbox_dn_4: 0.1587 (0.1993)  loss_giou_dn_4: 0.6428 (0.6568)  loss_vfl_dn_5: 0.4376 (0.4394)  loss_bbox_dn_5: 0.1588 (0.1994)  loss_giou_dn_5: 0.6435 (0.6564)\n",
            "Test:  [0/6]  eta: 0:00:04    time: 0.8322  data: 0.5239  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3805  data: 0.1097  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3952 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.629\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.366\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [39]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 16.9475 (16.9475)  loss_vfl: 0.8171 (0.8171)  loss_bbox: 0.1146 (0.1146)  loss_giou: 0.4316 (0.4316)  loss_vfl_aux_0: 0.7904 (0.7904)  loss_bbox_aux_0: 0.1299 (0.1299)  loss_giou_aux_0: 0.4893 (0.4893)  loss_vfl_aux_1: 0.8583 (0.8583)  loss_bbox_aux_1: 0.1180 (0.1180)  loss_giou_aux_1: 0.4589 (0.4589)  loss_vfl_aux_2: 0.7548 (0.7548)  loss_bbox_aux_2: 0.1307 (0.1307)  loss_giou_aux_2: 0.4598 (0.4598)  loss_vfl_aux_3: 0.7487 (0.7487)  loss_bbox_aux_3: 0.1270 (0.1270)  loss_giou_aux_3: 0.4681 (0.4681)  loss_vfl_aux_4: 0.8079 (0.8079)  loss_bbox_aux_4: 0.1194 (0.1194)  loss_giou_aux_4: 0.4364 (0.4364)  loss_vfl_aux_5: 0.7616 (0.7616)  loss_bbox_aux_5: 0.1761 (0.1761)  loss_giou_aux_5: 0.5970 (0.5970)  loss_vfl_dn_0: 0.4543 (0.4543)  loss_bbox_dn_0: 0.2910 (0.2910)  loss_giou_dn_0: 0.7524 (0.7524)  loss_vfl_dn_1: 0.4514 (0.4514)  loss_bbox_dn_1: 0.2083 (0.2083)  loss_giou_dn_1: 0.5578 (0.5578)  loss_vfl_dn_2: 0.4380 (0.4380)  loss_bbox_dn_2: 0.1825 (0.1825)  loss_giou_dn_2: 0.5106 (0.5106)  loss_vfl_dn_3: 0.4381 (0.4381)  loss_bbox_dn_3: 0.1740 (0.1740)  loss_giou_dn_3: 0.5020 (0.5020)  loss_vfl_dn_4: 0.4398 (0.4398)  loss_bbox_dn_4: 0.1678 (0.1678)  loss_giou_dn_4: 0.4928 (0.4928)  loss_vfl_dn_5: 0.4353 (0.4353)  loss_bbox_dn_5: 0.1658 (0.1658)  loss_giou_dn_5: 0.4900 (0.4900)  time: 0.9996  data: 0.5984  max mem: 7790\n",
            "Epoch: [39]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.3672 (18.5362)  loss_vfl: 0.6472 (0.6923)  loss_bbox: 0.1499 (0.1518)  loss_giou: 0.6320 (0.6069)  loss_vfl_aux_0: 0.6355 (0.6815)  loss_bbox_aux_0: 0.1488 (0.1701)  loss_giou_aux_0: 0.6733 (0.6538)  loss_vfl_aux_1: 0.6398 (0.6876)  loss_bbox_aux_1: 0.1449 (0.1597)  loss_giou_aux_1: 0.6522 (0.6249)  loss_vfl_aux_2: 0.6585 (0.6866)  loss_bbox_aux_2: 0.1499 (0.1571)  loss_giou_aux_2: 0.6440 (0.6162)  loss_vfl_aux_3: 0.6735 (0.6841)  loss_bbox_aux_3: 0.1510 (0.1581)  loss_giou_aux_3: 0.6303 (0.6140)  loss_vfl_aux_4: 0.6763 (0.6972)  loss_bbox_aux_4: 0.1407 (0.1517)  loss_giou_aux_4: 0.6301 (0.6062)  loss_vfl_aux_5: 0.6375 (0.6610)  loss_bbox_aux_5: 0.1868 (0.2200)  loss_giou_aux_5: 0.7900 (0.7738)  loss_vfl_dn_0: 0.4299 (0.4286)  loss_bbox_dn_0: 0.2062 (0.2589)  loss_giou_dn_0: 0.8603 (0.8731)  loss_vfl_dn_1: 0.4304 (0.4317)  loss_bbox_dn_1: 0.1631 (0.2100)  loss_giou_dn_1: 0.7150 (0.7218)  loss_vfl_dn_2: 0.4266 (0.4307)  loss_bbox_dn_2: 0.1542 (0.1966)  loss_giou_dn_2: 0.6661 (0.6794)  loss_vfl_dn_3: 0.4234 (0.4303)  loss_bbox_dn_3: 0.1532 (0.1925)  loss_giou_dn_3: 0.6557 (0.6647)  loss_vfl_dn_4: 0.4264 (0.4316)  loss_bbox_dn_4: 0.1533 (0.1910)  loss_giou_dn_4: 0.6521 (0.6600)  loss_vfl_dn_5: 0.4268 (0.4319)  loss_bbox_dn_5: 0.1528 (0.1903)  loss_giou_dn_5: 0.6495 (0.6585)  time: 0.3235  data: 0.0142  max mem: 7790\n",
            "Epoch: [39] Total time: 0:00:11 (0.3556 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.3672 (18.5362)  loss_vfl: 0.6472 (0.6923)  loss_bbox: 0.1499 (0.1518)  loss_giou: 0.6320 (0.6069)  loss_vfl_aux_0: 0.6355 (0.6815)  loss_bbox_aux_0: 0.1488 (0.1701)  loss_giou_aux_0: 0.6733 (0.6538)  loss_vfl_aux_1: 0.6398 (0.6876)  loss_bbox_aux_1: 0.1449 (0.1597)  loss_giou_aux_1: 0.6522 (0.6249)  loss_vfl_aux_2: 0.6585 (0.6866)  loss_bbox_aux_2: 0.1499 (0.1571)  loss_giou_aux_2: 0.6440 (0.6162)  loss_vfl_aux_3: 0.6735 (0.6841)  loss_bbox_aux_3: 0.1510 (0.1581)  loss_giou_aux_3: 0.6303 (0.6140)  loss_vfl_aux_4: 0.6763 (0.6972)  loss_bbox_aux_4: 0.1407 (0.1517)  loss_giou_aux_4: 0.6301 (0.6062)  loss_vfl_aux_5: 0.6375 (0.6610)  loss_bbox_aux_5: 0.1868 (0.2200)  loss_giou_aux_5: 0.7900 (0.7738)  loss_vfl_dn_0: 0.4299 (0.4286)  loss_bbox_dn_0: 0.2062 (0.2589)  loss_giou_dn_0: 0.8603 (0.8731)  loss_vfl_dn_1: 0.4304 (0.4317)  loss_bbox_dn_1: 0.1631 (0.2100)  loss_giou_dn_1: 0.7150 (0.7218)  loss_vfl_dn_2: 0.4266 (0.4307)  loss_bbox_dn_2: 0.1542 (0.1966)  loss_giou_dn_2: 0.6661 (0.6794)  loss_vfl_dn_3: 0.4234 (0.4303)  loss_bbox_dn_3: 0.1532 (0.1925)  loss_giou_dn_3: 0.6557 (0.6647)  loss_vfl_dn_4: 0.4264 (0.4316)  loss_bbox_dn_4: 0.1533 (0.1910)  loss_giou_dn_4: 0.6521 (0.6600)  loss_vfl_dn_5: 0.4268 (0.4319)  loss_bbox_dn_5: 0.1528 (0.1903)  loss_giou_dn_5: 0.6495 (0.6585)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8872  data: 0.5761  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3783  data: 0.1077  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3921 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.594\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [40]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 17.1039 (17.1039)  loss_vfl: 0.6361 (0.6361)  loss_bbox: 0.1309 (0.1309)  loss_giou: 0.5400 (0.5400)  loss_vfl_aux_0: 0.6659 (0.6659)  loss_bbox_aux_0: 0.1401 (0.1401)  loss_giou_aux_0: 0.5735 (0.5735)  loss_vfl_aux_1: 0.6757 (0.6757)  loss_bbox_aux_1: 0.1282 (0.1282)  loss_giou_aux_1: 0.5487 (0.5487)  loss_vfl_aux_2: 0.6815 (0.6815)  loss_bbox_aux_2: 0.1305 (0.1305)  loss_giou_aux_2: 0.5489 (0.5489)  loss_vfl_aux_3: 0.6377 (0.6377)  loss_bbox_aux_3: 0.1314 (0.1314)  loss_giou_aux_3: 0.5440 (0.5440)  loss_vfl_aux_4: 0.6369 (0.6369)  loss_bbox_aux_4: 0.1325 (0.1325)  loss_giou_aux_4: 0.5447 (0.5447)  loss_vfl_aux_5: 0.6843 (0.6843)  loss_bbox_aux_5: 0.1869 (0.1869)  loss_giou_aux_5: 0.7022 (0.7022)  loss_vfl_dn_0: 0.4352 (0.4352)  loss_bbox_dn_0: 0.2071 (0.2071)  loss_giou_dn_0: 0.8003 (0.8003)  loss_vfl_dn_1: 0.4267 (0.4267)  loss_bbox_dn_1: 0.1657 (0.1657)  loss_giou_dn_1: 0.6697 (0.6697)  loss_vfl_dn_2: 0.4223 (0.4223)  loss_bbox_dn_2: 0.1577 (0.1577)  loss_giou_dn_2: 0.6344 (0.6344)  loss_vfl_dn_3: 0.4200 (0.4200)  loss_bbox_dn_3: 0.1556 (0.1556)  loss_giou_dn_3: 0.6191 (0.6191)  loss_vfl_dn_4: 0.4238 (0.4238)  loss_bbox_dn_4: 0.1566 (0.1566)  loss_giou_dn_4: 0.6167 (0.6167)  loss_vfl_dn_5: 0.4253 (0.4253)  loss_bbox_dn_5: 0.1553 (0.1553)  loss_giou_dn_5: 0.6118 (0.6118)  time: 1.0819  data: 0.6430  max mem: 7790\n",
            "Epoch: [40]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.4384 (18.3154)  loss_vfl: 0.6251 (0.6685)  loss_bbox: 0.1691 (0.1694)  loss_giou: 0.5641 (0.5941)  loss_vfl_aux_0: 0.6652 (0.6812)  loss_bbox_aux_0: 0.1719 (0.1815)  loss_giou_aux_0: 0.5884 (0.6362)  loss_vfl_aux_1: 0.6418 (0.6660)  loss_bbox_aux_1: 0.1644 (0.1733)  loss_giou_aux_1: 0.5640 (0.6102)  loss_vfl_aux_2: 0.6261 (0.6614)  loss_bbox_aux_2: 0.1665 (0.1706)  loss_giou_aux_2: 0.5583 (0.6010)  loss_vfl_aux_3: 0.6131 (0.6605)  loss_bbox_aux_3: 0.1717 (0.1700)  loss_giou_aux_3: 0.5639 (0.5965)  loss_vfl_aux_4: 0.6136 (0.6599)  loss_bbox_aux_4: 0.1717 (0.1699)  loss_giou_aux_4: 0.5649 (0.5957)  loss_vfl_aux_5: 0.6732 (0.6881)  loss_bbox_aux_5: 0.1968 (0.2196)  loss_giou_aux_5: 0.7395 (0.7405)  loss_vfl_dn_0: 0.4310 (0.4298)  loss_bbox_dn_0: 0.2182 (0.2685)  loss_giou_dn_0: 0.8198 (0.8514)  loss_vfl_dn_1: 0.4334 (0.4339)  loss_bbox_dn_1: 0.1852 (0.2186)  loss_giou_dn_1: 0.6424 (0.6970)  loss_vfl_dn_2: 0.4313 (0.4329)  loss_bbox_dn_2: 0.1775 (0.2063)  loss_giou_dn_2: 0.5866 (0.6524)  loss_vfl_dn_3: 0.4305 (0.4314)  loss_bbox_dn_3: 0.1752 (0.2029)  loss_giou_dn_3: 0.5664 (0.6372)  loss_vfl_dn_4: 0.4330 (0.4329)  loss_bbox_dn_4: 0.1766 (0.2028)  loss_giou_dn_4: 0.5615 (0.6342)  loss_vfl_dn_5: 0.4357 (0.4334)  loss_bbox_dn_5: 0.1771 (0.2025)  loss_giou_dn_5: 0.5609 (0.6330)  time: 0.3386  data: 0.0150  max mem: 7790\n",
            "Epoch: [40] Total time: 0:00:11 (0.3616 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.4384 (18.3154)  loss_vfl: 0.6251 (0.6685)  loss_bbox: 0.1691 (0.1694)  loss_giou: 0.5641 (0.5941)  loss_vfl_aux_0: 0.6652 (0.6812)  loss_bbox_aux_0: 0.1719 (0.1815)  loss_giou_aux_0: 0.5884 (0.6362)  loss_vfl_aux_1: 0.6418 (0.6660)  loss_bbox_aux_1: 0.1644 (0.1733)  loss_giou_aux_1: 0.5640 (0.6102)  loss_vfl_aux_2: 0.6261 (0.6614)  loss_bbox_aux_2: 0.1665 (0.1706)  loss_giou_aux_2: 0.5583 (0.6010)  loss_vfl_aux_3: 0.6131 (0.6605)  loss_bbox_aux_3: 0.1717 (0.1700)  loss_giou_aux_3: 0.5639 (0.5965)  loss_vfl_aux_4: 0.6136 (0.6599)  loss_bbox_aux_4: 0.1717 (0.1699)  loss_giou_aux_4: 0.5649 (0.5957)  loss_vfl_aux_5: 0.6732 (0.6881)  loss_bbox_aux_5: 0.1968 (0.2196)  loss_giou_aux_5: 0.7395 (0.7405)  loss_vfl_dn_0: 0.4310 (0.4298)  loss_bbox_dn_0: 0.2182 (0.2685)  loss_giou_dn_0: 0.8198 (0.8514)  loss_vfl_dn_1: 0.4334 (0.4339)  loss_bbox_dn_1: 0.1852 (0.2186)  loss_giou_dn_1: 0.6424 (0.6970)  loss_vfl_dn_2: 0.4313 (0.4329)  loss_bbox_dn_2: 0.1775 (0.2063)  loss_giou_dn_2: 0.5866 (0.6524)  loss_vfl_dn_3: 0.4305 (0.4314)  loss_bbox_dn_3: 0.1752 (0.2029)  loss_giou_dn_3: 0.5664 (0.6372)  loss_vfl_dn_4: 0.4330 (0.4329)  loss_bbox_dn_4: 0.1766 (0.2028)  loss_giou_dn_4: 0.5615 (0.6342)  loss_vfl_dn_5: 0.4357 (0.4334)  loss_bbox_dn_5: 0.1771 (0.2025)  loss_giou_dn_5: 0.5609 (0.6330)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8863  data: 0.5787  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3826  data: 0.1109  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3958 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.587\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [41]  [ 0/33]  eta: 0:00:37  lr: 0.000001  loss: 20.2324 (20.2324)  loss_vfl: 0.6553 (0.6553)  loss_bbox: 0.1825 (0.1825)  loss_giou: 0.7587 (0.7587)  loss_vfl_aux_0: 0.7151 (0.7151)  loss_bbox_aux_0: 0.1827 (0.1827)  loss_giou_aux_0: 0.7915 (0.7915)  loss_vfl_aux_1: 0.6519 (0.6519)  loss_bbox_aux_1: 0.1753 (0.1753)  loss_giou_aux_1: 0.7622 (0.7622)  loss_vfl_aux_2: 0.6541 (0.6541)  loss_bbox_aux_2: 0.1752 (0.1752)  loss_giou_aux_2: 0.7570 (0.7570)  loss_vfl_aux_3: 0.6597 (0.6597)  loss_bbox_aux_3: 0.1840 (0.1840)  loss_giou_aux_3: 0.7598 (0.7598)  loss_vfl_aux_4: 0.6662 (0.6662)  loss_bbox_aux_4: 0.1826 (0.1826)  loss_giou_aux_4: 0.7559 (0.7559)  loss_vfl_aux_5: 0.6883 (0.6883)  loss_bbox_aux_5: 0.2134 (0.2134)  loss_giou_aux_5: 0.8668 (0.8668)  loss_vfl_dn_0: 0.4045 (0.4045)  loss_bbox_dn_0: 0.2333 (0.2333)  loss_giou_dn_0: 0.9745 (0.9745)  loss_vfl_dn_1: 0.4182 (0.4182)  loss_bbox_dn_1: 0.1953 (0.1953)  loss_giou_dn_1: 0.8350 (0.8350)  loss_vfl_dn_2: 0.4305 (0.4305)  loss_bbox_dn_2: 0.1940 (0.1940)  loss_giou_dn_2: 0.8100 (0.8100)  loss_vfl_dn_3: 0.4355 (0.4355)  loss_bbox_dn_3: 0.1969 (0.1969)  loss_giou_dn_3: 0.8006 (0.8006)  loss_vfl_dn_4: 0.4378 (0.4378)  loss_bbox_dn_4: 0.1965 (0.1965)  loss_giou_dn_4: 0.7973 (0.7973)  loss_vfl_dn_5: 0.4392 (0.4392)  loss_bbox_dn_5: 0.1972 (0.1972)  loss_giou_dn_5: 0.7978 (0.7978)  time: 1.1388  data: 0.7623  max mem: 7790\n",
            "Epoch: [41]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.1459 (18.4281)  loss_vfl: 0.6442 (0.6580)  loss_bbox: 0.1475 (0.1507)  loss_giou: 0.6020 (0.6311)  loss_vfl_aux_0: 0.6635 (0.6530)  loss_bbox_aux_0: 0.1562 (0.1630)  loss_giou_aux_0: 0.6428 (0.6783)  loss_vfl_aux_1: 0.6525 (0.6473)  loss_bbox_aux_1: 0.1509 (0.1550)  loss_giou_aux_1: 0.6192 (0.6495)  loss_vfl_aux_2: 0.6604 (0.6559)  loss_bbox_aux_2: 0.1416 (0.1512)  loss_giou_aux_2: 0.6000 (0.6348)  loss_vfl_aux_3: 0.6479 (0.6531)  loss_bbox_aux_3: 0.1495 (0.1514)  loss_giou_aux_3: 0.6023 (0.6344)  loss_vfl_aux_4: 0.6519 (0.6555)  loss_bbox_aux_4: 0.1471 (0.1518)  loss_giou_aux_4: 0.6003 (0.6323)  loss_vfl_aux_5: 0.6479 (0.6540)  loss_bbox_aux_5: 0.1863 (0.2118)  loss_giou_aux_5: 0.7876 (0.7944)  loss_vfl_dn_0: 0.4254 (0.4246)  loss_bbox_dn_0: 0.2340 (0.2405)  loss_giou_dn_0: 0.8602 (0.8893)  loss_vfl_dn_1: 0.4239 (0.4259)  loss_bbox_dn_1: 0.1876 (0.1926)  loss_giou_dn_1: 0.7033 (0.7365)  loss_vfl_dn_2: 0.4255 (0.4252)  loss_bbox_dn_2: 0.1806 (0.1800)  loss_giou_dn_2: 0.6634 (0.6972)  loss_vfl_dn_3: 0.4258 (0.4254)  loss_bbox_dn_3: 0.1754 (0.1767)  loss_giou_dn_3: 0.6481 (0.6838)  loss_vfl_dn_4: 0.4296 (0.4262)  loss_bbox_dn_4: 0.1749 (0.1759)  loss_giou_dn_4: 0.6442 (0.6802)  loss_vfl_dn_5: 0.4290 (0.4270)  loss_bbox_dn_5: 0.1741 (0.1756)  loss_giou_dn_5: 0.6408 (0.6792)  time: 0.3207  data: 0.0144  max mem: 7790\n",
            "Epoch: [41] Total time: 0:00:11 (0.3489 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.1459 (18.4281)  loss_vfl: 0.6442 (0.6580)  loss_bbox: 0.1475 (0.1507)  loss_giou: 0.6020 (0.6311)  loss_vfl_aux_0: 0.6635 (0.6530)  loss_bbox_aux_0: 0.1562 (0.1630)  loss_giou_aux_0: 0.6428 (0.6783)  loss_vfl_aux_1: 0.6525 (0.6473)  loss_bbox_aux_1: 0.1509 (0.1550)  loss_giou_aux_1: 0.6192 (0.6495)  loss_vfl_aux_2: 0.6604 (0.6559)  loss_bbox_aux_2: 0.1416 (0.1512)  loss_giou_aux_2: 0.6000 (0.6348)  loss_vfl_aux_3: 0.6479 (0.6531)  loss_bbox_aux_3: 0.1495 (0.1514)  loss_giou_aux_3: 0.6023 (0.6344)  loss_vfl_aux_4: 0.6519 (0.6555)  loss_bbox_aux_4: 0.1471 (0.1518)  loss_giou_aux_4: 0.6003 (0.6323)  loss_vfl_aux_5: 0.6479 (0.6540)  loss_bbox_aux_5: 0.1863 (0.2118)  loss_giou_aux_5: 0.7876 (0.7944)  loss_vfl_dn_0: 0.4254 (0.4246)  loss_bbox_dn_0: 0.2340 (0.2405)  loss_giou_dn_0: 0.8602 (0.8893)  loss_vfl_dn_1: 0.4239 (0.4259)  loss_bbox_dn_1: 0.1876 (0.1926)  loss_giou_dn_1: 0.7033 (0.7365)  loss_vfl_dn_2: 0.4255 (0.4252)  loss_bbox_dn_2: 0.1806 (0.1800)  loss_giou_dn_2: 0.6634 (0.6972)  loss_vfl_dn_3: 0.4258 (0.4254)  loss_bbox_dn_3: 0.1754 (0.1767)  loss_giou_dn_3: 0.6481 (0.6838)  loss_vfl_dn_4: 0.4296 (0.4262)  loss_bbox_dn_4: 0.1749 (0.1759)  loss_giou_dn_4: 0.6442 (0.6802)  loss_vfl_dn_5: 0.4290 (0.4270)  loss_bbox_dn_5: 0.1741 (0.1756)  loss_giou_dn_5: 0.6408 (0.6792)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8723  data: 0.5470  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3908  data: 0.1087  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4038 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.580\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.264\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.273\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [42]  [ 0/33]  eta: 0:00:39  lr: 0.000001  loss: 17.3327 (17.3327)  loss_vfl: 0.7080 (0.7080)  loss_bbox: 0.1417 (0.1417)  loss_giou: 0.5950 (0.5950)  loss_vfl_aux_0: 0.7905 (0.7905)  loss_bbox_aux_0: 0.1417 (0.1417)  loss_giou_aux_0: 0.6002 (0.6002)  loss_vfl_aux_1: 0.7053 (0.7053)  loss_bbox_aux_1: 0.1381 (0.1381)  loss_giou_aux_1: 0.5686 (0.5686)  loss_vfl_aux_2: 0.7022 (0.7022)  loss_bbox_aux_2: 0.1209 (0.1209)  loss_giou_aux_2: 0.5591 (0.5591)  loss_vfl_aux_3: 0.6765 (0.6765)  loss_bbox_aux_3: 0.1223 (0.1223)  loss_giou_aux_3: 0.5710 (0.5710)  loss_vfl_aux_4: 0.7028 (0.7028)  loss_bbox_aux_4: 0.1239 (0.1239)  loss_giou_aux_4: 0.5628 (0.5628)  loss_vfl_aux_5: 0.6944 (0.6944)  loss_bbox_aux_5: 0.2011 (0.2011)  loss_giou_aux_5: 0.7087 (0.7087)  loss_vfl_dn_0: 0.4269 (0.4269)  loss_bbox_dn_0: 0.1934 (0.1934)  loss_giou_dn_0: 0.8373 (0.8373)  loss_vfl_dn_1: 0.4314 (0.4314)  loss_bbox_dn_1: 0.1509 (0.1509)  loss_giou_dn_1: 0.6323 (0.6323)  loss_vfl_dn_2: 0.4290 (0.4290)  loss_bbox_dn_2: 0.1426 (0.1426)  loss_giou_dn_2: 0.5753 (0.5753)  loss_vfl_dn_3: 0.4318 (0.4318)  loss_bbox_dn_3: 0.1367 (0.1367)  loss_giou_dn_3: 0.5600 (0.5600)  loss_vfl_dn_4: 0.4341 (0.4341)  loss_bbox_dn_4: 0.1361 (0.1361)  loss_giou_dn_4: 0.5550 (0.5550)  loss_vfl_dn_5: 0.4421 (0.4421)  loss_bbox_dn_5: 0.1335 (0.1335)  loss_giou_dn_5: 0.5498 (0.5498)  time: 1.2033  data: 0.7279  max mem: 7790\n",
            "Epoch: [42]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.9597 (18.4601)  loss_vfl: 0.6696 (0.6929)  loss_bbox: 0.1565 (0.1737)  loss_giou: 0.5443 (0.5913)  loss_vfl_aux_0: 0.6745 (0.6940)  loss_bbox_aux_0: 0.1719 (0.1849)  loss_giou_aux_0: 0.6001 (0.6423)  loss_vfl_aux_1: 0.6791 (0.6752)  loss_bbox_aux_1: 0.1588 (0.1777)  loss_giou_aux_1: 0.5798 (0.6150)  loss_vfl_aux_2: 0.6746 (0.6838)  loss_bbox_aux_2: 0.1602 (0.1746)  loss_giou_aux_2: 0.5714 (0.6038)  loss_vfl_aux_3: 0.6610 (0.6844)  loss_bbox_aux_3: 0.1570 (0.1719)  loss_giou_aux_3: 0.5518 (0.5960)  loss_vfl_aux_4: 0.6643 (0.6888)  loss_bbox_aux_4: 0.1533 (0.1714)  loss_giou_aux_4: 0.5473 (0.5929)  loss_vfl_aux_5: 0.6839 (0.7103)  loss_bbox_aux_5: 0.2245 (0.2320)  loss_giou_aux_5: 0.7067 (0.7473)  loss_vfl_dn_0: 0.4330 (0.4316)  loss_bbox_dn_0: 0.2517 (0.2770)  loss_giou_dn_0: 0.8272 (0.8461)  loss_vfl_dn_1: 0.4327 (0.4316)  loss_bbox_dn_1: 0.1979 (0.2205)  loss_giou_dn_1: 0.6620 (0.6902)  loss_vfl_dn_2: 0.4315 (0.4297)  loss_bbox_dn_2: 0.1841 (0.2067)  loss_giou_dn_2: 0.6132 (0.6463)  loss_vfl_dn_3: 0.4351 (0.4291)  loss_bbox_dn_3: 0.1804 (0.2025)  loss_giou_dn_3: 0.5970 (0.6319)  loss_vfl_dn_4: 0.4353 (0.4290)  loss_bbox_dn_4: 0.1804 (0.2016)  loss_giou_dn_4: 0.5926 (0.6271)  loss_vfl_dn_5: 0.4337 (0.4288)  loss_bbox_dn_5: 0.1800 (0.2009)  loss_giou_dn_5: 0.5942 (0.6254)  time: 0.3236  data: 0.0138  max mem: 7790\n",
            "Epoch: [42] Total time: 0:00:11 (0.3537 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.9597 (18.4601)  loss_vfl: 0.6696 (0.6929)  loss_bbox: 0.1565 (0.1737)  loss_giou: 0.5443 (0.5913)  loss_vfl_aux_0: 0.6745 (0.6940)  loss_bbox_aux_0: 0.1719 (0.1849)  loss_giou_aux_0: 0.6001 (0.6423)  loss_vfl_aux_1: 0.6791 (0.6752)  loss_bbox_aux_1: 0.1588 (0.1777)  loss_giou_aux_1: 0.5798 (0.6150)  loss_vfl_aux_2: 0.6746 (0.6838)  loss_bbox_aux_2: 0.1602 (0.1746)  loss_giou_aux_2: 0.5714 (0.6038)  loss_vfl_aux_3: 0.6610 (0.6844)  loss_bbox_aux_3: 0.1570 (0.1719)  loss_giou_aux_3: 0.5518 (0.5960)  loss_vfl_aux_4: 0.6643 (0.6888)  loss_bbox_aux_4: 0.1533 (0.1714)  loss_giou_aux_4: 0.5473 (0.5929)  loss_vfl_aux_5: 0.6839 (0.7103)  loss_bbox_aux_5: 0.2245 (0.2320)  loss_giou_aux_5: 0.7067 (0.7473)  loss_vfl_dn_0: 0.4330 (0.4316)  loss_bbox_dn_0: 0.2517 (0.2770)  loss_giou_dn_0: 0.8272 (0.8461)  loss_vfl_dn_1: 0.4327 (0.4316)  loss_bbox_dn_1: 0.1979 (0.2205)  loss_giou_dn_1: 0.6620 (0.6902)  loss_vfl_dn_2: 0.4315 (0.4297)  loss_bbox_dn_2: 0.1841 (0.2067)  loss_giou_dn_2: 0.6132 (0.6463)  loss_vfl_dn_3: 0.4351 (0.4291)  loss_bbox_dn_3: 0.1804 (0.2025)  loss_giou_dn_3: 0.5970 (0.6319)  loss_vfl_dn_4: 0.4353 (0.4290)  loss_bbox_dn_4: 0.1804 (0.2016)  loss_giou_dn_4: 0.5926 (0.6271)  loss_vfl_dn_5: 0.4337 (0.4288)  loss_bbox_dn_5: 0.1800 (0.2009)  loss_giou_dn_5: 0.5942 (0.6254)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9291  data: 0.6191  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3877  data: 0.1149  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4019 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.617\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.291\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.343\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [43]  [ 0/33]  eta: 0:00:41  lr: 0.000001  loss: 17.5845 (17.5845)  loss_vfl: 0.6881 (0.6881)  loss_bbox: 0.1026 (0.1026)  loss_giou: 0.5241 (0.5241)  loss_vfl_aux_0: 0.7130 (0.7130)  loss_bbox_aux_0: 0.1117 (0.1117)  loss_giou_aux_0: 0.5583 (0.5583)  loss_vfl_aux_1: 0.6708 (0.6708)  loss_bbox_aux_1: 0.1167 (0.1167)  loss_giou_aux_1: 0.5656 (0.5656)  loss_vfl_aux_2: 0.6718 (0.6718)  loss_bbox_aux_2: 0.1100 (0.1100)  loss_giou_aux_2: 0.5503 (0.5503)  loss_vfl_aux_3: 0.6657 (0.6657)  loss_bbox_aux_3: 0.1134 (0.1134)  loss_giou_aux_3: 0.5673 (0.5673)  loss_vfl_aux_4: 0.6708 (0.6708)  loss_bbox_aux_4: 0.1097 (0.1097)  loss_giou_aux_4: 0.5475 (0.5475)  loss_vfl_aux_5: 0.7236 (0.7236)  loss_bbox_aux_5: 0.1783 (0.1783)  loss_giou_aux_5: 0.7189 (0.7189)  loss_vfl_dn_0: 0.4161 (0.4161)  loss_bbox_dn_0: 0.2674 (0.2674)  loss_giou_dn_0: 0.8853 (0.8853)  loss_vfl_dn_1: 0.4177 (0.4177)  loss_bbox_dn_1: 0.2049 (0.2049)  loss_giou_dn_1: 0.7156 (0.7156)  loss_vfl_dn_2: 0.4218 (0.4218)  loss_bbox_dn_2: 0.1819 (0.1819)  loss_giou_dn_2: 0.6658 (0.6658)  loss_vfl_dn_3: 0.4201 (0.4201)  loss_bbox_dn_3: 0.1756 (0.1756)  loss_giou_dn_3: 0.6547 (0.6547)  loss_vfl_dn_4: 0.4206 (0.4206)  loss_bbox_dn_4: 0.1731 (0.1731)  loss_giou_dn_4: 0.6491 (0.6491)  loss_vfl_dn_5: 0.4199 (0.4199)  loss_bbox_dn_5: 0.1721 (0.1721)  loss_giou_dn_5: 0.6446 (0.6446)  time: 1.2715  data: 0.8585  max mem: 7790\n",
            "Epoch: [43]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.1922 (18.5629)  loss_vfl: 0.6320 (0.6747)  loss_bbox: 0.1593 (0.1620)  loss_giou: 0.6264 (0.6197)  loss_vfl_aux_0: 0.6522 (0.6669)  loss_bbox_aux_0: 0.1848 (0.1783)  loss_giou_aux_0: 0.6705 (0.6630)  loss_vfl_aux_1: 0.6236 (0.6528)  loss_bbox_aux_1: 0.1761 (0.1730)  loss_giou_aux_1: 0.6593 (0.6464)  loss_vfl_aux_2: 0.6250 (0.6596)  loss_bbox_aux_2: 0.1589 (0.1637)  loss_giou_aux_2: 0.6452 (0.6310)  loss_vfl_aux_3: 0.6355 (0.6655)  loss_bbox_aux_3: 0.1559 (0.1610)  loss_giou_aux_3: 0.6453 (0.6253)  loss_vfl_aux_4: 0.6350 (0.6652)  loss_bbox_aux_4: 0.1582 (0.1624)  loss_giou_aux_4: 0.6410 (0.6235)  loss_vfl_aux_5: 0.6239 (0.6644)  loss_bbox_aux_5: 0.1980 (0.2155)  loss_giou_aux_5: 0.7598 (0.7691)  loss_vfl_dn_0: 0.4253 (0.4241)  loss_bbox_dn_0: 0.2678 (0.2720)  loss_giou_dn_0: 0.8667 (0.8689)  loss_vfl_dn_1: 0.4311 (0.4278)  loss_bbox_dn_1: 0.2046 (0.2182)  loss_giou_dn_1: 0.7129 (0.7213)  loss_vfl_dn_2: 0.4243 (0.4234)  loss_bbox_dn_2: 0.1800 (0.2049)  loss_giou_dn_2: 0.6778 (0.6831)  loss_vfl_dn_3: 0.4232 (0.4224)  loss_bbox_dn_3: 0.1727 (0.2017)  loss_giou_dn_3: 0.6661 (0.6713)  loss_vfl_dn_4: 0.4239 (0.4226)  loss_bbox_dn_4: 0.1722 (0.2008)  loss_giou_dn_4: 0.6628 (0.6674)  loss_vfl_dn_5: 0.4217 (0.4236)  loss_bbox_dn_5: 0.1728 (0.2003)  loss_giou_dn_5: 0.6633 (0.6662)  time: 0.3148  data: 0.0158  max mem: 7790\n",
            "Epoch: [43] Total time: 0:00:11 (0.3484 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.1922 (18.5629)  loss_vfl: 0.6320 (0.6747)  loss_bbox: 0.1593 (0.1620)  loss_giou: 0.6264 (0.6197)  loss_vfl_aux_0: 0.6522 (0.6669)  loss_bbox_aux_0: 0.1848 (0.1783)  loss_giou_aux_0: 0.6705 (0.6630)  loss_vfl_aux_1: 0.6236 (0.6528)  loss_bbox_aux_1: 0.1761 (0.1730)  loss_giou_aux_1: 0.6593 (0.6464)  loss_vfl_aux_2: 0.6250 (0.6596)  loss_bbox_aux_2: 0.1589 (0.1637)  loss_giou_aux_2: 0.6452 (0.6310)  loss_vfl_aux_3: 0.6355 (0.6655)  loss_bbox_aux_3: 0.1559 (0.1610)  loss_giou_aux_3: 0.6453 (0.6253)  loss_vfl_aux_4: 0.6350 (0.6652)  loss_bbox_aux_4: 0.1582 (0.1624)  loss_giou_aux_4: 0.6410 (0.6235)  loss_vfl_aux_5: 0.6239 (0.6644)  loss_bbox_aux_5: 0.1980 (0.2155)  loss_giou_aux_5: 0.7598 (0.7691)  loss_vfl_dn_0: 0.4253 (0.4241)  loss_bbox_dn_0: 0.2678 (0.2720)  loss_giou_dn_0: 0.8667 (0.8689)  loss_vfl_dn_1: 0.4311 (0.4278)  loss_bbox_dn_1: 0.2046 (0.2182)  loss_giou_dn_1: 0.7129 (0.7213)  loss_vfl_dn_2: 0.4243 (0.4234)  loss_bbox_dn_2: 0.1800 (0.2049)  loss_giou_dn_2: 0.6778 (0.6831)  loss_vfl_dn_3: 0.4232 (0.4224)  loss_bbox_dn_3: 0.1727 (0.2017)  loss_giou_dn_3: 0.6661 (0.6713)  loss_vfl_dn_4: 0.4239 (0.4226)  loss_bbox_dn_4: 0.1722 (0.2008)  loss_giou_dn_4: 0.6628 (0.6674)  loss_vfl_dn_5: 0.4217 (0.4236)  loss_bbox_dn_5: 0.1728 (0.2003)  loss_giou_dn_5: 0.6633 (0.6662)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8868  data: 0.5768  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4356  data: 0.1108  max mem: 7790\n",
            "Test: Total time: 0:00:03 (0.6475 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.588\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.546\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [44]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 17.5499 (17.5499)  loss_vfl: 0.7208 (0.7208)  loss_bbox: 0.1769 (0.1769)  loss_giou: 0.5428 (0.5428)  loss_vfl_aux_0: 0.6811 (0.6811)  loss_bbox_aux_0: 0.2103 (0.2103)  loss_giou_aux_0: 0.5897 (0.5897)  loss_vfl_aux_1: 0.7223 (0.7223)  loss_bbox_aux_1: 0.1855 (0.1855)  loss_giou_aux_1: 0.5502 (0.5502)  loss_vfl_aux_2: 0.7396 (0.7396)  loss_bbox_aux_2: 0.1537 (0.1537)  loss_giou_aux_2: 0.5261 (0.5261)  loss_vfl_aux_3: 0.7565 (0.7565)  loss_bbox_aux_3: 0.1619 (0.1619)  loss_giou_aux_3: 0.5256 (0.5256)  loss_vfl_aux_4: 0.7584 (0.7584)  loss_bbox_aux_4: 0.1620 (0.1620)  loss_giou_aux_4: 0.5219 (0.5219)  loss_vfl_aux_5: 0.6482 (0.6482)  loss_bbox_aux_5: 0.2657 (0.2657)  loss_giou_aux_5: 0.6865 (0.6865)  loss_vfl_dn_0: 0.4413 (0.4413)  loss_bbox_dn_0: 0.2759 (0.2759)  loss_giou_dn_0: 0.7458 (0.7458)  loss_vfl_dn_1: 0.4429 (0.4429)  loss_bbox_dn_1: 0.2125 (0.2125)  loss_giou_dn_1: 0.5697 (0.5697)  loss_vfl_dn_2: 0.4395 (0.4395)  loss_bbox_dn_2: 0.1944 (0.1944)  loss_giou_dn_2: 0.5235 (0.5235)  loss_vfl_dn_3: 0.4353 (0.4353)  loss_bbox_dn_3: 0.1928 (0.1928)  loss_giou_dn_3: 0.5150 (0.5150)  loss_vfl_dn_4: 0.4336 (0.4336)  loss_bbox_dn_4: 0.1928 (0.1928)  loss_giou_dn_4: 0.5099 (0.5099)  loss_vfl_dn_5: 0.4327 (0.4327)  loss_bbox_dn_5: 0.1935 (0.1935)  loss_giou_dn_5: 0.5132 (0.5132)  time: 0.9878  data: 0.5923  max mem: 7790\n",
            "Epoch: [44]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.3515 (18.1356)  loss_vfl: 0.6592 (0.6649)  loss_bbox: 0.1433 (0.1498)  loss_giou: 0.6632 (0.6206)  loss_vfl_aux_0: 0.6380 (0.6521)  loss_bbox_aux_0: 0.1368 (0.1591)  loss_giou_aux_0: 0.6784 (0.6634)  loss_vfl_aux_1: 0.6312 (0.6477)  loss_bbox_aux_1: 0.1404 (0.1545)  loss_giou_aux_1: 0.6576 (0.6383)  loss_vfl_aux_2: 0.6573 (0.6593)  loss_bbox_aux_2: 0.1448 (0.1483)  loss_giou_aux_2: 0.6659 (0.6253)  loss_vfl_aux_3: 0.6608 (0.6606)  loss_bbox_aux_3: 0.1448 (0.1487)  loss_giou_aux_3: 0.6684 (0.6226)  loss_vfl_aux_4: 0.6628 (0.6685)  loss_bbox_aux_4: 0.1433 (0.1472)  loss_giou_aux_4: 0.6574 (0.6197)  loss_vfl_aux_5: 0.6504 (0.6658)  loss_bbox_aux_5: 0.1696 (0.1935)  loss_giou_aux_5: 0.7714 (0.7543)  loss_vfl_dn_0: 0.4317 (0.4325)  loss_bbox_dn_0: 0.1846 (0.2264)  loss_giou_dn_0: 0.8653 (0.8587)  loss_vfl_dn_1: 0.4284 (0.4331)  loss_bbox_dn_1: 0.1593 (0.1807)  loss_giou_dn_1: 0.7397 (0.7107)  loss_vfl_dn_2: 0.4282 (0.4318)  loss_bbox_dn_2: 0.1507 (0.1689)  loss_giou_dn_2: 0.6947 (0.6702)  loss_vfl_dn_3: 0.4325 (0.4311)  loss_bbox_dn_3: 0.1479 (0.1658)  loss_giou_dn_3: 0.6836 (0.6579)  loss_vfl_dn_4: 0.4333 (0.4331)  loss_bbox_dn_4: 0.1491 (0.1652)  loss_giou_dn_4: 0.6753 (0.6544)  loss_vfl_dn_5: 0.4320 (0.4336)  loss_bbox_dn_5: 0.1490 (0.1648)  loss_giou_dn_5: 0.6827 (0.6531)  time: 0.3199  data: 0.0152  max mem: 7790\n",
            "Epoch: [44] Total time: 0:00:11 (0.3392 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.3515 (18.1356)  loss_vfl: 0.6592 (0.6649)  loss_bbox: 0.1433 (0.1498)  loss_giou: 0.6632 (0.6206)  loss_vfl_aux_0: 0.6380 (0.6521)  loss_bbox_aux_0: 0.1368 (0.1591)  loss_giou_aux_0: 0.6784 (0.6634)  loss_vfl_aux_1: 0.6312 (0.6477)  loss_bbox_aux_1: 0.1404 (0.1545)  loss_giou_aux_1: 0.6576 (0.6383)  loss_vfl_aux_2: 0.6573 (0.6593)  loss_bbox_aux_2: 0.1448 (0.1483)  loss_giou_aux_2: 0.6659 (0.6253)  loss_vfl_aux_3: 0.6608 (0.6606)  loss_bbox_aux_3: 0.1448 (0.1487)  loss_giou_aux_3: 0.6684 (0.6226)  loss_vfl_aux_4: 0.6628 (0.6685)  loss_bbox_aux_4: 0.1433 (0.1472)  loss_giou_aux_4: 0.6574 (0.6197)  loss_vfl_aux_5: 0.6504 (0.6658)  loss_bbox_aux_5: 0.1696 (0.1935)  loss_giou_aux_5: 0.7714 (0.7543)  loss_vfl_dn_0: 0.4317 (0.4325)  loss_bbox_dn_0: 0.1846 (0.2264)  loss_giou_dn_0: 0.8653 (0.8587)  loss_vfl_dn_1: 0.4284 (0.4331)  loss_bbox_dn_1: 0.1593 (0.1807)  loss_giou_dn_1: 0.7397 (0.7107)  loss_vfl_dn_2: 0.4282 (0.4318)  loss_bbox_dn_2: 0.1507 (0.1689)  loss_giou_dn_2: 0.6947 (0.6702)  loss_vfl_dn_3: 0.4325 (0.4311)  loss_bbox_dn_3: 0.1479 (0.1658)  loss_giou_dn_3: 0.6836 (0.6579)  loss_vfl_dn_4: 0.4333 (0.4331)  loss_bbox_dn_4: 0.1491 (0.1652)  loss_giou_dn_4: 0.6753 (0.6544)  loss_vfl_dn_5: 0.4320 (0.4336)  loss_bbox_dn_5: 0.1490 (0.1648)  loss_giou_dn_5: 0.6827 (0.6531)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8646  data: 0.5540  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3812  data: 0.1067  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3941 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [45]  [ 0/33]  eta: 0:00:50  lr: 0.000001  loss: 19.3870 (19.3870)  loss_vfl: 0.7988 (0.7988)  loss_bbox: 0.2046 (0.2046)  loss_giou: 0.4837 (0.4837)  loss_vfl_aux_0: 0.8637 (0.8637)  loss_bbox_aux_0: 0.2018 (0.2018)  loss_giou_aux_0: 0.5317 (0.5317)  loss_vfl_aux_1: 0.7728 (0.7728)  loss_bbox_aux_1: 0.1939 (0.1939)  loss_giou_aux_1: 0.5120 (0.5120)  loss_vfl_aux_2: 0.8126 (0.8126)  loss_bbox_aux_2: 0.1921 (0.1921)  loss_giou_aux_2: 0.4779 (0.4779)  loss_vfl_aux_3: 0.7999 (0.7999)  loss_bbox_aux_3: 0.1969 (0.1969)  loss_giou_aux_3: 0.4802 (0.4802)  loss_vfl_aux_4: 0.8019 (0.8019)  loss_bbox_aux_4: 0.1998 (0.1998)  loss_giou_aux_4: 0.4820 (0.4820)  loss_vfl_aux_5: 0.8783 (0.8783)  loss_bbox_aux_5: 0.3151 (0.3151)  loss_giou_aux_5: 0.6499 (0.6499)  loss_vfl_dn_0: 0.4175 (0.4175)  loss_bbox_dn_0: 0.3835 (0.3835)  loss_giou_dn_0: 0.8491 (0.8491)  loss_vfl_dn_1: 0.4188 (0.4188)  loss_bbox_dn_1: 0.3327 (0.3327)  loss_giou_dn_1: 0.6790 (0.6790)  loss_vfl_dn_2: 0.4179 (0.4179)  loss_bbox_dn_2: 0.3179 (0.3179)  loss_giou_dn_2: 0.6428 (0.6428)  loss_vfl_dn_3: 0.4215 (0.4215)  loss_bbox_dn_3: 0.3123 (0.3123)  loss_giou_dn_3: 0.6275 (0.6275)  loss_vfl_dn_4: 0.4187 (0.4187)  loss_bbox_dn_4: 0.3118 (0.3118)  loss_giou_dn_4: 0.6243 (0.6243)  loss_vfl_dn_5: 0.4247 (0.4247)  loss_bbox_dn_5: 0.3113 (0.3113)  loss_giou_dn_5: 0.6261 (0.6261)  time: 1.5251  data: 0.8729  max mem: 7790\n",
            "Epoch: [45]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.5559 (17.8106)  loss_vfl: 0.6458 (0.6731)  loss_bbox: 0.1429 (0.1527)  loss_giou: 0.5599 (0.5717)  loss_vfl_aux_0: 0.6706 (0.6766)  loss_bbox_aux_0: 0.1557 (0.1649)  loss_giou_aux_0: 0.5783 (0.6147)  loss_vfl_aux_1: 0.6566 (0.6699)  loss_bbox_aux_1: 0.1473 (0.1578)  loss_giou_aux_1: 0.5520 (0.5852)  loss_vfl_aux_2: 0.6508 (0.6728)  loss_bbox_aux_2: 0.1446 (0.1545)  loss_giou_aux_2: 0.5460 (0.5751)  loss_vfl_aux_3: 0.6406 (0.6711)  loss_bbox_aux_3: 0.1438 (0.1537)  loss_giou_aux_3: 0.5631 (0.5731)  loss_vfl_aux_4: 0.6397 (0.6716)  loss_bbox_aux_4: 0.1439 (0.1527)  loss_giou_aux_4: 0.5578 (0.5717)  loss_vfl_aux_5: 0.6398 (0.6675)  loss_bbox_aux_5: 0.1941 (0.2126)  loss_giou_aux_5: 0.7287 (0.7454)  loss_vfl_dn_0: 0.4341 (0.4342)  loss_bbox_dn_0: 0.2310 (0.2543)  loss_giou_dn_0: 0.8177 (0.8301)  loss_vfl_dn_1: 0.4286 (0.4316)  loss_bbox_dn_1: 0.1911 (0.2017)  loss_giou_dn_1: 0.6314 (0.6682)  loss_vfl_dn_2: 0.4273 (0.4278)  loss_bbox_dn_2: 0.1771 (0.1884)  loss_giou_dn_2: 0.5833 (0.6250)  loss_vfl_dn_3: 0.4253 (0.4258)  loss_bbox_dn_3: 0.1756 (0.1849)  loss_giou_dn_3: 0.5662 (0.6128)  loss_vfl_dn_4: 0.4259 (0.4269)  loss_bbox_dn_4: 0.1761 (0.1838)  loss_giou_dn_4: 0.5618 (0.6092)  loss_vfl_dn_5: 0.4239 (0.4265)  loss_bbox_dn_5: 0.1748 (0.1831)  loss_giou_dn_5: 0.5628 (0.6082)  time: 0.3223  data: 0.0151  max mem: 7790\n",
            "Epoch: [45] Total time: 0:00:12 (0.3644 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.5559 (17.8106)  loss_vfl: 0.6458 (0.6731)  loss_bbox: 0.1429 (0.1527)  loss_giou: 0.5599 (0.5717)  loss_vfl_aux_0: 0.6706 (0.6766)  loss_bbox_aux_0: 0.1557 (0.1649)  loss_giou_aux_0: 0.5783 (0.6147)  loss_vfl_aux_1: 0.6566 (0.6699)  loss_bbox_aux_1: 0.1473 (0.1578)  loss_giou_aux_1: 0.5520 (0.5852)  loss_vfl_aux_2: 0.6508 (0.6728)  loss_bbox_aux_2: 0.1446 (0.1545)  loss_giou_aux_2: 0.5460 (0.5751)  loss_vfl_aux_3: 0.6406 (0.6711)  loss_bbox_aux_3: 0.1438 (0.1537)  loss_giou_aux_3: 0.5631 (0.5731)  loss_vfl_aux_4: 0.6397 (0.6716)  loss_bbox_aux_4: 0.1439 (0.1527)  loss_giou_aux_4: 0.5578 (0.5717)  loss_vfl_aux_5: 0.6398 (0.6675)  loss_bbox_aux_5: 0.1941 (0.2126)  loss_giou_aux_5: 0.7287 (0.7454)  loss_vfl_dn_0: 0.4341 (0.4342)  loss_bbox_dn_0: 0.2310 (0.2543)  loss_giou_dn_0: 0.8177 (0.8301)  loss_vfl_dn_1: 0.4286 (0.4316)  loss_bbox_dn_1: 0.1911 (0.2017)  loss_giou_dn_1: 0.6314 (0.6682)  loss_vfl_dn_2: 0.4273 (0.4278)  loss_bbox_dn_2: 0.1771 (0.1884)  loss_giou_dn_2: 0.5833 (0.6250)  loss_vfl_dn_3: 0.4253 (0.4258)  loss_bbox_dn_3: 0.1756 (0.1849)  loss_giou_dn_3: 0.5662 (0.6128)  loss_vfl_dn_4: 0.4259 (0.4269)  loss_bbox_dn_4: 0.1761 (0.1838)  loss_giou_dn_4: 0.5618 (0.6092)  loss_vfl_dn_5: 0.4239 (0.4265)  loss_bbox_dn_5: 0.1748 (0.1831)  loss_giou_dn_5: 0.5628 (0.6082)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8443  data: 0.5332  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3811  data: 0.1098  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3962 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.619\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [46]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 16.5572 (16.5572)  loss_vfl: 0.7174 (0.7174)  loss_bbox: 0.1399 (0.1399)  loss_giou: 0.4622 (0.4622)  loss_vfl_aux_0: 0.6686 (0.6686)  loss_bbox_aux_0: 0.1611 (0.1611)  loss_giou_aux_0: 0.5133 (0.5133)  loss_vfl_aux_1: 0.7194 (0.7194)  loss_bbox_aux_1: 0.1529 (0.1529)  loss_giou_aux_1: 0.4892 (0.4892)  loss_vfl_aux_2: 0.7151 (0.7151)  loss_bbox_aux_2: 0.1444 (0.1444)  loss_giou_aux_2: 0.4767 (0.4767)  loss_vfl_aux_3: 0.7084 (0.7084)  loss_bbox_aux_3: 0.1438 (0.1438)  loss_giou_aux_3: 0.4740 (0.4740)  loss_vfl_aux_4: 0.7070 (0.7070)  loss_bbox_aux_4: 0.1395 (0.1395)  loss_giou_aux_4: 0.4646 (0.4646)  loss_vfl_aux_5: 0.6544 (0.6544)  loss_bbox_aux_5: 0.1809 (0.1809)  loss_giou_aux_5: 0.6026 (0.6026)  loss_vfl_dn_0: 0.4407 (0.4407)  loss_bbox_dn_0: 0.2441 (0.2441)  loss_giou_dn_0: 0.7448 (0.7448)  loss_vfl_dn_1: 0.4298 (0.4298)  loss_bbox_dn_1: 0.1949 (0.1949)  loss_giou_dn_1: 0.5922 (0.5922)  loss_vfl_dn_2: 0.4181 (0.4181)  loss_bbox_dn_2: 0.1754 (0.1754)  loss_giou_dn_2: 0.5344 (0.5344)  loss_vfl_dn_3: 0.4126 (0.4126)  loss_bbox_dn_3: 0.1748 (0.1748)  loss_giou_dn_3: 0.5292 (0.5292)  loss_vfl_dn_4: 0.4128 (0.4128)  loss_bbox_dn_4: 0.1748 (0.1748)  loss_giou_dn_4: 0.5242 (0.5242)  loss_vfl_dn_5: 0.4175 (0.4175)  loss_bbox_dn_5: 0.1758 (0.1758)  loss_giou_dn_5: 0.5255 (0.5255)  time: 1.0493  data: 0.6492  max mem: 7790\n",
            "Epoch: [46]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 18.0483 (17.8562)  loss_vfl: 0.6564 (0.6607)  loss_bbox: 0.1514 (0.1523)  loss_giou: 0.5639 (0.5846)  loss_vfl_aux_0: 0.6513 (0.6571)  loss_bbox_aux_0: 0.1569 (0.1669)  loss_giou_aux_0: 0.5768 (0.6276)  loss_vfl_aux_1: 0.6411 (0.6540)  loss_bbox_aux_1: 0.1492 (0.1575)  loss_giou_aux_1: 0.5890 (0.6027)  loss_vfl_aux_2: 0.6380 (0.6507)  loss_bbox_aux_2: 0.1542 (0.1551)  loss_giou_aux_2: 0.5627 (0.5932)  loss_vfl_aux_3: 0.6460 (0.6509)  loss_bbox_aux_3: 0.1536 (0.1545)  loss_giou_aux_3: 0.5546 (0.5890)  loss_vfl_aux_4: 0.6498 (0.6575)  loss_bbox_aux_4: 0.1591 (0.1525)  loss_giou_aux_4: 0.5641 (0.5856)  loss_vfl_aux_5: 0.6524 (0.6618)  loss_bbox_aux_5: 0.2191 (0.2092)  loss_giou_aux_5: 0.6868 (0.7298)  loss_vfl_dn_0: 0.4355 (0.4325)  loss_bbox_dn_0: 0.2407 (0.2556)  loss_giou_dn_0: 0.8298 (0.8359)  loss_vfl_dn_1: 0.4265 (0.4320)  loss_bbox_dn_1: 0.2000 (0.2023)  loss_giou_dn_1: 0.6359 (0.6787)  loss_vfl_dn_2: 0.4333 (0.4291)  loss_bbox_dn_2: 0.1861 (0.1896)  loss_giou_dn_2: 0.5923 (0.6389)  loss_vfl_dn_3: 0.4289 (0.4283)  loss_bbox_dn_3: 0.1791 (0.1856)  loss_giou_dn_3: 0.5741 (0.6257)  loss_vfl_dn_4: 0.4338 (0.4290)  loss_bbox_dn_4: 0.1768 (0.1847)  loss_giou_dn_4: 0.5736 (0.6214)  loss_vfl_dn_5: 0.4361 (0.4299)  loss_bbox_dn_5: 0.1751 (0.1839)  loss_giou_dn_5: 0.5709 (0.6201)  time: 0.3399  data: 0.0147  max mem: 7790\n",
            "Epoch: [46] Total time: 0:00:11 (0.3617 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 18.0483 (17.8562)  loss_vfl: 0.6564 (0.6607)  loss_bbox: 0.1514 (0.1523)  loss_giou: 0.5639 (0.5846)  loss_vfl_aux_0: 0.6513 (0.6571)  loss_bbox_aux_0: 0.1569 (0.1669)  loss_giou_aux_0: 0.5768 (0.6276)  loss_vfl_aux_1: 0.6411 (0.6540)  loss_bbox_aux_1: 0.1492 (0.1575)  loss_giou_aux_1: 0.5890 (0.6027)  loss_vfl_aux_2: 0.6380 (0.6507)  loss_bbox_aux_2: 0.1542 (0.1551)  loss_giou_aux_2: 0.5627 (0.5932)  loss_vfl_aux_3: 0.6460 (0.6509)  loss_bbox_aux_3: 0.1536 (0.1545)  loss_giou_aux_3: 0.5546 (0.5890)  loss_vfl_aux_4: 0.6498 (0.6575)  loss_bbox_aux_4: 0.1591 (0.1525)  loss_giou_aux_4: 0.5641 (0.5856)  loss_vfl_aux_5: 0.6524 (0.6618)  loss_bbox_aux_5: 0.2191 (0.2092)  loss_giou_aux_5: 0.6868 (0.7298)  loss_vfl_dn_0: 0.4355 (0.4325)  loss_bbox_dn_0: 0.2407 (0.2556)  loss_giou_dn_0: 0.8298 (0.8359)  loss_vfl_dn_1: 0.4265 (0.4320)  loss_bbox_dn_1: 0.2000 (0.2023)  loss_giou_dn_1: 0.6359 (0.6787)  loss_vfl_dn_2: 0.4333 (0.4291)  loss_bbox_dn_2: 0.1861 (0.1896)  loss_giou_dn_2: 0.5923 (0.6389)  loss_vfl_dn_3: 0.4289 (0.4283)  loss_bbox_dn_3: 0.1791 (0.1856)  loss_giou_dn_3: 0.5741 (0.6257)  loss_vfl_dn_4: 0.4338 (0.4290)  loss_bbox_dn_4: 0.1768 (0.1847)  loss_giou_dn_4: 0.5736 (0.6214)  loss_vfl_dn_5: 0.4361 (0.4299)  loss_bbox_dn_5: 0.1751 (0.1839)  loss_giou_dn_5: 0.5709 (0.6201)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9185  data: 0.5963  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3963  data: 0.1147  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4093 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.606\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.272\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [47]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 19.3780 (19.3780)  loss_vfl: 0.6435 (0.6435)  loss_bbox: 0.2443 (0.2443)  loss_giou: 0.6440 (0.6440)  loss_vfl_aux_0: 0.6317 (0.6317)  loss_bbox_aux_0: 0.2246 (0.2246)  loss_giou_aux_0: 0.6795 (0.6795)  loss_vfl_aux_1: 0.6633 (0.6633)  loss_bbox_aux_1: 0.2166 (0.2166)  loss_giou_aux_1: 0.6006 (0.6006)  loss_vfl_aux_2: 0.6699 (0.6699)  loss_bbox_aux_2: 0.2193 (0.2193)  loss_giou_aux_2: 0.5967 (0.5967)  loss_vfl_aux_3: 0.6714 (0.6714)  loss_bbox_aux_3: 0.2242 (0.2242)  loss_giou_aux_3: 0.6077 (0.6077)  loss_vfl_aux_4: 0.6494 (0.6494)  loss_bbox_aux_4: 0.2397 (0.2397)  loss_giou_aux_4: 0.6361 (0.6361)  loss_vfl_aux_5: 0.7874 (0.7874)  loss_bbox_aux_5: 0.2118 (0.2118)  loss_giou_aux_5: 0.7614 (0.7614)  loss_vfl_dn_0: 0.4340 (0.4340)  loss_bbox_dn_0: 0.3062 (0.3062)  loss_giou_dn_0: 0.8432 (0.8432)  loss_vfl_dn_1: 0.4288 (0.4288)  loss_bbox_dn_1: 0.2695 (0.2695)  loss_giou_dn_1: 0.7405 (0.7405)  loss_vfl_dn_2: 0.4270 (0.4270)  loss_bbox_dn_2: 0.2622 (0.2622)  loss_giou_dn_2: 0.7055 (0.7055)  loss_vfl_dn_3: 0.4320 (0.4320)  loss_bbox_dn_3: 0.2574 (0.2574)  loss_giou_dn_3: 0.6949 (0.6949)  loss_vfl_dn_4: 0.4340 (0.4340)  loss_bbox_dn_4: 0.2529 (0.2529)  loss_giou_dn_4: 0.6889 (0.6889)  loss_vfl_dn_5: 0.4343 (0.4343)  loss_bbox_dn_5: 0.2524 (0.2524)  loss_giou_dn_5: 0.6908 (0.6908)  time: 1.0187  data: 0.6163  max mem: 7790\n",
            "Epoch: [47]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.3917 (17.8766)  loss_vfl: 0.6385 (0.6502)  loss_bbox: 0.1372 (0.1567)  loss_giou: 0.5500 (0.5896)  loss_vfl_aux_0: 0.6658 (0.6520)  loss_bbox_aux_0: 0.1590 (0.1671)  loss_giou_aux_0: 0.5910 (0.6300)  loss_vfl_aux_1: 0.6448 (0.6430)  loss_bbox_aux_1: 0.1545 (0.1605)  loss_giou_aux_1: 0.5632 (0.6021)  loss_vfl_aux_2: 0.6190 (0.6392)  loss_bbox_aux_2: 0.1545 (0.1598)  loss_giou_aux_2: 0.5573 (0.5977)  loss_vfl_aux_3: 0.6254 (0.6419)  loss_bbox_aux_3: 0.1497 (0.1593)  loss_giou_aux_3: 0.5546 (0.5939)  loss_vfl_aux_4: 0.6352 (0.6449)  loss_bbox_aux_4: 0.1406 (0.1576)  loss_giou_aux_4: 0.5545 (0.5904)  loss_vfl_aux_5: 0.6670 (0.6699)  loss_bbox_aux_5: 0.2018 (0.2042)  loss_giou_aux_5: 0.6991 (0.7376)  loss_vfl_dn_0: 0.4364 (0.4327)  loss_bbox_dn_0: 0.2197 (0.2501)  loss_giou_dn_0: 0.8344 (0.8465)  loss_vfl_dn_1: 0.4350 (0.4326)  loss_bbox_dn_1: 0.1821 (0.2003)  loss_giou_dn_1: 0.6529 (0.6907)  loss_vfl_dn_2: 0.4322 (0.4305)  loss_bbox_dn_2: 0.1699 (0.1868)  loss_giou_dn_2: 0.6098 (0.6462)  loss_vfl_dn_3: 0.4262 (0.4271)  loss_bbox_dn_3: 0.1631 (0.1831)  loss_giou_dn_3: 0.5900 (0.6310)  loss_vfl_dn_4: 0.4267 (0.4267)  loss_bbox_dn_4: 0.1613 (0.1821)  loss_giou_dn_4: 0.5835 (0.6264)  loss_vfl_dn_5: 0.4270 (0.4278)  loss_bbox_dn_5: 0.1607 (0.1819)  loss_giou_dn_5: 0.5842 (0.6268)  time: 0.3246  data: 0.0139  max mem: 7790\n",
            "Epoch: [47] Total time: 0:00:11 (0.3453 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.3917 (17.8766)  loss_vfl: 0.6385 (0.6502)  loss_bbox: 0.1372 (0.1567)  loss_giou: 0.5500 (0.5896)  loss_vfl_aux_0: 0.6658 (0.6520)  loss_bbox_aux_0: 0.1590 (0.1671)  loss_giou_aux_0: 0.5910 (0.6300)  loss_vfl_aux_1: 0.6448 (0.6430)  loss_bbox_aux_1: 0.1545 (0.1605)  loss_giou_aux_1: 0.5632 (0.6021)  loss_vfl_aux_2: 0.6190 (0.6392)  loss_bbox_aux_2: 0.1545 (0.1598)  loss_giou_aux_2: 0.5573 (0.5977)  loss_vfl_aux_3: 0.6254 (0.6419)  loss_bbox_aux_3: 0.1497 (0.1593)  loss_giou_aux_3: 0.5546 (0.5939)  loss_vfl_aux_4: 0.6352 (0.6449)  loss_bbox_aux_4: 0.1406 (0.1576)  loss_giou_aux_4: 0.5545 (0.5904)  loss_vfl_aux_5: 0.6670 (0.6699)  loss_bbox_aux_5: 0.2018 (0.2042)  loss_giou_aux_5: 0.6991 (0.7376)  loss_vfl_dn_0: 0.4364 (0.4327)  loss_bbox_dn_0: 0.2197 (0.2501)  loss_giou_dn_0: 0.8344 (0.8465)  loss_vfl_dn_1: 0.4350 (0.4326)  loss_bbox_dn_1: 0.1821 (0.2003)  loss_giou_dn_1: 0.6529 (0.6907)  loss_vfl_dn_2: 0.4322 (0.4305)  loss_bbox_dn_2: 0.1699 (0.1868)  loss_giou_dn_2: 0.6098 (0.6462)  loss_vfl_dn_3: 0.4262 (0.4271)  loss_bbox_dn_3: 0.1631 (0.1831)  loss_giou_dn_3: 0.5900 (0.6310)  loss_vfl_dn_4: 0.4267 (0.4267)  loss_bbox_dn_4: 0.1613 (0.1821)  loss_giou_dn_4: 0.5835 (0.6264)  loss_vfl_dn_5: 0.4270 (0.4278)  loss_bbox_dn_5: 0.1607 (0.1819)  loss_giou_dn_5: 0.5842 (0.6268)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8738  data: 0.5649  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3837  data: 0.1117  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3976 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.600\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [48]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 16.8286 (16.8286)  loss_vfl: 0.7696 (0.7696)  loss_bbox: 0.1323 (0.1323)  loss_giou: 0.3878 (0.3878)  loss_vfl_aux_0: 0.8433 (0.8433)  loss_bbox_aux_0: 0.1629 (0.1629)  loss_giou_aux_0: 0.4813 (0.4813)  loss_vfl_aux_1: 0.8008 (0.8008)  loss_bbox_aux_1: 0.1416 (0.1416)  loss_giou_aux_1: 0.4176 (0.4176)  loss_vfl_aux_2: 0.7586 (0.7586)  loss_bbox_aux_2: 0.1334 (0.1334)  loss_giou_aux_2: 0.4062 (0.4062)  loss_vfl_aux_3: 0.7407 (0.7407)  loss_bbox_aux_3: 0.1314 (0.1314)  loss_giou_aux_3: 0.3947 (0.3947)  loss_vfl_aux_4: 0.7561 (0.7561)  loss_bbox_aux_4: 0.1321 (0.1321)  loss_giou_aux_4: 0.3931 (0.3931)  loss_vfl_aux_5: 0.8205 (0.8205)  loss_bbox_aux_5: 0.2202 (0.2202)  loss_giou_aux_5: 0.6189 (0.6189)  loss_vfl_dn_0: 0.4453 (0.4453)  loss_bbox_dn_0: 0.3164 (0.3164)  loss_giou_dn_0: 0.7539 (0.7539)  loss_vfl_dn_1: 0.4274 (0.4274)  loss_bbox_dn_1: 0.2412 (0.2412)  loss_giou_dn_1: 0.5699 (0.5699)  loss_vfl_dn_2: 0.4187 (0.4187)  loss_bbox_dn_2: 0.2165 (0.2165)  loss_giou_dn_2: 0.5182 (0.5182)  loss_vfl_dn_3: 0.4158 (0.4158)  loss_bbox_dn_3: 0.1975 (0.1975)  loss_giou_dn_3: 0.4867 (0.4867)  loss_vfl_dn_4: 0.4177 (0.4177)  loss_bbox_dn_4: 0.1951 (0.1951)  loss_giou_dn_4: 0.4808 (0.4808)  loss_vfl_dn_5: 0.4125 (0.4125)  loss_bbox_dn_5: 0.1932 (0.1932)  loss_giou_dn_5: 0.4784 (0.4784)  time: 1.0663  data: 0.6192  max mem: 7790\n",
            "Epoch: [48]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.8717 (17.6527)  loss_vfl: 0.6623 (0.6746)  loss_bbox: 0.1321 (0.1446)  loss_giou: 0.5869 (0.5605)  loss_vfl_aux_0: 0.6652 (0.6487)  loss_bbox_aux_0: 0.1413 (0.1638)  loss_giou_aux_0: 0.6183 (0.6199)  loss_vfl_aux_1: 0.6545 (0.6534)  loss_bbox_aux_1: 0.1464 (0.1544)  loss_giou_aux_1: 0.5959 (0.5837)  loss_vfl_aux_2: 0.6629 (0.6612)  loss_bbox_aux_2: 0.1426 (0.1484)  loss_giou_aux_2: 0.5982 (0.5700)  loss_vfl_aux_3: 0.6589 (0.6673)  loss_bbox_aux_3: 0.1364 (0.1462)  loss_giou_aux_3: 0.5907 (0.5627)  loss_vfl_aux_4: 0.6596 (0.6747)  loss_bbox_aux_4: 0.1293 (0.1446)  loss_giou_aux_4: 0.5901 (0.5596)  loss_vfl_aux_5: 0.6650 (0.6791)  loss_bbox_aux_5: 0.1723 (0.2045)  loss_giou_aux_5: 0.7446 (0.7163)  loss_vfl_dn_0: 0.4335 (0.4323)  loss_bbox_dn_0: 0.2408 (0.2580)  loss_giou_dn_0: 0.8420 (0.8372)  loss_vfl_dn_1: 0.4301 (0.4306)  loss_bbox_dn_1: 0.1677 (0.2026)  loss_giou_dn_1: 0.6691 (0.6742)  loss_vfl_dn_2: 0.4274 (0.4256)  loss_bbox_dn_2: 0.1480 (0.1873)  loss_giou_dn_2: 0.6168 (0.6285)  loss_vfl_dn_3: 0.4272 (0.4238)  loss_bbox_dn_3: 0.1461 (0.1816)  loss_giou_dn_3: 0.6085 (0.6125)  loss_vfl_dn_4: 0.4243 (0.4236)  loss_bbox_dn_4: 0.1458 (0.1799)  loss_giou_dn_4: 0.6106 (0.6076)  loss_vfl_dn_5: 0.4242 (0.4238)  loss_bbox_dn_5: 0.1457 (0.1790)  loss_giou_dn_5: 0.6096 (0.6062)  time: 0.3281  data: 0.0135  max mem: 7790\n",
            "Epoch: [48] Total time: 0:00:11 (0.3529 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.8717 (17.6527)  loss_vfl: 0.6623 (0.6746)  loss_bbox: 0.1321 (0.1446)  loss_giou: 0.5869 (0.5605)  loss_vfl_aux_0: 0.6652 (0.6487)  loss_bbox_aux_0: 0.1413 (0.1638)  loss_giou_aux_0: 0.6183 (0.6199)  loss_vfl_aux_1: 0.6545 (0.6534)  loss_bbox_aux_1: 0.1464 (0.1544)  loss_giou_aux_1: 0.5959 (0.5837)  loss_vfl_aux_2: 0.6629 (0.6612)  loss_bbox_aux_2: 0.1426 (0.1484)  loss_giou_aux_2: 0.5982 (0.5700)  loss_vfl_aux_3: 0.6589 (0.6673)  loss_bbox_aux_3: 0.1364 (0.1462)  loss_giou_aux_3: 0.5907 (0.5627)  loss_vfl_aux_4: 0.6596 (0.6747)  loss_bbox_aux_4: 0.1293 (0.1446)  loss_giou_aux_4: 0.5901 (0.5596)  loss_vfl_aux_5: 0.6650 (0.6791)  loss_bbox_aux_5: 0.1723 (0.2045)  loss_giou_aux_5: 0.7446 (0.7163)  loss_vfl_dn_0: 0.4335 (0.4323)  loss_bbox_dn_0: 0.2408 (0.2580)  loss_giou_dn_0: 0.8420 (0.8372)  loss_vfl_dn_1: 0.4301 (0.4306)  loss_bbox_dn_1: 0.1677 (0.2026)  loss_giou_dn_1: 0.6691 (0.6742)  loss_vfl_dn_2: 0.4274 (0.4256)  loss_bbox_dn_2: 0.1480 (0.1873)  loss_giou_dn_2: 0.6168 (0.6285)  loss_vfl_dn_3: 0.4272 (0.4238)  loss_bbox_dn_3: 0.1461 (0.1816)  loss_giou_dn_3: 0.6085 (0.6125)  loss_vfl_dn_4: 0.4243 (0.4236)  loss_bbox_dn_4: 0.1458 (0.1799)  loss_giou_dn_4: 0.6106 (0.6076)  loss_vfl_dn_5: 0.4242 (0.4238)  loss_bbox_dn_5: 0.1457 (0.1790)  loss_giou_dn_5: 0.6096 (0.6062)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9172  data: 0.6068  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3891  data: 0.1126  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4026 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.602\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n",
            "best_stat:  {'epoch': 38, 'coco_eval_bbox': 0.3114314052690972}\n",
            "Epoch: [49]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 18.5045 (18.5045)  loss_vfl: 0.5581 (0.5581)  loss_bbox: 0.1074 (0.1074)  loss_giou: 0.7623 (0.7623)  loss_vfl_aux_0: 0.5500 (0.5500)  loss_bbox_aux_0: 0.1201 (0.1201)  loss_giou_aux_0: 0.8118 (0.8118)  loss_vfl_aux_1: 0.5651 (0.5651)  loss_bbox_aux_1: 0.1129 (0.1129)  loss_giou_aux_1: 0.7919 (0.7919)  loss_vfl_aux_2: 0.5473 (0.5473)  loss_bbox_aux_2: 0.1125 (0.1125)  loss_giou_aux_2: 0.7902 (0.7902)  loss_vfl_aux_3: 0.5585 (0.5585)  loss_bbox_aux_3: 0.1070 (0.1070)  loss_giou_aux_3: 0.7719 (0.7719)  loss_vfl_aux_4: 0.5527 (0.5527)  loss_bbox_aux_4: 0.1066 (0.1066)  loss_giou_aux_4: 0.7678 (0.7678)  loss_vfl_aux_5: 0.5370 (0.5370)  loss_bbox_aux_5: 0.1138 (0.1138)  loss_giou_aux_5: 0.8431 (0.8431)  loss_vfl_dn_0: 0.4106 (0.4106)  loss_bbox_dn_0: 0.1259 (0.1259)  loss_giou_dn_0: 0.9747 (0.9747)  loss_vfl_dn_1: 0.4262 (0.4262)  loss_bbox_dn_1: 0.1102 (0.1102)  loss_giou_dn_1: 0.8685 (0.8685)  loss_vfl_dn_2: 0.4216 (0.4216)  loss_bbox_dn_2: 0.1067 (0.1067)  loss_giou_dn_2: 0.8347 (0.8347)  loss_vfl_dn_3: 0.4203 (0.4203)  loss_bbox_dn_3: 0.1051 (0.1051)  loss_giou_dn_3: 0.8254 (0.8254)  loss_vfl_dn_4: 0.4165 (0.4165)  loss_bbox_dn_4: 0.1057 (0.1057)  loss_giou_dn_4: 0.8234 (0.8234)  loss_vfl_dn_5: 0.4110 (0.4110)  loss_bbox_dn_5: 0.1060 (0.1060)  loss_giou_dn_5: 0.8240 (0.8240)  time: 0.9552  data: 0.5812  max mem: 7790\n",
            "Epoch: [49]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.7212 (17.3641)  loss_vfl: 0.6504 (0.6603)  loss_bbox: 0.1527 (0.1472)  loss_giou: 0.4844 (0.5543)  loss_vfl_aux_0: 0.6490 (0.6514)  loss_bbox_aux_0: 0.1611 (0.1635)  loss_giou_aux_0: 0.5354 (0.6043)  loss_vfl_aux_1: 0.6407 (0.6487)  loss_bbox_aux_1: 0.1541 (0.1516)  loss_giou_aux_1: 0.5089 (0.5733)  loss_vfl_aux_2: 0.6342 (0.6484)  loss_bbox_aux_2: 0.1559 (0.1477)  loss_giou_aux_2: 0.4886 (0.5643)  loss_vfl_aux_3: 0.6231 (0.6520)  loss_bbox_aux_3: 0.1546 (0.1485)  loss_giou_aux_3: 0.5070 (0.5589)  loss_vfl_aux_4: 0.6334 (0.6556)  loss_bbox_aux_4: 0.1536 (0.1474)  loss_giou_aux_4: 0.5052 (0.5565)  loss_vfl_aux_5: 0.6565 (0.6650)  loss_bbox_aux_5: 0.2000 (0.2011)  loss_giou_aux_5: 0.6705 (0.7048)  loss_vfl_dn_0: 0.4382 (0.4389)  loss_bbox_dn_0: 0.2423 (0.2504)  loss_giou_dn_0: 0.8083 (0.8040)  loss_vfl_dn_1: 0.4393 (0.4354)  loss_bbox_dn_1: 0.1947 (0.1966)  loss_giou_dn_1: 0.6241 (0.6424)  loss_vfl_dn_2: 0.4319 (0.4307)  loss_bbox_dn_2: 0.1796 (0.1837)  loss_giou_dn_2: 0.5656 (0.5998)  loss_vfl_dn_3: 0.4280 (0.4273)  loss_bbox_dn_3: 0.1781 (0.1808)  loss_giou_dn_3: 0.5586 (0.5875)  loss_vfl_dn_4: 0.4292 (0.4276)  loss_bbox_dn_4: 0.1763 (0.1807)  loss_giou_dn_4: 0.5520 (0.5834)  loss_vfl_dn_5: 0.4291 (0.4270)  loss_bbox_dn_5: 0.1759 (0.1805)  loss_giou_dn_5: 0.5478 (0.5825)  time: 0.3272  data: 0.0149  max mem: 7790\n",
            "Epoch: [49] Total time: 0:00:11 (0.3482 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.7212 (17.3641)  loss_vfl: 0.6504 (0.6603)  loss_bbox: 0.1527 (0.1472)  loss_giou: 0.4844 (0.5543)  loss_vfl_aux_0: 0.6490 (0.6514)  loss_bbox_aux_0: 0.1611 (0.1635)  loss_giou_aux_0: 0.5354 (0.6043)  loss_vfl_aux_1: 0.6407 (0.6487)  loss_bbox_aux_1: 0.1541 (0.1516)  loss_giou_aux_1: 0.5089 (0.5733)  loss_vfl_aux_2: 0.6342 (0.6484)  loss_bbox_aux_2: 0.1559 (0.1477)  loss_giou_aux_2: 0.4886 (0.5643)  loss_vfl_aux_3: 0.6231 (0.6520)  loss_bbox_aux_3: 0.1546 (0.1485)  loss_giou_aux_3: 0.5070 (0.5589)  loss_vfl_aux_4: 0.6334 (0.6556)  loss_bbox_aux_4: 0.1536 (0.1474)  loss_giou_aux_4: 0.5052 (0.5565)  loss_vfl_aux_5: 0.6565 (0.6650)  loss_bbox_aux_5: 0.2000 (0.2011)  loss_giou_aux_5: 0.6705 (0.7048)  loss_vfl_dn_0: 0.4382 (0.4389)  loss_bbox_dn_0: 0.2423 (0.2504)  loss_giou_dn_0: 0.8083 (0.8040)  loss_vfl_dn_1: 0.4393 (0.4354)  loss_bbox_dn_1: 0.1947 (0.1966)  loss_giou_dn_1: 0.6241 (0.6424)  loss_vfl_dn_2: 0.4319 (0.4307)  loss_bbox_dn_2: 0.1796 (0.1837)  loss_giou_dn_2: 0.5656 (0.5998)  loss_vfl_dn_3: 0.4280 (0.4273)  loss_bbox_dn_3: 0.1781 (0.1808)  loss_giou_dn_3: 0.5586 (0.5875)  loss_vfl_dn_4: 0.4292 (0.4276)  loss_bbox_dn_4: 0.1763 (0.1807)  loss_giou_dn_4: 0.5520 (0.5834)  loss_vfl_dn_5: 0.4291 (0.4270)  loss_bbox_dn_5: 0.1759 (0.1805)  loss_giou_dn_5: 0.5478 (0.5825)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8946  data: 0.5741  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4353  data: 0.1101  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4489 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [50]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 16.2188 (16.2188)  loss_vfl: 0.5649 (0.5649)  loss_bbox: 0.2146 (0.2146)  loss_giou: 0.4163 (0.4163)  loss_vfl_aux_0: 0.6186 (0.6186)  loss_bbox_aux_0: 0.1988 (0.1988)  loss_giou_aux_0: 0.4462 (0.4462)  loss_vfl_aux_1: 0.6057 (0.6057)  loss_bbox_aux_1: 0.2011 (0.2011)  loss_giou_aux_1: 0.4180 (0.4180)  loss_vfl_aux_2: 0.5682 (0.5682)  loss_bbox_aux_2: 0.2135 (0.2135)  loss_giou_aux_2: 0.4270 (0.4270)  loss_vfl_aux_3: 0.5720 (0.5720)  loss_bbox_aux_3: 0.2134 (0.2134)  loss_giou_aux_3: 0.4155 (0.4155)  loss_vfl_aux_4: 0.5789 (0.5789)  loss_bbox_aux_4: 0.2120 (0.2120)  loss_giou_aux_4: 0.4136 (0.4136)  loss_vfl_aux_5: 0.6216 (0.6216)  loss_bbox_aux_5: 0.3196 (0.3196)  loss_giou_aux_5: 0.7059 (0.7059)  loss_vfl_dn_0: 0.4436 (0.4436)  loss_bbox_dn_0: 0.3776 (0.3776)  loss_giou_dn_0: 0.7397 (0.7397)  loss_vfl_dn_1: 0.4426 (0.4426)  loss_bbox_dn_1: 0.2801 (0.2801)  loss_giou_dn_1: 0.5422 (0.5422)  loss_vfl_dn_2: 0.4316 (0.4316)  loss_bbox_dn_2: 0.2475 (0.2475)  loss_giou_dn_2: 0.4687 (0.4687)  loss_vfl_dn_3: 0.4266 (0.4266)  loss_bbox_dn_3: 0.2410 (0.2410)  loss_giou_dn_3: 0.4390 (0.4390)  loss_vfl_dn_4: 0.4246 (0.4246)  loss_bbox_dn_4: 0.2385 (0.2385)  loss_giou_dn_4: 0.4332 (0.4332)  loss_vfl_dn_5: 0.4248 (0.4248)  loss_bbox_dn_5: 0.2402 (0.2402)  loss_giou_dn_5: 0.4320 (0.4320)  time: 0.9961  data: 0.6300  max mem: 7790\n",
            "Epoch: [50]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.4543 (17.4530)  loss_vfl: 0.6257 (0.6363)  loss_bbox: 0.1313 (0.1478)  loss_giou: 0.5893 (0.5665)  loss_vfl_aux_0: 0.6310 (0.6346)  loss_bbox_aux_0: 0.1463 (0.1613)  loss_giou_aux_0: 0.6304 (0.6189)  loss_vfl_aux_1: 0.6202 (0.6312)  loss_bbox_aux_1: 0.1367 (0.1521)  loss_giou_aux_1: 0.5876 (0.5867)  loss_vfl_aux_2: 0.6180 (0.6284)  loss_bbox_aux_2: 0.1344 (0.1501)  loss_giou_aux_2: 0.5967 (0.5760)  loss_vfl_aux_3: 0.6171 (0.6283)  loss_bbox_aux_3: 0.1313 (0.1484)  loss_giou_aux_3: 0.5898 (0.5711)  loss_vfl_aux_4: 0.6299 (0.6359)  loss_bbox_aux_4: 0.1326 (0.1473)  loss_giou_aux_4: 0.5812 (0.5664)  loss_vfl_aux_5: 0.6332 (0.6450)  loss_bbox_aux_5: 0.2153 (0.2182)  loss_giou_aux_5: 0.7705 (0.7553)  loss_vfl_dn_0: 0.4247 (0.4320)  loss_bbox_dn_0: 0.2128 (0.2460)  loss_giou_dn_0: 0.8242 (0.8263)  loss_vfl_dn_1: 0.4260 (0.4277)  loss_bbox_dn_1: 0.1643 (0.1938)  loss_giou_dn_1: 0.6675 (0.6681)  loss_vfl_dn_2: 0.4262 (0.4242)  loss_bbox_dn_2: 0.1462 (0.1800)  loss_giou_dn_2: 0.6381 (0.6266)  loss_vfl_dn_3: 0.4232 (0.4228)  loss_bbox_dn_3: 0.1431 (0.1758)  loss_giou_dn_3: 0.6179 (0.6122)  loss_vfl_dn_4: 0.4222 (0.4219)  loss_bbox_dn_4: 0.1405 (0.1748)  loss_giou_dn_4: 0.6067 (0.6093)  loss_vfl_dn_5: 0.4214 (0.4222)  loss_bbox_dn_5: 0.1392 (0.1745)  loss_giou_dn_5: 0.6062 (0.6090)  time: 0.3221  data: 0.0140  max mem: 7790\n",
            "Epoch: [50] Total time: 0:00:11 (0.3444 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.4543 (17.4530)  loss_vfl: 0.6257 (0.6363)  loss_bbox: 0.1313 (0.1478)  loss_giou: 0.5893 (0.5665)  loss_vfl_aux_0: 0.6310 (0.6346)  loss_bbox_aux_0: 0.1463 (0.1613)  loss_giou_aux_0: 0.6304 (0.6189)  loss_vfl_aux_1: 0.6202 (0.6312)  loss_bbox_aux_1: 0.1367 (0.1521)  loss_giou_aux_1: 0.5876 (0.5867)  loss_vfl_aux_2: 0.6180 (0.6284)  loss_bbox_aux_2: 0.1344 (0.1501)  loss_giou_aux_2: 0.5967 (0.5760)  loss_vfl_aux_3: 0.6171 (0.6283)  loss_bbox_aux_3: 0.1313 (0.1484)  loss_giou_aux_3: 0.5898 (0.5711)  loss_vfl_aux_4: 0.6299 (0.6359)  loss_bbox_aux_4: 0.1326 (0.1473)  loss_giou_aux_4: 0.5812 (0.5664)  loss_vfl_aux_5: 0.6332 (0.6450)  loss_bbox_aux_5: 0.2153 (0.2182)  loss_giou_aux_5: 0.7705 (0.7553)  loss_vfl_dn_0: 0.4247 (0.4320)  loss_bbox_dn_0: 0.2128 (0.2460)  loss_giou_dn_0: 0.8242 (0.8263)  loss_vfl_dn_1: 0.4260 (0.4277)  loss_bbox_dn_1: 0.1643 (0.1938)  loss_giou_dn_1: 0.6675 (0.6681)  loss_vfl_dn_2: 0.4262 (0.4242)  loss_bbox_dn_2: 0.1462 (0.1800)  loss_giou_dn_2: 0.6381 (0.6266)  loss_vfl_dn_3: 0.4232 (0.4228)  loss_bbox_dn_3: 0.1431 (0.1758)  loss_giou_dn_3: 0.6179 (0.6122)  loss_vfl_dn_4: 0.4222 (0.4219)  loss_bbox_dn_4: 0.1405 (0.1748)  loss_giou_dn_4: 0.6067 (0.6093)  loss_vfl_dn_5: 0.4214 (0.4222)  loss_bbox_dn_5: 0.1392 (0.1745)  loss_giou_dn_5: 0.6062 (0.6090)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8720  data: 0.5652  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4355  data: 0.1115  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4491 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.595\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.546\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [51]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 19.2865 (19.2865)  loss_vfl: 0.6619 (0.6619)  loss_bbox: 0.1572 (0.1572)  loss_giou: 0.7040 (0.7040)  loss_vfl_aux_0: 0.6525 (0.6525)  loss_bbox_aux_0: 0.1789 (0.1789)  loss_giou_aux_0: 0.7449 (0.7449)  loss_vfl_aux_1: 0.6290 (0.6290)  loss_bbox_aux_1: 0.1660 (0.1660)  loss_giou_aux_1: 0.7242 (0.7242)  loss_vfl_aux_2: 0.6480 (0.6480)  loss_bbox_aux_2: 0.1639 (0.1639)  loss_giou_aux_2: 0.7097 (0.7097)  loss_vfl_aux_3: 0.6285 (0.6285)  loss_bbox_aux_3: 0.1676 (0.1676)  loss_giou_aux_3: 0.7186 (0.7186)  loss_vfl_aux_4: 0.6493 (0.6493)  loss_bbox_aux_4: 0.1604 (0.1604)  loss_giou_aux_4: 0.7171 (0.7171)  loss_vfl_aux_5: 0.5817 (0.5817)  loss_bbox_aux_5: 0.2052 (0.2052)  loss_giou_aux_5: 0.8032 (0.8032)  loss_vfl_dn_0: 0.4057 (0.4057)  loss_bbox_dn_0: 0.2118 (0.2118)  loss_giou_dn_0: 0.9462 (0.9462)  loss_vfl_dn_1: 0.4022 (0.4022)  loss_bbox_dn_1: 0.1764 (0.1764)  loss_giou_dn_1: 0.8446 (0.8446)  loss_vfl_dn_2: 0.4001 (0.4001)  loss_bbox_dn_2: 0.1679 (0.1679)  loss_giou_dn_2: 0.8178 (0.8178)  loss_vfl_dn_3: 0.4020 (0.4020)  loss_bbox_dn_3: 0.1689 (0.1689)  loss_giou_dn_3: 0.8098 (0.8098)  loss_vfl_dn_4: 0.4025 (0.4025)  loss_bbox_dn_4: 0.1694 (0.1694)  loss_giou_dn_4: 0.8108 (0.8108)  loss_vfl_dn_5: 0.4010 (0.4010)  loss_bbox_dn_5: 0.1691 (0.1691)  loss_giou_dn_5: 0.8086 (0.8086)  time: 0.9614  data: 0.5656  max mem: 7790\n",
            "Epoch: [51]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.2406 (17.4360)  loss_vfl: 0.6644 (0.6695)  loss_bbox: 0.1198 (0.1456)  loss_giou: 0.4973 (0.5449)  loss_vfl_aux_0: 0.6616 (0.6672)  loss_bbox_aux_0: 0.1295 (0.1608)  loss_giou_aux_0: 0.5740 (0.5992)  loss_vfl_aux_1: 0.6608 (0.6636)  loss_bbox_aux_1: 0.1282 (0.1492)  loss_giou_aux_1: 0.5187 (0.5644)  loss_vfl_aux_2: 0.6363 (0.6635)  loss_bbox_aux_2: 0.1199 (0.1468)  loss_giou_aux_2: 0.4906 (0.5514)  loss_vfl_aux_3: 0.6417 (0.6617)  loss_bbox_aux_3: 0.1179 (0.1474)  loss_giou_aux_3: 0.4939 (0.5484)  loss_vfl_aux_4: 0.6528 (0.6652)  loss_bbox_aux_4: 0.1198 (0.1456)  loss_giou_aux_4: 0.4933 (0.5451)  loss_vfl_aux_5: 0.6601 (0.6878)  loss_bbox_aux_5: 0.1786 (0.2148)  loss_giou_aux_5: 0.6877 (0.7205)  loss_vfl_dn_0: 0.4388 (0.4331)  loss_bbox_dn_0: 0.1914 (0.2538)  loss_giou_dn_0: 0.8083 (0.8128)  loss_vfl_dn_1: 0.4335 (0.4321)  loss_bbox_dn_1: 0.1446 (0.1968)  loss_giou_dn_1: 0.6363 (0.6507)  loss_vfl_dn_2: 0.4258 (0.4273)  loss_bbox_dn_2: 0.1388 (0.1820)  loss_giou_dn_2: 0.6001 (0.6068)  loss_vfl_dn_3: 0.4288 (0.4256)  loss_bbox_dn_3: 0.1381 (0.1773)  loss_giou_dn_3: 0.5836 (0.5935)  loss_vfl_dn_4: 0.4276 (0.4257)  loss_bbox_dn_4: 0.1392 (0.1760)  loss_giou_dn_4: 0.5763 (0.5901)  loss_vfl_dn_5: 0.4283 (0.4259)  loss_bbox_dn_5: 0.1391 (0.1755)  loss_giou_dn_5: 0.5734 (0.5887)  time: 0.3287  data: 0.0145  max mem: 7790\n",
            "Epoch: [51] Total time: 0:00:11 (0.3488 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.2406 (17.4360)  loss_vfl: 0.6644 (0.6695)  loss_bbox: 0.1198 (0.1456)  loss_giou: 0.4973 (0.5449)  loss_vfl_aux_0: 0.6616 (0.6672)  loss_bbox_aux_0: 0.1295 (0.1608)  loss_giou_aux_0: 0.5740 (0.5992)  loss_vfl_aux_1: 0.6608 (0.6636)  loss_bbox_aux_1: 0.1282 (0.1492)  loss_giou_aux_1: 0.5187 (0.5644)  loss_vfl_aux_2: 0.6363 (0.6635)  loss_bbox_aux_2: 0.1199 (0.1468)  loss_giou_aux_2: 0.4906 (0.5514)  loss_vfl_aux_3: 0.6417 (0.6617)  loss_bbox_aux_3: 0.1179 (0.1474)  loss_giou_aux_3: 0.4939 (0.5484)  loss_vfl_aux_4: 0.6528 (0.6652)  loss_bbox_aux_4: 0.1198 (0.1456)  loss_giou_aux_4: 0.4933 (0.5451)  loss_vfl_aux_5: 0.6601 (0.6878)  loss_bbox_aux_5: 0.1786 (0.2148)  loss_giou_aux_5: 0.6877 (0.7205)  loss_vfl_dn_0: 0.4388 (0.4331)  loss_bbox_dn_0: 0.1914 (0.2538)  loss_giou_dn_0: 0.8083 (0.8128)  loss_vfl_dn_1: 0.4335 (0.4321)  loss_bbox_dn_1: 0.1446 (0.1968)  loss_giou_dn_1: 0.6363 (0.6507)  loss_vfl_dn_2: 0.4258 (0.4273)  loss_bbox_dn_2: 0.1388 (0.1820)  loss_giou_dn_2: 0.6001 (0.6068)  loss_vfl_dn_3: 0.4288 (0.4256)  loss_bbox_dn_3: 0.1381 (0.1773)  loss_giou_dn_3: 0.5836 (0.5935)  loss_vfl_dn_4: 0.4276 (0.4257)  loss_bbox_dn_4: 0.1392 (0.1760)  loss_giou_dn_4: 0.5763 (0.5901)  loss_vfl_dn_5: 0.4283 (0.4259)  loss_bbox_dn_5: 0.1391 (0.1755)  loss_giou_dn_5: 0.5734 (0.5887)\n",
            "Test:  [0/6]  eta: 0:00:04    time: 0.8275  data: 0.5187  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3824  data: 0.1091  max mem: 7790\n",
            "Test: Total time: 0:00:04 (0.7209 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.615\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [52]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 15.3536 (15.3536)  loss_vfl: 0.6629 (0.6629)  loss_bbox: 0.1176 (0.1176)  loss_giou: 0.4530 (0.4530)  loss_vfl_aux_0: 0.6322 (0.6322)  loss_bbox_aux_0: 0.1307 (0.1307)  loss_giou_aux_0: 0.5123 (0.5123)  loss_vfl_aux_1: 0.6545 (0.6545)  loss_bbox_aux_1: 0.1268 (0.1268)  loss_giou_aux_1: 0.4821 (0.4821)  loss_vfl_aux_2: 0.6378 (0.6378)  loss_bbox_aux_2: 0.1313 (0.1313)  loss_giou_aux_2: 0.4743 (0.4743)  loss_vfl_aux_3: 0.6414 (0.6414)  loss_bbox_aux_3: 0.1253 (0.1253)  loss_giou_aux_3: 0.4640 (0.4640)  loss_vfl_aux_4: 0.6560 (0.6560)  loss_bbox_aux_4: 0.1213 (0.1213)  loss_giou_aux_4: 0.4549 (0.4549)  loss_vfl_aux_5: 0.6892 (0.6892)  loss_bbox_aux_5: 0.1507 (0.1507)  loss_giou_aux_5: 0.6013 (0.6013)  loss_vfl_dn_0: 0.4405 (0.4405)  loss_bbox_dn_0: 0.1956 (0.1956)  loss_giou_dn_0: 0.7237 (0.7237)  loss_vfl_dn_1: 0.4178 (0.4178)  loss_bbox_dn_1: 0.1398 (0.1398)  loss_giou_dn_1: 0.5352 (0.5352)  loss_vfl_dn_2: 0.4046 (0.4046)  loss_bbox_dn_2: 0.1279 (0.1279)  loss_giou_dn_2: 0.4846 (0.4846)  loss_vfl_dn_3: 0.4002 (0.4002)  loss_bbox_dn_3: 0.1244 (0.1244)  loss_giou_dn_3: 0.4688 (0.4688)  loss_vfl_dn_4: 0.4003 (0.4003)  loss_bbox_dn_4: 0.1232 (0.1232)  loss_giou_dn_4: 0.4624 (0.4624)  loss_vfl_dn_5: 0.4007 (0.4007)  loss_bbox_dn_5: 0.1234 (0.1234)  loss_giou_dn_5: 0.4611 (0.4611)  time: 0.9933  data: 0.6182  max mem: 7790\n",
            "Epoch: [52]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.0393 (17.5382)  loss_vfl: 0.6583 (0.6663)  loss_bbox: 0.1443 (0.1479)  loss_giou: 0.5373 (0.5539)  loss_vfl_aux_0: 0.6342 (0.6571)  loss_bbox_aux_0: 0.1525 (0.1620)  loss_giou_aux_0: 0.6381 (0.6048)  loss_vfl_aux_1: 0.6423 (0.6553)  loss_bbox_aux_1: 0.1392 (0.1511)  loss_giou_aux_1: 0.5848 (0.5720)  loss_vfl_aux_2: 0.6553 (0.6538)  loss_bbox_aux_2: 0.1402 (0.1500)  loss_giou_aux_2: 0.5561 (0.5658)  loss_vfl_aux_3: 0.6601 (0.6577)  loss_bbox_aux_3: 0.1435 (0.1509)  loss_giou_aux_3: 0.5500 (0.5605)  loss_vfl_aux_4: 0.6547 (0.6667)  loss_bbox_aux_4: 0.1414 (0.1483)  loss_giou_aux_4: 0.5418 (0.5549)  loss_vfl_aux_5: 0.6530 (0.6787)  loss_bbox_aux_5: 0.2086 (0.2070)  loss_giou_aux_5: 0.7421 (0.7175)  loss_vfl_dn_0: 0.4288 (0.4341)  loss_bbox_dn_0: 0.2170 (0.2485)  loss_giou_dn_0: 0.8432 (0.8262)  loss_vfl_dn_1: 0.4321 (0.4324)  loss_bbox_dn_1: 0.1736 (0.1973)  loss_giou_dn_1: 0.6857 (0.6638)  loss_vfl_dn_2: 0.4291 (0.4271)  loss_bbox_dn_2: 0.1592 (0.1841)  loss_giou_dn_2: 0.6342 (0.6220)  loss_vfl_dn_3: 0.4233 (0.4234)  loss_bbox_dn_3: 0.1548 (0.1807)  loss_giou_dn_3: 0.6270 (0.6079)  loss_vfl_dn_4: 0.4239 (0.4237)  loss_bbox_dn_4: 0.1536 (0.1794)  loss_giou_dn_4: 0.6218 (0.6019)  loss_vfl_dn_5: 0.4240 (0.4235)  loss_bbox_dn_5: 0.1549 (0.1791)  loss_giou_dn_5: 0.6208 (0.6011)  time: 0.3386  data: 0.0140  max mem: 7790\n",
            "Epoch: [52] Total time: 0:00:11 (0.3588 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.0393 (17.5382)  loss_vfl: 0.6583 (0.6663)  loss_bbox: 0.1443 (0.1479)  loss_giou: 0.5373 (0.5539)  loss_vfl_aux_0: 0.6342 (0.6571)  loss_bbox_aux_0: 0.1525 (0.1620)  loss_giou_aux_0: 0.6381 (0.6048)  loss_vfl_aux_1: 0.6423 (0.6553)  loss_bbox_aux_1: 0.1392 (0.1511)  loss_giou_aux_1: 0.5848 (0.5720)  loss_vfl_aux_2: 0.6553 (0.6538)  loss_bbox_aux_2: 0.1402 (0.1500)  loss_giou_aux_2: 0.5561 (0.5658)  loss_vfl_aux_3: 0.6601 (0.6577)  loss_bbox_aux_3: 0.1435 (0.1509)  loss_giou_aux_3: 0.5500 (0.5605)  loss_vfl_aux_4: 0.6547 (0.6667)  loss_bbox_aux_4: 0.1414 (0.1483)  loss_giou_aux_4: 0.5418 (0.5549)  loss_vfl_aux_5: 0.6530 (0.6787)  loss_bbox_aux_5: 0.2086 (0.2070)  loss_giou_aux_5: 0.7421 (0.7175)  loss_vfl_dn_0: 0.4288 (0.4341)  loss_bbox_dn_0: 0.2170 (0.2485)  loss_giou_dn_0: 0.8432 (0.8262)  loss_vfl_dn_1: 0.4321 (0.4324)  loss_bbox_dn_1: 0.1736 (0.1973)  loss_giou_dn_1: 0.6857 (0.6638)  loss_vfl_dn_2: 0.4291 (0.4271)  loss_bbox_dn_2: 0.1592 (0.1841)  loss_giou_dn_2: 0.6342 (0.6220)  loss_vfl_dn_3: 0.4233 (0.4234)  loss_bbox_dn_3: 0.1548 (0.1807)  loss_giou_dn_3: 0.6270 (0.6079)  loss_vfl_dn_4: 0.4239 (0.4237)  loss_bbox_dn_4: 0.1536 (0.1794)  loss_giou_dn_4: 0.6218 (0.6019)  loss_vfl_dn_5: 0.4240 (0.4235)  loss_bbox_dn_5: 0.1549 (0.1791)  loss_giou_dn_5: 0.6208 (0.6011)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9102  data: 0.5897  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3932  data: 0.1135  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4071 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.617\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [53]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 17.6346 (17.6346)  loss_vfl: 0.5714 (0.5714)  loss_bbox: 0.1554 (0.1554)  loss_giou: 0.6732 (0.6732)  loss_vfl_aux_0: 0.5420 (0.5420)  loss_bbox_aux_0: 0.1546 (0.1546)  loss_giou_aux_0: 0.7095 (0.7095)  loss_vfl_aux_1: 0.5799 (0.5799)  loss_bbox_aux_1: 0.1512 (0.1512)  loss_giou_aux_1: 0.6883 (0.6883)  loss_vfl_aux_2: 0.5659 (0.5659)  loss_bbox_aux_2: 0.1500 (0.1500)  loss_giou_aux_2: 0.6777 (0.6777)  loss_vfl_aux_3: 0.5978 (0.5978)  loss_bbox_aux_3: 0.1485 (0.1485)  loss_giou_aux_3: 0.6663 (0.6663)  loss_vfl_aux_4: 0.5905 (0.5905)  loss_bbox_aux_4: 0.1465 (0.1465)  loss_giou_aux_4: 0.6650 (0.6650)  loss_vfl_aux_5: 0.5324 (0.5324)  loss_bbox_aux_5: 0.1780 (0.1780)  loss_giou_aux_5: 0.7755 (0.7755)  loss_vfl_dn_0: 0.4358 (0.4358)  loss_bbox_dn_0: 0.1801 (0.1801)  loss_giou_dn_0: 0.8360 (0.8360)  loss_vfl_dn_1: 0.4236 (0.4236)  loss_bbox_dn_1: 0.1494 (0.1494)  loss_giou_dn_1: 0.7177 (0.7177)  loss_vfl_dn_2: 0.4182 (0.4182)  loss_bbox_dn_2: 0.1393 (0.1393)  loss_giou_dn_2: 0.6845 (0.6845)  loss_vfl_dn_3: 0.4222 (0.4222)  loss_bbox_dn_3: 0.1384 (0.1384)  loss_giou_dn_3: 0.6818 (0.6818)  loss_vfl_dn_4: 0.4256 (0.4256)  loss_bbox_dn_4: 0.1379 (0.1379)  loss_giou_dn_4: 0.6787 (0.6787)  loss_vfl_dn_5: 0.4290 (0.4290)  loss_bbox_dn_5: 0.1373 (0.1373)  loss_giou_dn_5: 0.6793 (0.6793)  time: 1.0596  data: 0.6978  max mem: 7790\n",
            "Epoch: [53]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.1811 (17.3207)  loss_vfl: 0.6280 (0.6441)  loss_bbox: 0.1394 (0.1476)  loss_giou: 0.5640 (0.5612)  loss_vfl_aux_0: 0.6556 (0.6550)  loss_bbox_aux_0: 0.1457 (0.1575)  loss_giou_aux_0: 0.5843 (0.6016)  loss_vfl_aux_1: 0.6251 (0.6391)  loss_bbox_aux_1: 0.1445 (0.1519)  loss_giou_aux_1: 0.5563 (0.5746)  loss_vfl_aux_2: 0.6350 (0.6449)  loss_bbox_aux_2: 0.1392 (0.1461)  loss_giou_aux_2: 0.5462 (0.5645)  loss_vfl_aux_3: 0.6184 (0.6419)  loss_bbox_aux_3: 0.1378 (0.1450)  loss_giou_aux_3: 0.5567 (0.5616)  loss_vfl_aux_4: 0.6232 (0.6467)  loss_bbox_aux_4: 0.1395 (0.1431)  loss_giou_aux_4: 0.5536 (0.5575)  loss_vfl_aux_5: 0.6473 (0.6655)  loss_bbox_aux_5: 0.1917 (0.1995)  loss_giou_aux_5: 0.6911 (0.7114)  loss_vfl_dn_0: 0.4357 (0.4339)  loss_bbox_dn_0: 0.2252 (0.2363)  loss_giou_dn_0: 0.8143 (0.8159)  loss_vfl_dn_1: 0.4285 (0.4326)  loss_bbox_dn_1: 0.1698 (0.1861)  loss_giou_dn_1: 0.6636 (0.6566)  loss_vfl_dn_2: 0.4278 (0.4280)  loss_bbox_dn_2: 0.1553 (0.1740)  loss_giou_dn_2: 0.6240 (0.6146)  loss_vfl_dn_3: 0.4233 (0.4262)  loss_bbox_dn_3: 0.1525 (0.1701)  loss_giou_dn_3: 0.6172 (0.6002)  loss_vfl_dn_4: 0.4282 (0.4275)  loss_bbox_dn_4: 0.1519 (0.1689)  loss_giou_dn_4: 0.6134 (0.5964)  loss_vfl_dn_5: 0.4263 (0.4288)  loss_bbox_dn_5: 0.1515 (0.1686)  loss_giou_dn_5: 0.6110 (0.5958)  time: 0.3533  data: 0.0154  max mem: 7790\n",
            "Epoch: [53] Total time: 0:00:12 (0.3704 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.1811 (17.3207)  loss_vfl: 0.6280 (0.6441)  loss_bbox: 0.1394 (0.1476)  loss_giou: 0.5640 (0.5612)  loss_vfl_aux_0: 0.6556 (0.6550)  loss_bbox_aux_0: 0.1457 (0.1575)  loss_giou_aux_0: 0.5843 (0.6016)  loss_vfl_aux_1: 0.6251 (0.6391)  loss_bbox_aux_1: 0.1445 (0.1519)  loss_giou_aux_1: 0.5563 (0.5746)  loss_vfl_aux_2: 0.6350 (0.6449)  loss_bbox_aux_2: 0.1392 (0.1461)  loss_giou_aux_2: 0.5462 (0.5645)  loss_vfl_aux_3: 0.6184 (0.6419)  loss_bbox_aux_3: 0.1378 (0.1450)  loss_giou_aux_3: 0.5567 (0.5616)  loss_vfl_aux_4: 0.6232 (0.6467)  loss_bbox_aux_4: 0.1395 (0.1431)  loss_giou_aux_4: 0.5536 (0.5575)  loss_vfl_aux_5: 0.6473 (0.6655)  loss_bbox_aux_5: 0.1917 (0.1995)  loss_giou_aux_5: 0.6911 (0.7114)  loss_vfl_dn_0: 0.4357 (0.4339)  loss_bbox_dn_0: 0.2252 (0.2363)  loss_giou_dn_0: 0.8143 (0.8159)  loss_vfl_dn_1: 0.4285 (0.4326)  loss_bbox_dn_1: 0.1698 (0.1861)  loss_giou_dn_1: 0.6636 (0.6566)  loss_vfl_dn_2: 0.4278 (0.4280)  loss_bbox_dn_2: 0.1553 (0.1740)  loss_giou_dn_2: 0.6240 (0.6146)  loss_vfl_dn_3: 0.4233 (0.4262)  loss_bbox_dn_3: 0.1525 (0.1701)  loss_giou_dn_3: 0.6172 (0.6002)  loss_vfl_dn_4: 0.4282 (0.4275)  loss_bbox_dn_4: 0.1519 (0.1689)  loss_giou_dn_4: 0.6134 (0.5964)  loss_vfl_dn_5: 0.4263 (0.4288)  loss_bbox_dn_5: 0.1515 (0.1686)  loss_giou_dn_5: 0.6110 (0.5958)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8609  data: 0.5336  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3897  data: 0.1119  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4029 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.618\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.542\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [54]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 19.8354 (19.8354)  loss_vfl: 0.6920 (0.6920)  loss_bbox: 0.1777 (0.1777)  loss_giou: 0.6758 (0.6758)  loss_vfl_aux_0: 0.6738 (0.6738)  loss_bbox_aux_0: 0.1886 (0.1886)  loss_giou_aux_0: 0.6901 (0.6901)  loss_vfl_aux_1: 0.6893 (0.6893)  loss_bbox_aux_1: 0.1864 (0.1864)  loss_giou_aux_1: 0.6834 (0.6834)  loss_vfl_aux_2: 0.6908 (0.6908)  loss_bbox_aux_2: 0.1831 (0.1831)  loss_giou_aux_2: 0.6746 (0.6746)  loss_vfl_aux_3: 0.6914 (0.6914)  loss_bbox_aux_3: 0.1843 (0.1843)  loss_giou_aux_3: 0.6775 (0.6775)  loss_vfl_aux_4: 0.6858 (0.6858)  loss_bbox_aux_4: 0.1826 (0.1826)  loss_giou_aux_4: 0.6787 (0.6787)  loss_vfl_aux_5: 0.6886 (0.6886)  loss_bbox_aux_5: 0.2132 (0.2132)  loss_giou_aux_5: 0.7530 (0.7530)  loss_vfl_dn_0: 0.4153 (0.4153)  loss_bbox_dn_0: 0.2622 (0.2622)  loss_giou_dn_0: 0.9110 (0.9110)  loss_vfl_dn_1: 0.4208 (0.4208)  loss_bbox_dn_1: 0.2358 (0.2358)  loss_giou_dn_1: 0.8296 (0.8296)  loss_vfl_dn_2: 0.4261 (0.4261)  loss_bbox_dn_2: 0.2299 (0.2299)  loss_giou_dn_2: 0.7987 (0.7987)  loss_vfl_dn_3: 0.4239 (0.4239)  loss_bbox_dn_3: 0.2304 (0.2304)  loss_giou_dn_3: 0.7881 (0.7881)  loss_vfl_dn_4: 0.4281 (0.4281)  loss_bbox_dn_4: 0.2331 (0.2331)  loss_giou_dn_4: 0.7889 (0.7889)  loss_vfl_dn_5: 0.4269 (0.4269)  loss_bbox_dn_5: 0.2344 (0.2344)  loss_giou_dn_5: 0.7920 (0.7920)  time: 0.9599  data: 0.5803  max mem: 7790\n",
            "Epoch: [54]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.1904 (17.6403)  loss_vfl: 0.6550 (0.6641)  loss_bbox: 0.1343 (0.1455)  loss_giou: 0.5513 (0.5657)  loss_vfl_aux_0: 0.6463 (0.6538)  loss_bbox_aux_0: 0.1499 (0.1600)  loss_giou_aux_0: 0.5952 (0.6139)  loss_vfl_aux_1: 0.6399 (0.6627)  loss_bbox_aux_1: 0.1387 (0.1478)  loss_giou_aux_1: 0.5598 (0.5819)  loss_vfl_aux_2: 0.6522 (0.6565)  loss_bbox_aux_2: 0.1389 (0.1471)  loss_giou_aux_2: 0.5459 (0.5742)  loss_vfl_aux_3: 0.6587 (0.6588)  loss_bbox_aux_3: 0.1293 (0.1453)  loss_giou_aux_3: 0.5497 (0.5678)  loss_vfl_aux_4: 0.6417 (0.6590)  loss_bbox_aux_4: 0.1328 (0.1471)  loss_giou_aux_4: 0.5498 (0.5673)  loss_vfl_aux_5: 0.6594 (0.6701)  loss_bbox_aux_5: 0.1891 (0.2024)  loss_giou_aux_5: 0.7233 (0.7141)  loss_vfl_dn_0: 0.4291 (0.4296)  loss_bbox_dn_0: 0.2099 (0.2531)  loss_giou_dn_0: 0.8369 (0.8328)  loss_vfl_dn_1: 0.4234 (0.4248)  loss_bbox_dn_1: 0.1700 (0.2010)  loss_giou_dn_1: 0.6664 (0.6821)  loss_vfl_dn_2: 0.4241 (0.4222)  loss_bbox_dn_2: 0.1573 (0.1868)  loss_giou_dn_2: 0.6294 (0.6386)  loss_vfl_dn_3: 0.4242 (0.4196)  loss_bbox_dn_3: 0.1566 (0.1824)  loss_giou_dn_3: 0.6082 (0.6235)  loss_vfl_dn_4: 0.4231 (0.4201)  loss_bbox_dn_4: 0.1548 (0.1811)  loss_giou_dn_4: 0.6081 (0.6192)  loss_vfl_dn_5: 0.4233 (0.4202)  loss_bbox_dn_5: 0.1523 (0.1801)  loss_giou_dn_5: 0.6058 (0.6176)  time: 0.3171  data: 0.0142  max mem: 7790\n",
            "Epoch: [54] Total time: 0:00:11 (0.3454 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.1904 (17.6403)  loss_vfl: 0.6550 (0.6641)  loss_bbox: 0.1343 (0.1455)  loss_giou: 0.5513 (0.5657)  loss_vfl_aux_0: 0.6463 (0.6538)  loss_bbox_aux_0: 0.1499 (0.1600)  loss_giou_aux_0: 0.5952 (0.6139)  loss_vfl_aux_1: 0.6399 (0.6627)  loss_bbox_aux_1: 0.1387 (0.1478)  loss_giou_aux_1: 0.5598 (0.5819)  loss_vfl_aux_2: 0.6522 (0.6565)  loss_bbox_aux_2: 0.1389 (0.1471)  loss_giou_aux_2: 0.5459 (0.5742)  loss_vfl_aux_3: 0.6587 (0.6588)  loss_bbox_aux_3: 0.1293 (0.1453)  loss_giou_aux_3: 0.5497 (0.5678)  loss_vfl_aux_4: 0.6417 (0.6590)  loss_bbox_aux_4: 0.1328 (0.1471)  loss_giou_aux_4: 0.5498 (0.5673)  loss_vfl_aux_5: 0.6594 (0.6701)  loss_bbox_aux_5: 0.1891 (0.2024)  loss_giou_aux_5: 0.7233 (0.7141)  loss_vfl_dn_0: 0.4291 (0.4296)  loss_bbox_dn_0: 0.2099 (0.2531)  loss_giou_dn_0: 0.8369 (0.8328)  loss_vfl_dn_1: 0.4234 (0.4248)  loss_bbox_dn_1: 0.1700 (0.2010)  loss_giou_dn_1: 0.6664 (0.6821)  loss_vfl_dn_2: 0.4241 (0.4222)  loss_bbox_dn_2: 0.1573 (0.1868)  loss_giou_dn_2: 0.6294 (0.6386)  loss_vfl_dn_3: 0.4242 (0.4196)  loss_bbox_dn_3: 0.1566 (0.1824)  loss_giou_dn_3: 0.6082 (0.6235)  loss_vfl_dn_4: 0.4231 (0.4201)  loss_bbox_dn_4: 0.1548 (0.1811)  loss_giou_dn_4: 0.6081 (0.6192)  loss_vfl_dn_5: 0.4233 (0.4202)  loss_bbox_dn_5: 0.1523 (0.1801)  loss_giou_dn_5: 0.6058 (0.6176)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9040  data: 0.5916  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3871  data: 0.1145  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4008 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.626\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.290\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.526\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.542\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [55]  [ 0/33]  eta: 0:00:37  lr: 0.000001  loss: 17.0211 (17.0211)  loss_vfl: 0.7758 (0.7758)  loss_bbox: 0.1282 (0.1282)  loss_giou: 0.5101 (0.5101)  loss_vfl_aux_0: 0.7855 (0.7855)  loss_bbox_aux_0: 0.1170 (0.1170)  loss_giou_aux_0: 0.4818 (0.4818)  loss_vfl_aux_1: 0.7621 (0.7621)  loss_bbox_aux_1: 0.1206 (0.1206)  loss_giou_aux_1: 0.4709 (0.4709)  loss_vfl_aux_2: 0.7693 (0.7693)  loss_bbox_aux_2: 0.1246 (0.1246)  loss_giou_aux_2: 0.4784 (0.4784)  loss_vfl_aux_3: 0.7814 (0.7814)  loss_bbox_aux_3: 0.1276 (0.1276)  loss_giou_aux_3: 0.5020 (0.5020)  loss_vfl_aux_4: 0.7666 (0.7666)  loss_bbox_aux_4: 0.1279 (0.1279)  loss_giou_aux_4: 0.5085 (0.5085)  loss_vfl_aux_5: 0.7254 (0.7254)  loss_bbox_aux_5: 0.1512 (0.1512)  loss_giou_aux_5: 0.5815 (0.5815)  loss_vfl_dn_0: 0.4345 (0.4345)  loss_bbox_dn_0: 0.2223 (0.2223)  loss_giou_dn_0: 0.7667 (0.7667)  loss_vfl_dn_1: 0.4233 (0.4233)  loss_bbox_dn_1: 0.1697 (0.1697)  loss_giou_dn_1: 0.6052 (0.6052)  loss_vfl_dn_2: 0.4182 (0.4182)  loss_bbox_dn_2: 0.1590 (0.1590)  loss_giou_dn_2: 0.5854 (0.5854)  loss_vfl_dn_3: 0.4191 (0.4191)  loss_bbox_dn_3: 0.1570 (0.1570)  loss_giou_dn_3: 0.5758 (0.5758)  loss_vfl_dn_4: 0.4209 (0.4209)  loss_bbox_dn_4: 0.1546 (0.1546)  loss_giou_dn_4: 0.5703 (0.5703)  loss_vfl_dn_5: 0.4201 (0.4201)  loss_bbox_dn_5: 0.1539 (0.1539)  loss_giou_dn_5: 0.5689 (0.5689)  time: 1.1430  data: 0.7751  max mem: 7790\n",
            "Epoch: [55]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.2120 (17.0502)  loss_vfl: 0.6138 (0.6503)  loss_bbox: 0.1293 (0.1458)  loss_giou: 0.4865 (0.5383)  loss_vfl_aux_0: 0.6412 (0.6493)  loss_bbox_aux_0: 0.1584 (0.1609)  loss_giou_aux_0: 0.5318 (0.5910)  loss_vfl_aux_1: 0.6368 (0.6427)  loss_bbox_aux_1: 0.1432 (0.1509)  loss_giou_aux_1: 0.5049 (0.5564)  loss_vfl_aux_2: 0.6296 (0.6439)  loss_bbox_aux_2: 0.1264 (0.1465)  loss_giou_aux_2: 0.4892 (0.5449)  loss_vfl_aux_3: 0.6297 (0.6463)  loss_bbox_aux_3: 0.1249 (0.1464)  loss_giou_aux_3: 0.5032 (0.5433)  loss_vfl_aux_4: 0.6237 (0.6467)  loss_bbox_aux_4: 0.1300 (0.1463)  loss_giou_aux_4: 0.4945 (0.5398)  loss_vfl_aux_5: 0.6681 (0.6565)  loss_bbox_aux_5: 0.1872 (0.2060)  loss_giou_aux_5: 0.6437 (0.7092)  loss_vfl_dn_0: 0.4392 (0.4368)  loss_bbox_dn_0: 0.2741 (0.2411)  loss_giou_dn_0: 0.7709 (0.7962)  loss_vfl_dn_1: 0.4317 (0.4325)  loss_bbox_dn_1: 0.1938 (0.1876)  loss_giou_dn_1: 0.6013 (0.6247)  loss_vfl_dn_2: 0.4303 (0.4274)  loss_bbox_dn_2: 0.1692 (0.1750)  loss_giou_dn_2: 0.5549 (0.5824)  loss_vfl_dn_3: 0.4245 (0.4252)  loss_bbox_dn_3: 0.1590 (0.1713)  loss_giou_dn_3: 0.5440 (0.5692)  loss_vfl_dn_4: 0.4227 (0.4244)  loss_bbox_dn_4: 0.1534 (0.1701)  loss_giou_dn_4: 0.5331 (0.5651)  loss_vfl_dn_5: 0.4242 (0.4255)  loss_bbox_dn_5: 0.1532 (0.1699)  loss_giou_dn_5: 0.5338 (0.5646)  time: 0.3197  data: 0.0137  max mem: 7790\n",
            "Epoch: [55] Total time: 0:00:11 (0.3504 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.2120 (17.0502)  loss_vfl: 0.6138 (0.6503)  loss_bbox: 0.1293 (0.1458)  loss_giou: 0.4865 (0.5383)  loss_vfl_aux_0: 0.6412 (0.6493)  loss_bbox_aux_0: 0.1584 (0.1609)  loss_giou_aux_0: 0.5318 (0.5910)  loss_vfl_aux_1: 0.6368 (0.6427)  loss_bbox_aux_1: 0.1432 (0.1509)  loss_giou_aux_1: 0.5049 (0.5564)  loss_vfl_aux_2: 0.6296 (0.6439)  loss_bbox_aux_2: 0.1264 (0.1465)  loss_giou_aux_2: 0.4892 (0.5449)  loss_vfl_aux_3: 0.6297 (0.6463)  loss_bbox_aux_3: 0.1249 (0.1464)  loss_giou_aux_3: 0.5032 (0.5433)  loss_vfl_aux_4: 0.6237 (0.6467)  loss_bbox_aux_4: 0.1300 (0.1463)  loss_giou_aux_4: 0.4945 (0.5398)  loss_vfl_aux_5: 0.6681 (0.6565)  loss_bbox_aux_5: 0.1872 (0.2060)  loss_giou_aux_5: 0.6437 (0.7092)  loss_vfl_dn_0: 0.4392 (0.4368)  loss_bbox_dn_0: 0.2741 (0.2411)  loss_giou_dn_0: 0.7709 (0.7962)  loss_vfl_dn_1: 0.4317 (0.4325)  loss_bbox_dn_1: 0.1938 (0.1876)  loss_giou_dn_1: 0.6013 (0.6247)  loss_vfl_dn_2: 0.4303 (0.4274)  loss_bbox_dn_2: 0.1692 (0.1750)  loss_giou_dn_2: 0.5549 (0.5824)  loss_vfl_dn_3: 0.4245 (0.4252)  loss_bbox_dn_3: 0.1590 (0.1713)  loss_giou_dn_3: 0.5440 (0.5692)  loss_vfl_dn_4: 0.4227 (0.4244)  loss_bbox_dn_4: 0.1534 (0.1701)  loss_giou_dn_4: 0.5331 (0.5651)  loss_vfl_dn_5: 0.4242 (0.4255)  loss_bbox_dn_5: 0.1532 (0.1699)  loss_giou_dn_5: 0.5338 (0.5646)\n",
            "Test:  [0/6]  eta: 0:00:08    time: 1.4410  data: 0.8787  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4893  data: 0.1681  max mem: 7790\n",
            "Test: Total time: 0:00:03 (0.5066 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.613\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [56]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 17.9806 (17.9806)  loss_vfl: 0.6028 (0.6028)  loss_bbox: 0.1476 (0.1476)  loss_giou: 0.6184 (0.6184)  loss_vfl_aux_0: 0.5965 (0.5965)  loss_bbox_aux_0: 0.1420 (0.1420)  loss_giou_aux_0: 0.6300 (0.6300)  loss_vfl_aux_1: 0.6027 (0.6027)  loss_bbox_aux_1: 0.1467 (0.1467)  loss_giou_aux_1: 0.6251 (0.6251)  loss_vfl_aux_2: 0.5933 (0.5933)  loss_bbox_aux_2: 0.1456 (0.1456)  loss_giou_aux_2: 0.6171 (0.6171)  loss_vfl_aux_3: 0.6223 (0.6223)  loss_bbox_aux_3: 0.1443 (0.1443)  loss_giou_aux_3: 0.6128 (0.6128)  loss_vfl_aux_4: 0.5920 (0.5920)  loss_bbox_aux_4: 0.1463 (0.1463)  loss_giou_aux_4: 0.6273 (0.6273)  loss_vfl_aux_5: 0.5632 (0.5632)  loss_bbox_aux_5: 0.1686 (0.1686)  loss_giou_aux_5: 0.7599 (0.7599)  loss_vfl_dn_0: 0.4326 (0.4326)  loss_bbox_dn_0: 0.2324 (0.2324)  loss_giou_dn_0: 0.8774 (0.8774)  loss_vfl_dn_1: 0.4372 (0.4372)  loss_bbox_dn_1: 0.1884 (0.1884)  loss_giou_dn_1: 0.7409 (0.7409)  loss_vfl_dn_2: 0.4373 (0.4373)  loss_bbox_dn_2: 0.1846 (0.1846)  loss_giou_dn_2: 0.7160 (0.7160)  loss_vfl_dn_3: 0.4378 (0.4378)  loss_bbox_dn_3: 0.1867 (0.1867)  loss_giou_dn_3: 0.7161 (0.7161)  loss_vfl_dn_4: 0.4383 (0.4383)  loss_bbox_dn_4: 0.1872 (0.1872)  loss_giou_dn_4: 0.7164 (0.7164)  loss_vfl_dn_5: 0.4417 (0.4417)  loss_bbox_dn_5: 0.1872 (0.1872)  loss_giou_dn_5: 0.7179 (0.7179)  time: 0.9197  data: 0.5582  max mem: 7790\n",
            "Epoch: [56]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.5330 (17.0962)  loss_vfl: 0.6207 (0.6293)  loss_bbox: 0.1255 (0.1409)  loss_giou: 0.5408 (0.5623)  loss_vfl_aux_0: 0.6087 (0.6200)  loss_bbox_aux_0: 0.1429 (0.1577)  loss_giou_aux_0: 0.5990 (0.6153)  loss_vfl_aux_1: 0.5963 (0.6138)  loss_bbox_aux_1: 0.1305 (0.1488)  loss_giou_aux_1: 0.5857 (0.5839)  loss_vfl_aux_2: 0.6090 (0.6168)  loss_bbox_aux_2: 0.1265 (0.1435)  loss_giou_aux_2: 0.5637 (0.5711)  loss_vfl_aux_3: 0.6176 (0.6288)  loss_bbox_aux_3: 0.1249 (0.1398)  loss_giou_aux_3: 0.5577 (0.5627)  loss_vfl_aux_4: 0.6106 (0.6212)  loss_bbox_aux_4: 0.1247 (0.1418)  loss_giou_aux_4: 0.5467 (0.5645)  loss_vfl_aux_5: 0.6341 (0.6492)  loss_bbox_aux_5: 0.1837 (0.1895)  loss_giou_aux_5: 0.7103 (0.7214)  loss_vfl_dn_0: 0.4312 (0.4372)  loss_bbox_dn_0: 0.2282 (0.2274)  loss_giou_dn_0: 0.7880 (0.8050)  loss_vfl_dn_1: 0.4251 (0.4316)  loss_bbox_dn_1: 0.1773 (0.1779)  loss_giou_dn_1: 0.6298 (0.6466)  loss_vfl_dn_2: 0.4178 (0.4257)  loss_bbox_dn_2: 0.1600 (0.1673)  loss_giou_dn_2: 0.5871 (0.6094)  loss_vfl_dn_3: 0.4167 (0.4235)  loss_bbox_dn_3: 0.1510 (0.1645)  loss_giou_dn_3: 0.5728 (0.5963)  loss_vfl_dn_4: 0.4164 (0.4237)  loss_bbox_dn_4: 0.1511 (0.1643)  loss_giou_dn_4: 0.5719 (0.5931)  loss_vfl_dn_5: 0.4171 (0.4241)  loss_bbox_dn_5: 0.1508 (0.1639)  loss_giou_dn_5: 0.5711 (0.5922)  time: 0.3264  data: 0.0142  max mem: 7790\n",
            "Epoch: [56] Total time: 0:00:11 (0.3483 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.5330 (17.0962)  loss_vfl: 0.6207 (0.6293)  loss_bbox: 0.1255 (0.1409)  loss_giou: 0.5408 (0.5623)  loss_vfl_aux_0: 0.6087 (0.6200)  loss_bbox_aux_0: 0.1429 (0.1577)  loss_giou_aux_0: 0.5990 (0.6153)  loss_vfl_aux_1: 0.5963 (0.6138)  loss_bbox_aux_1: 0.1305 (0.1488)  loss_giou_aux_1: 0.5857 (0.5839)  loss_vfl_aux_2: 0.6090 (0.6168)  loss_bbox_aux_2: 0.1265 (0.1435)  loss_giou_aux_2: 0.5637 (0.5711)  loss_vfl_aux_3: 0.6176 (0.6288)  loss_bbox_aux_3: 0.1249 (0.1398)  loss_giou_aux_3: 0.5577 (0.5627)  loss_vfl_aux_4: 0.6106 (0.6212)  loss_bbox_aux_4: 0.1247 (0.1418)  loss_giou_aux_4: 0.5467 (0.5645)  loss_vfl_aux_5: 0.6341 (0.6492)  loss_bbox_aux_5: 0.1837 (0.1895)  loss_giou_aux_5: 0.7103 (0.7214)  loss_vfl_dn_0: 0.4312 (0.4372)  loss_bbox_dn_0: 0.2282 (0.2274)  loss_giou_dn_0: 0.7880 (0.8050)  loss_vfl_dn_1: 0.4251 (0.4316)  loss_bbox_dn_1: 0.1773 (0.1779)  loss_giou_dn_1: 0.6298 (0.6466)  loss_vfl_dn_2: 0.4178 (0.4257)  loss_bbox_dn_2: 0.1600 (0.1673)  loss_giou_dn_2: 0.5871 (0.6094)  loss_vfl_dn_3: 0.4167 (0.4235)  loss_bbox_dn_3: 0.1510 (0.1645)  loss_giou_dn_3: 0.5728 (0.5963)  loss_vfl_dn_4: 0.4164 (0.4237)  loss_bbox_dn_4: 0.1511 (0.1643)  loss_giou_dn_4: 0.5719 (0.5931)  loss_vfl_dn_5: 0.4171 (0.4241)  loss_bbox_dn_5: 0.1508 (0.1639)  loss_giou_dn_5: 0.5711 (0.5922)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8702  data: 0.5609  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4335  data: 0.1125  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4461 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.617\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [57]  [ 0/33]  eta: 0:00:28  lr: 0.000001  loss: 16.2481 (16.2481)  loss_vfl: 0.7077 (0.7077)  loss_bbox: 0.1502 (0.1502)  loss_giou: 0.3650 (0.3650)  loss_vfl_aux_0: 0.6805 (0.6805)  loss_bbox_aux_0: 0.1891 (0.1891)  loss_giou_aux_0: 0.4680 (0.4680)  loss_vfl_aux_1: 0.6595 (0.6595)  loss_bbox_aux_1: 0.1856 (0.1856)  loss_giou_aux_1: 0.4201 (0.4201)  loss_vfl_aux_2: 0.6612 (0.6612)  loss_bbox_aux_2: 0.1682 (0.1682)  loss_giou_aux_2: 0.3809 (0.3809)  loss_vfl_aux_3: 0.6826 (0.6826)  loss_bbox_aux_3: 0.1540 (0.1540)  loss_giou_aux_3: 0.3698 (0.3698)  loss_vfl_aux_4: 0.6767 (0.6767)  loss_bbox_aux_4: 0.1527 (0.1527)  loss_giou_aux_4: 0.3691 (0.3691)  loss_vfl_aux_5: 0.9376 (0.9376)  loss_bbox_aux_5: 0.2431 (0.2431)  loss_giou_aux_5: 0.5548 (0.5548)  loss_vfl_dn_0: 0.4429 (0.4429)  loss_bbox_dn_0: 0.3575 (0.3575)  loss_giou_dn_0: 0.7616 (0.7616)  loss_vfl_dn_1: 0.4064 (0.4064)  loss_bbox_dn_1: 0.2586 (0.2586)  loss_giou_dn_1: 0.5597 (0.5597)  loss_vfl_dn_2: 0.3860 (0.3860)  loss_bbox_dn_2: 0.2323 (0.2323)  loss_giou_dn_2: 0.4856 (0.4856)  loss_vfl_dn_3: 0.3787 (0.3787)  loss_bbox_dn_3: 0.2233 (0.2233)  loss_giou_dn_3: 0.4611 (0.4611)  loss_vfl_dn_4: 0.3831 (0.3831)  loss_bbox_dn_4: 0.2243 (0.2243)  loss_giou_dn_4: 0.4534 (0.4534)  loss_vfl_dn_5: 0.3844 (0.3844)  loss_bbox_dn_5: 0.2239 (0.2239)  loss_giou_dn_5: 0.4488 (0.4488)  time: 0.8549  data: 0.4520  max mem: 7790\n",
            "Epoch: [57]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.8585 (16.8838)  loss_vfl: 0.6243 (0.6347)  loss_bbox: 0.1290 (0.1400)  loss_giou: 0.5551 (0.5337)  loss_vfl_aux_0: 0.6066 (0.6208)  loss_bbox_aux_0: 0.1335 (0.1581)  loss_giou_aux_0: 0.5850 (0.5891)  loss_vfl_aux_1: 0.6269 (0.6201)  loss_bbox_aux_1: 0.1363 (0.1483)  loss_giou_aux_1: 0.5575 (0.5560)  loss_vfl_aux_2: 0.6221 (0.6276)  loss_bbox_aux_2: 0.1269 (0.1433)  loss_giou_aux_2: 0.5576 (0.5424)  loss_vfl_aux_3: 0.6221 (0.6284)  loss_bbox_aux_3: 0.1286 (0.1408)  loss_giou_aux_3: 0.5493 (0.5386)  loss_vfl_aux_4: 0.6184 (0.6345)  loss_bbox_aux_4: 0.1292 (0.1388)  loss_giou_aux_4: 0.5501 (0.5342)  loss_vfl_aux_5: 0.6439 (0.6562)  loss_bbox_aux_5: 0.1833 (0.2024)  loss_giou_aux_5: 0.6762 (0.7022)  loss_vfl_dn_0: 0.4419 (0.4397)  loss_bbox_dn_0: 0.1899 (0.2366)  loss_giou_dn_0: 0.7746 (0.7942)  loss_vfl_dn_1: 0.4319 (0.4331)  loss_bbox_dn_1: 0.1480 (0.1841)  loss_giou_dn_1: 0.6226 (0.6301)  loss_vfl_dn_2: 0.4256 (0.4262)  loss_bbox_dn_2: 0.1340 (0.1718)  loss_giou_dn_2: 0.5896 (0.5879)  loss_vfl_dn_3: 0.4271 (0.4234)  loss_bbox_dn_3: 0.1312 (0.1684)  loss_giou_dn_3: 0.5774 (0.5751)  loss_vfl_dn_4: 0.4240 (0.4239)  loss_bbox_dn_4: 0.1315 (0.1674)  loss_giou_dn_4: 0.5738 (0.5707)  loss_vfl_dn_5: 0.4228 (0.4234)  loss_bbox_dn_5: 0.1319 (0.1674)  loss_giou_dn_5: 0.5662 (0.5702)  time: 0.3317  data: 0.0150  max mem: 7790\n",
            "Epoch: [57] Total time: 0:00:11 (0.3499 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.8585 (16.8838)  loss_vfl: 0.6243 (0.6347)  loss_bbox: 0.1290 (0.1400)  loss_giou: 0.5551 (0.5337)  loss_vfl_aux_0: 0.6066 (0.6208)  loss_bbox_aux_0: 0.1335 (0.1581)  loss_giou_aux_0: 0.5850 (0.5891)  loss_vfl_aux_1: 0.6269 (0.6201)  loss_bbox_aux_1: 0.1363 (0.1483)  loss_giou_aux_1: 0.5575 (0.5560)  loss_vfl_aux_2: 0.6221 (0.6276)  loss_bbox_aux_2: 0.1269 (0.1433)  loss_giou_aux_2: 0.5576 (0.5424)  loss_vfl_aux_3: 0.6221 (0.6284)  loss_bbox_aux_3: 0.1286 (0.1408)  loss_giou_aux_3: 0.5493 (0.5386)  loss_vfl_aux_4: 0.6184 (0.6345)  loss_bbox_aux_4: 0.1292 (0.1388)  loss_giou_aux_4: 0.5501 (0.5342)  loss_vfl_aux_5: 0.6439 (0.6562)  loss_bbox_aux_5: 0.1833 (0.2024)  loss_giou_aux_5: 0.6762 (0.7022)  loss_vfl_dn_0: 0.4419 (0.4397)  loss_bbox_dn_0: 0.1899 (0.2366)  loss_giou_dn_0: 0.7746 (0.7942)  loss_vfl_dn_1: 0.4319 (0.4331)  loss_bbox_dn_1: 0.1480 (0.1841)  loss_giou_dn_1: 0.6226 (0.6301)  loss_vfl_dn_2: 0.4256 (0.4262)  loss_bbox_dn_2: 0.1340 (0.1718)  loss_giou_dn_2: 0.5896 (0.5879)  loss_vfl_dn_3: 0.4271 (0.4234)  loss_bbox_dn_3: 0.1312 (0.1684)  loss_giou_dn_3: 0.5774 (0.5751)  loss_vfl_dn_4: 0.4240 (0.4239)  loss_bbox_dn_4: 0.1315 (0.1674)  loss_giou_dn_4: 0.5738 (0.5707)  loss_vfl_dn_5: 0.4228 (0.4234)  loss_bbox_dn_5: 0.1319 (0.1674)  loss_giou_dn_5: 0.5662 (0.5702)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8815  data: 0.5625  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4544  data: 0.1131  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4677 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [58]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 17.0006 (17.0006)  loss_vfl: 0.6308 (0.6308)  loss_bbox: 0.1217 (0.1217)  loss_giou: 0.5820 (0.5820)  loss_vfl_aux_0: 0.6577 (0.6577)  loss_bbox_aux_0: 0.1305 (0.1305)  loss_giou_aux_0: 0.5819 (0.5819)  loss_vfl_aux_1: 0.6562 (0.6562)  loss_bbox_aux_1: 0.1214 (0.1214)  loss_giou_aux_1: 0.5784 (0.5784)  loss_vfl_aux_2: 0.6482 (0.6482)  loss_bbox_aux_2: 0.1243 (0.1243)  loss_giou_aux_2: 0.5888 (0.5888)  loss_vfl_aux_3: 0.6420 (0.6420)  loss_bbox_aux_3: 0.1242 (0.1242)  loss_giou_aux_3: 0.5855 (0.5855)  loss_vfl_aux_4: 0.6183 (0.6183)  loss_bbox_aux_4: 0.1439 (0.1439)  loss_giou_aux_4: 0.6001 (0.6001)  loss_vfl_aux_5: 0.6773 (0.6773)  loss_bbox_aux_5: 0.1261 (0.1261)  loss_giou_aux_5: 0.5989 (0.5989)  loss_vfl_dn_0: 0.4582 (0.4582)  loss_bbox_dn_0: 0.1727 (0.1727)  loss_giou_dn_0: 0.7592 (0.7592)  loss_vfl_dn_1: 0.4592 (0.4592)  loss_bbox_dn_1: 0.1334 (0.1334)  loss_giou_dn_1: 0.6499 (0.6499)  loss_vfl_dn_2: 0.4543 (0.4543)  loss_bbox_dn_2: 0.1253 (0.1253)  loss_giou_dn_2: 0.6300 (0.6300)  loss_vfl_dn_3: 0.4513 (0.4513)  loss_bbox_dn_3: 0.1269 (0.1269)  loss_giou_dn_3: 0.6313 (0.6313)  loss_vfl_dn_4: 0.4504 (0.4504)  loss_bbox_dn_4: 0.1268 (0.1268)  loss_giou_dn_4: 0.6303 (0.6303)  loss_vfl_dn_5: 0.4486 (0.4486)  loss_bbox_dn_5: 0.1261 (0.1261)  loss_giou_dn_5: 0.6285 (0.6285)  time: 1.0234  data: 0.6331  max mem: 7790\n",
            "Epoch: [58]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.3330 (16.6070)  loss_vfl: 0.6153 (0.6244)  loss_bbox: 0.1170 (0.1308)  loss_giou: 0.5162 (0.5346)  loss_vfl_aux_0: 0.6271 (0.6377)  loss_bbox_aux_0: 0.1342 (0.1427)  loss_giou_aux_0: 0.5465 (0.5778)  loss_vfl_aux_1: 0.6310 (0.6374)  loss_bbox_aux_1: 0.1243 (0.1325)  loss_giou_aux_1: 0.5270 (0.5474)  loss_vfl_aux_2: 0.6257 (0.6282)  loss_bbox_aux_2: 0.1229 (0.1321)  loss_giou_aux_2: 0.5135 (0.5405)  loss_vfl_aux_3: 0.6208 (0.6234)  loss_bbox_aux_3: 0.1213 (0.1315)  loss_giou_aux_3: 0.5222 (0.5366)  loss_vfl_aux_4: 0.6181 (0.6210)  loss_bbox_aux_4: 0.1172 (0.1320)  loss_giou_aux_4: 0.5189 (0.5369)  loss_vfl_aux_5: 0.6554 (0.6491)  loss_bbox_aux_5: 0.1627 (0.1819)  loss_giou_aux_5: 0.6656 (0.6914)  loss_vfl_dn_0: 0.4397 (0.4378)  loss_bbox_dn_0: 0.1976 (0.2090)  loss_giou_dn_0: 0.7756 (0.7859)  loss_vfl_dn_1: 0.4345 (0.4331)  loss_bbox_dn_1: 0.1505 (0.1621)  loss_giou_dn_1: 0.6054 (0.6242)  loss_vfl_dn_2: 0.4298 (0.4271)  loss_bbox_dn_2: 0.1425 (0.1521)  loss_giou_dn_2: 0.5752 (0.5846)  loss_vfl_dn_3: 0.4258 (0.4242)  loss_bbox_dn_3: 0.1358 (0.1488)  loss_giou_dn_3: 0.5686 (0.5718)  loss_vfl_dn_4: 0.4246 (0.4237)  loss_bbox_dn_4: 0.1335 (0.1480)  loss_giou_dn_4: 0.5611 (0.5672)  loss_vfl_dn_5: 0.4236 (0.4228)  loss_bbox_dn_5: 0.1332 (0.1478)  loss_giou_dn_5: 0.5605 (0.5669)  time: 0.3355  data: 0.0141  max mem: 7790\n",
            "Epoch: [58] Total time: 0:00:11 (0.3541 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.3330 (16.6070)  loss_vfl: 0.6153 (0.6244)  loss_bbox: 0.1170 (0.1308)  loss_giou: 0.5162 (0.5346)  loss_vfl_aux_0: 0.6271 (0.6377)  loss_bbox_aux_0: 0.1342 (0.1427)  loss_giou_aux_0: 0.5465 (0.5778)  loss_vfl_aux_1: 0.6310 (0.6374)  loss_bbox_aux_1: 0.1243 (0.1325)  loss_giou_aux_1: 0.5270 (0.5474)  loss_vfl_aux_2: 0.6257 (0.6282)  loss_bbox_aux_2: 0.1229 (0.1321)  loss_giou_aux_2: 0.5135 (0.5405)  loss_vfl_aux_3: 0.6208 (0.6234)  loss_bbox_aux_3: 0.1213 (0.1315)  loss_giou_aux_3: 0.5222 (0.5366)  loss_vfl_aux_4: 0.6181 (0.6210)  loss_bbox_aux_4: 0.1172 (0.1320)  loss_giou_aux_4: 0.5189 (0.5369)  loss_vfl_aux_5: 0.6554 (0.6491)  loss_bbox_aux_5: 0.1627 (0.1819)  loss_giou_aux_5: 0.6656 (0.6914)  loss_vfl_dn_0: 0.4397 (0.4378)  loss_bbox_dn_0: 0.1976 (0.2090)  loss_giou_dn_0: 0.7756 (0.7859)  loss_vfl_dn_1: 0.4345 (0.4331)  loss_bbox_dn_1: 0.1505 (0.1621)  loss_giou_dn_1: 0.6054 (0.6242)  loss_vfl_dn_2: 0.4298 (0.4271)  loss_bbox_dn_2: 0.1425 (0.1521)  loss_giou_dn_2: 0.5752 (0.5846)  loss_vfl_dn_3: 0.4258 (0.4242)  loss_bbox_dn_3: 0.1358 (0.1488)  loss_giou_dn_3: 0.5686 (0.5718)  loss_vfl_dn_4: 0.4246 (0.4237)  loss_bbox_dn_4: 0.1335 (0.1480)  loss_giou_dn_4: 0.5611 (0.5672)  loss_vfl_dn_5: 0.4236 (0.4228)  loss_bbox_dn_5: 0.1332 (0.1478)  loss_giou_dn_5: 0.5605 (0.5669)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9196  data: 0.6118  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3875  data: 0.1167  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3994 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.377\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [59]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 14.3379 (14.3379)  loss_vfl: 0.5279 (0.5279)  loss_bbox: 0.1199 (0.1199)  loss_giou: 0.4297 (0.4297)  loss_vfl_aux_0: 0.6218 (0.6218)  loss_bbox_aux_0: 0.1304 (0.1304)  loss_giou_aux_0: 0.4658 (0.4658)  loss_vfl_aux_1: 0.5825 (0.5825)  loss_bbox_aux_1: 0.1180 (0.1180)  loss_giou_aux_1: 0.4182 (0.4182)  loss_vfl_aux_2: 0.5531 (0.5531)  loss_bbox_aux_2: 0.1196 (0.1196)  loss_giou_aux_2: 0.4233 (0.4233)  loss_vfl_aux_3: 0.5368 (0.5368)  loss_bbox_aux_3: 0.1254 (0.1254)  loss_giou_aux_3: 0.4441 (0.4441)  loss_vfl_aux_4: 0.5306 (0.5306)  loss_bbox_aux_4: 0.1198 (0.1198)  loss_giou_aux_4: 0.4297 (0.4297)  loss_vfl_aux_5: 0.6777 (0.6777)  loss_bbox_aux_5: 0.1677 (0.1677)  loss_giou_aux_5: 0.5957 (0.5957)  loss_vfl_dn_0: 0.4392 (0.4392)  loss_bbox_dn_0: 0.1956 (0.1956)  loss_giou_dn_0: 0.6853 (0.6853)  loss_vfl_dn_1: 0.4227 (0.4227)  loss_bbox_dn_1: 0.1319 (0.1319)  loss_giou_dn_1: 0.5044 (0.5044)  loss_vfl_dn_2: 0.4173 (0.4173)  loss_bbox_dn_2: 0.1123 (0.1123)  loss_giou_dn_2: 0.4495 (0.4495)  loss_vfl_dn_3: 0.4180 (0.4180)  loss_bbox_dn_3: 0.1057 (0.1057)  loss_giou_dn_3: 0.4316 (0.4316)  loss_vfl_dn_4: 0.4153 (0.4153)  loss_bbox_dn_4: 0.1028 (0.1028)  loss_giou_dn_4: 0.4269 (0.4269)  loss_vfl_dn_5: 0.4144 (0.4144)  loss_bbox_dn_5: 0.1024 (0.1024)  loss_giou_dn_5: 0.4249 (0.4249)  time: 0.9191  data: 0.5186  max mem: 7790\n",
            "Epoch: [59]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 17.0708 (16.7155)  loss_vfl: 0.5970 (0.6156)  loss_bbox: 0.1192 (0.1307)  loss_giou: 0.5696 (0.5461)  loss_vfl_aux_0: 0.6235 (0.6278)  loss_bbox_aux_0: 0.1361 (0.1489)  loss_giou_aux_0: 0.5846 (0.5983)  loss_vfl_aux_1: 0.5929 (0.6097)  loss_bbox_aux_1: 0.1313 (0.1367)  loss_giou_aux_1: 0.5781 (0.5631)  loss_vfl_aux_2: 0.5986 (0.6106)  loss_bbox_aux_2: 0.1211 (0.1338)  loss_giou_aux_2: 0.5803 (0.5549)  loss_vfl_aux_3: 0.6244 (0.6142)  loss_bbox_aux_3: 0.1174 (0.1319)  loss_giou_aux_3: 0.5723 (0.5500)  loss_vfl_aux_4: 0.6149 (0.6171)  loss_bbox_aux_4: 0.1164 (0.1299)  loss_giou_aux_4: 0.5626 (0.5450)  loss_vfl_aux_5: 0.6228 (0.6289)  loss_bbox_aux_5: 0.1754 (0.1975)  loss_giou_aux_5: 0.7180 (0.7299)  loss_vfl_dn_0: 0.4341 (0.4348)  loss_bbox_dn_0: 0.1909 (0.2198)  loss_giou_dn_0: 0.8206 (0.7946)  loss_vfl_dn_1: 0.4189 (0.4275)  loss_bbox_dn_1: 0.1500 (0.1704)  loss_giou_dn_1: 0.6676 (0.6348)  loss_vfl_dn_2: 0.4131 (0.4215)  loss_bbox_dn_2: 0.1374 (0.1581)  loss_giou_dn_2: 0.6354 (0.5920)  loss_vfl_dn_3: 0.4117 (0.4181)  loss_bbox_dn_3: 0.1345 (0.1547)  loss_giou_dn_3: 0.6124 (0.5790)  loss_vfl_dn_4: 0.4123 (0.4174)  loss_bbox_dn_4: 0.1327 (0.1538)  loss_giou_dn_4: 0.6086 (0.5747)  loss_vfl_dn_5: 0.4098 (0.4173)  loss_bbox_dn_5: 0.1324 (0.1535)  loss_giou_dn_5: 0.6069 (0.5733)  time: 0.3223  data: 0.0143  max mem: 7790\n",
            "Epoch: [59] Total time: 0:00:11 (0.3531 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 17.0708 (16.7155)  loss_vfl: 0.5970 (0.6156)  loss_bbox: 0.1192 (0.1307)  loss_giou: 0.5696 (0.5461)  loss_vfl_aux_0: 0.6235 (0.6278)  loss_bbox_aux_0: 0.1361 (0.1489)  loss_giou_aux_0: 0.5846 (0.5983)  loss_vfl_aux_1: 0.5929 (0.6097)  loss_bbox_aux_1: 0.1313 (0.1367)  loss_giou_aux_1: 0.5781 (0.5631)  loss_vfl_aux_2: 0.5986 (0.6106)  loss_bbox_aux_2: 0.1211 (0.1338)  loss_giou_aux_2: 0.5803 (0.5549)  loss_vfl_aux_3: 0.6244 (0.6142)  loss_bbox_aux_3: 0.1174 (0.1319)  loss_giou_aux_3: 0.5723 (0.5500)  loss_vfl_aux_4: 0.6149 (0.6171)  loss_bbox_aux_4: 0.1164 (0.1299)  loss_giou_aux_4: 0.5626 (0.5450)  loss_vfl_aux_5: 0.6228 (0.6289)  loss_bbox_aux_5: 0.1754 (0.1975)  loss_giou_aux_5: 0.7180 (0.7299)  loss_vfl_dn_0: 0.4341 (0.4348)  loss_bbox_dn_0: 0.1909 (0.2198)  loss_giou_dn_0: 0.8206 (0.7946)  loss_vfl_dn_1: 0.4189 (0.4275)  loss_bbox_dn_1: 0.1500 (0.1704)  loss_giou_dn_1: 0.6676 (0.6348)  loss_vfl_dn_2: 0.4131 (0.4215)  loss_bbox_dn_2: 0.1374 (0.1581)  loss_giou_dn_2: 0.6354 (0.5920)  loss_vfl_dn_3: 0.4117 (0.4181)  loss_bbox_dn_3: 0.1345 (0.1547)  loss_giou_dn_3: 0.6124 (0.5790)  loss_vfl_dn_4: 0.4123 (0.4174)  loss_bbox_dn_4: 0.1327 (0.1538)  loss_giou_dn_4: 0.6086 (0.5747)  loss_vfl_dn_5: 0.4098 (0.4173)  loss_bbox_dn_5: 0.1324 (0.1535)  loss_giou_dn_5: 0.6069 (0.5733)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8997  data: 0.5844  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3898  data: 0.1138  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4042 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.656\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.281\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [60]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 18.2670 (18.2670)  loss_vfl: 0.6255 (0.6255)  loss_bbox: 0.1410 (0.1410)  loss_giou: 0.6045 (0.6045)  loss_vfl_aux_0: 0.5993 (0.5993)  loss_bbox_aux_0: 0.1777 (0.1777)  loss_giou_aux_0: 0.6996 (0.6996)  loss_vfl_aux_1: 0.6424 (0.6424)  loss_bbox_aux_1: 0.1464 (0.1464)  loss_giou_aux_1: 0.6209 (0.6209)  loss_vfl_aux_2: 0.6287 (0.6287)  loss_bbox_aux_2: 0.1350 (0.1350)  loss_giou_aux_2: 0.6013 (0.6013)  loss_vfl_aux_3: 0.6294 (0.6294)  loss_bbox_aux_3: 0.1403 (0.1403)  loss_giou_aux_3: 0.6066 (0.6066)  loss_vfl_aux_4: 0.6270 (0.6270)  loss_bbox_aux_4: 0.1423 (0.1423)  loss_giou_aux_4: 0.6094 (0.6094)  loss_vfl_aux_5: 0.5169 (0.5169)  loss_bbox_aux_5: 0.2865 (0.2865)  loss_giou_aux_5: 0.9558 (0.9558)  loss_vfl_dn_0: 0.4325 (0.4325)  loss_bbox_dn_0: 0.3011 (0.3011)  loss_giou_dn_0: 0.8944 (0.8944)  loss_vfl_dn_1: 0.4401 (0.4401)  loss_bbox_dn_1: 0.2246 (0.2246)  loss_giou_dn_1: 0.7377 (0.7377)  loss_vfl_dn_2: 0.4424 (0.4424)  loss_bbox_dn_2: 0.1960 (0.1960)  loss_giou_dn_2: 0.6758 (0.6758)  loss_vfl_dn_3: 0.4376 (0.4376)  loss_bbox_dn_3: 0.1843 (0.1843)  loss_giou_dn_3: 0.6568 (0.6568)  loss_vfl_dn_4: 0.4328 (0.4328)  loss_bbox_dn_4: 0.1790 (0.1790)  loss_giou_dn_4: 0.6449 (0.6449)  loss_vfl_dn_5: 0.4328 (0.4328)  loss_bbox_dn_5: 0.1757 (0.1757)  loss_giou_dn_5: 0.6420 (0.6420)  time: 1.0851  data: 0.7026  max mem: 7790\n",
            "Epoch: [60]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.4563 (16.9686)  loss_vfl: 0.6004 (0.6298)  loss_bbox: 0.1142 (0.1467)  loss_giou: 0.4994 (0.5398)  loss_vfl_aux_0: 0.6007 (0.6298)  loss_bbox_aux_0: 0.1366 (0.1650)  loss_giou_aux_0: 0.5767 (0.5943)  loss_vfl_aux_1: 0.5941 (0.6154)  loss_bbox_aux_1: 0.1251 (0.1530)  loss_giou_aux_1: 0.5316 (0.5612)  loss_vfl_aux_2: 0.5964 (0.6175)  loss_bbox_aux_2: 0.1225 (0.1485)  loss_giou_aux_2: 0.5092 (0.5491)  loss_vfl_aux_3: 0.5949 (0.6196)  loss_bbox_aux_3: 0.1161 (0.1468)  loss_giou_aux_3: 0.5005 (0.5421)  loss_vfl_aux_4: 0.6026 (0.6265)  loss_bbox_aux_4: 0.1121 (0.1478)  loss_giou_aux_4: 0.4974 (0.5413)  loss_vfl_aux_5: 0.6252 (0.6450)  loss_bbox_aux_5: 0.1962 (0.2149)  loss_giou_aux_5: 0.7329 (0.7262)  loss_vfl_dn_0: 0.4382 (0.4372)  loss_bbox_dn_0: 0.1729 (0.2494)  loss_giou_dn_0: 0.7723 (0.7939)  loss_vfl_dn_1: 0.4268 (0.4279)  loss_bbox_dn_1: 0.1316 (0.1924)  loss_giou_dn_1: 0.6050 (0.6264)  loss_vfl_dn_2: 0.4222 (0.4220)  loss_bbox_dn_2: 0.1261 (0.1792)  loss_giou_dn_2: 0.5680 (0.5849)  loss_vfl_dn_3: 0.4201 (0.4191)  loss_bbox_dn_3: 0.1226 (0.1759)  loss_giou_dn_3: 0.5570 (0.5730)  loss_vfl_dn_4: 0.4174 (0.4190)  loss_bbox_dn_4: 0.1233 (0.1751)  loss_giou_dn_4: 0.5543 (0.5697)  loss_vfl_dn_5: 0.4211 (0.4195)  loss_bbox_dn_5: 0.1228 (0.1746)  loss_giou_dn_5: 0.5518 (0.5689)  time: 0.3208  data: 0.0143  max mem: 7790\n",
            "Epoch: [60] Total time: 0:00:11 (0.3480 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.4563 (16.9686)  loss_vfl: 0.6004 (0.6298)  loss_bbox: 0.1142 (0.1467)  loss_giou: 0.4994 (0.5398)  loss_vfl_aux_0: 0.6007 (0.6298)  loss_bbox_aux_0: 0.1366 (0.1650)  loss_giou_aux_0: 0.5767 (0.5943)  loss_vfl_aux_1: 0.5941 (0.6154)  loss_bbox_aux_1: 0.1251 (0.1530)  loss_giou_aux_1: 0.5316 (0.5612)  loss_vfl_aux_2: 0.5964 (0.6175)  loss_bbox_aux_2: 0.1225 (0.1485)  loss_giou_aux_2: 0.5092 (0.5491)  loss_vfl_aux_3: 0.5949 (0.6196)  loss_bbox_aux_3: 0.1161 (0.1468)  loss_giou_aux_3: 0.5005 (0.5421)  loss_vfl_aux_4: 0.6026 (0.6265)  loss_bbox_aux_4: 0.1121 (0.1478)  loss_giou_aux_4: 0.4974 (0.5413)  loss_vfl_aux_5: 0.6252 (0.6450)  loss_bbox_aux_5: 0.1962 (0.2149)  loss_giou_aux_5: 0.7329 (0.7262)  loss_vfl_dn_0: 0.4382 (0.4372)  loss_bbox_dn_0: 0.1729 (0.2494)  loss_giou_dn_0: 0.7723 (0.7939)  loss_vfl_dn_1: 0.4268 (0.4279)  loss_bbox_dn_1: 0.1316 (0.1924)  loss_giou_dn_1: 0.6050 (0.6264)  loss_vfl_dn_2: 0.4222 (0.4220)  loss_bbox_dn_2: 0.1261 (0.1792)  loss_giou_dn_2: 0.5680 (0.5849)  loss_vfl_dn_3: 0.4201 (0.4191)  loss_bbox_dn_3: 0.1226 (0.1759)  loss_giou_dn_3: 0.5570 (0.5730)  loss_vfl_dn_4: 0.4174 (0.4190)  loss_bbox_dn_4: 0.1233 (0.1751)  loss_giou_dn_4: 0.5543 (0.5697)  loss_vfl_dn_5: 0.4211 (0.4195)  loss_bbox_dn_5: 0.1228 (0.1746)  loss_giou_dn_5: 0.5518 (0.5689)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9059  data: 0.5948  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3856  data: 0.1115  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3980 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.608\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.766\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [61]  [ 0/33]  eta: 0:00:29  lr: 0.000001  loss: 13.6982 (13.6982)  loss_vfl: 0.5984 (0.5984)  loss_bbox: 0.0744 (0.0744)  loss_giou: 0.3346 (0.3346)  loss_vfl_aux_0: 0.6017 (0.6017)  loss_bbox_aux_0: 0.0973 (0.0973)  loss_giou_aux_0: 0.4297 (0.4297)  loss_vfl_aux_1: 0.5960 (0.5960)  loss_bbox_aux_1: 0.0793 (0.0793)  loss_giou_aux_1: 0.3789 (0.3789)  loss_vfl_aux_2: 0.5864 (0.5864)  loss_bbox_aux_2: 0.0747 (0.0747)  loss_giou_aux_2: 0.3488 (0.3488)  loss_vfl_aux_3: 0.5804 (0.5804)  loss_bbox_aux_3: 0.0743 (0.0743)  loss_giou_aux_3: 0.3391 (0.3391)  loss_vfl_aux_4: 0.5839 (0.5839)  loss_bbox_aux_4: 0.0749 (0.0749)  loss_giou_aux_4: 0.3389 (0.3389)  loss_vfl_aux_5: 0.6081 (0.6081)  loss_bbox_aux_5: 0.1342 (0.1342)  loss_giou_aux_5: 0.5520 (0.5520)  loss_vfl_dn_0: 0.4449 (0.4449)  loss_bbox_dn_0: 0.1843 (0.1843)  loss_giou_dn_0: 0.7223 (0.7223)  loss_vfl_dn_1: 0.4127 (0.4127)  loss_bbox_dn_1: 0.1335 (0.1335)  loss_giou_dn_1: 0.5032 (0.5032)  loss_vfl_dn_2: 0.4039 (0.4039)  loss_bbox_dn_2: 0.1197 (0.1197)  loss_giou_dn_2: 0.4517 (0.4517)  loss_vfl_dn_3: 0.3988 (0.3988)  loss_bbox_dn_3: 0.1171 (0.1171)  loss_giou_dn_3: 0.4314 (0.4314)  loss_vfl_dn_4: 0.3990 (0.3990)  loss_bbox_dn_4: 0.1175 (0.1175)  loss_giou_dn_4: 0.4275 (0.4275)  loss_vfl_dn_5: 0.3992 (0.3992)  loss_bbox_dn_5: 0.1180 (0.1180)  loss_giou_dn_5: 0.4274 (0.4274)  time: 0.9046  data: 0.4905  max mem: 7790\n",
            "Epoch: [61]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.5117 (16.6921)  loss_vfl: 0.6331 (0.6307)  loss_bbox: 0.1344 (0.1317)  loss_giou: 0.4784 (0.5254)  loss_vfl_aux_0: 0.6168 (0.6326)  loss_bbox_aux_0: 0.1367 (0.1470)  loss_giou_aux_0: 0.5479 (0.5830)  loss_vfl_aux_1: 0.6137 (0.6227)  loss_bbox_aux_1: 0.1159 (0.1370)  loss_giou_aux_1: 0.5399 (0.5469)  loss_vfl_aux_2: 0.6240 (0.6197)  loss_bbox_aux_2: 0.1256 (0.1333)  loss_giou_aux_2: 0.4909 (0.5346)  loss_vfl_aux_3: 0.6238 (0.6227)  loss_bbox_aux_3: 0.1281 (0.1317)  loss_giou_aux_3: 0.4759 (0.5291)  loss_vfl_aux_4: 0.6345 (0.6313)  loss_bbox_aux_4: 0.1328 (0.1306)  loss_giou_aux_4: 0.4774 (0.5258)  loss_vfl_aux_5: 0.6569 (0.6590)  loss_bbox_aux_5: 0.1803 (0.1945)  loss_giou_aux_5: 0.6267 (0.6915)  loss_vfl_dn_0: 0.4428 (0.4404)  loss_bbox_dn_0: 0.2369 (0.2345)  loss_giou_dn_0: 0.7734 (0.7858)  loss_vfl_dn_1: 0.4277 (0.4283)  loss_bbox_dn_1: 0.1939 (0.1817)  loss_giou_dn_1: 0.6162 (0.6253)  loss_vfl_dn_2: 0.4164 (0.4212)  loss_bbox_dn_2: 0.1786 (0.1692)  loss_giou_dn_2: 0.5652 (0.5839)  loss_vfl_dn_3: 0.4142 (0.4178)  loss_bbox_dn_3: 0.1763 (0.1666)  loss_giou_dn_3: 0.5522 (0.5723)  loss_vfl_dn_4: 0.4133 (0.4168)  loss_bbox_dn_4: 0.1761 (0.1664)  loss_giou_dn_4: 0.5495 (0.5694)  loss_vfl_dn_5: 0.4132 (0.4169)  loss_bbox_dn_5: 0.1753 (0.1662)  loss_giou_dn_5: 0.5506 (0.5686)  time: 0.3326  data: 0.0140  max mem: 7790\n",
            "Epoch: [61] Total time: 0:00:11 (0.3509 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.5117 (16.6921)  loss_vfl: 0.6331 (0.6307)  loss_bbox: 0.1344 (0.1317)  loss_giou: 0.4784 (0.5254)  loss_vfl_aux_0: 0.6168 (0.6326)  loss_bbox_aux_0: 0.1367 (0.1470)  loss_giou_aux_0: 0.5479 (0.5830)  loss_vfl_aux_1: 0.6137 (0.6227)  loss_bbox_aux_1: 0.1159 (0.1370)  loss_giou_aux_1: 0.5399 (0.5469)  loss_vfl_aux_2: 0.6240 (0.6197)  loss_bbox_aux_2: 0.1256 (0.1333)  loss_giou_aux_2: 0.4909 (0.5346)  loss_vfl_aux_3: 0.6238 (0.6227)  loss_bbox_aux_3: 0.1281 (0.1317)  loss_giou_aux_3: 0.4759 (0.5291)  loss_vfl_aux_4: 0.6345 (0.6313)  loss_bbox_aux_4: 0.1328 (0.1306)  loss_giou_aux_4: 0.4774 (0.5258)  loss_vfl_aux_5: 0.6569 (0.6590)  loss_bbox_aux_5: 0.1803 (0.1945)  loss_giou_aux_5: 0.6267 (0.6915)  loss_vfl_dn_0: 0.4428 (0.4404)  loss_bbox_dn_0: 0.2369 (0.2345)  loss_giou_dn_0: 0.7734 (0.7858)  loss_vfl_dn_1: 0.4277 (0.4283)  loss_bbox_dn_1: 0.1939 (0.1817)  loss_giou_dn_1: 0.6162 (0.6253)  loss_vfl_dn_2: 0.4164 (0.4212)  loss_bbox_dn_2: 0.1786 (0.1692)  loss_giou_dn_2: 0.5652 (0.5839)  loss_vfl_dn_3: 0.4142 (0.4178)  loss_bbox_dn_3: 0.1763 (0.1666)  loss_giou_dn_3: 0.5522 (0.5723)  loss_vfl_dn_4: 0.4133 (0.4168)  loss_bbox_dn_4: 0.1761 (0.1664)  loss_giou_dn_4: 0.5495 (0.5694)  loss_vfl_dn_5: 0.4132 (0.4169)  loss_bbox_dn_5: 0.1753 (0.1662)  loss_giou_dn_5: 0.5506 (0.5686)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9040  data: 0.5948  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3919  data: 0.1182  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4053 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.361\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [62]  [ 0/33]  eta: 0:00:37  lr: 0.000001  loss: 17.1575 (17.1575)  loss_vfl: 0.5790 (0.5790)  loss_bbox: 0.2322 (0.2322)  loss_giou: 0.5603 (0.5603)  loss_vfl_aux_0: 0.5864 (0.5864)  loss_bbox_aux_0: 0.2595 (0.2595)  loss_giou_aux_0: 0.5911 (0.5911)  loss_vfl_aux_1: 0.5325 (0.5325)  loss_bbox_aux_1: 0.2499 (0.2499)  loss_giou_aux_1: 0.5744 (0.5744)  loss_vfl_aux_2: 0.5509 (0.5509)  loss_bbox_aux_2: 0.2441 (0.2441)  loss_giou_aux_2: 0.5758 (0.5758)  loss_vfl_aux_3: 0.5672 (0.5672)  loss_bbox_aux_3: 0.2368 (0.2368)  loss_giou_aux_3: 0.5666 (0.5666)  loss_vfl_aux_4: 0.5695 (0.5695)  loss_bbox_aux_4: 0.2344 (0.2344)  loss_giou_aux_4: 0.5647 (0.5647)  loss_vfl_aux_5: 0.6712 (0.6712)  loss_bbox_aux_5: 0.2713 (0.2713)  loss_giou_aux_5: 0.7038 (0.7038)  loss_vfl_dn_0: 0.4511 (0.4511)  loss_bbox_dn_0: 0.3023 (0.3023)  loss_giou_dn_0: 0.7094 (0.7094)  loss_vfl_dn_1: 0.4198 (0.4198)  loss_bbox_dn_1: 0.2429 (0.2429)  loss_giou_dn_1: 0.5404 (0.5404)  loss_vfl_dn_2: 0.4136 (0.4136)  loss_bbox_dn_2: 0.2296 (0.2296)  loss_giou_dn_2: 0.5128 (0.5128)  loss_vfl_dn_3: 0.4173 (0.4173)  loss_bbox_dn_3: 0.2241 (0.2241)  loss_giou_dn_3: 0.5017 (0.5017)  loss_vfl_dn_4: 0.4181 (0.4181)  loss_bbox_dn_4: 0.2226 (0.2226)  loss_giou_dn_4: 0.4976 (0.4976)  loss_vfl_dn_5: 0.4146 (0.4146)  loss_bbox_dn_5: 0.2225 (0.2225)  loss_giou_dn_5: 0.4958 (0.4958)  time: 1.1357  data: 0.7346  max mem: 7790\n",
            "Epoch: [62]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.2164 (16.3898)  loss_vfl: 0.6045 (0.6207)  loss_bbox: 0.1312 (0.1360)  loss_giou: 0.4879 (0.5092)  loss_vfl_aux_0: 0.6277 (0.6153)  loss_bbox_aux_0: 0.1499 (0.1533)  loss_giou_aux_0: 0.5484 (0.5647)  loss_vfl_aux_1: 0.6351 (0.6280)  loss_bbox_aux_1: 0.1381 (0.1409)  loss_giou_aux_1: 0.5124 (0.5247)  loss_vfl_aux_2: 0.6177 (0.6207)  loss_bbox_aux_2: 0.1318 (0.1384)  loss_giou_aux_2: 0.4906 (0.5170)  loss_vfl_aux_3: 0.6191 (0.6285)  loss_bbox_aux_3: 0.1274 (0.1354)  loss_giou_aux_3: 0.4936 (0.5087)  loss_vfl_aux_4: 0.6093 (0.6262)  loss_bbox_aux_4: 0.1320 (0.1347)  loss_giou_aux_4: 0.4923 (0.5062)  loss_vfl_aux_5: 0.6379 (0.6409)  loss_bbox_aux_5: 0.1800 (0.1977)  loss_giou_aux_5: 0.6884 (0.6816)  loss_vfl_dn_0: 0.4415 (0.4395)  loss_bbox_dn_0: 0.2210 (0.2229)  loss_giou_dn_0: 0.7676 (0.7751)  loss_vfl_dn_1: 0.4318 (0.4331)  loss_bbox_dn_1: 0.1706 (0.1711)  loss_giou_dn_1: 0.5998 (0.6060)  loss_vfl_dn_2: 0.4245 (0.4278)  loss_bbox_dn_2: 0.1562 (0.1576)  loss_giou_dn_2: 0.5448 (0.5609)  loss_vfl_dn_3: 0.4211 (0.4254)  loss_bbox_dn_3: 0.1544 (0.1541)  loss_giou_dn_3: 0.5257 (0.5465)  loss_vfl_dn_4: 0.4188 (0.4245)  loss_bbox_dn_4: 0.1530 (0.1535)  loss_giou_dn_4: 0.5223 (0.5427)  loss_vfl_dn_5: 0.4179 (0.4249)  loss_bbox_dn_5: 0.1539 (0.1534)  loss_giou_dn_5: 0.5240 (0.5418)  time: 0.3192  data: 0.0142  max mem: 7790\n",
            "Epoch: [62] Total time: 0:00:11 (0.3495 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.2164 (16.3898)  loss_vfl: 0.6045 (0.6207)  loss_bbox: 0.1312 (0.1360)  loss_giou: 0.4879 (0.5092)  loss_vfl_aux_0: 0.6277 (0.6153)  loss_bbox_aux_0: 0.1499 (0.1533)  loss_giou_aux_0: 0.5484 (0.5647)  loss_vfl_aux_1: 0.6351 (0.6280)  loss_bbox_aux_1: 0.1381 (0.1409)  loss_giou_aux_1: 0.5124 (0.5247)  loss_vfl_aux_2: 0.6177 (0.6207)  loss_bbox_aux_2: 0.1318 (0.1384)  loss_giou_aux_2: 0.4906 (0.5170)  loss_vfl_aux_3: 0.6191 (0.6285)  loss_bbox_aux_3: 0.1274 (0.1354)  loss_giou_aux_3: 0.4936 (0.5087)  loss_vfl_aux_4: 0.6093 (0.6262)  loss_bbox_aux_4: 0.1320 (0.1347)  loss_giou_aux_4: 0.4923 (0.5062)  loss_vfl_aux_5: 0.6379 (0.6409)  loss_bbox_aux_5: 0.1800 (0.1977)  loss_giou_aux_5: 0.6884 (0.6816)  loss_vfl_dn_0: 0.4415 (0.4395)  loss_bbox_dn_0: 0.2210 (0.2229)  loss_giou_dn_0: 0.7676 (0.7751)  loss_vfl_dn_1: 0.4318 (0.4331)  loss_bbox_dn_1: 0.1706 (0.1711)  loss_giou_dn_1: 0.5998 (0.6060)  loss_vfl_dn_2: 0.4245 (0.4278)  loss_bbox_dn_2: 0.1562 (0.1576)  loss_giou_dn_2: 0.5448 (0.5609)  loss_vfl_dn_3: 0.4211 (0.4254)  loss_bbox_dn_3: 0.1544 (0.1541)  loss_giou_dn_3: 0.5257 (0.5465)  loss_vfl_dn_4: 0.4188 (0.4245)  loss_bbox_dn_4: 0.1530 (0.1535)  loss_giou_dn_4: 0.5223 (0.5427)  loss_vfl_dn_5: 0.4179 (0.4249)  loss_bbox_dn_5: 0.1539 (0.1534)  loss_giou_dn_5: 0.5240 (0.5418)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8767  data: 0.5681  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4338  data: 0.1091  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4463 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.373\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [63]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 14.2232 (14.2232)  loss_vfl: 0.5725 (0.5725)  loss_bbox: 0.1011 (0.1011)  loss_giou: 0.3473 (0.3473)  loss_vfl_aux_0: 0.6245 (0.6245)  loss_bbox_aux_0: 0.1264 (0.1264)  loss_giou_aux_0: 0.4469 (0.4469)  loss_vfl_aux_1: 0.5720 (0.5720)  loss_bbox_aux_1: 0.1048 (0.1048)  loss_giou_aux_1: 0.3750 (0.3750)  loss_vfl_aux_2: 0.5857 (0.5857)  loss_bbox_aux_2: 0.0999 (0.0999)  loss_giou_aux_2: 0.3587 (0.3587)  loss_vfl_aux_3: 0.5920 (0.5920)  loss_bbox_aux_3: 0.1013 (0.1013)  loss_giou_aux_3: 0.3503 (0.3503)  loss_vfl_aux_4: 0.5818 (0.5818)  loss_bbox_aux_4: 0.1010 (0.1010)  loss_giou_aux_4: 0.3476 (0.3476)  loss_vfl_aux_5: 0.6942 (0.6942)  loss_bbox_aux_5: 0.2037 (0.2037)  loss_giou_aux_5: 0.5903 (0.5903)  loss_vfl_dn_0: 0.4388 (0.4388)  loss_bbox_dn_0: 0.2216 (0.2216)  loss_giou_dn_0: 0.7789 (0.7789)  loss_vfl_dn_1: 0.4251 (0.4251)  loss_bbox_dn_1: 0.1468 (0.1468)  loss_giou_dn_1: 0.5355 (0.5355)  loss_vfl_dn_2: 0.4118 (0.4118)  loss_bbox_dn_2: 0.1217 (0.1217)  loss_giou_dn_2: 0.4564 (0.4564)  loss_vfl_dn_3: 0.4055 (0.4055)  loss_bbox_dn_3: 0.1152 (0.1152)  loss_giou_dn_3: 0.4258 (0.4258)  loss_vfl_dn_4: 0.4025 (0.4025)  loss_bbox_dn_4: 0.1136 (0.1136)  loss_giou_dn_4: 0.4152 (0.4152)  loss_vfl_dn_5: 0.4010 (0.4010)  loss_bbox_dn_5: 0.1143 (0.1143)  loss_giou_dn_5: 0.4165 (0.4165)  time: 0.9523  data: 0.5339  max mem: 7790\n",
            "Epoch: [63]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.4856 (16.6724)  loss_vfl: 0.6389 (0.6238)  loss_bbox: 0.1181 (0.1327)  loss_giou: 0.5021 (0.5353)  loss_vfl_aux_0: 0.5948 (0.6162)  loss_bbox_aux_0: 0.1440 (0.1510)  loss_giou_aux_0: 0.5758 (0.5944)  loss_vfl_aux_1: 0.6010 (0.6182)  loss_bbox_aux_1: 0.1271 (0.1387)  loss_giou_aux_1: 0.5263 (0.5553)  loss_vfl_aux_2: 0.6106 (0.6191)  loss_bbox_aux_2: 0.1213 (0.1332)  loss_giou_aux_2: 0.5082 (0.5422)  loss_vfl_aux_3: 0.6146 (0.6193)  loss_bbox_aux_3: 0.1216 (0.1323)  loss_giou_aux_3: 0.5095 (0.5380)  loss_vfl_aux_4: 0.6263 (0.6234)  loss_bbox_aux_4: 0.1207 (0.1318)  loss_giou_aux_4: 0.5079 (0.5357)  loss_vfl_aux_5: 0.6369 (0.6541)  loss_bbox_aux_5: 0.1788 (0.1970)  loss_giou_aux_5: 0.7143 (0.7246)  loss_vfl_dn_0: 0.4376 (0.4368)  loss_bbox_dn_0: 0.1872 (0.2238)  loss_giou_dn_0: 0.7574 (0.7837)  loss_vfl_dn_1: 0.4288 (0.4280)  loss_bbox_dn_1: 0.1422 (0.1724)  loss_giou_dn_1: 0.6010 (0.6193)  loss_vfl_dn_2: 0.4232 (0.4228)  loss_bbox_dn_2: 0.1383 (0.1602)  loss_giou_dn_2: 0.5563 (0.5789)  loss_vfl_dn_3: 0.4220 (0.4208)  loss_bbox_dn_3: 0.1357 (0.1574)  loss_giou_dn_3: 0.5517 (0.5675)  loss_vfl_dn_4: 0.4195 (0.4214)  loss_bbox_dn_4: 0.1362 (0.1571)  loss_giou_dn_4: 0.5454 (0.5642)  loss_vfl_dn_5: 0.4254 (0.4220)  loss_bbox_dn_5: 0.1370 (0.1568)  loss_giou_dn_5: 0.5442 (0.5631)  time: 0.3245  data: 0.0150  max mem: 7790\n",
            "Epoch: [63] Total time: 0:00:11 (0.3428 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.4856 (16.6724)  loss_vfl: 0.6389 (0.6238)  loss_bbox: 0.1181 (0.1327)  loss_giou: 0.5021 (0.5353)  loss_vfl_aux_0: 0.5948 (0.6162)  loss_bbox_aux_0: 0.1440 (0.1510)  loss_giou_aux_0: 0.5758 (0.5944)  loss_vfl_aux_1: 0.6010 (0.6182)  loss_bbox_aux_1: 0.1271 (0.1387)  loss_giou_aux_1: 0.5263 (0.5553)  loss_vfl_aux_2: 0.6106 (0.6191)  loss_bbox_aux_2: 0.1213 (0.1332)  loss_giou_aux_2: 0.5082 (0.5422)  loss_vfl_aux_3: 0.6146 (0.6193)  loss_bbox_aux_3: 0.1216 (0.1323)  loss_giou_aux_3: 0.5095 (0.5380)  loss_vfl_aux_4: 0.6263 (0.6234)  loss_bbox_aux_4: 0.1207 (0.1318)  loss_giou_aux_4: 0.5079 (0.5357)  loss_vfl_aux_5: 0.6369 (0.6541)  loss_bbox_aux_5: 0.1788 (0.1970)  loss_giou_aux_5: 0.7143 (0.7246)  loss_vfl_dn_0: 0.4376 (0.4368)  loss_bbox_dn_0: 0.1872 (0.2238)  loss_giou_dn_0: 0.7574 (0.7837)  loss_vfl_dn_1: 0.4288 (0.4280)  loss_bbox_dn_1: 0.1422 (0.1724)  loss_giou_dn_1: 0.6010 (0.6193)  loss_vfl_dn_2: 0.4232 (0.4228)  loss_bbox_dn_2: 0.1383 (0.1602)  loss_giou_dn_2: 0.5563 (0.5789)  loss_vfl_dn_3: 0.4220 (0.4208)  loss_bbox_dn_3: 0.1357 (0.1574)  loss_giou_dn_3: 0.5517 (0.5675)  loss_vfl_dn_4: 0.4195 (0.4214)  loss_bbox_dn_4: 0.1362 (0.1571)  loss_giou_dn_4: 0.5454 (0.5642)  loss_vfl_dn_5: 0.4254 (0.4220)  loss_bbox_dn_5: 0.1370 (0.1568)  loss_giou_dn_5: 0.5442 (0.5631)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8839  data: 0.5706  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4483  data: 0.1169  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4630 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.622\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.280\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [64]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 17.9295 (17.9295)  loss_vfl: 0.5101 (0.5101)  loss_bbox: 0.1004 (0.1004)  loss_giou: 0.7691 (0.7691)  loss_vfl_aux_0: 0.5139 (0.5139)  loss_bbox_aux_0: 0.1174 (0.1174)  loss_giou_aux_0: 0.8147 (0.8147)  loss_vfl_aux_1: 0.5192 (0.5192)  loss_bbox_aux_1: 0.1002 (0.1002)  loss_giou_aux_1: 0.7794 (0.7794)  loss_vfl_aux_2: 0.5125 (0.5125)  loss_bbox_aux_2: 0.0975 (0.0975)  loss_giou_aux_2: 0.7774 (0.7774)  loss_vfl_aux_3: 0.5116 (0.5116)  loss_bbox_aux_3: 0.0987 (0.0987)  loss_giou_aux_3: 0.7676 (0.7676)  loss_vfl_aux_4: 0.5169 (0.5169)  loss_bbox_aux_4: 0.0990 (0.0990)  loss_giou_aux_4: 0.7644 (0.7644)  loss_vfl_aux_5: 0.5117 (0.5117)  loss_bbox_aux_5: 0.1342 (0.1342)  loss_giou_aux_5: 0.9038 (0.9038)  loss_vfl_dn_0: 0.4271 (0.4271)  loss_bbox_dn_0: 0.1367 (0.1367)  loss_giou_dn_0: 0.9043 (0.9043)  loss_vfl_dn_1: 0.4076 (0.4076)  loss_bbox_dn_1: 0.1088 (0.1088)  loss_giou_dn_1: 0.8135 (0.8135)  loss_vfl_dn_2: 0.4057 (0.4057)  loss_bbox_dn_2: 0.1030 (0.1030)  loss_giou_dn_2: 0.8076 (0.8076)  loss_vfl_dn_3: 0.4001 (0.4001)  loss_bbox_dn_3: 0.0997 (0.0997)  loss_giou_dn_3: 0.8021 (0.8021)  loss_vfl_dn_4: 0.3987 (0.3987)  loss_bbox_dn_4: 0.0988 (0.0988)  loss_giou_dn_4: 0.8006 (0.8006)  loss_vfl_dn_5: 0.3943 (0.3943)  loss_bbox_dn_5: 0.0991 (0.0991)  loss_giou_dn_5: 0.8021 (0.8021)  time: 1.0613  data: 0.6963  max mem: 7790\n",
            "Epoch: [64]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.7326 (16.3377)  loss_vfl: 0.6239 (0.6307)  loss_bbox: 0.1392 (0.1365)  loss_giou: 0.4509 (0.5008)  loss_vfl_aux_0: 0.6549 (0.6424)  loss_bbox_aux_0: 0.1507 (0.1552)  loss_giou_aux_0: 0.5041 (0.5506)  loss_vfl_aux_1: 0.6197 (0.6309)  loss_bbox_aux_1: 0.1452 (0.1440)  loss_giou_aux_1: 0.4735 (0.5180)  loss_vfl_aux_2: 0.6190 (0.6316)  loss_bbox_aux_2: 0.1353 (0.1379)  loss_giou_aux_2: 0.4537 (0.5059)  loss_vfl_aux_3: 0.6038 (0.6339)  loss_bbox_aux_3: 0.1305 (0.1364)  loss_giou_aux_3: 0.4489 (0.5014)  loss_vfl_aux_4: 0.6136 (0.6313)  loss_bbox_aux_4: 0.1392 (0.1364)  loss_giou_aux_4: 0.4490 (0.5010)  loss_vfl_aux_5: 0.6351 (0.6602)  loss_bbox_aux_5: 0.1964 (0.1944)  loss_giou_aux_5: 0.6499 (0.6598)  loss_vfl_dn_0: 0.4389 (0.4413)  loss_bbox_dn_0: 0.2385 (0.2270)  loss_giou_dn_0: 0.7393 (0.7587)  loss_vfl_dn_1: 0.4299 (0.4284)  loss_bbox_dn_1: 0.1792 (0.1742)  loss_giou_dn_1: 0.5766 (0.5886)  loss_vfl_dn_2: 0.4216 (0.4245)  loss_bbox_dn_2: 0.1576 (0.1623)  loss_giou_dn_2: 0.5366 (0.5493)  loss_vfl_dn_3: 0.4184 (0.4219)  loss_bbox_dn_3: 0.1582 (0.1588)  loss_giou_dn_3: 0.5300 (0.5377)  loss_vfl_dn_4: 0.4202 (0.4209)  loss_bbox_dn_4: 0.1586 (0.1581)  loss_giou_dn_4: 0.5281 (0.5341)  loss_vfl_dn_5: 0.4189 (0.4209)  loss_bbox_dn_5: 0.1592 (0.1581)  loss_giou_dn_5: 0.5302 (0.5339)  time: 0.3194  data: 0.0149  max mem: 7790\n",
            "Epoch: [64] Total time: 0:00:11 (0.3439 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.7326 (16.3377)  loss_vfl: 0.6239 (0.6307)  loss_bbox: 0.1392 (0.1365)  loss_giou: 0.4509 (0.5008)  loss_vfl_aux_0: 0.6549 (0.6424)  loss_bbox_aux_0: 0.1507 (0.1552)  loss_giou_aux_0: 0.5041 (0.5506)  loss_vfl_aux_1: 0.6197 (0.6309)  loss_bbox_aux_1: 0.1452 (0.1440)  loss_giou_aux_1: 0.4735 (0.5180)  loss_vfl_aux_2: 0.6190 (0.6316)  loss_bbox_aux_2: 0.1353 (0.1379)  loss_giou_aux_2: 0.4537 (0.5059)  loss_vfl_aux_3: 0.6038 (0.6339)  loss_bbox_aux_3: 0.1305 (0.1364)  loss_giou_aux_3: 0.4489 (0.5014)  loss_vfl_aux_4: 0.6136 (0.6313)  loss_bbox_aux_4: 0.1392 (0.1364)  loss_giou_aux_4: 0.4490 (0.5010)  loss_vfl_aux_5: 0.6351 (0.6602)  loss_bbox_aux_5: 0.1964 (0.1944)  loss_giou_aux_5: 0.6499 (0.6598)  loss_vfl_dn_0: 0.4389 (0.4413)  loss_bbox_dn_0: 0.2385 (0.2270)  loss_giou_dn_0: 0.7393 (0.7587)  loss_vfl_dn_1: 0.4299 (0.4284)  loss_bbox_dn_1: 0.1792 (0.1742)  loss_giou_dn_1: 0.5766 (0.5886)  loss_vfl_dn_2: 0.4216 (0.4245)  loss_bbox_dn_2: 0.1576 (0.1623)  loss_giou_dn_2: 0.5366 (0.5493)  loss_vfl_dn_3: 0.4184 (0.4219)  loss_bbox_dn_3: 0.1582 (0.1588)  loss_giou_dn_3: 0.5300 (0.5377)  loss_vfl_dn_4: 0.4202 (0.4209)  loss_bbox_dn_4: 0.1586 (0.1581)  loss_giou_dn_4: 0.5281 (0.5341)  loss_vfl_dn_5: 0.4189 (0.4209)  loss_bbox_dn_5: 0.1592 (0.1581)  loss_giou_dn_5: 0.5302 (0.5339)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8715  data: 0.5629  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3791  data: 0.1085  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3914 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.624\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.545\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [65]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 17.1932 (17.1932)  loss_vfl: 0.6757 (0.6757)  loss_bbox: 0.1128 (0.1128)  loss_giou: 0.5649 (0.5649)  loss_vfl_aux_0: 0.5981 (0.5981)  loss_bbox_aux_0: 0.1330 (0.1330)  loss_giou_aux_0: 0.6483 (0.6483)  loss_vfl_aux_1: 0.6073 (0.6073)  loss_bbox_aux_1: 0.1171 (0.1171)  loss_giou_aux_1: 0.6053 (0.6053)  loss_vfl_aux_2: 0.6242 (0.6242)  loss_bbox_aux_2: 0.1199 (0.1199)  loss_giou_aux_2: 0.5951 (0.5951)  loss_vfl_aux_3: 0.6374 (0.6374)  loss_bbox_aux_3: 0.1169 (0.1169)  loss_giou_aux_3: 0.5776 (0.5776)  loss_vfl_aux_4: 0.6697 (0.6697)  loss_bbox_aux_4: 0.1177 (0.1177)  loss_giou_aux_4: 0.5729 (0.5729)  loss_vfl_aux_5: 0.6131 (0.6131)  loss_bbox_aux_5: 0.1661 (0.1661)  loss_giou_aux_5: 0.7422 (0.7422)  loss_vfl_dn_0: 0.4245 (0.4245)  loss_bbox_dn_0: 0.1862 (0.1862)  loss_giou_dn_0: 0.8438 (0.8438)  loss_vfl_dn_1: 0.4348 (0.4348)  loss_bbox_dn_1: 0.1477 (0.1477)  loss_giou_dn_1: 0.6977 (0.6977)  loss_vfl_dn_2: 0.4375 (0.4375)  loss_bbox_dn_2: 0.1387 (0.1387)  loss_giou_dn_2: 0.6542 (0.6542)  loss_vfl_dn_3: 0.4326 (0.4326)  loss_bbox_dn_3: 0.1358 (0.1358)  loss_giou_dn_3: 0.6411 (0.6411)  loss_vfl_dn_4: 0.4368 (0.4368)  loss_bbox_dn_4: 0.1357 (0.1357)  loss_giou_dn_4: 0.6324 (0.6324)  loss_vfl_dn_5: 0.4336 (0.4336)  loss_bbox_dn_5: 0.1356 (0.1356)  loss_giou_dn_5: 0.6290 (0.6290)  time: 0.9183  data: 0.5176  max mem: 7790\n",
            "Epoch: [65]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.3945 (16.8582)  loss_vfl: 0.6233 (0.6333)  loss_bbox: 0.1149 (0.1311)  loss_giou: 0.5214 (0.5515)  loss_vfl_aux_0: 0.6377 (0.6340)  loss_bbox_aux_0: 0.1371 (0.1477)  loss_giou_aux_0: 0.5688 (0.6006)  loss_vfl_aux_1: 0.6159 (0.6241)  loss_bbox_aux_1: 0.1337 (0.1397)  loss_giou_aux_1: 0.5337 (0.5733)  loss_vfl_aux_2: 0.6311 (0.6276)  loss_bbox_aux_2: 0.1246 (0.1361)  loss_giou_aux_2: 0.5367 (0.5638)  loss_vfl_aux_3: 0.6144 (0.6240)  loss_bbox_aux_3: 0.1181 (0.1343)  loss_giou_aux_3: 0.5317 (0.5583)  loss_vfl_aux_4: 0.6253 (0.6286)  loss_bbox_aux_4: 0.1156 (0.1306)  loss_giou_aux_4: 0.5406 (0.5552)  loss_vfl_aux_5: 0.6335 (0.6454)  loss_bbox_aux_5: 0.2033 (0.1903)  loss_giou_aux_5: 0.6993 (0.7206)  loss_vfl_dn_0: 0.4387 (0.4354)  loss_bbox_dn_0: 0.2039 (0.2130)  loss_giou_dn_0: 0.7768 (0.7947)  loss_vfl_dn_1: 0.4319 (0.4269)  loss_bbox_dn_1: 0.1754 (0.1664)  loss_giou_dn_1: 0.6133 (0.6399)  loss_vfl_dn_2: 0.4222 (0.4224)  loss_bbox_dn_2: 0.1666 (0.1549)  loss_giou_dn_2: 0.5682 (0.5982)  loss_vfl_dn_3: 0.4170 (0.4210)  loss_bbox_dn_3: 0.1584 (0.1516)  loss_giou_dn_3: 0.5586 (0.5843)  loss_vfl_dn_4: 0.4168 (0.4199)  loss_bbox_dn_4: 0.1581 (0.1507)  loss_giou_dn_4: 0.5500 (0.5799)  loss_vfl_dn_5: 0.4170 (0.4200)  loss_bbox_dn_5: 0.1575 (0.1504)  loss_giou_dn_5: 0.5475 (0.5786)  time: 0.3362  data: 0.0140  max mem: 7790\n",
            "Epoch: [65] Total time: 0:00:11 (0.3567 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.3945 (16.8582)  loss_vfl: 0.6233 (0.6333)  loss_bbox: 0.1149 (0.1311)  loss_giou: 0.5214 (0.5515)  loss_vfl_aux_0: 0.6377 (0.6340)  loss_bbox_aux_0: 0.1371 (0.1477)  loss_giou_aux_0: 0.5688 (0.6006)  loss_vfl_aux_1: 0.6159 (0.6241)  loss_bbox_aux_1: 0.1337 (0.1397)  loss_giou_aux_1: 0.5337 (0.5733)  loss_vfl_aux_2: 0.6311 (0.6276)  loss_bbox_aux_2: 0.1246 (0.1361)  loss_giou_aux_2: 0.5367 (0.5638)  loss_vfl_aux_3: 0.6144 (0.6240)  loss_bbox_aux_3: 0.1181 (0.1343)  loss_giou_aux_3: 0.5317 (0.5583)  loss_vfl_aux_4: 0.6253 (0.6286)  loss_bbox_aux_4: 0.1156 (0.1306)  loss_giou_aux_4: 0.5406 (0.5552)  loss_vfl_aux_5: 0.6335 (0.6454)  loss_bbox_aux_5: 0.2033 (0.1903)  loss_giou_aux_5: 0.6993 (0.7206)  loss_vfl_dn_0: 0.4387 (0.4354)  loss_bbox_dn_0: 0.2039 (0.2130)  loss_giou_dn_0: 0.7768 (0.7947)  loss_vfl_dn_1: 0.4319 (0.4269)  loss_bbox_dn_1: 0.1754 (0.1664)  loss_giou_dn_1: 0.6133 (0.6399)  loss_vfl_dn_2: 0.4222 (0.4224)  loss_bbox_dn_2: 0.1666 (0.1549)  loss_giou_dn_2: 0.5682 (0.5982)  loss_vfl_dn_3: 0.4170 (0.4210)  loss_bbox_dn_3: 0.1584 (0.1516)  loss_giou_dn_3: 0.5586 (0.5843)  loss_vfl_dn_4: 0.4168 (0.4199)  loss_bbox_dn_4: 0.1581 (0.1507)  loss_giou_dn_4: 0.5500 (0.5799)  loss_vfl_dn_5: 0.4170 (0.4200)  loss_bbox_dn_5: 0.1575 (0.1504)  loss_giou_dn_5: 0.5475 (0.5786)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8618  data: 0.5440  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3893  data: 0.1138  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4030 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.652\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.383\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [66]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 16.5473 (16.5473)  loss_vfl: 0.5001 (0.5001)  loss_bbox: 0.1432 (0.1432)  loss_giou: 0.5879 (0.5879)  loss_vfl_aux_0: 0.5674 (0.5674)  loss_bbox_aux_0: 0.1566 (0.1566)  loss_giou_aux_0: 0.6297 (0.6297)  loss_vfl_aux_1: 0.5145 (0.5145)  loss_bbox_aux_1: 0.1566 (0.1566)  loss_giou_aux_1: 0.6142 (0.6142)  loss_vfl_aux_2: 0.5169 (0.5169)  loss_bbox_aux_2: 0.1448 (0.1448)  loss_giou_aux_2: 0.5911 (0.5911)  loss_vfl_aux_3: 0.5093 (0.5093)  loss_bbox_aux_3: 0.1445 (0.1445)  loss_giou_aux_3: 0.5884 (0.5884)  loss_vfl_aux_4: 0.5082 (0.5082)  loss_bbox_aux_4: 0.1375 (0.1375)  loss_giou_aux_4: 0.5857 (0.5857)  loss_vfl_aux_5: 0.6256 (0.6256)  loss_bbox_aux_5: 0.1798 (0.1798)  loss_giou_aux_5: 0.7043 (0.7043)  loss_vfl_dn_0: 0.4140 (0.4140)  loss_bbox_dn_0: 0.2019 (0.2019)  loss_giou_dn_0: 0.8523 (0.8523)  loss_vfl_dn_1: 0.4092 (0.4092)  loss_bbox_dn_1: 0.1583 (0.1583)  loss_giou_dn_1: 0.6869 (0.6869)  loss_vfl_dn_2: 0.4071 (0.4071)  loss_bbox_dn_2: 0.1486 (0.1486)  loss_giou_dn_2: 0.6414 (0.6414)  loss_vfl_dn_3: 0.4088 (0.4088)  loss_bbox_dn_3: 0.1486 (0.1486)  loss_giou_dn_3: 0.6283 (0.6283)  loss_vfl_dn_4: 0.4084 (0.4084)  loss_bbox_dn_4: 0.1473 (0.1473)  loss_giou_dn_4: 0.6178 (0.6178)  loss_vfl_dn_5: 0.4031 (0.4031)  loss_bbox_dn_5: 0.1475 (0.1475)  loss_giou_dn_5: 0.6113 (0.6113)  time: 0.9848  data: 0.6009  max mem: 7790\n",
            "Epoch: [66]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.8239 (16.0510)  loss_vfl: 0.5671 (0.5941)  loss_bbox: 0.1284 (0.1330)  loss_giou: 0.4536 (0.5048)  loss_vfl_aux_0: 0.6172 (0.6248)  loss_bbox_aux_0: 0.1316 (0.1464)  loss_giou_aux_0: 0.5175 (0.5527)  loss_vfl_aux_1: 0.5769 (0.5938)  loss_bbox_aux_1: 0.1271 (0.1374)  loss_giou_aux_1: 0.4610 (0.5204)  loss_vfl_aux_2: 0.5764 (0.5881)  loss_bbox_aux_2: 0.1274 (0.1344)  loss_giou_aux_2: 0.4584 (0.5114)  loss_vfl_aux_3: 0.5650 (0.5894)  loss_bbox_aux_3: 0.1312 (0.1333)  loss_giou_aux_3: 0.4552 (0.5074)  loss_vfl_aux_4: 0.5697 (0.5921)  loss_bbox_aux_4: 0.1286 (0.1326)  loss_giou_aux_4: 0.4531 (0.5032)  loss_vfl_aux_5: 0.6575 (0.6626)  loss_bbox_aux_5: 0.1823 (0.1946)  loss_giou_aux_5: 0.6342 (0.6789)  loss_vfl_dn_0: 0.4371 (0.4365)  loss_bbox_dn_0: 0.2045 (0.2266)  loss_giou_dn_0: 0.7317 (0.7682)  loss_vfl_dn_1: 0.4231 (0.4234)  loss_bbox_dn_1: 0.1501 (0.1695)  loss_giou_dn_1: 0.5646 (0.5940)  loss_vfl_dn_2: 0.4117 (0.4148)  loss_bbox_dn_2: 0.1331 (0.1554)  loss_giou_dn_2: 0.4983 (0.5492)  loss_vfl_dn_3: 0.4103 (0.4102)  loss_bbox_dn_3: 0.1279 (0.1512)  loss_giou_dn_3: 0.4798 (0.5357)  loss_vfl_dn_4: 0.4090 (0.4095)  loss_bbox_dn_4: 0.1277 (0.1504)  loss_giou_dn_4: 0.4735 (0.5319)  loss_vfl_dn_5: 0.4081 (0.4090)  loss_bbox_dn_5: 0.1266 (0.1500)  loss_giou_dn_5: 0.4686 (0.5302)  time: 0.3479  data: 0.0149  max mem: 7790\n",
            "Epoch: [66] Total time: 0:00:11 (0.3610 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.8239 (16.0510)  loss_vfl: 0.5671 (0.5941)  loss_bbox: 0.1284 (0.1330)  loss_giou: 0.4536 (0.5048)  loss_vfl_aux_0: 0.6172 (0.6248)  loss_bbox_aux_0: 0.1316 (0.1464)  loss_giou_aux_0: 0.5175 (0.5527)  loss_vfl_aux_1: 0.5769 (0.5938)  loss_bbox_aux_1: 0.1271 (0.1374)  loss_giou_aux_1: 0.4610 (0.5204)  loss_vfl_aux_2: 0.5764 (0.5881)  loss_bbox_aux_2: 0.1274 (0.1344)  loss_giou_aux_2: 0.4584 (0.5114)  loss_vfl_aux_3: 0.5650 (0.5894)  loss_bbox_aux_3: 0.1312 (0.1333)  loss_giou_aux_3: 0.4552 (0.5074)  loss_vfl_aux_4: 0.5697 (0.5921)  loss_bbox_aux_4: 0.1286 (0.1326)  loss_giou_aux_4: 0.4531 (0.5032)  loss_vfl_aux_5: 0.6575 (0.6626)  loss_bbox_aux_5: 0.1823 (0.1946)  loss_giou_aux_5: 0.6342 (0.6789)  loss_vfl_dn_0: 0.4371 (0.4365)  loss_bbox_dn_0: 0.2045 (0.2266)  loss_giou_dn_0: 0.7317 (0.7682)  loss_vfl_dn_1: 0.4231 (0.4234)  loss_bbox_dn_1: 0.1501 (0.1695)  loss_giou_dn_1: 0.5646 (0.5940)  loss_vfl_dn_2: 0.4117 (0.4148)  loss_bbox_dn_2: 0.1331 (0.1554)  loss_giou_dn_2: 0.4983 (0.5492)  loss_vfl_dn_3: 0.4103 (0.4102)  loss_bbox_dn_3: 0.1279 (0.1512)  loss_giou_dn_3: 0.4798 (0.5357)  loss_vfl_dn_4: 0.4090 (0.4095)  loss_bbox_dn_4: 0.1277 (0.1504)  loss_giou_dn_4: 0.4735 (0.5319)  loss_vfl_dn_5: 0.4081 (0.4090)  loss_bbox_dn_5: 0.1266 (0.1500)  loss_giou_dn_5: 0.4686 (0.5302)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8949  data: 0.5823  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3880  data: 0.1150  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4012 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.636\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [67]  [ 0/33]  eta: 0:00:28  lr: 0.000001  loss: 16.9780 (16.9780)  loss_vfl: 0.5863 (0.5863)  loss_bbox: 0.1592 (0.1592)  loss_giou: 0.5723 (0.5723)  loss_vfl_aux_0: 0.5664 (0.5664)  loss_bbox_aux_0: 0.1829 (0.1829)  loss_giou_aux_0: 0.6099 (0.6099)  loss_vfl_aux_1: 0.5476 (0.5476)  loss_bbox_aux_1: 0.1706 (0.1706)  loss_giou_aux_1: 0.6015 (0.6015)  loss_vfl_aux_2: 0.5605 (0.5605)  loss_bbox_aux_2: 0.1647 (0.1647)  loss_giou_aux_2: 0.5908 (0.5908)  loss_vfl_aux_3: 0.5732 (0.5732)  loss_bbox_aux_3: 0.1616 (0.1616)  loss_giou_aux_3: 0.5779 (0.5779)  loss_vfl_aux_4: 0.5806 (0.5806)  loss_bbox_aux_4: 0.1596 (0.1596)  loss_giou_aux_4: 0.5669 (0.5669)  loss_vfl_aux_5: 0.6052 (0.6052)  loss_bbox_aux_5: 0.2391 (0.2391)  loss_giou_aux_5: 0.7431 (0.7431)  loss_vfl_dn_0: 0.4448 (0.4448)  loss_bbox_dn_0: 0.2343 (0.2343)  loss_giou_dn_0: 0.7809 (0.7809)  loss_vfl_dn_1: 0.4554 (0.4554)  loss_bbox_dn_1: 0.1815 (0.1815)  loss_giou_dn_1: 0.6210 (0.6210)  loss_vfl_dn_2: 0.4484 (0.4484)  loss_bbox_dn_2: 0.1708 (0.1708)  loss_giou_dn_2: 0.5833 (0.5833)  loss_vfl_dn_3: 0.4470 (0.4470)  loss_bbox_dn_3: 0.1694 (0.1694)  loss_giou_dn_3: 0.5619 (0.5619)  loss_vfl_dn_4: 0.4466 (0.4466)  loss_bbox_dn_4: 0.1697 (0.1697)  loss_giou_dn_4: 0.5615 (0.5615)  loss_vfl_dn_5: 0.4477 (0.4477)  loss_bbox_dn_5: 0.1700 (0.1700)  loss_giou_dn_5: 0.5641 (0.5641)  time: 0.8587  data: 0.4910  max mem: 7790\n",
            "Epoch: [67]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.5553 (16.0522)  loss_vfl: 0.6121 (0.6070)  loss_bbox: 0.1328 (0.1279)  loss_giou: 0.4748 (0.5020)  loss_vfl_aux_0: 0.5994 (0.6050)  loss_bbox_aux_0: 0.1369 (0.1424)  loss_giou_aux_0: 0.5389 (0.5584)  loss_vfl_aux_1: 0.6008 (0.6048)  loss_bbox_aux_1: 0.1286 (0.1310)  loss_giou_aux_1: 0.4967 (0.5194)  loss_vfl_aux_2: 0.6069 (0.6042)  loss_bbox_aux_2: 0.1315 (0.1299)  loss_giou_aux_2: 0.4838 (0.5105)  loss_vfl_aux_3: 0.6061 (0.6032)  loss_bbox_aux_3: 0.1336 (0.1285)  loss_giou_aux_3: 0.4811 (0.5053)  loss_vfl_aux_4: 0.5999 (0.6041)  loss_bbox_aux_4: 0.1308 (0.1277)  loss_giou_aux_4: 0.4770 (0.5035)  loss_vfl_aux_5: 0.6386 (0.6368)  loss_bbox_aux_5: 0.1830 (0.1882)  loss_giou_aux_5: 0.6484 (0.6833)  loss_vfl_dn_0: 0.4403 (0.4384)  loss_bbox_dn_0: 0.2013 (0.2182)  loss_giou_dn_0: 0.7470 (0.7737)  loss_vfl_dn_1: 0.4311 (0.4287)  loss_bbox_dn_1: 0.1520 (0.1650)  loss_giou_dn_1: 0.5802 (0.5939)  loss_vfl_dn_2: 0.4217 (0.4213)  loss_bbox_dn_2: 0.1369 (0.1522)  loss_giou_dn_2: 0.5306 (0.5476)  loss_vfl_dn_3: 0.4119 (0.4165)  loss_bbox_dn_3: 0.1362 (0.1491)  loss_giou_dn_3: 0.5167 (0.5339)  loss_vfl_dn_4: 0.4094 (0.4149)  loss_bbox_dn_4: 0.1373 (0.1490)  loss_giou_dn_4: 0.5137 (0.5317)  loss_vfl_dn_5: 0.4094 (0.4150)  loss_bbox_dn_5: 0.1368 (0.1487)  loss_giou_dn_5: 0.5148 (0.5312)  time: 0.3252  data: 0.0143  max mem: 7790\n",
            "Epoch: [67] Total time: 0:00:11 (0.3507 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.5553 (16.0522)  loss_vfl: 0.6121 (0.6070)  loss_bbox: 0.1328 (0.1279)  loss_giou: 0.4748 (0.5020)  loss_vfl_aux_0: 0.5994 (0.6050)  loss_bbox_aux_0: 0.1369 (0.1424)  loss_giou_aux_0: 0.5389 (0.5584)  loss_vfl_aux_1: 0.6008 (0.6048)  loss_bbox_aux_1: 0.1286 (0.1310)  loss_giou_aux_1: 0.4967 (0.5194)  loss_vfl_aux_2: 0.6069 (0.6042)  loss_bbox_aux_2: 0.1315 (0.1299)  loss_giou_aux_2: 0.4838 (0.5105)  loss_vfl_aux_3: 0.6061 (0.6032)  loss_bbox_aux_3: 0.1336 (0.1285)  loss_giou_aux_3: 0.4811 (0.5053)  loss_vfl_aux_4: 0.5999 (0.6041)  loss_bbox_aux_4: 0.1308 (0.1277)  loss_giou_aux_4: 0.4770 (0.5035)  loss_vfl_aux_5: 0.6386 (0.6368)  loss_bbox_aux_5: 0.1830 (0.1882)  loss_giou_aux_5: 0.6484 (0.6833)  loss_vfl_dn_0: 0.4403 (0.4384)  loss_bbox_dn_0: 0.2013 (0.2182)  loss_giou_dn_0: 0.7470 (0.7737)  loss_vfl_dn_1: 0.4311 (0.4287)  loss_bbox_dn_1: 0.1520 (0.1650)  loss_giou_dn_1: 0.5802 (0.5939)  loss_vfl_dn_2: 0.4217 (0.4213)  loss_bbox_dn_2: 0.1369 (0.1522)  loss_giou_dn_2: 0.5306 (0.5476)  loss_vfl_dn_3: 0.4119 (0.4165)  loss_bbox_dn_3: 0.1362 (0.1491)  loss_giou_dn_3: 0.5167 (0.5339)  loss_vfl_dn_4: 0.4094 (0.4149)  loss_bbox_dn_4: 0.1373 (0.1490)  loss_giou_dn_4: 0.5137 (0.5317)  loss_vfl_dn_5: 0.4094 (0.4150)  loss_bbox_dn_5: 0.1368 (0.1487)  loss_giou_dn_5: 0.5148 (0.5312)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9388  data: 0.6024  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3988  data: 0.1167  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4131 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [68]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 17.3247 (17.3247)  loss_vfl: 0.6537 (0.6537)  loss_bbox: 0.0870 (0.0870)  loss_giou: 0.6675 (0.6675)  loss_vfl_aux_0: 0.6343 (0.6343)  loss_bbox_aux_0: 0.1228 (0.1228)  loss_giou_aux_0: 0.7517 (0.7517)  loss_vfl_aux_1: 0.6290 (0.6290)  loss_bbox_aux_1: 0.1013 (0.1013)  loss_giou_aux_1: 0.6914 (0.6914)  loss_vfl_aux_2: 0.6354 (0.6354)  loss_bbox_aux_2: 0.0875 (0.0875)  loss_giou_aux_2: 0.6597 (0.6597)  loss_vfl_aux_3: 0.6289 (0.6289)  loss_bbox_aux_3: 0.0870 (0.0870)  loss_giou_aux_3: 0.6582 (0.6582)  loss_vfl_aux_4: 0.6377 (0.6377)  loss_bbox_aux_4: 0.0871 (0.0871)  loss_giou_aux_4: 0.6633 (0.6633)  loss_vfl_aux_5: 0.5821 (0.5821)  loss_bbox_aux_5: 0.1016 (0.1016)  loss_giou_aux_5: 0.7964 (0.7964)  loss_vfl_dn_0: 0.4037 (0.4037)  loss_bbox_dn_0: 0.1005 (0.1005)  loss_giou_dn_0: 0.8878 (0.8878)  loss_vfl_dn_1: 0.4061 (0.4061)  loss_bbox_dn_1: 0.0853 (0.0853)  loss_giou_dn_1: 0.7549 (0.7549)  loss_vfl_dn_2: 0.4143 (0.4143)  loss_bbox_dn_2: 0.0826 (0.0826)  loss_giou_dn_2: 0.6892 (0.6892)  loss_vfl_dn_3: 0.4143 (0.4143)  loss_bbox_dn_3: 0.0824 (0.0824)  loss_giou_dn_3: 0.6813 (0.6813)  loss_vfl_dn_4: 0.4110 (0.4110)  loss_bbox_dn_4: 0.0835 (0.0835)  loss_giou_dn_4: 0.6831 (0.6831)  loss_vfl_dn_5: 0.4117 (0.4117)  loss_bbox_dn_5: 0.0835 (0.0835)  loss_giou_dn_5: 0.6858 (0.6858)  time: 1.0699  data: 0.6776  max mem: 7790\n",
            "Epoch: [68]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.1531 (16.0779)  loss_vfl: 0.5939 (0.6288)  loss_bbox: 0.1067 (0.1073)  loss_giou: 0.4901 (0.5179)  loss_vfl_aux_0: 0.6106 (0.6173)  loss_bbox_aux_0: 0.1108 (0.1244)  loss_giou_aux_0: 0.5525 (0.5786)  loss_vfl_aux_1: 0.5915 (0.6152)  loss_bbox_aux_1: 0.1091 (0.1135)  loss_giou_aux_1: 0.4998 (0.5398)  loss_vfl_aux_2: 0.5894 (0.6123)  loss_bbox_aux_2: 0.1072 (0.1107)  loss_giou_aux_2: 0.4893 (0.5286)  loss_vfl_aux_3: 0.5879 (0.6164)  loss_bbox_aux_3: 0.1058 (0.1087)  loss_giou_aux_3: 0.4836 (0.5228)  loss_vfl_aux_4: 0.5931 (0.6225)  loss_bbox_aux_4: 0.1057 (0.1073)  loss_giou_aux_4: 0.4889 (0.5199)  loss_vfl_aux_5: 0.6099 (0.6217)  loss_bbox_aux_5: 0.1494 (0.1650)  loss_giou_aux_5: 0.6748 (0.7027)  loss_vfl_dn_0: 0.4379 (0.4339)  loss_bbox_dn_0: 0.1772 (0.1860)  loss_giou_dn_0: 0.7355 (0.7825)  loss_vfl_dn_1: 0.4276 (0.4262)  loss_bbox_dn_1: 0.1262 (0.1401)  loss_giou_dn_1: 0.5583 (0.6157)  loss_vfl_dn_2: 0.4188 (0.4196)  loss_bbox_dn_2: 0.1111 (0.1283)  loss_giou_dn_2: 0.5107 (0.5733)  loss_vfl_dn_3: 0.4147 (0.4163)  loss_bbox_dn_3: 0.1075 (0.1249)  loss_giou_dn_3: 0.4992 (0.5598)  loss_vfl_dn_4: 0.4155 (0.4153)  loss_bbox_dn_4: 0.1077 (0.1240)  loss_giou_dn_4: 0.4982 (0.5560)  loss_vfl_dn_5: 0.4150 (0.4158)  loss_bbox_dn_5: 0.1085 (0.1236)  loss_giou_dn_5: 0.4997 (0.5550)  time: 0.3301  data: 0.0141  max mem: 7790\n",
            "Epoch: [68] Total time: 0:00:11 (0.3537 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.1531 (16.0779)  loss_vfl: 0.5939 (0.6288)  loss_bbox: 0.1067 (0.1073)  loss_giou: 0.4901 (0.5179)  loss_vfl_aux_0: 0.6106 (0.6173)  loss_bbox_aux_0: 0.1108 (0.1244)  loss_giou_aux_0: 0.5525 (0.5786)  loss_vfl_aux_1: 0.5915 (0.6152)  loss_bbox_aux_1: 0.1091 (0.1135)  loss_giou_aux_1: 0.4998 (0.5398)  loss_vfl_aux_2: 0.5894 (0.6123)  loss_bbox_aux_2: 0.1072 (0.1107)  loss_giou_aux_2: 0.4893 (0.5286)  loss_vfl_aux_3: 0.5879 (0.6164)  loss_bbox_aux_3: 0.1058 (0.1087)  loss_giou_aux_3: 0.4836 (0.5228)  loss_vfl_aux_4: 0.5931 (0.6225)  loss_bbox_aux_4: 0.1057 (0.1073)  loss_giou_aux_4: 0.4889 (0.5199)  loss_vfl_aux_5: 0.6099 (0.6217)  loss_bbox_aux_5: 0.1494 (0.1650)  loss_giou_aux_5: 0.6748 (0.7027)  loss_vfl_dn_0: 0.4379 (0.4339)  loss_bbox_dn_0: 0.1772 (0.1860)  loss_giou_dn_0: 0.7355 (0.7825)  loss_vfl_dn_1: 0.4276 (0.4262)  loss_bbox_dn_1: 0.1262 (0.1401)  loss_giou_dn_1: 0.5583 (0.6157)  loss_vfl_dn_2: 0.4188 (0.4196)  loss_bbox_dn_2: 0.1111 (0.1283)  loss_giou_dn_2: 0.5107 (0.5733)  loss_vfl_dn_3: 0.4147 (0.4163)  loss_bbox_dn_3: 0.1075 (0.1249)  loss_giou_dn_3: 0.4992 (0.5598)  loss_vfl_dn_4: 0.4155 (0.4153)  loss_bbox_dn_4: 0.1077 (0.1240)  loss_giou_dn_4: 0.4982 (0.5560)  loss_vfl_dn_5: 0.4150 (0.4158)  loss_bbox_dn_5: 0.1085 (0.1236)  loss_giou_dn_5: 0.4997 (0.5550)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8872  data: 0.5681  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4464  data: 0.1098  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4596 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.635\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.559\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [69]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 15.3178 (15.3178)  loss_vfl: 0.6367 (0.6367)  loss_bbox: 0.1699 (0.1699)  loss_giou: 0.3357 (0.3357)  loss_vfl_aux_0: 0.6965 (0.6965)  loss_bbox_aux_0: 0.1788 (0.1788)  loss_giou_aux_0: 0.3570 (0.3570)  loss_vfl_aux_1: 0.7093 (0.7093)  loss_bbox_aux_1: 0.1505 (0.1505)  loss_giou_aux_1: 0.2977 (0.2977)  loss_vfl_aux_2: 0.6572 (0.6572)  loss_bbox_aux_2: 0.1647 (0.1647)  loss_giou_aux_2: 0.3341 (0.3341)  loss_vfl_aux_3: 0.6448 (0.6448)  loss_bbox_aux_3: 0.1633 (0.1633)  loss_giou_aux_3: 0.3268 (0.3268)  loss_vfl_aux_4: 0.6468 (0.6468)  loss_bbox_aux_4: 0.1685 (0.1685)  loss_giou_aux_4: 0.3296 (0.3296)  loss_vfl_aux_5: 0.8267 (0.8267)  loss_bbox_aux_5: 0.2436 (0.2436)  loss_giou_aux_5: 0.4867 (0.4867)  loss_vfl_dn_0: 0.4524 (0.4524)  loss_bbox_dn_0: 0.3502 (0.3502)  loss_giou_dn_0: 0.6746 (0.6746)  loss_vfl_dn_1: 0.4041 (0.4041)  loss_bbox_dn_1: 0.2693 (0.2693)  loss_giou_dn_1: 0.4623 (0.4623)  loss_vfl_dn_2: 0.3909 (0.3909)  loss_bbox_dn_2: 0.2629 (0.2629)  loss_giou_dn_2: 0.4165 (0.4165)  loss_vfl_dn_3: 0.3861 (0.3861)  loss_bbox_dn_3: 0.2590 (0.2590)  loss_giou_dn_3: 0.3944 (0.3944)  loss_vfl_dn_4: 0.3861 (0.3861)  loss_bbox_dn_4: 0.2614 (0.2614)  loss_giou_dn_4: 0.3890 (0.3890)  loss_vfl_dn_5: 0.3855 (0.3855)  loss_bbox_dn_5: 0.2616 (0.2616)  loss_giou_dn_5: 0.3865 (0.3865)  time: 0.9851  data: 0.5696  max mem: 7790\n",
            "Epoch: [69]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.7254 (16.5175)  loss_vfl: 0.5842 (0.6025)  loss_bbox: 0.1310 (0.1383)  loss_giou: 0.4866 (0.5321)  loss_vfl_aux_0: 0.6108 (0.6078)  loss_bbox_aux_0: 0.1278 (0.1552)  loss_giou_aux_0: 0.5335 (0.5820)  loss_vfl_aux_1: 0.5852 (0.5940)  loss_bbox_aux_1: 0.1220 (0.1451)  loss_giou_aux_1: 0.4992 (0.5510)  loss_vfl_aux_2: 0.5787 (0.5936)  loss_bbox_aux_2: 0.1236 (0.1424)  loss_giou_aux_2: 0.4852 (0.5408)  loss_vfl_aux_3: 0.5881 (0.6017)  loss_bbox_aux_3: 0.1273 (0.1402)  loss_giou_aux_3: 0.4794 (0.5327)  loss_vfl_aux_4: 0.5754 (0.6023)  loss_bbox_aux_4: 0.1323 (0.1392)  loss_giou_aux_4: 0.4858 (0.5313)  loss_vfl_aux_5: 0.6225 (0.6325)  loss_bbox_aux_5: 0.1808 (0.1983)  loss_giou_aux_5: 0.6947 (0.7089)  loss_vfl_dn_0: 0.4370 (0.4358)  loss_bbox_dn_0: 0.2239 (0.2291)  loss_giou_dn_0: 0.7512 (0.7862)  loss_vfl_dn_1: 0.4226 (0.4221)  loss_bbox_dn_1: 0.1558 (0.1758)  loss_giou_dn_1: 0.5762 (0.6196)  loss_vfl_dn_2: 0.4140 (0.4150)  loss_bbox_dn_2: 0.1421 (0.1651)  loss_giou_dn_2: 0.5442 (0.5809)  loss_vfl_dn_3: 0.4111 (0.4124)  loss_bbox_dn_3: 0.1350 (0.1622)  loss_giou_dn_3: 0.5396 (0.5680)  loss_vfl_dn_4: 0.4096 (0.4118)  loss_bbox_dn_4: 0.1311 (0.1618)  loss_giou_dn_4: 0.5371 (0.5638)  loss_vfl_dn_5: 0.4086 (0.4116)  loss_bbox_dn_5: 0.1300 (0.1617)  loss_giou_dn_5: 0.5356 (0.5628)  time: 0.3191  data: 0.0154  max mem: 7790\n",
            "Epoch: [69] Total time: 0:00:11 (0.3447 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.7254 (16.5175)  loss_vfl: 0.5842 (0.6025)  loss_bbox: 0.1310 (0.1383)  loss_giou: 0.4866 (0.5321)  loss_vfl_aux_0: 0.6108 (0.6078)  loss_bbox_aux_0: 0.1278 (0.1552)  loss_giou_aux_0: 0.5335 (0.5820)  loss_vfl_aux_1: 0.5852 (0.5940)  loss_bbox_aux_1: 0.1220 (0.1451)  loss_giou_aux_1: 0.4992 (0.5510)  loss_vfl_aux_2: 0.5787 (0.5936)  loss_bbox_aux_2: 0.1236 (0.1424)  loss_giou_aux_2: 0.4852 (0.5408)  loss_vfl_aux_3: 0.5881 (0.6017)  loss_bbox_aux_3: 0.1273 (0.1402)  loss_giou_aux_3: 0.4794 (0.5327)  loss_vfl_aux_4: 0.5754 (0.6023)  loss_bbox_aux_4: 0.1323 (0.1392)  loss_giou_aux_4: 0.4858 (0.5313)  loss_vfl_aux_5: 0.6225 (0.6325)  loss_bbox_aux_5: 0.1808 (0.1983)  loss_giou_aux_5: 0.6947 (0.7089)  loss_vfl_dn_0: 0.4370 (0.4358)  loss_bbox_dn_0: 0.2239 (0.2291)  loss_giou_dn_0: 0.7512 (0.7862)  loss_vfl_dn_1: 0.4226 (0.4221)  loss_bbox_dn_1: 0.1558 (0.1758)  loss_giou_dn_1: 0.5762 (0.6196)  loss_vfl_dn_2: 0.4140 (0.4150)  loss_bbox_dn_2: 0.1421 (0.1651)  loss_giou_dn_2: 0.5442 (0.5809)  loss_vfl_dn_3: 0.4111 (0.4124)  loss_bbox_dn_3: 0.1350 (0.1622)  loss_giou_dn_3: 0.5396 (0.5680)  loss_vfl_dn_4: 0.4096 (0.4118)  loss_bbox_dn_4: 0.1311 (0.1618)  loss_giou_dn_4: 0.5371 (0.5638)  loss_vfl_dn_5: 0.4086 (0.4116)  loss_bbox_dn_5: 0.1300 (0.1617)  loss_giou_dn_5: 0.5356 (0.5628)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9159  data: 0.6016  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4479  data: 0.1189  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4631 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.552\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [70]  [ 0/33]  eta: 0:00:37  lr: 0.000001  loss: 15.4281 (15.4281)  loss_vfl: 0.5347 (0.5347)  loss_bbox: 0.1226 (0.1226)  loss_giou: 0.5296 (0.5296)  loss_vfl_aux_0: 0.5757 (0.5757)  loss_bbox_aux_0: 0.1420 (0.1420)  loss_giou_aux_0: 0.5720 (0.5720)  loss_vfl_aux_1: 0.5375 (0.5375)  loss_bbox_aux_1: 0.1362 (0.1362)  loss_giou_aux_1: 0.5503 (0.5503)  loss_vfl_aux_2: 0.5293 (0.5293)  loss_bbox_aux_2: 0.1323 (0.1323)  loss_giou_aux_2: 0.5385 (0.5385)  loss_vfl_aux_3: 0.5134 (0.5134)  loss_bbox_aux_3: 0.1303 (0.1303)  loss_giou_aux_3: 0.5415 (0.5415)  loss_vfl_aux_4: 0.5215 (0.5215)  loss_bbox_aux_4: 0.1289 (0.1289)  loss_giou_aux_4: 0.5324 (0.5324)  loss_vfl_aux_5: 0.5634 (0.5634)  loss_bbox_aux_5: 0.1839 (0.1839)  loss_giou_aux_5: 0.6692 (0.6692)  loss_vfl_dn_0: 0.4355 (0.4355)  loss_bbox_dn_0: 0.1945 (0.1945)  loss_giou_dn_0: 0.7075 (0.7075)  loss_vfl_dn_1: 0.4147 (0.4147)  loss_bbox_dn_1: 0.1444 (0.1444)  loss_giou_dn_1: 0.5494 (0.5494)  loss_vfl_dn_2: 0.4138 (0.4138)  loss_bbox_dn_2: 0.1383 (0.1383)  loss_giou_dn_2: 0.5275 (0.5275)  loss_vfl_dn_3: 0.4109 (0.4109)  loss_bbox_dn_3: 0.1374 (0.1374)  loss_giou_dn_3: 0.5227 (0.5227)  loss_vfl_dn_4: 0.4135 (0.4135)  loss_bbox_dn_4: 0.1363 (0.1363)  loss_giou_dn_4: 0.5217 (0.5217)  loss_vfl_dn_5: 0.4158 (0.4158)  loss_bbox_dn_5: 0.1356 (0.1356)  loss_giou_dn_5: 0.5234 (0.5234)  time: 1.1316  data: 0.7707  max mem: 7790\n",
            "Epoch: [70]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.3886 (15.9784)  loss_vfl: 0.6102 (0.5989)  loss_bbox: 0.1187 (0.1291)  loss_giou: 0.4942 (0.4998)  loss_vfl_aux_0: 0.6204 (0.6042)  loss_bbox_aux_0: 0.1345 (0.1457)  loss_giou_aux_0: 0.5312 (0.5559)  loss_vfl_aux_1: 0.5854 (0.5947)  loss_bbox_aux_1: 0.1256 (0.1334)  loss_giou_aux_1: 0.5114 (0.5181)  loss_vfl_aux_2: 0.6008 (0.5964)  loss_bbox_aux_2: 0.1214 (0.1291)  loss_giou_aux_2: 0.4896 (0.5063)  loss_vfl_aux_3: 0.6093 (0.5951)  loss_bbox_aux_3: 0.1244 (0.1277)  loss_giou_aux_3: 0.4932 (0.5016)  loss_vfl_aux_4: 0.6103 (0.6024)  loss_bbox_aux_4: 0.1197 (0.1278)  loss_giou_aux_4: 0.4970 (0.5003)  loss_vfl_aux_5: 0.6351 (0.6309)  loss_bbox_aux_5: 0.1742 (0.1927)  loss_giou_aux_5: 0.6289 (0.6742)  loss_vfl_dn_0: 0.4409 (0.4383)  loss_bbox_dn_0: 0.2186 (0.2201)  loss_giou_dn_0: 0.7331 (0.7474)  loss_vfl_dn_1: 0.4253 (0.4244)  loss_bbox_dn_1: 0.1546 (0.1689)  loss_giou_dn_1: 0.5846 (0.5816)  loss_vfl_dn_2: 0.4201 (0.4183)  loss_bbox_dn_2: 0.1450 (0.1577)  loss_giou_dn_2: 0.5447 (0.5455)  loss_vfl_dn_3: 0.4165 (0.4153)  loss_bbox_dn_3: 0.1415 (0.1554)  loss_giou_dn_3: 0.5388 (0.5354)  loss_vfl_dn_4: 0.4152 (0.4157)  loss_bbox_dn_4: 0.1397 (0.1547)  loss_giou_dn_4: 0.5323 (0.5328)  loss_vfl_dn_5: 0.4176 (0.4159)  loss_bbox_dn_5: 0.1373 (0.1543)  loss_giou_dn_5: 0.5313 (0.5322)  time: 0.3253  data: 0.0150  max mem: 7790\n",
            "Epoch: [70] Total time: 0:00:11 (0.3525 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.3886 (15.9784)  loss_vfl: 0.6102 (0.5989)  loss_bbox: 0.1187 (0.1291)  loss_giou: 0.4942 (0.4998)  loss_vfl_aux_0: 0.6204 (0.6042)  loss_bbox_aux_0: 0.1345 (0.1457)  loss_giou_aux_0: 0.5312 (0.5559)  loss_vfl_aux_1: 0.5854 (0.5947)  loss_bbox_aux_1: 0.1256 (0.1334)  loss_giou_aux_1: 0.5114 (0.5181)  loss_vfl_aux_2: 0.6008 (0.5964)  loss_bbox_aux_2: 0.1214 (0.1291)  loss_giou_aux_2: 0.4896 (0.5063)  loss_vfl_aux_3: 0.6093 (0.5951)  loss_bbox_aux_3: 0.1244 (0.1277)  loss_giou_aux_3: 0.4932 (0.5016)  loss_vfl_aux_4: 0.6103 (0.6024)  loss_bbox_aux_4: 0.1197 (0.1278)  loss_giou_aux_4: 0.4970 (0.5003)  loss_vfl_aux_5: 0.6351 (0.6309)  loss_bbox_aux_5: 0.1742 (0.1927)  loss_giou_aux_5: 0.6289 (0.6742)  loss_vfl_dn_0: 0.4409 (0.4383)  loss_bbox_dn_0: 0.2186 (0.2201)  loss_giou_dn_0: 0.7331 (0.7474)  loss_vfl_dn_1: 0.4253 (0.4244)  loss_bbox_dn_1: 0.1546 (0.1689)  loss_giou_dn_1: 0.5846 (0.5816)  loss_vfl_dn_2: 0.4201 (0.4183)  loss_bbox_dn_2: 0.1450 (0.1577)  loss_giou_dn_2: 0.5447 (0.5455)  loss_vfl_dn_3: 0.4165 (0.4153)  loss_bbox_dn_3: 0.1415 (0.1554)  loss_giou_dn_3: 0.5388 (0.5354)  loss_vfl_dn_4: 0.4152 (0.4157)  loss_bbox_dn_4: 0.1397 (0.1547)  loss_giou_dn_4: 0.5323 (0.5328)  loss_vfl_dn_5: 0.4176 (0.4159)  loss_bbox_dn_5: 0.1373 (0.1543)  loss_giou_dn_5: 0.5313 (0.5322)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8618  data: 0.5527  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3821  data: 0.1108  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3950 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681\n",
            "best_stat:  {'epoch': 49, 'coco_eval_bbox': 0.32702498713278927}\n",
            "Epoch: [71]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 15.3259 (15.3259)  loss_vfl: 0.5585 (0.5585)  loss_bbox: 0.1061 (0.1061)  loss_giou: 0.4563 (0.4563)  loss_vfl_aux_0: 0.6072 (0.6072)  loss_bbox_aux_0: 0.1177 (0.1177)  loss_giou_aux_0: 0.5080 (0.5080)  loss_vfl_aux_1: 0.5740 (0.5740)  loss_bbox_aux_1: 0.1129 (0.1129)  loss_giou_aux_1: 0.4708 (0.4708)  loss_vfl_aux_2: 0.5676 (0.5676)  loss_bbox_aux_2: 0.1084 (0.1084)  loss_giou_aux_2: 0.4554 (0.4554)  loss_vfl_aux_3: 0.5680 (0.5680)  loss_bbox_aux_3: 0.1054 (0.1054)  loss_giou_aux_3: 0.4551 (0.4551)  loss_vfl_aux_4: 0.5602 (0.5602)  loss_bbox_aux_4: 0.1057 (0.1057)  loss_giou_aux_4: 0.4535 (0.4535)  loss_vfl_aux_5: 0.6189 (0.6189)  loss_bbox_aux_5: 0.1436 (0.1436)  loss_giou_aux_5: 0.6064 (0.6064)  loss_vfl_dn_0: 0.4442 (0.4442)  loss_bbox_dn_0: 0.2032 (0.2032)  loss_giou_dn_0: 0.7713 (0.7713)  loss_vfl_dn_1: 0.4417 (0.4417)  loss_bbox_dn_1: 0.1606 (0.1606)  loss_giou_dn_1: 0.5911 (0.5911)  loss_vfl_dn_2: 0.4283 (0.4283)  loss_bbox_dn_2: 0.1506 (0.1506)  loss_giou_dn_2: 0.5504 (0.5504)  loss_vfl_dn_3: 0.4286 (0.4286)  loss_bbox_dn_3: 0.1461 (0.1461)  loss_giou_dn_3: 0.5373 (0.5373)  loss_vfl_dn_4: 0.4268 (0.4268)  loss_bbox_dn_4: 0.1452 (0.1452)  loss_giou_dn_4: 0.5319 (0.5319)  loss_vfl_dn_5: 0.4297 (0.4297)  loss_bbox_dn_5: 0.1456 (0.1456)  loss_giou_dn_5: 0.5337 (0.5337)  time: 0.9956  data: 0.5720  max mem: 7790\n",
            "Epoch: [71]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.9859 (16.1976)  loss_vfl: 0.6221 (0.6211)  loss_bbox: 0.1169 (0.1246)  loss_giou: 0.4863 (0.5086)  loss_vfl_aux_0: 0.5910 (0.6146)  loss_bbox_aux_0: 0.1316 (0.1386)  loss_giou_aux_0: 0.5603 (0.5643)  loss_vfl_aux_1: 0.5922 (0.6130)  loss_bbox_aux_1: 0.1216 (0.1313)  loss_giou_aux_1: 0.5102 (0.5272)  loss_vfl_aux_2: 0.5909 (0.6080)  loss_bbox_aux_2: 0.1198 (0.1270)  loss_giou_aux_2: 0.4984 (0.5170)  loss_vfl_aux_3: 0.6062 (0.6123)  loss_bbox_aux_3: 0.1190 (0.1253)  loss_giou_aux_3: 0.4889 (0.5107)  loss_vfl_aux_4: 0.6094 (0.6177)  loss_bbox_aux_4: 0.1149 (0.1245)  loss_giou_aux_4: 0.4826 (0.5072)  loss_vfl_aux_5: 0.6406 (0.6453)  loss_bbox_aux_5: 0.1748 (0.1799)  loss_giou_aux_5: 0.6796 (0.6691)  loss_vfl_dn_0: 0.4403 (0.4373)  loss_bbox_dn_0: 0.1982 (0.2118)  loss_giou_dn_0: 0.7653 (0.7655)  loss_vfl_dn_1: 0.4322 (0.4252)  loss_bbox_dn_1: 0.1566 (0.1652)  loss_giou_dn_1: 0.5874 (0.6051)  loss_vfl_dn_2: 0.4230 (0.4191)  loss_bbox_dn_2: 0.1362 (0.1542)  loss_giou_dn_2: 0.5590 (0.5658)  loss_vfl_dn_3: 0.4203 (0.4180)  loss_bbox_dn_3: 0.1290 (0.1513)  loss_giou_dn_3: 0.5479 (0.5539)  loss_vfl_dn_4: 0.4173 (0.4171)  loss_bbox_dn_4: 0.1291 (0.1507)  loss_giou_dn_4: 0.5467 (0.5512)  loss_vfl_dn_5: 0.4186 (0.4175)  loss_bbox_dn_5: 0.1299 (0.1507)  loss_giou_dn_5: 0.5464 (0.5509)  time: 0.3299  data: 0.0162  max mem: 7790\n",
            "Epoch: [71] Total time: 0:00:12 (0.3645 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.9859 (16.1976)  loss_vfl: 0.6221 (0.6211)  loss_bbox: 0.1169 (0.1246)  loss_giou: 0.4863 (0.5086)  loss_vfl_aux_0: 0.5910 (0.6146)  loss_bbox_aux_0: 0.1316 (0.1386)  loss_giou_aux_0: 0.5603 (0.5643)  loss_vfl_aux_1: 0.5922 (0.6130)  loss_bbox_aux_1: 0.1216 (0.1313)  loss_giou_aux_1: 0.5102 (0.5272)  loss_vfl_aux_2: 0.5909 (0.6080)  loss_bbox_aux_2: 0.1198 (0.1270)  loss_giou_aux_2: 0.4984 (0.5170)  loss_vfl_aux_3: 0.6062 (0.6123)  loss_bbox_aux_3: 0.1190 (0.1253)  loss_giou_aux_3: 0.4889 (0.5107)  loss_vfl_aux_4: 0.6094 (0.6177)  loss_bbox_aux_4: 0.1149 (0.1245)  loss_giou_aux_4: 0.4826 (0.5072)  loss_vfl_aux_5: 0.6406 (0.6453)  loss_bbox_aux_5: 0.1748 (0.1799)  loss_giou_aux_5: 0.6796 (0.6691)  loss_vfl_dn_0: 0.4403 (0.4373)  loss_bbox_dn_0: 0.1982 (0.2118)  loss_giou_dn_0: 0.7653 (0.7655)  loss_vfl_dn_1: 0.4322 (0.4252)  loss_bbox_dn_1: 0.1566 (0.1652)  loss_giou_dn_1: 0.5874 (0.6051)  loss_vfl_dn_2: 0.4230 (0.4191)  loss_bbox_dn_2: 0.1362 (0.1542)  loss_giou_dn_2: 0.5590 (0.5658)  loss_vfl_dn_3: 0.4203 (0.4180)  loss_bbox_dn_3: 0.1290 (0.1513)  loss_giou_dn_3: 0.5479 (0.5539)  loss_vfl_dn_4: 0.4173 (0.4171)  loss_bbox_dn_4: 0.1291 (0.1507)  loss_giou_dn_4: 0.5467 (0.5512)  loss_vfl_dn_5: 0.4186 (0.4175)  loss_bbox_dn_5: 0.1299 (0.1507)  loss_giou_dn_5: 0.5464 (0.5509)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8859  data: 0.5677  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3874  data: 0.1143  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4022 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.658\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.363\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 71, 'coco_eval_bbox': 0.3288741029254648}\n",
            "Epoch: [72]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 17.4426 (17.4426)  loss_vfl: 0.5451 (0.5451)  loss_bbox: 0.1856 (0.1856)  loss_giou: 0.5444 (0.5444)  loss_vfl_aux_0: 0.5742 (0.5742)  loss_bbox_aux_0: 0.2014 (0.2014)  loss_giou_aux_0: 0.6037 (0.6037)  loss_vfl_aux_1: 0.5504 (0.5504)  loss_bbox_aux_1: 0.1896 (0.1896)  loss_giou_aux_1: 0.5686 (0.5686)  loss_vfl_aux_2: 0.5571 (0.5571)  loss_bbox_aux_2: 0.1881 (0.1881)  loss_giou_aux_2: 0.5584 (0.5584)  loss_vfl_aux_3: 0.5522 (0.5522)  loss_bbox_aux_3: 0.1849 (0.1849)  loss_giou_aux_3: 0.5434 (0.5434)  loss_vfl_aux_4: 0.5476 (0.5476)  loss_bbox_aux_4: 0.1851 (0.1851)  loss_giou_aux_4: 0.5442 (0.5442)  loss_vfl_aux_5: 0.5940 (0.5940)  loss_bbox_aux_5: 0.2861 (0.2861)  loss_giou_aux_5: 0.8226 (0.8226)  loss_vfl_dn_0: 0.4508 (0.4508)  loss_bbox_dn_0: 0.2793 (0.2793)  loss_giou_dn_0: 0.7946 (0.7946)  loss_vfl_dn_1: 0.4594 (0.4594)  loss_bbox_dn_1: 0.2166 (0.2166)  loss_giou_dn_1: 0.6508 (0.6508)  loss_vfl_dn_2: 0.4586 (0.4586)  loss_bbox_dn_2: 0.2054 (0.2054)  loss_giou_dn_2: 0.6145 (0.6145)  loss_vfl_dn_3: 0.4607 (0.4607)  loss_bbox_dn_3: 0.2010 (0.2010)  loss_giou_dn_3: 0.6019 (0.6019)  loss_vfl_dn_4: 0.4607 (0.4607)  loss_bbox_dn_4: 0.2013 (0.2013)  loss_giou_dn_4: 0.6007 (0.6007)  loss_vfl_dn_5: 0.4581 (0.4581)  loss_bbox_dn_5: 0.2013 (0.2013)  loss_giou_dn_5: 0.6002 (0.6002)  time: 0.9634  data: 0.6022  max mem: 7790\n",
            "Epoch: [72]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.3041 (16.1827)  loss_vfl: 0.6212 (0.6279)  loss_bbox: 0.1196 (0.1283)  loss_giou: 0.5592 (0.5077)  loss_vfl_aux_0: 0.5986 (0.6213)  loss_bbox_aux_0: 0.1356 (0.1453)  loss_giou_aux_0: 0.6004 (0.5655)  loss_vfl_aux_1: 0.6011 (0.6137)  loss_bbox_aux_1: 0.1278 (0.1356)  loss_giou_aux_1: 0.5614 (0.5297)  loss_vfl_aux_2: 0.5956 (0.6088)  loss_bbox_aux_2: 0.1236 (0.1322)  loss_giou_aux_2: 0.5679 (0.5169)  loss_vfl_aux_3: 0.5983 (0.6159)  loss_bbox_aux_3: 0.1233 (0.1306)  loss_giou_aux_3: 0.5636 (0.5118)  loss_vfl_aux_4: 0.6063 (0.6221)  loss_bbox_aux_4: 0.1197 (0.1292)  loss_giou_aux_4: 0.5636 (0.5088)  loss_vfl_aux_5: 0.6262 (0.6409)  loss_bbox_aux_5: 0.1837 (0.2000)  loss_giou_aux_5: 0.7504 (0.7066)  loss_vfl_dn_0: 0.4338 (0.4385)  loss_bbox_dn_0: 0.1755 (0.2176)  loss_giou_dn_0: 0.7713 (0.7477)  loss_vfl_dn_1: 0.4200 (0.4242)  loss_bbox_dn_1: 0.1323 (0.1661)  loss_giou_dn_1: 0.6264 (0.5808)  loss_vfl_dn_2: 0.4159 (0.4177)  loss_bbox_dn_2: 0.1265 (0.1550)  loss_giou_dn_2: 0.5977 (0.5438)  loss_vfl_dn_3: 0.4142 (0.4139)  loss_bbox_dn_3: 0.1269 (0.1523)  loss_giou_dn_3: 0.5905 (0.5342)  loss_vfl_dn_4: 0.4087 (0.4127)  loss_bbox_dn_4: 0.1271 (0.1518)  loss_giou_dn_4: 0.5876 (0.5314)  loss_vfl_dn_5: 0.4090 (0.4128)  loss_bbox_dn_5: 0.1278 (0.1518)  loss_giou_dn_5: 0.5889 (0.5314)  time: 0.3354  data: 0.0149  max mem: 7790\n",
            "Epoch: [72] Total time: 0:00:11 (0.3569 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.3041 (16.1827)  loss_vfl: 0.6212 (0.6279)  loss_bbox: 0.1196 (0.1283)  loss_giou: 0.5592 (0.5077)  loss_vfl_aux_0: 0.5986 (0.6213)  loss_bbox_aux_0: 0.1356 (0.1453)  loss_giou_aux_0: 0.6004 (0.5655)  loss_vfl_aux_1: 0.6011 (0.6137)  loss_bbox_aux_1: 0.1278 (0.1356)  loss_giou_aux_1: 0.5614 (0.5297)  loss_vfl_aux_2: 0.5956 (0.6088)  loss_bbox_aux_2: 0.1236 (0.1322)  loss_giou_aux_2: 0.5679 (0.5169)  loss_vfl_aux_3: 0.5983 (0.6159)  loss_bbox_aux_3: 0.1233 (0.1306)  loss_giou_aux_3: 0.5636 (0.5118)  loss_vfl_aux_4: 0.6063 (0.6221)  loss_bbox_aux_4: 0.1197 (0.1292)  loss_giou_aux_4: 0.5636 (0.5088)  loss_vfl_aux_5: 0.6262 (0.6409)  loss_bbox_aux_5: 0.1837 (0.2000)  loss_giou_aux_5: 0.7504 (0.7066)  loss_vfl_dn_0: 0.4338 (0.4385)  loss_bbox_dn_0: 0.1755 (0.2176)  loss_giou_dn_0: 0.7713 (0.7477)  loss_vfl_dn_1: 0.4200 (0.4242)  loss_bbox_dn_1: 0.1323 (0.1661)  loss_giou_dn_1: 0.6264 (0.5808)  loss_vfl_dn_2: 0.4159 (0.4177)  loss_bbox_dn_2: 0.1265 (0.1550)  loss_giou_dn_2: 0.5977 (0.5438)  loss_vfl_dn_3: 0.4142 (0.4139)  loss_bbox_dn_3: 0.1269 (0.1523)  loss_giou_dn_3: 0.5905 (0.5342)  loss_vfl_dn_4: 0.4087 (0.4127)  loss_bbox_dn_4: 0.1271 (0.1518)  loss_giou_dn_4: 0.5876 (0.5314)  loss_vfl_dn_5: 0.4090 (0.4128)  loss_bbox_dn_5: 0.1278 (0.1518)  loss_giou_dn_5: 0.5889 (0.5314)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8754  data: 0.5509  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4006  data: 0.1133  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4137 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.626\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            "best_stat:  {'epoch': 71, 'coco_eval_bbox': 0.3288741029254648}\n",
            "Epoch: [73]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 16.3445 (16.3445)  loss_vfl: 0.6049 (0.6049)  loss_bbox: 0.1003 (0.1003)  loss_giou: 0.5865 (0.5865)  loss_vfl_aux_0: 0.5529 (0.5529)  loss_bbox_aux_0: 0.1090 (0.1090)  loss_giou_aux_0: 0.6285 (0.6285)  loss_vfl_aux_1: 0.5808 (0.5808)  loss_bbox_aux_1: 0.1037 (0.1037)  loss_giou_aux_1: 0.5971 (0.5971)  loss_vfl_aux_2: 0.5892 (0.5892)  loss_bbox_aux_2: 0.1011 (0.1011)  loss_giou_aux_2: 0.5920 (0.5920)  loss_vfl_aux_3: 0.5988 (0.5988)  loss_bbox_aux_3: 0.1008 (0.1008)  loss_giou_aux_3: 0.5899 (0.5899)  loss_vfl_aux_4: 0.6060 (0.6060)  loss_bbox_aux_4: 0.1000 (0.1000)  loss_giou_aux_4: 0.5862 (0.5862)  loss_vfl_aux_5: 0.5919 (0.5919)  loss_bbox_aux_5: 0.1222 (0.1222)  loss_giou_aux_5: 0.6579 (0.6579)  loss_vfl_dn_0: 0.4374 (0.4374)  loss_bbox_dn_0: 0.1435 (0.1435)  loss_giou_dn_0: 0.8079 (0.8079)  loss_vfl_dn_1: 0.4485 (0.4485)  loss_bbox_dn_1: 0.1199 (0.1199)  loss_giou_dn_1: 0.6537 (0.6537)  loss_vfl_dn_2: 0.4478 (0.4478)  loss_bbox_dn_2: 0.1117 (0.1117)  loss_giou_dn_2: 0.6107 (0.6107)  loss_vfl_dn_3: 0.4517 (0.4517)  loss_bbox_dn_3: 0.1103 (0.1103)  loss_giou_dn_3: 0.5952 (0.5952)  loss_vfl_dn_4: 0.4520 (0.4520)  loss_bbox_dn_4: 0.1107 (0.1107)  loss_giou_dn_4: 0.5916 (0.5916)  loss_vfl_dn_5: 0.4523 (0.4523)  loss_bbox_dn_5: 0.1106 (0.1106)  loss_giou_dn_5: 0.5893 (0.5893)  time: 1.0862  data: 0.7114  max mem: 7790\n",
            "Epoch: [73]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.1486 (16.3701)  loss_vfl: 0.5876 (0.6003)  loss_bbox: 0.1304 (0.1369)  loss_giou: 0.4776 (0.5169)  loss_vfl_aux_0: 0.6130 (0.6014)  loss_bbox_aux_0: 0.1446 (0.1568)  loss_giou_aux_0: 0.5409 (0.5860)  loss_vfl_aux_1: 0.6033 (0.6031)  loss_bbox_aux_1: 0.1340 (0.1428)  loss_giou_aux_1: 0.4841 (0.5358)  loss_vfl_aux_2: 0.5783 (0.5941)  loss_bbox_aux_2: 0.1284 (0.1410)  loss_giou_aux_2: 0.4789 (0.5279)  loss_vfl_aux_3: 0.5908 (0.5998)  loss_bbox_aux_3: 0.1291 (0.1385)  loss_giou_aux_3: 0.4805 (0.5226)  loss_vfl_aux_4: 0.5811 (0.6013)  loss_bbox_aux_4: 0.1295 (0.1369)  loss_giou_aux_4: 0.4754 (0.5188)  loss_vfl_aux_5: 0.6185 (0.6320)  loss_bbox_aux_5: 0.2014 (0.2090)  loss_giou_aux_5: 0.6595 (0.7059)  loss_vfl_dn_0: 0.4340 (0.4337)  loss_bbox_dn_0: 0.2225 (0.2301)  loss_giou_dn_0: 0.7451 (0.7814)  loss_vfl_dn_1: 0.4262 (0.4251)  loss_bbox_dn_1: 0.1737 (0.1773)  loss_giou_dn_1: 0.5794 (0.6055)  loss_vfl_dn_2: 0.4179 (0.4175)  loss_bbox_dn_2: 0.1569 (0.1641)  loss_giou_dn_2: 0.5396 (0.5621)  loss_vfl_dn_3: 0.4166 (0.4159)  loss_bbox_dn_3: 0.1520 (0.1601)  loss_giou_dn_3: 0.5300 (0.5486)  loss_vfl_dn_4: 0.4188 (0.4163)  loss_bbox_dn_4: 0.1509 (0.1592)  loss_giou_dn_4: 0.5259 (0.5454)  loss_vfl_dn_5: 0.4199 (0.4164)  loss_bbox_dn_5: 0.1512 (0.1588)  loss_giou_dn_5: 0.5205 (0.5446)  time: 0.3239  data: 0.0155  max mem: 7790\n",
            "Epoch: [73] Total time: 0:00:11 (0.3492 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.1486 (16.3701)  loss_vfl: 0.5876 (0.6003)  loss_bbox: 0.1304 (0.1369)  loss_giou: 0.4776 (0.5169)  loss_vfl_aux_0: 0.6130 (0.6014)  loss_bbox_aux_0: 0.1446 (0.1568)  loss_giou_aux_0: 0.5409 (0.5860)  loss_vfl_aux_1: 0.6033 (0.6031)  loss_bbox_aux_1: 0.1340 (0.1428)  loss_giou_aux_1: 0.4841 (0.5358)  loss_vfl_aux_2: 0.5783 (0.5941)  loss_bbox_aux_2: 0.1284 (0.1410)  loss_giou_aux_2: 0.4789 (0.5279)  loss_vfl_aux_3: 0.5908 (0.5998)  loss_bbox_aux_3: 0.1291 (0.1385)  loss_giou_aux_3: 0.4805 (0.5226)  loss_vfl_aux_4: 0.5811 (0.6013)  loss_bbox_aux_4: 0.1295 (0.1369)  loss_giou_aux_4: 0.4754 (0.5188)  loss_vfl_aux_5: 0.6185 (0.6320)  loss_bbox_aux_5: 0.2014 (0.2090)  loss_giou_aux_5: 0.6595 (0.7059)  loss_vfl_dn_0: 0.4340 (0.4337)  loss_bbox_dn_0: 0.2225 (0.2301)  loss_giou_dn_0: 0.7451 (0.7814)  loss_vfl_dn_1: 0.4262 (0.4251)  loss_bbox_dn_1: 0.1737 (0.1773)  loss_giou_dn_1: 0.5794 (0.6055)  loss_vfl_dn_2: 0.4179 (0.4175)  loss_bbox_dn_2: 0.1569 (0.1641)  loss_giou_dn_2: 0.5396 (0.5621)  loss_vfl_dn_3: 0.4166 (0.4159)  loss_bbox_dn_3: 0.1520 (0.1601)  loss_giou_dn_3: 0.5300 (0.5486)  loss_vfl_dn_4: 0.4188 (0.4163)  loss_bbox_dn_4: 0.1509 (0.1592)  loss_giou_dn_4: 0.5259 (0.5454)  loss_vfl_dn_5: 0.4199 (0.4164)  loss_bbox_dn_5: 0.1512 (0.1588)  loss_giou_dn_5: 0.5205 (0.5446)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9305  data: 0.6201  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3920  data: 0.1166  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4067 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.622\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 71, 'coco_eval_bbox': 0.3288741029254648}\n",
            "Epoch: [74]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 15.5722 (15.5722)  loss_vfl: 0.5194 (0.5194)  loss_bbox: 0.1957 (0.1957)  loss_giou: 0.4313 (0.4313)  loss_vfl_aux_0: 0.5662 (0.5662)  loss_bbox_aux_0: 0.2102 (0.2102)  loss_giou_aux_0: 0.4944 (0.4944)  loss_vfl_aux_1: 0.5570 (0.5570)  loss_bbox_aux_1: 0.2026 (0.2026)  loss_giou_aux_1: 0.4430 (0.4430)  loss_vfl_aux_2: 0.5307 (0.5307)  loss_bbox_aux_2: 0.1936 (0.1936)  loss_giou_aux_2: 0.4329 (0.4329)  loss_vfl_aux_3: 0.5156 (0.5156)  loss_bbox_aux_3: 0.1949 (0.1949)  loss_giou_aux_3: 0.4330 (0.4330)  loss_vfl_aux_4: 0.5261 (0.5261)  loss_bbox_aux_4: 0.1924 (0.1924)  loss_giou_aux_4: 0.4279 (0.4279)  loss_vfl_aux_5: 0.6504 (0.6504)  loss_bbox_aux_5: 0.2839 (0.2839)  loss_giou_aux_5: 0.6308 (0.6308)  loss_vfl_dn_0: 0.4407 (0.4407)  loss_bbox_dn_0: 0.3011 (0.3011)  loss_giou_dn_0: 0.7559 (0.7559)  loss_vfl_dn_1: 0.4262 (0.4262)  loss_bbox_dn_1: 0.2369 (0.2369)  loss_giou_dn_1: 0.5426 (0.5426)  loss_vfl_dn_2: 0.4107 (0.4107)  loss_bbox_dn_2: 0.2124 (0.2124)  loss_giou_dn_2: 0.4653 (0.4653)  loss_vfl_dn_3: 0.3974 (0.3974)  loss_bbox_dn_3: 0.2097 (0.2097)  loss_giou_dn_3: 0.4491 (0.4491)  loss_vfl_dn_4: 0.3896 (0.3896)  loss_bbox_dn_4: 0.2109 (0.2109)  loss_giou_dn_4: 0.4462 (0.4462)  loss_vfl_dn_5: 0.3860 (0.3860)  loss_bbox_dn_5: 0.2126 (0.2126)  loss_giou_dn_5: 0.4469 (0.4469)  time: 1.0446  data: 0.6090  max mem: 7790\n",
            "Epoch: [74]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.2999 (16.9069)  loss_vfl: 0.5832 (0.5904)  loss_bbox: 0.1151 (0.1282)  loss_giou: 0.5394 (0.5848)  loss_vfl_aux_0: 0.5688 (0.5843)  loss_bbox_aux_0: 0.1309 (0.1460)  loss_giou_aux_0: 0.5915 (0.6485)  loss_vfl_aux_1: 0.5678 (0.5895)  loss_bbox_aux_1: 0.1218 (0.1343)  loss_giou_aux_1: 0.5479 (0.6061)  loss_vfl_aux_2: 0.5886 (0.5849)  loss_bbox_aux_2: 0.1210 (0.1313)  loss_giou_aux_2: 0.5510 (0.5968)  loss_vfl_aux_3: 0.5826 (0.5882)  loss_bbox_aux_3: 0.1181 (0.1291)  loss_giou_aux_3: 0.5397 (0.5879)  loss_vfl_aux_4: 0.5769 (0.5890)  loss_bbox_aux_4: 0.1168 (0.1290)  loss_giou_aux_4: 0.5424 (0.5851)  loss_vfl_aux_5: 0.6234 (0.6188)  loss_bbox_aux_5: 0.1636 (0.1978)  loss_giou_aux_5: 0.7465 (0.7785)  loss_vfl_dn_0: 0.4299 (0.4329)  loss_bbox_dn_0: 0.1970 (0.2105)  loss_giou_dn_0: 0.8052 (0.8223)  loss_vfl_dn_1: 0.4292 (0.4279)  loss_bbox_dn_1: 0.1504 (0.1598)  loss_giou_dn_1: 0.6037 (0.6601)  loss_vfl_dn_2: 0.4194 (0.4190)  loss_bbox_dn_2: 0.1349 (0.1465)  loss_giou_dn_2: 0.5520 (0.6184)  loss_vfl_dn_3: 0.4170 (0.4139)  loss_bbox_dn_3: 0.1315 (0.1430)  loss_giou_dn_3: 0.5483 (0.6061)  loss_vfl_dn_4: 0.4155 (0.4136)  loss_bbox_dn_4: 0.1288 (0.1422)  loss_giou_dn_4: 0.5459 (0.6031)  loss_vfl_dn_5: 0.4124 (0.4142)  loss_bbox_dn_5: 0.1275 (0.1419)  loss_giou_dn_5: 0.5489 (0.6026)  time: 0.3262  data: 0.0146  max mem: 7790\n",
            "Epoch: [74] Total time: 0:00:11 (0.3474 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.2999 (16.9069)  loss_vfl: 0.5832 (0.5904)  loss_bbox: 0.1151 (0.1282)  loss_giou: 0.5394 (0.5848)  loss_vfl_aux_0: 0.5688 (0.5843)  loss_bbox_aux_0: 0.1309 (0.1460)  loss_giou_aux_0: 0.5915 (0.6485)  loss_vfl_aux_1: 0.5678 (0.5895)  loss_bbox_aux_1: 0.1218 (0.1343)  loss_giou_aux_1: 0.5479 (0.6061)  loss_vfl_aux_2: 0.5886 (0.5849)  loss_bbox_aux_2: 0.1210 (0.1313)  loss_giou_aux_2: 0.5510 (0.5968)  loss_vfl_aux_3: 0.5826 (0.5882)  loss_bbox_aux_3: 0.1181 (0.1291)  loss_giou_aux_3: 0.5397 (0.5879)  loss_vfl_aux_4: 0.5769 (0.5890)  loss_bbox_aux_4: 0.1168 (0.1290)  loss_giou_aux_4: 0.5424 (0.5851)  loss_vfl_aux_5: 0.6234 (0.6188)  loss_bbox_aux_5: 0.1636 (0.1978)  loss_giou_aux_5: 0.7465 (0.7785)  loss_vfl_dn_0: 0.4299 (0.4329)  loss_bbox_dn_0: 0.1970 (0.2105)  loss_giou_dn_0: 0.8052 (0.8223)  loss_vfl_dn_1: 0.4292 (0.4279)  loss_bbox_dn_1: 0.1504 (0.1598)  loss_giou_dn_1: 0.6037 (0.6601)  loss_vfl_dn_2: 0.4194 (0.4190)  loss_bbox_dn_2: 0.1349 (0.1465)  loss_giou_dn_2: 0.5520 (0.6184)  loss_vfl_dn_3: 0.4170 (0.4139)  loss_bbox_dn_3: 0.1315 (0.1430)  loss_giou_dn_3: 0.5483 (0.6061)  loss_vfl_dn_4: 0.4155 (0.4136)  loss_bbox_dn_4: 0.1288 (0.1422)  loss_giou_dn_4: 0.5459 (0.6031)  loss_vfl_dn_5: 0.4124 (0.4142)  loss_bbox_dn_5: 0.1275 (0.1419)  loss_giou_dn_5: 0.5489 (0.6026)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8374  data: 0.5260  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3789  data: 0.1080  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3911 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.378\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n",
            "best_stat:  {'epoch': 71, 'coco_eval_bbox': 0.3288741029254648}\n",
            "Epoch: [75]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 15.5772 (15.5772)  loss_vfl: 0.6694 (0.6694)  loss_bbox: 0.0894 (0.0894)  loss_giou: 0.4082 (0.4082)  loss_vfl_aux_0: 0.7386 (0.7386)  loss_bbox_aux_0: 0.1013 (0.1013)  loss_giou_aux_0: 0.4899 (0.4899)  loss_vfl_aux_1: 0.6180 (0.6180)  loss_bbox_aux_1: 0.0927 (0.0927)  loss_giou_aux_1: 0.4603 (0.4603)  loss_vfl_aux_2: 0.6294 (0.6294)  loss_bbox_aux_2: 0.0913 (0.0913)  loss_giou_aux_2: 0.4277 (0.4277)  loss_vfl_aux_3: 0.6539 (0.6539)  loss_bbox_aux_3: 0.0896 (0.0896)  loss_giou_aux_3: 0.4162 (0.4162)  loss_vfl_aux_4: 0.6719 (0.6719)  loss_bbox_aux_4: 0.0905 (0.0905)  loss_giou_aux_4: 0.4111 (0.4111)  loss_vfl_aux_5: 0.7224 (0.7224)  loss_bbox_aux_5: 0.1432 (0.1432)  loss_giou_aux_5: 0.5986 (0.5986)  loss_vfl_dn_0: 0.4308 (0.4308)  loss_bbox_dn_0: 0.1796 (0.1796)  loss_giou_dn_0: 0.8001 (0.8001)  loss_vfl_dn_1: 0.4193 (0.4193)  loss_bbox_dn_1: 0.1351 (0.1351)  loss_giou_dn_1: 0.6151 (0.6151)  loss_vfl_dn_2: 0.4159 (0.4159)  loss_bbox_dn_2: 0.1295 (0.1295)  loss_giou_dn_2: 0.5685 (0.5685)  loss_vfl_dn_3: 0.4125 (0.4125)  loss_bbox_dn_3: 0.1261 (0.1261)  loss_giou_dn_3: 0.5532 (0.5532)  loss_vfl_dn_4: 0.4156 (0.4156)  loss_bbox_dn_4: 0.1265 (0.1265)  loss_giou_dn_4: 0.5461 (0.5461)  loss_vfl_dn_5: 0.4181 (0.4181)  loss_bbox_dn_5: 0.1264 (0.1264)  loss_giou_dn_5: 0.5455 (0.5455)  time: 0.9484  data: 0.5524  max mem: 7790\n",
            "Epoch: [75]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.5131 (15.7282)  loss_vfl: 0.5765 (0.5984)  loss_bbox: 0.1303 (0.1291)  loss_giou: 0.4716 (0.4827)  loss_vfl_aux_0: 0.5952 (0.6080)  loss_bbox_aux_0: 0.1432 (0.1427)  loss_giou_aux_0: 0.5332 (0.5346)  loss_vfl_aux_1: 0.5899 (0.5892)  loss_bbox_aux_1: 0.1270 (0.1329)  loss_giou_aux_1: 0.4982 (0.5016)  loss_vfl_aux_2: 0.5759 (0.5858)  loss_bbox_aux_2: 0.1258 (0.1309)  loss_giou_aux_2: 0.4790 (0.4929)  loss_vfl_aux_3: 0.5845 (0.5909)  loss_bbox_aux_3: 0.1269 (0.1295)  loss_giou_aux_3: 0.4719 (0.4868)  loss_vfl_aux_4: 0.5809 (0.5905)  loss_bbox_aux_4: 0.1248 (0.1291)  loss_giou_aux_4: 0.4711 (0.4861)  loss_vfl_aux_5: 0.6358 (0.6555)  loss_bbox_aux_5: 0.1736 (0.1917)  loss_giou_aux_5: 0.6321 (0.6679)  loss_vfl_dn_0: 0.4393 (0.4387)  loss_bbox_dn_0: 0.2022 (0.2190)  loss_giou_dn_0: 0.7189 (0.7377)  loss_vfl_dn_1: 0.4218 (0.4252)  loss_bbox_dn_1: 0.1620 (0.1653)  loss_giou_dn_1: 0.5397 (0.5660)  loss_vfl_dn_2: 0.4113 (0.4180)  loss_bbox_dn_2: 0.1536 (0.1531)  loss_giou_dn_2: 0.5123 (0.5252)  loss_vfl_dn_3: 0.4071 (0.4145)  loss_bbox_dn_3: 0.1510 (0.1492)  loss_giou_dn_3: 0.4923 (0.5132)  loss_vfl_dn_4: 0.4077 (0.4151)  loss_bbox_dn_4: 0.1521 (0.1486)  loss_giou_dn_4: 0.4876 (0.5099)  loss_vfl_dn_5: 0.4074 (0.4158)  loss_bbox_dn_5: 0.1519 (0.1483)  loss_giou_dn_5: 0.4860 (0.5090)  time: 0.3246  data: 0.0137  max mem: 7790\n",
            "Epoch: [75] Total time: 0:00:11 (0.3485 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.5131 (15.7282)  loss_vfl: 0.5765 (0.5984)  loss_bbox: 0.1303 (0.1291)  loss_giou: 0.4716 (0.4827)  loss_vfl_aux_0: 0.5952 (0.6080)  loss_bbox_aux_0: 0.1432 (0.1427)  loss_giou_aux_0: 0.5332 (0.5346)  loss_vfl_aux_1: 0.5899 (0.5892)  loss_bbox_aux_1: 0.1270 (0.1329)  loss_giou_aux_1: 0.4982 (0.5016)  loss_vfl_aux_2: 0.5759 (0.5858)  loss_bbox_aux_2: 0.1258 (0.1309)  loss_giou_aux_2: 0.4790 (0.4929)  loss_vfl_aux_3: 0.5845 (0.5909)  loss_bbox_aux_3: 0.1269 (0.1295)  loss_giou_aux_3: 0.4719 (0.4868)  loss_vfl_aux_4: 0.5809 (0.5905)  loss_bbox_aux_4: 0.1248 (0.1291)  loss_giou_aux_4: 0.4711 (0.4861)  loss_vfl_aux_5: 0.6358 (0.6555)  loss_bbox_aux_5: 0.1736 (0.1917)  loss_giou_aux_5: 0.6321 (0.6679)  loss_vfl_dn_0: 0.4393 (0.4387)  loss_bbox_dn_0: 0.2022 (0.2190)  loss_giou_dn_0: 0.7189 (0.7377)  loss_vfl_dn_1: 0.4218 (0.4252)  loss_bbox_dn_1: 0.1620 (0.1653)  loss_giou_dn_1: 0.5397 (0.5660)  loss_vfl_dn_2: 0.4113 (0.4180)  loss_bbox_dn_2: 0.1536 (0.1531)  loss_giou_dn_2: 0.5123 (0.5252)  loss_vfl_dn_3: 0.4071 (0.4145)  loss_bbox_dn_3: 0.1510 (0.1492)  loss_giou_dn_3: 0.4923 (0.5132)  loss_vfl_dn_4: 0.4077 (0.4151)  loss_bbox_dn_4: 0.1521 (0.1486)  loss_giou_dn_4: 0.4876 (0.5099)  loss_vfl_dn_5: 0.4074 (0.4158)  loss_bbox_dn_5: 0.1519 (0.1483)  loss_giou_dn_5: 0.4860 (0.5090)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8909  data: 0.5771  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4353  data: 0.1117  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4496 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.629\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            "best_stat:  {'epoch': 71, 'coco_eval_bbox': 0.3288741029254648}\n",
            "Epoch: [76]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 17.7569 (17.7569)  loss_vfl: 0.7143 (0.7143)  loss_bbox: 0.1308 (0.1308)  loss_giou: 0.5849 (0.5849)  loss_vfl_aux_0: 0.6541 (0.6541)  loss_bbox_aux_0: 0.1547 (0.1547)  loss_giou_aux_0: 0.6217 (0.6217)  loss_vfl_aux_1: 0.7194 (0.7194)  loss_bbox_aux_1: 0.1318 (0.1318)  loss_giou_aux_1: 0.5896 (0.5896)  loss_vfl_aux_2: 0.6994 (0.6994)  loss_bbox_aux_2: 0.1463 (0.1463)  loss_giou_aux_2: 0.5862 (0.5862)  loss_vfl_aux_3: 0.7075 (0.7075)  loss_bbox_aux_3: 0.1326 (0.1326)  loss_giou_aux_3: 0.5795 (0.5795)  loss_vfl_aux_4: 0.7224 (0.7224)  loss_bbox_aux_4: 0.1326 (0.1326)  loss_giou_aux_4: 0.5797 (0.5797)  loss_vfl_aux_5: 0.6944 (0.6944)  loss_bbox_aux_5: 0.1776 (0.1776)  loss_giou_aux_5: 0.6937 (0.6937)  loss_vfl_dn_0: 0.4313 (0.4313)  loss_bbox_dn_0: 0.2278 (0.2278)  loss_giou_dn_0: 0.7995 (0.7995)  loss_vfl_dn_1: 0.4351 (0.4351)  loss_bbox_dn_1: 0.1938 (0.1938)  loss_giou_dn_1: 0.6467 (0.6467)  loss_vfl_dn_2: 0.4379 (0.4379)  loss_bbox_dn_2: 0.1816 (0.1816)  loss_giou_dn_2: 0.6090 (0.6090)  loss_vfl_dn_3: 0.4343 (0.4343)  loss_bbox_dn_3: 0.1771 (0.1771)  loss_giou_dn_3: 0.6023 (0.6023)  loss_vfl_dn_4: 0.4343 (0.4343)  loss_bbox_dn_4: 0.1766 (0.1766)  loss_giou_dn_4: 0.6035 (0.6035)  loss_vfl_dn_5: 0.4304 (0.4304)  loss_bbox_dn_5: 0.1776 (0.1776)  loss_giou_dn_5: 0.6050 (0.6050)  time: 1.0315  data: 0.6484  max mem: 7790\n",
            "Epoch: [76]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.0625 (15.8547)  loss_vfl: 0.5965 (0.6059)  loss_bbox: 0.1114 (0.1274)  loss_giou: 0.4773 (0.4900)  loss_vfl_aux_0: 0.5869 (0.6072)  loss_bbox_aux_0: 0.1453 (0.1526)  loss_giou_aux_0: 0.5322 (0.5483)  loss_vfl_aux_1: 0.5742 (0.5992)  loss_bbox_aux_1: 0.1202 (0.1366)  loss_giou_aux_1: 0.4857 (0.5102)  loss_vfl_aux_2: 0.5874 (0.5974)  loss_bbox_aux_2: 0.1201 (0.1311)  loss_giou_aux_2: 0.4829 (0.4978)  loss_vfl_aux_3: 0.5973 (0.5999)  loss_bbox_aux_3: 0.1131 (0.1288)  loss_giou_aux_3: 0.4808 (0.4935)  loss_vfl_aux_4: 0.5943 (0.6014)  loss_bbox_aux_4: 0.1103 (0.1277)  loss_giou_aux_4: 0.4792 (0.4910)  loss_vfl_aux_5: 0.6258 (0.6398)  loss_bbox_aux_5: 0.1866 (0.1898)  loss_giou_aux_5: 0.6440 (0.6704)  loss_vfl_dn_0: 0.4374 (0.4374)  loss_bbox_dn_0: 0.2204 (0.2277)  loss_giou_dn_0: 0.7551 (0.7510)  loss_vfl_dn_1: 0.4175 (0.4192)  loss_bbox_dn_1: 0.1527 (0.1723)  loss_giou_dn_1: 0.6087 (0.5729)  loss_vfl_dn_2: 0.4070 (0.4104)  loss_bbox_dn_2: 0.1369 (0.1586)  loss_giou_dn_2: 0.5371 (0.5311)  loss_vfl_dn_3: 0.4075 (0.4061)  loss_bbox_dn_3: 0.1304 (0.1544)  loss_giou_dn_3: 0.5258 (0.5190)  loss_vfl_dn_4: 0.4045 (0.4055)  loss_bbox_dn_4: 0.1289 (0.1534)  loss_giou_dn_4: 0.5198 (0.5164)  loss_vfl_dn_5: 0.4003 (0.4049)  loss_bbox_dn_5: 0.1297 (0.1529)  loss_giou_dn_5: 0.5133 (0.5156)  time: 0.3277  data: 0.0144  max mem: 7790\n",
            "Epoch: [76] Total time: 0:00:11 (0.3502 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.0625 (15.8547)  loss_vfl: 0.5965 (0.6059)  loss_bbox: 0.1114 (0.1274)  loss_giou: 0.4773 (0.4900)  loss_vfl_aux_0: 0.5869 (0.6072)  loss_bbox_aux_0: 0.1453 (0.1526)  loss_giou_aux_0: 0.5322 (0.5483)  loss_vfl_aux_1: 0.5742 (0.5992)  loss_bbox_aux_1: 0.1202 (0.1366)  loss_giou_aux_1: 0.4857 (0.5102)  loss_vfl_aux_2: 0.5874 (0.5974)  loss_bbox_aux_2: 0.1201 (0.1311)  loss_giou_aux_2: 0.4829 (0.4978)  loss_vfl_aux_3: 0.5973 (0.5999)  loss_bbox_aux_3: 0.1131 (0.1288)  loss_giou_aux_3: 0.4808 (0.4935)  loss_vfl_aux_4: 0.5943 (0.6014)  loss_bbox_aux_4: 0.1103 (0.1277)  loss_giou_aux_4: 0.4792 (0.4910)  loss_vfl_aux_5: 0.6258 (0.6398)  loss_bbox_aux_5: 0.1866 (0.1898)  loss_giou_aux_5: 0.6440 (0.6704)  loss_vfl_dn_0: 0.4374 (0.4374)  loss_bbox_dn_0: 0.2204 (0.2277)  loss_giou_dn_0: 0.7551 (0.7510)  loss_vfl_dn_1: 0.4175 (0.4192)  loss_bbox_dn_1: 0.1527 (0.1723)  loss_giou_dn_1: 0.6087 (0.5729)  loss_vfl_dn_2: 0.4070 (0.4104)  loss_bbox_dn_2: 0.1369 (0.1586)  loss_giou_dn_2: 0.5371 (0.5311)  loss_vfl_dn_3: 0.4075 (0.4061)  loss_bbox_dn_3: 0.1304 (0.1544)  loss_giou_dn_3: 0.5258 (0.5190)  loss_vfl_dn_4: 0.4045 (0.4055)  loss_bbox_dn_4: 0.1289 (0.1534)  loss_giou_dn_4: 0.5198 (0.5164)  loss_vfl_dn_5: 0.4003 (0.4049)  loss_bbox_dn_5: 0.1297 (0.1529)  loss_giou_dn_5: 0.5133 (0.5156)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9172  data: 0.6102  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3851  data: 0.1132  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3989 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.660\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.369\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n",
            "best_stat:  {'epoch': 76, 'coco_eval_bbox': 0.33277129658756494}\n",
            "Epoch: [77]  [ 0/33]  eta: 0:00:51  lr: 0.000001  loss: 16.6583 (16.6583)  loss_vfl: 0.6430 (0.6430)  loss_bbox: 0.1167 (0.1167)  loss_giou: 0.5068 (0.5068)  loss_vfl_aux_0: 0.6145 (0.6145)  loss_bbox_aux_0: 0.1253 (0.1253)  loss_giou_aux_0: 0.5834 (0.5834)  loss_vfl_aux_1: 0.6295 (0.6295)  loss_bbox_aux_1: 0.1181 (0.1181)  loss_giou_aux_1: 0.5483 (0.5483)  loss_vfl_aux_2: 0.6299 (0.6299)  loss_bbox_aux_2: 0.1168 (0.1168)  loss_giou_aux_2: 0.5283 (0.5283)  loss_vfl_aux_3: 0.6312 (0.6312)  loss_bbox_aux_3: 0.1165 (0.1165)  loss_giou_aux_3: 0.5213 (0.5213)  loss_vfl_aux_4: 0.6451 (0.6451)  loss_bbox_aux_4: 0.1172 (0.1172)  loss_giou_aux_4: 0.5082 (0.5082)  loss_vfl_aux_5: 0.5867 (0.5867)  loss_bbox_aux_5: 0.2269 (0.2269)  loss_giou_aux_5: 0.8803 (0.8803)  loss_vfl_dn_0: 0.4258 (0.4258)  loss_bbox_dn_0: 0.2309 (0.2309)  loss_giou_dn_0: 0.8053 (0.8053)  loss_vfl_dn_1: 0.4248 (0.4248)  loss_bbox_dn_1: 0.1679 (0.1679)  loss_giou_dn_1: 0.6454 (0.6454)  loss_vfl_dn_2: 0.4185 (0.4185)  loss_bbox_dn_2: 0.1513 (0.1513)  loss_giou_dn_2: 0.5878 (0.5878)  loss_vfl_dn_3: 0.4164 (0.4164)  loss_bbox_dn_3: 0.1470 (0.1470)  loss_giou_dn_3: 0.5757 (0.5757)  loss_vfl_dn_4: 0.4185 (0.4185)  loss_bbox_dn_4: 0.1461 (0.1461)  loss_giou_dn_4: 0.5712 (0.5712)  loss_vfl_dn_5: 0.4169 (0.4169)  loss_bbox_dn_5: 0.1454 (0.1454)  loss_giou_dn_5: 0.5696 (0.5696)  time: 1.5612  data: 0.9554  max mem: 7790\n",
            "Epoch: [77]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.0733 (16.1682)  loss_vfl: 0.5871 (0.6119)  loss_bbox: 0.1427 (0.1402)  loss_giou: 0.5414 (0.4921)  loss_vfl_aux_0: 0.5962 (0.6164)  loss_bbox_aux_0: 0.1487 (0.1599)  loss_giou_aux_0: 0.5715 (0.5558)  loss_vfl_aux_1: 0.5957 (0.6106)  loss_bbox_aux_1: 0.1303 (0.1466)  loss_giou_aux_1: 0.5719 (0.5130)  loss_vfl_aux_2: 0.5881 (0.6081)  loss_bbox_aux_2: 0.1312 (0.1408)  loss_giou_aux_2: 0.5394 (0.4986)  loss_vfl_aux_3: 0.5780 (0.6057)  loss_bbox_aux_3: 0.1435 (0.1431)  loss_giou_aux_3: 0.5468 (0.4954)  loss_vfl_aux_4: 0.5853 (0.6117)  loss_bbox_aux_4: 0.1423 (0.1410)  loss_giou_aux_4: 0.5421 (0.4943)  loss_vfl_aux_5: 0.6470 (0.6447)  loss_bbox_aux_5: 0.1785 (0.2121)  loss_giou_aux_5: 0.7045 (0.6884)  loss_vfl_dn_0: 0.4312 (0.4359)  loss_bbox_dn_0: 0.2173 (0.2391)  loss_giou_dn_0: 0.7920 (0.7557)  loss_vfl_dn_1: 0.4237 (0.4225)  loss_bbox_dn_1: 0.1679 (0.1846)  loss_giou_dn_1: 0.5989 (0.5786)  loss_vfl_dn_2: 0.4144 (0.4157)  loss_bbox_dn_2: 0.1601 (0.1719)  loss_giou_dn_2: 0.5757 (0.5352)  loss_vfl_dn_3: 0.4120 (0.4124)  loss_bbox_dn_3: 0.1557 (0.1683)  loss_giou_dn_3: 0.5652 (0.5222)  loss_vfl_dn_4: 0.4104 (0.4119)  loss_bbox_dn_4: 0.1565 (0.1679)  loss_giou_dn_4: 0.5640 (0.5186)  loss_vfl_dn_5: 0.4094 (0.4117)  loss_bbox_dn_5: 0.1568 (0.1680)  loss_giou_dn_5: 0.5647 (0.5177)  time: 0.3326  data: 0.0162  max mem: 7790\n",
            "Epoch: [77] Total time: 0:00:12 (0.3719 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.0733 (16.1682)  loss_vfl: 0.5871 (0.6119)  loss_bbox: 0.1427 (0.1402)  loss_giou: 0.5414 (0.4921)  loss_vfl_aux_0: 0.5962 (0.6164)  loss_bbox_aux_0: 0.1487 (0.1599)  loss_giou_aux_0: 0.5715 (0.5558)  loss_vfl_aux_1: 0.5957 (0.6106)  loss_bbox_aux_1: 0.1303 (0.1466)  loss_giou_aux_1: 0.5719 (0.5130)  loss_vfl_aux_2: 0.5881 (0.6081)  loss_bbox_aux_2: 0.1312 (0.1408)  loss_giou_aux_2: 0.5394 (0.4986)  loss_vfl_aux_3: 0.5780 (0.6057)  loss_bbox_aux_3: 0.1435 (0.1431)  loss_giou_aux_3: 0.5468 (0.4954)  loss_vfl_aux_4: 0.5853 (0.6117)  loss_bbox_aux_4: 0.1423 (0.1410)  loss_giou_aux_4: 0.5421 (0.4943)  loss_vfl_aux_5: 0.6470 (0.6447)  loss_bbox_aux_5: 0.1785 (0.2121)  loss_giou_aux_5: 0.7045 (0.6884)  loss_vfl_dn_0: 0.4312 (0.4359)  loss_bbox_dn_0: 0.2173 (0.2391)  loss_giou_dn_0: 0.7920 (0.7557)  loss_vfl_dn_1: 0.4237 (0.4225)  loss_bbox_dn_1: 0.1679 (0.1846)  loss_giou_dn_1: 0.5989 (0.5786)  loss_vfl_dn_2: 0.4144 (0.4157)  loss_bbox_dn_2: 0.1601 (0.1719)  loss_giou_dn_2: 0.5757 (0.5352)  loss_vfl_dn_3: 0.4120 (0.4124)  loss_bbox_dn_3: 0.1557 (0.1683)  loss_giou_dn_3: 0.5652 (0.5222)  loss_vfl_dn_4: 0.4104 (0.4119)  loss_bbox_dn_4: 0.1565 (0.1679)  loss_giou_dn_4: 0.5640 (0.5186)  loss_vfl_dn_5: 0.4094 (0.4117)  loss_bbox_dn_5: 0.1568 (0.1680)  loss_giou_dn_5: 0.5647 (0.5177)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8497  data: 0.5284  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3842  data: 0.1087  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3964 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "best_stat:  {'epoch': 76, 'coco_eval_bbox': 0.33277129658756494}\n",
            "Epoch: [78]  [ 0/33]  eta: 0:00:28  lr: 0.000001  loss: 16.6620 (16.6620)  loss_vfl: 0.6033 (0.6033)  loss_bbox: 0.1595 (0.1595)  loss_giou: 0.5110 (0.5110)  loss_vfl_aux_0: 0.5410 (0.5410)  loss_bbox_aux_0: 0.2192 (0.2192)  loss_giou_aux_0: 0.6267 (0.6267)  loss_vfl_aux_1: 0.5523 (0.5523)  loss_bbox_aux_1: 0.2020 (0.2020)  loss_giou_aux_1: 0.5534 (0.5534)  loss_vfl_aux_2: 0.5417 (0.5417)  loss_bbox_aux_2: 0.1893 (0.1893)  loss_giou_aux_2: 0.5284 (0.5284)  loss_vfl_aux_3: 0.5544 (0.5544)  loss_bbox_aux_3: 0.1772 (0.1772)  loss_giou_aux_3: 0.5238 (0.5238)  loss_vfl_aux_4: 0.5827 (0.5827)  loss_bbox_aux_4: 0.1757 (0.1757)  loss_giou_aux_4: 0.5176 (0.5176)  loss_vfl_aux_5: 0.6286 (0.6286)  loss_bbox_aux_5: 0.2586 (0.2586)  loss_giou_aux_5: 0.7689 (0.7689)  loss_vfl_dn_0: 0.4358 (0.4358)  loss_bbox_dn_0: 0.2401 (0.2401)  loss_giou_dn_0: 0.7613 (0.7613)  loss_vfl_dn_1: 0.4298 (0.4298)  loss_bbox_dn_1: 0.1876 (0.1876)  loss_giou_dn_1: 0.5764 (0.5764)  loss_vfl_dn_2: 0.4267 (0.4267)  loss_bbox_dn_2: 0.1871 (0.1871)  loss_giou_dn_2: 0.5444 (0.5444)  loss_vfl_dn_3: 0.4288 (0.4288)  loss_bbox_dn_3: 0.1866 (0.1866)  loss_giou_dn_3: 0.5369 (0.5369)  loss_vfl_dn_4: 0.4306 (0.4306)  loss_bbox_dn_4: 0.1871 (0.1871)  loss_giou_dn_4: 0.5347 (0.5347)  loss_vfl_dn_5: 0.4284 (0.4284)  loss_bbox_dn_5: 0.1875 (0.1875)  loss_giou_dn_5: 0.5367 (0.5367)  time: 0.8569  data: 0.4983  max mem: 7790\n",
            "Epoch: [78]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.7013 (15.9305)  loss_vfl: 0.5913 (0.5810)  loss_bbox: 0.1114 (0.1182)  loss_giou: 0.5391 (0.5284)  loss_vfl_aux_0: 0.5801 (0.5695)  loss_bbox_aux_0: 0.1345 (0.1380)  loss_giou_aux_0: 0.5858 (0.6000)  loss_vfl_aux_1: 0.5653 (0.5671)  loss_bbox_aux_1: 0.1212 (0.1247)  loss_giou_aux_1: 0.5622 (0.5532)  loss_vfl_aux_2: 0.5667 (0.5715)  loss_bbox_aux_2: 0.1180 (0.1231)  loss_giou_aux_2: 0.5509 (0.5388)  loss_vfl_aux_3: 0.5757 (0.5717)  loss_bbox_aux_3: 0.1138 (0.1203)  loss_giou_aux_3: 0.5489 (0.5333)  loss_vfl_aux_4: 0.5758 (0.5761)  loss_bbox_aux_4: 0.1136 (0.1190)  loss_giou_aux_4: 0.5440 (0.5303)  loss_vfl_aux_5: 0.6173 (0.6068)  loss_bbox_aux_5: 0.1729 (0.1819)  loss_giou_aux_5: 0.7403 (0.7259)  loss_vfl_dn_0: 0.4360 (0.4380)  loss_bbox_dn_0: 0.1651 (0.1929)  loss_giou_dn_0: 0.7447 (0.7597)  loss_vfl_dn_1: 0.4221 (0.4232)  loss_bbox_dn_1: 0.1283 (0.1476)  loss_giou_dn_1: 0.5989 (0.6001)  loss_vfl_dn_2: 0.4114 (0.4158)  loss_bbox_dn_2: 0.1142 (0.1375)  loss_giou_dn_2: 0.5471 (0.5598)  loss_vfl_dn_3: 0.4070 (0.4122)  loss_bbox_dn_3: 0.1116 (0.1344)  loss_giou_dn_3: 0.5320 (0.5481)  loss_vfl_dn_4: 0.4059 (0.4122)  loss_bbox_dn_4: 0.1115 (0.1341)  loss_giou_dn_4: 0.5237 (0.5456)  loss_vfl_dn_5: 0.4058 (0.4114)  loss_bbox_dn_5: 0.1118 (0.1337)  loss_giou_dn_5: 0.5214 (0.5453)  time: 0.3376  data: 0.0144  max mem: 7790\n",
            "Epoch: [78] Total time: 0:00:11 (0.3532 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.7013 (15.9305)  loss_vfl: 0.5913 (0.5810)  loss_bbox: 0.1114 (0.1182)  loss_giou: 0.5391 (0.5284)  loss_vfl_aux_0: 0.5801 (0.5695)  loss_bbox_aux_0: 0.1345 (0.1380)  loss_giou_aux_0: 0.5858 (0.6000)  loss_vfl_aux_1: 0.5653 (0.5671)  loss_bbox_aux_1: 0.1212 (0.1247)  loss_giou_aux_1: 0.5622 (0.5532)  loss_vfl_aux_2: 0.5667 (0.5715)  loss_bbox_aux_2: 0.1180 (0.1231)  loss_giou_aux_2: 0.5509 (0.5388)  loss_vfl_aux_3: 0.5757 (0.5717)  loss_bbox_aux_3: 0.1138 (0.1203)  loss_giou_aux_3: 0.5489 (0.5333)  loss_vfl_aux_4: 0.5758 (0.5761)  loss_bbox_aux_4: 0.1136 (0.1190)  loss_giou_aux_4: 0.5440 (0.5303)  loss_vfl_aux_5: 0.6173 (0.6068)  loss_bbox_aux_5: 0.1729 (0.1819)  loss_giou_aux_5: 0.7403 (0.7259)  loss_vfl_dn_0: 0.4360 (0.4380)  loss_bbox_dn_0: 0.1651 (0.1929)  loss_giou_dn_0: 0.7447 (0.7597)  loss_vfl_dn_1: 0.4221 (0.4232)  loss_bbox_dn_1: 0.1283 (0.1476)  loss_giou_dn_1: 0.5989 (0.6001)  loss_vfl_dn_2: 0.4114 (0.4158)  loss_bbox_dn_2: 0.1142 (0.1375)  loss_giou_dn_2: 0.5471 (0.5598)  loss_vfl_dn_3: 0.4070 (0.4122)  loss_bbox_dn_3: 0.1116 (0.1344)  loss_giou_dn_3: 0.5320 (0.5481)  loss_vfl_dn_4: 0.4059 (0.4122)  loss_bbox_dn_4: 0.1115 (0.1341)  loss_giou_dn_4: 0.5237 (0.5456)  loss_vfl_dn_5: 0.4058 (0.4114)  loss_bbox_dn_5: 0.1118 (0.1337)  loss_giou_dn_5: 0.5214 (0.5453)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8972  data: 0.5901  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3827  data: 0.1100  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3967 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.669\n",
            "best_stat:  {'epoch': 76, 'coco_eval_bbox': 0.33277129658756494}\n",
            "Epoch: [79]  [ 0/33]  eta: 0:00:38  lr: 0.000001  loss: 17.6342 (17.6342)  loss_vfl: 0.6758 (0.6758)  loss_bbox: 0.1866 (0.1866)  loss_giou: 0.5756 (0.5756)  loss_vfl_aux_0: 0.6951 (0.6951)  loss_bbox_aux_0: 0.1852 (0.1852)  loss_giou_aux_0: 0.6323 (0.6323)  loss_vfl_aux_1: 0.6665 (0.6665)  loss_bbox_aux_1: 0.1983 (0.1983)  loss_giou_aux_1: 0.5921 (0.5921)  loss_vfl_aux_2: 0.6764 (0.6764)  loss_bbox_aux_2: 0.1887 (0.1887)  loss_giou_aux_2: 0.5614 (0.5614)  loss_vfl_aux_3: 0.6557 (0.6557)  loss_bbox_aux_3: 0.1851 (0.1851)  loss_giou_aux_3: 0.5622 (0.5622)  loss_vfl_aux_4: 0.6733 (0.6733)  loss_bbox_aux_4: 0.1862 (0.1862)  loss_giou_aux_4: 0.5733 (0.5733)  loss_vfl_aux_5: 0.7244 (0.7244)  loss_bbox_aux_5: 0.2184 (0.2184)  loss_giou_aux_5: 0.7252 (0.7252)  loss_vfl_dn_0: 0.4265 (0.4265)  loss_bbox_dn_0: 0.2407 (0.2407)  loss_giou_dn_0: 0.7890 (0.7890)  loss_vfl_dn_1: 0.4166 (0.4166)  loss_bbox_dn_1: 0.1811 (0.1811)  loss_giou_dn_1: 0.6353 (0.6353)  loss_vfl_dn_2: 0.4133 (0.4133)  loss_bbox_dn_2: 0.1731 (0.1731)  loss_giou_dn_2: 0.5770 (0.5770)  loss_vfl_dn_3: 0.4163 (0.4163)  loss_bbox_dn_3: 0.1683 (0.1683)  loss_giou_dn_3: 0.5668 (0.5668)  loss_vfl_dn_4: 0.4198 (0.4198)  loss_bbox_dn_4: 0.1684 (0.1684)  loss_giou_dn_4: 0.5592 (0.5592)  loss_vfl_dn_5: 0.4209 (0.4209)  loss_bbox_dn_5: 0.1682 (0.1682)  loss_giou_dn_5: 0.5558 (0.5558)  time: 1.1736  data: 0.7414  max mem: 7790\n",
            "Epoch: [79]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.0053 (16.0435)  loss_vfl: 0.5464 (0.5923)  loss_bbox: 0.0951 (0.1294)  loss_giou: 0.4966 (0.5018)  loss_vfl_aux_0: 0.5680 (0.6158)  loss_bbox_aux_0: 0.1178 (0.1499)  loss_giou_aux_0: 0.5645 (0.5689)  loss_vfl_aux_1: 0.5641 (0.5967)  loss_bbox_aux_1: 0.1108 (0.1395)  loss_giou_aux_1: 0.5285 (0.5264)  loss_vfl_aux_2: 0.5399 (0.5921)  loss_bbox_aux_2: 0.1020 (0.1339)  loss_giou_aux_2: 0.5095 (0.5104)  loss_vfl_aux_3: 0.5393 (0.5926)  loss_bbox_aux_3: 0.0960 (0.1299)  loss_giou_aux_3: 0.4932 (0.5050)  loss_vfl_aux_4: 0.5340 (0.5892)  loss_bbox_aux_4: 0.0949 (0.1298)  loss_giou_aux_4: 0.4968 (0.5034)  loss_vfl_aux_5: 0.5971 (0.6377)  loss_bbox_aux_5: 0.1483 (0.1898)  loss_giou_aux_5: 0.6916 (0.6948)  loss_vfl_dn_0: 0.4360 (0.4341)  loss_bbox_dn_0: 0.1756 (0.2199)  loss_giou_dn_0: 0.7776 (0.7584)  loss_vfl_dn_1: 0.4195 (0.4230)  loss_bbox_dn_1: 0.1294 (0.1693)  loss_giou_dn_1: 0.5797 (0.5902)  loss_vfl_dn_2: 0.4111 (0.4153)  loss_bbox_dn_2: 0.1225 (0.1571)  loss_giou_dn_2: 0.5278 (0.5483)  loss_vfl_dn_3: 0.4081 (0.4126)  loss_bbox_dn_3: 0.1214 (0.1541)  loss_giou_dn_3: 0.5112 (0.5361)  loss_vfl_dn_4: 0.4096 (0.4113)  loss_bbox_dn_4: 0.1217 (0.1534)  loss_giou_dn_4: 0.5134 (0.5335)  loss_vfl_dn_5: 0.4081 (0.4113)  loss_bbox_dn_5: 0.1213 (0.1531)  loss_giou_dn_5: 0.5126 (0.5331)  time: 0.3419  data: 0.0137  max mem: 7790\n",
            "Epoch: [79] Total time: 0:00:12 (0.3665 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.0053 (16.0435)  loss_vfl: 0.5464 (0.5923)  loss_bbox: 0.0951 (0.1294)  loss_giou: 0.4966 (0.5018)  loss_vfl_aux_0: 0.5680 (0.6158)  loss_bbox_aux_0: 0.1178 (0.1499)  loss_giou_aux_0: 0.5645 (0.5689)  loss_vfl_aux_1: 0.5641 (0.5967)  loss_bbox_aux_1: 0.1108 (0.1395)  loss_giou_aux_1: 0.5285 (0.5264)  loss_vfl_aux_2: 0.5399 (0.5921)  loss_bbox_aux_2: 0.1020 (0.1339)  loss_giou_aux_2: 0.5095 (0.5104)  loss_vfl_aux_3: 0.5393 (0.5926)  loss_bbox_aux_3: 0.0960 (0.1299)  loss_giou_aux_3: 0.4932 (0.5050)  loss_vfl_aux_4: 0.5340 (0.5892)  loss_bbox_aux_4: 0.0949 (0.1298)  loss_giou_aux_4: 0.4968 (0.5034)  loss_vfl_aux_5: 0.5971 (0.6377)  loss_bbox_aux_5: 0.1483 (0.1898)  loss_giou_aux_5: 0.6916 (0.6948)  loss_vfl_dn_0: 0.4360 (0.4341)  loss_bbox_dn_0: 0.1756 (0.2199)  loss_giou_dn_0: 0.7776 (0.7584)  loss_vfl_dn_1: 0.4195 (0.4230)  loss_bbox_dn_1: 0.1294 (0.1693)  loss_giou_dn_1: 0.5797 (0.5902)  loss_vfl_dn_2: 0.4111 (0.4153)  loss_bbox_dn_2: 0.1225 (0.1571)  loss_giou_dn_2: 0.5278 (0.5483)  loss_vfl_dn_3: 0.4081 (0.4126)  loss_bbox_dn_3: 0.1214 (0.1541)  loss_giou_dn_3: 0.5112 (0.5361)  loss_vfl_dn_4: 0.4096 (0.4113)  loss_bbox_dn_4: 0.1217 (0.1534)  loss_giou_dn_4: 0.5134 (0.5335)  loss_vfl_dn_5: 0.4081 (0.4113)  loss_bbox_dn_5: 0.1213 (0.1531)  loss_giou_dn_5: 0.5126 (0.5331)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8397  data: 0.5310  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3815  data: 0.1091  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3937 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678\n",
            "best_stat:  {'epoch': 76, 'coco_eval_bbox': 0.33277129658756494}\n",
            "Epoch: [80]  [ 0/33]  eta: 0:00:28  lr: 0.000001  loss: 15.9877 (15.9877)  loss_vfl: 0.6448 (0.6448)  loss_bbox: 0.1415 (0.1415)  loss_giou: 0.4930 (0.4930)  loss_vfl_aux_0: 0.5932 (0.5932)  loss_bbox_aux_0: 0.1610 (0.1610)  loss_giou_aux_0: 0.5466 (0.5466)  loss_vfl_aux_1: 0.5931 (0.5931)  loss_bbox_aux_1: 0.1574 (0.1574)  loss_giou_aux_1: 0.5069 (0.5069)  loss_vfl_aux_2: 0.6031 (0.6031)  loss_bbox_aux_2: 0.1558 (0.1558)  loss_giou_aux_2: 0.5069 (0.5069)  loss_vfl_aux_3: 0.6389 (0.6389)  loss_bbox_aux_3: 0.1463 (0.1463)  loss_giou_aux_3: 0.5003 (0.5003)  loss_vfl_aux_4: 0.6306 (0.6306)  loss_bbox_aux_4: 0.1491 (0.1491)  loss_giou_aux_4: 0.5011 (0.5011)  loss_vfl_aux_5: 0.6518 (0.6518)  loss_bbox_aux_5: 0.1924 (0.1924)  loss_giou_aux_5: 0.5921 (0.5921)  loss_vfl_dn_0: 0.4339 (0.4339)  loss_bbox_dn_0: 0.2334 (0.2334)  loss_giou_dn_0: 0.7486 (0.7486)  loss_vfl_dn_1: 0.4191 (0.4191)  loss_bbox_dn_1: 0.1678 (0.1678)  loss_giou_dn_1: 0.5636 (0.5636)  loss_vfl_dn_2: 0.4108 (0.4108)  loss_bbox_dn_2: 0.1572 (0.1572)  loss_giou_dn_2: 0.5285 (0.5285)  loss_vfl_dn_3: 0.4045 (0.4045)  loss_bbox_dn_3: 0.1517 (0.1517)  loss_giou_dn_3: 0.5240 (0.5240)  loss_vfl_dn_4: 0.4018 (0.4018)  loss_bbox_dn_4: 0.1495 (0.1495)  loss_giou_dn_4: 0.5166 (0.5166)  loss_vfl_dn_5: 0.4051 (0.4051)  loss_bbox_dn_5: 0.1493 (0.1493)  loss_giou_dn_5: 0.5163 (0.5163)  time: 0.8586  data: 0.4685  max mem: 7790\n",
            "Epoch: [80]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.8572 (16.1223)  loss_vfl: 0.5858 (0.5936)  loss_bbox: 0.1052 (0.1169)  loss_giou: 0.4966 (0.5286)  loss_vfl_aux_0: 0.5765 (0.6097)  loss_bbox_aux_0: 0.1282 (0.1372)  loss_giou_aux_0: 0.5699 (0.5829)  loss_vfl_aux_1: 0.5684 (0.5897)  loss_bbox_aux_1: 0.1155 (0.1237)  loss_giou_aux_1: 0.5086 (0.5442)  loss_vfl_aux_2: 0.5896 (0.5889)  loss_bbox_aux_2: 0.1063 (0.1190)  loss_giou_aux_2: 0.4991 (0.5337)  loss_vfl_aux_3: 0.5962 (0.5905)  loss_bbox_aux_3: 0.1039 (0.1163)  loss_giou_aux_3: 0.5014 (0.5303)  loss_vfl_aux_4: 0.5892 (0.5906)  loss_bbox_aux_4: 0.1041 (0.1170)  loss_giou_aux_4: 0.4967 (0.5290)  loss_vfl_aux_5: 0.5965 (0.6274)  loss_bbox_aux_5: 0.1585 (0.1806)  loss_giou_aux_5: 0.6681 (0.7000)  loss_vfl_dn_0: 0.4311 (0.4340)  loss_bbox_dn_0: 0.1937 (0.2060)  loss_giou_dn_0: 0.7576 (0.7725)  loss_vfl_dn_1: 0.4252 (0.4233)  loss_bbox_dn_1: 0.1416 (0.1589)  loss_giou_dn_1: 0.5877 (0.6099)  loss_vfl_dn_2: 0.4196 (0.4174)  loss_bbox_dn_2: 0.1274 (0.1459)  loss_giou_dn_2: 0.5502 (0.5690)  loss_vfl_dn_3: 0.4206 (0.4146)  loss_bbox_dn_3: 0.1240 (0.1427)  loss_giou_dn_3: 0.5380 (0.5574)  loss_vfl_dn_4: 0.4158 (0.4139)  loss_bbox_dn_4: 0.1253 (0.1421)  loss_giou_dn_4: 0.5353 (0.5546)  loss_vfl_dn_5: 0.4149 (0.4146)  loss_bbox_dn_5: 0.1257 (0.1419)  loss_giou_dn_5: 0.5373 (0.5539)  time: 0.3273  data: 0.0142  max mem: 7790\n",
            "Epoch: [80] Total time: 0:00:11 (0.3472 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.8572 (16.1223)  loss_vfl: 0.5858 (0.5936)  loss_bbox: 0.1052 (0.1169)  loss_giou: 0.4966 (0.5286)  loss_vfl_aux_0: 0.5765 (0.6097)  loss_bbox_aux_0: 0.1282 (0.1372)  loss_giou_aux_0: 0.5699 (0.5829)  loss_vfl_aux_1: 0.5684 (0.5897)  loss_bbox_aux_1: 0.1155 (0.1237)  loss_giou_aux_1: 0.5086 (0.5442)  loss_vfl_aux_2: 0.5896 (0.5889)  loss_bbox_aux_2: 0.1063 (0.1190)  loss_giou_aux_2: 0.4991 (0.5337)  loss_vfl_aux_3: 0.5962 (0.5905)  loss_bbox_aux_3: 0.1039 (0.1163)  loss_giou_aux_3: 0.5014 (0.5303)  loss_vfl_aux_4: 0.5892 (0.5906)  loss_bbox_aux_4: 0.1041 (0.1170)  loss_giou_aux_4: 0.4967 (0.5290)  loss_vfl_aux_5: 0.5965 (0.6274)  loss_bbox_aux_5: 0.1585 (0.1806)  loss_giou_aux_5: 0.6681 (0.7000)  loss_vfl_dn_0: 0.4311 (0.4340)  loss_bbox_dn_0: 0.1937 (0.2060)  loss_giou_dn_0: 0.7576 (0.7725)  loss_vfl_dn_1: 0.4252 (0.4233)  loss_bbox_dn_1: 0.1416 (0.1589)  loss_giou_dn_1: 0.5877 (0.6099)  loss_vfl_dn_2: 0.4196 (0.4174)  loss_bbox_dn_2: 0.1274 (0.1459)  loss_giou_dn_2: 0.5502 (0.5690)  loss_vfl_dn_3: 0.4206 (0.4146)  loss_bbox_dn_3: 0.1240 (0.1427)  loss_giou_dn_3: 0.5380 (0.5574)  loss_vfl_dn_4: 0.4158 (0.4139)  loss_bbox_dn_4: 0.1253 (0.1421)  loss_giou_dn_4: 0.5353 (0.5546)  loss_vfl_dn_5: 0.4149 (0.4146)  loss_bbox_dn_5: 0.1257 (0.1419)  loss_giou_dn_5: 0.5373 (0.5539)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8883  data: 0.5660  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3988  data: 0.1112  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4116 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.636\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "best_stat:  {'epoch': 76, 'coco_eval_bbox': 0.33277129658756494}\n",
            "Epoch: [81]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 13.8291 (13.8291)  loss_vfl: 0.6010 (0.6010)  loss_bbox: 0.0843 (0.0843)  loss_giou: 0.3669 (0.3669)  loss_vfl_aux_0: 0.6067 (0.6067)  loss_bbox_aux_0: 0.1137 (0.1137)  loss_giou_aux_0: 0.4494 (0.4494)  loss_vfl_aux_1: 0.5148 (0.5148)  loss_bbox_aux_1: 0.0965 (0.0965)  loss_giou_aux_1: 0.4137 (0.4137)  loss_vfl_aux_2: 0.5764 (0.5764)  loss_bbox_aux_2: 0.0909 (0.0909)  loss_giou_aux_2: 0.3834 (0.3834)  loss_vfl_aux_3: 0.5565 (0.5565)  loss_bbox_aux_3: 0.0902 (0.0902)  loss_giou_aux_3: 0.3941 (0.3941)  loss_vfl_aux_4: 0.6010 (0.6010)  loss_bbox_aux_4: 0.0878 (0.0878)  loss_giou_aux_4: 0.3775 (0.3775)  loss_vfl_aux_5: 0.6500 (0.6500)  loss_bbox_aux_5: 0.1798 (0.1798)  loss_giou_aux_5: 0.6133 (0.6133)  loss_vfl_dn_0: 0.4438 (0.4438)  loss_bbox_dn_0: 0.1869 (0.1869)  loss_giou_dn_0: 0.6668 (0.6668)  loss_vfl_dn_1: 0.4076 (0.4076)  loss_bbox_dn_1: 0.1243 (0.1243)  loss_giou_dn_1: 0.4584 (0.4584)  loss_vfl_dn_2: 0.3973 (0.3973)  loss_bbox_dn_2: 0.1163 (0.1163)  loss_giou_dn_2: 0.4242 (0.4242)  loss_vfl_dn_3: 0.3927 (0.3927)  loss_bbox_dn_3: 0.1117 (0.1117)  loss_giou_dn_3: 0.4175 (0.4175)  loss_vfl_dn_4: 0.3932 (0.3932)  loss_bbox_dn_4: 0.1113 (0.1113)  loss_giou_dn_4: 0.4153 (0.4153)  loss_vfl_dn_5: 0.3900 (0.3900)  loss_bbox_dn_5: 0.1099 (0.1099)  loss_giou_dn_5: 0.4141 (0.4141)  time: 1.0551  data: 0.6134  max mem: 7790\n",
            "Epoch: [81]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.9697 (15.6406)  loss_vfl: 0.5871 (0.5936)  loss_bbox: 0.1147 (0.1207)  loss_giou: 0.4435 (0.4755)  loss_vfl_aux_0: 0.6383 (0.6239)  loss_bbox_aux_0: 0.1332 (0.1354)  loss_giou_aux_0: 0.5076 (0.5301)  loss_vfl_aux_1: 0.6085 (0.6035)  loss_bbox_aux_1: 0.1088 (0.1256)  loss_giou_aux_1: 0.4662 (0.4924)  loss_vfl_aux_2: 0.6028 (0.5952)  loss_bbox_aux_2: 0.1147 (0.1240)  loss_giou_aux_2: 0.4473 (0.4817)  loss_vfl_aux_3: 0.6190 (0.5959)  loss_bbox_aux_3: 0.1151 (0.1223)  loss_giou_aux_3: 0.4386 (0.4771)  loss_vfl_aux_4: 0.5924 (0.5932)  loss_bbox_aux_4: 0.1153 (0.1211)  loss_giou_aux_4: 0.4451 (0.4765)  loss_vfl_aux_5: 0.6370 (0.6401)  loss_bbox_aux_5: 0.1793 (0.1819)  loss_giou_aux_5: 0.6352 (0.6494)  loss_vfl_dn_0: 0.4370 (0.4377)  loss_bbox_dn_0: 0.2050 (0.2176)  loss_giou_dn_0: 0.7212 (0.7484)  loss_vfl_dn_1: 0.4227 (0.4239)  loss_bbox_dn_1: 0.1561 (0.1663)  loss_giou_dn_1: 0.5401 (0.5728)  loss_vfl_dn_2: 0.4109 (0.4144)  loss_bbox_dn_2: 0.1490 (0.1531)  loss_giou_dn_2: 0.4671 (0.5290)  loss_vfl_dn_3: 0.4098 (0.4108)  loss_bbox_dn_3: 0.1417 (0.1499)  loss_giou_dn_3: 0.4533 (0.5158)  loss_vfl_dn_4: 0.4107 (0.4098)  loss_bbox_dn_4: 0.1420 (0.1493)  loss_giou_dn_4: 0.4448 (0.5125)  loss_vfl_dn_5: 0.4082 (0.4100)  loss_bbox_dn_5: 0.1409 (0.1490)  loss_giou_dn_5: 0.4419 (0.5113)  time: 0.3271  data: 0.0137  max mem: 7790\n",
            "Epoch: [81] Total time: 0:00:11 (0.3512 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.9697 (15.6406)  loss_vfl: 0.5871 (0.5936)  loss_bbox: 0.1147 (0.1207)  loss_giou: 0.4435 (0.4755)  loss_vfl_aux_0: 0.6383 (0.6239)  loss_bbox_aux_0: 0.1332 (0.1354)  loss_giou_aux_0: 0.5076 (0.5301)  loss_vfl_aux_1: 0.6085 (0.6035)  loss_bbox_aux_1: 0.1088 (0.1256)  loss_giou_aux_1: 0.4662 (0.4924)  loss_vfl_aux_2: 0.6028 (0.5952)  loss_bbox_aux_2: 0.1147 (0.1240)  loss_giou_aux_2: 0.4473 (0.4817)  loss_vfl_aux_3: 0.6190 (0.5959)  loss_bbox_aux_3: 0.1151 (0.1223)  loss_giou_aux_3: 0.4386 (0.4771)  loss_vfl_aux_4: 0.5924 (0.5932)  loss_bbox_aux_4: 0.1153 (0.1211)  loss_giou_aux_4: 0.4451 (0.4765)  loss_vfl_aux_5: 0.6370 (0.6401)  loss_bbox_aux_5: 0.1793 (0.1819)  loss_giou_aux_5: 0.6352 (0.6494)  loss_vfl_dn_0: 0.4370 (0.4377)  loss_bbox_dn_0: 0.2050 (0.2176)  loss_giou_dn_0: 0.7212 (0.7484)  loss_vfl_dn_1: 0.4227 (0.4239)  loss_bbox_dn_1: 0.1561 (0.1663)  loss_giou_dn_1: 0.5401 (0.5728)  loss_vfl_dn_2: 0.4109 (0.4144)  loss_bbox_dn_2: 0.1490 (0.1531)  loss_giou_dn_2: 0.4671 (0.5290)  loss_vfl_dn_3: 0.4098 (0.4108)  loss_bbox_dn_3: 0.1417 (0.1499)  loss_giou_dn_3: 0.4533 (0.5158)  loss_vfl_dn_4: 0.4107 (0.4098)  loss_bbox_dn_4: 0.1420 (0.1493)  loss_giou_dn_4: 0.4448 (0.5125)  loss_vfl_dn_5: 0.4082 (0.4100)  loss_bbox_dn_5: 0.1409 (0.1490)  loss_giou_dn_5: 0.4419 (0.5113)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8653  data: 0.5541  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3877  data: 0.1117  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4015 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.223\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "best_stat:  {'epoch': 76, 'coco_eval_bbox': 0.33277129658756494}\n",
            "Epoch: [82]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 15.1843 (15.1843)  loss_vfl: 0.5740 (0.5740)  loss_bbox: 0.1107 (0.1107)  loss_giou: 0.4827 (0.4827)  loss_vfl_aux_0: 0.5888 (0.5888)  loss_bbox_aux_0: 0.1098 (0.1098)  loss_giou_aux_0: 0.5271 (0.5271)  loss_vfl_aux_1: 0.5822 (0.5822)  loss_bbox_aux_1: 0.0987 (0.0987)  loss_giou_aux_1: 0.4670 (0.4670)  loss_vfl_aux_2: 0.5774 (0.5774)  loss_bbox_aux_2: 0.1035 (0.1035)  loss_giou_aux_2: 0.4721 (0.4721)  loss_vfl_aux_3: 0.5713 (0.5713)  loss_bbox_aux_3: 0.1064 (0.1064)  loss_giou_aux_3: 0.4749 (0.4749)  loss_vfl_aux_4: 0.5768 (0.5768)  loss_bbox_aux_4: 0.1093 (0.1093)  loss_giou_aux_4: 0.4803 (0.4803)  loss_vfl_aux_5: 0.6025 (0.6025)  loss_bbox_aux_5: 0.1894 (0.1894)  loss_giou_aux_5: 0.7450 (0.7450)  loss_vfl_dn_0: 0.4337 (0.4337)  loss_bbox_dn_0: 0.1879 (0.1879)  loss_giou_dn_0: 0.7569 (0.7569)  loss_vfl_dn_1: 0.4137 (0.4137)  loss_bbox_dn_1: 0.1356 (0.1356)  loss_giou_dn_1: 0.5613 (0.5613)  loss_vfl_dn_2: 0.4010 (0.4010)  loss_bbox_dn_2: 0.1277 (0.1277)  loss_giou_dn_2: 0.5172 (0.5172)  loss_vfl_dn_3: 0.3993 (0.3993)  loss_bbox_dn_3: 0.1260 (0.1260)  loss_giou_dn_3: 0.5059 (0.5059)  loss_vfl_dn_4: 0.4008 (0.4008)  loss_bbox_dn_4: 0.1271 (0.1271)  loss_giou_dn_4: 0.5065 (0.5065)  loss_vfl_dn_5: 0.3991 (0.3991)  loss_bbox_dn_5: 0.1268 (0.1268)  loss_giou_dn_5: 0.5080 (0.5080)  time: 1.0477  data: 0.6783  max mem: 7790\n",
            "Epoch: [82]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.5482 (15.7470)  loss_vfl: 0.5703 (0.5909)  loss_bbox: 0.1073 (0.1213)  loss_giou: 0.5082 (0.4870)  loss_vfl_aux_0: 0.5819 (0.6077)  loss_bbox_aux_0: 0.1268 (0.1360)  loss_giou_aux_0: 0.5344 (0.5424)  loss_vfl_aux_1: 0.5678 (0.5870)  loss_bbox_aux_1: 0.1149 (0.1268)  loss_giou_aux_1: 0.5140 (0.5074)  loss_vfl_aux_2: 0.5783 (0.5909)  loss_bbox_aux_2: 0.1148 (0.1241)  loss_giou_aux_2: 0.5127 (0.4943)  loss_vfl_aux_3: 0.5546 (0.5931)  loss_bbox_aux_3: 0.1120 (0.1213)  loss_giou_aux_3: 0.5019 (0.4883)  loss_vfl_aux_4: 0.5620 (0.5902)  loss_bbox_aux_4: 0.1077 (0.1208)  loss_giou_aux_4: 0.5182 (0.4874)  loss_vfl_aux_5: 0.6045 (0.6292)  loss_bbox_aux_5: 0.1718 (0.2008)  loss_giou_aux_5: 0.6362 (0.6825)  loss_vfl_dn_0: 0.4319 (0.4343)  loss_bbox_dn_0: 0.1976 (0.2303)  loss_giou_dn_0: 0.7424 (0.7564)  loss_vfl_dn_1: 0.4225 (0.4213)  loss_bbox_dn_1: 0.1388 (0.1675)  loss_giou_dn_1: 0.5618 (0.5766)  loss_vfl_dn_2: 0.4081 (0.4117)  loss_bbox_dn_2: 0.1260 (0.1544)  loss_giou_dn_2: 0.5200 (0.5357)  loss_vfl_dn_3: 0.4073 (0.4080)  loss_bbox_dn_3: 0.1244 (0.1501)  loss_giou_dn_3: 0.5028 (0.5227)  loss_vfl_dn_4: 0.4070 (0.4067)  loss_bbox_dn_4: 0.1240 (0.1487)  loss_giou_dn_4: 0.4971 (0.5194)  loss_vfl_dn_5: 0.4078 (0.4069)  loss_bbox_dn_5: 0.1244 (0.1485)  loss_giou_dn_5: 0.4972 (0.5185)  time: 0.3225  data: 0.0154  max mem: 7790\n",
            "Epoch: [82] Total time: 0:00:11 (0.3482 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.5482 (15.7470)  loss_vfl: 0.5703 (0.5909)  loss_bbox: 0.1073 (0.1213)  loss_giou: 0.5082 (0.4870)  loss_vfl_aux_0: 0.5819 (0.6077)  loss_bbox_aux_0: 0.1268 (0.1360)  loss_giou_aux_0: 0.5344 (0.5424)  loss_vfl_aux_1: 0.5678 (0.5870)  loss_bbox_aux_1: 0.1149 (0.1268)  loss_giou_aux_1: 0.5140 (0.5074)  loss_vfl_aux_2: 0.5783 (0.5909)  loss_bbox_aux_2: 0.1148 (0.1241)  loss_giou_aux_2: 0.5127 (0.4943)  loss_vfl_aux_3: 0.5546 (0.5931)  loss_bbox_aux_3: 0.1120 (0.1213)  loss_giou_aux_3: 0.5019 (0.4883)  loss_vfl_aux_4: 0.5620 (0.5902)  loss_bbox_aux_4: 0.1077 (0.1208)  loss_giou_aux_4: 0.5182 (0.4874)  loss_vfl_aux_5: 0.6045 (0.6292)  loss_bbox_aux_5: 0.1718 (0.2008)  loss_giou_aux_5: 0.6362 (0.6825)  loss_vfl_dn_0: 0.4319 (0.4343)  loss_bbox_dn_0: 0.1976 (0.2303)  loss_giou_dn_0: 0.7424 (0.7564)  loss_vfl_dn_1: 0.4225 (0.4213)  loss_bbox_dn_1: 0.1388 (0.1675)  loss_giou_dn_1: 0.5618 (0.5766)  loss_vfl_dn_2: 0.4081 (0.4117)  loss_bbox_dn_2: 0.1260 (0.1544)  loss_giou_dn_2: 0.5200 (0.5357)  loss_vfl_dn_3: 0.4073 (0.4080)  loss_bbox_dn_3: 0.1244 (0.1501)  loss_giou_dn_3: 0.5028 (0.5227)  loss_vfl_dn_4: 0.4070 (0.4067)  loss_bbox_dn_4: 0.1240 (0.1487)  loss_giou_dn_4: 0.4971 (0.5194)  loss_vfl_dn_5: 0.4078 (0.4069)  loss_bbox_dn_5: 0.1244 (0.1485)  loss_giou_dn_5: 0.4972 (0.5185)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8585  data: 0.5390  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4353  data: 0.1113  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4479 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 82, 'coco_eval_bbox': 0.34056821465340825}\n",
            "Epoch: [83]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 15.5508 (15.5508)  loss_vfl: 0.5647 (0.5647)  loss_bbox: 0.1501 (0.1501)  loss_giou: 0.4235 (0.4235)  loss_vfl_aux_0: 0.6219 (0.6219)  loss_bbox_aux_0: 0.1534 (0.1534)  loss_giou_aux_0: 0.4758 (0.4758)  loss_vfl_aux_1: 0.5794 (0.5794)  loss_bbox_aux_1: 0.1615 (0.1615)  loss_giou_aux_1: 0.4598 (0.4598)  loss_vfl_aux_2: 0.5892 (0.5892)  loss_bbox_aux_2: 0.1489 (0.1489)  loss_giou_aux_2: 0.4315 (0.4315)  loss_vfl_aux_3: 0.5728 (0.5728)  loss_bbox_aux_3: 0.1489 (0.1489)  loss_giou_aux_3: 0.4246 (0.4246)  loss_vfl_aux_4: 0.5666 (0.5666)  loss_bbox_aux_4: 0.1510 (0.1510)  loss_giou_aux_4: 0.4261 (0.4261)  loss_vfl_aux_5: 0.5600 (0.5600)  loss_bbox_aux_5: 0.2251 (0.2251)  loss_giou_aux_5: 0.5888 (0.5888)  loss_vfl_dn_0: 0.4402 (0.4402)  loss_bbox_dn_0: 0.2738 (0.2738)  loss_giou_dn_0: 0.7315 (0.7315)  loss_vfl_dn_1: 0.4272 (0.4272)  loss_bbox_dn_1: 0.2163 (0.2163)  loss_giou_dn_1: 0.5512 (0.5512)  loss_vfl_dn_2: 0.4193 (0.4193)  loss_bbox_dn_2: 0.2044 (0.2044)  loss_giou_dn_2: 0.5203 (0.5203)  loss_vfl_dn_3: 0.4082 (0.4082)  loss_bbox_dn_3: 0.2034 (0.2034)  loss_giou_dn_3: 0.5071 (0.5071)  loss_vfl_dn_4: 0.4030 (0.4030)  loss_bbox_dn_4: 0.2038 (0.2038)  loss_giou_dn_4: 0.5053 (0.5053)  loss_vfl_dn_5: 0.4022 (0.4022)  loss_bbox_dn_5: 0.2043 (0.2043)  loss_giou_dn_5: 0.5057 (0.5057)  time: 1.0070  data: 0.6220  max mem: 7790\n",
            "Epoch: [83]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 16.0866 (15.7530)  loss_vfl: 0.5877 (0.5896)  loss_bbox: 0.1182 (0.1244)  loss_giou: 0.4617 (0.4916)  loss_vfl_aux_0: 0.5800 (0.5951)  loss_bbox_aux_0: 0.1399 (0.1420)  loss_giou_aux_0: 0.5366 (0.5464)  loss_vfl_aux_1: 0.5940 (0.5905)  loss_bbox_aux_1: 0.1247 (0.1314)  loss_giou_aux_1: 0.4855 (0.5060)  loss_vfl_aux_2: 0.5990 (0.5876)  loss_bbox_aux_2: 0.1265 (0.1281)  loss_giou_aux_2: 0.4787 (0.4971)  loss_vfl_aux_3: 0.5821 (0.5860)  loss_bbox_aux_3: 0.1214 (0.1260)  loss_giou_aux_3: 0.4646 (0.4954)  loss_vfl_aux_4: 0.5816 (0.5918)  loss_bbox_aux_4: 0.1206 (0.1242)  loss_giou_aux_4: 0.4626 (0.4909)  loss_vfl_aux_5: 0.6042 (0.6340)  loss_bbox_aux_5: 0.1949 (0.1939)  loss_giou_aux_5: 0.6834 (0.6822)  loss_vfl_dn_0: 0.4356 (0.4358)  loss_bbox_dn_0: 0.1962 (0.2171)  loss_giou_dn_0: 0.7249 (0.7458)  loss_vfl_dn_1: 0.4191 (0.4170)  loss_bbox_dn_1: 0.1436 (0.1671)  loss_giou_dn_1: 0.5663 (0.5775)  loss_vfl_dn_2: 0.4087 (0.4061)  loss_bbox_dn_2: 0.1289 (0.1555)  loss_giou_dn_2: 0.5277 (0.5382)  loss_vfl_dn_3: 0.4074 (0.4022)  loss_bbox_dn_3: 0.1260 (0.1531)  loss_giou_dn_3: 0.5233 (0.5275)  loss_vfl_dn_4: 0.4048 (0.4010)  loss_bbox_dn_4: 0.1254 (0.1525)  loss_giou_dn_4: 0.5207 (0.5246)  loss_vfl_dn_5: 0.4006 (0.4009)  loss_bbox_dn_5: 0.1249 (0.1524)  loss_giou_dn_5: 0.5235 (0.5244)  time: 0.3237  data: 0.0137  max mem: 7790\n",
            "Epoch: [83] Total time: 0:00:11 (0.3504 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 16.0866 (15.7530)  loss_vfl: 0.5877 (0.5896)  loss_bbox: 0.1182 (0.1244)  loss_giou: 0.4617 (0.4916)  loss_vfl_aux_0: 0.5800 (0.5951)  loss_bbox_aux_0: 0.1399 (0.1420)  loss_giou_aux_0: 0.5366 (0.5464)  loss_vfl_aux_1: 0.5940 (0.5905)  loss_bbox_aux_1: 0.1247 (0.1314)  loss_giou_aux_1: 0.4855 (0.5060)  loss_vfl_aux_2: 0.5990 (0.5876)  loss_bbox_aux_2: 0.1265 (0.1281)  loss_giou_aux_2: 0.4787 (0.4971)  loss_vfl_aux_3: 0.5821 (0.5860)  loss_bbox_aux_3: 0.1214 (0.1260)  loss_giou_aux_3: 0.4646 (0.4954)  loss_vfl_aux_4: 0.5816 (0.5918)  loss_bbox_aux_4: 0.1206 (0.1242)  loss_giou_aux_4: 0.4626 (0.4909)  loss_vfl_aux_5: 0.6042 (0.6340)  loss_bbox_aux_5: 0.1949 (0.1939)  loss_giou_aux_5: 0.6834 (0.6822)  loss_vfl_dn_0: 0.4356 (0.4358)  loss_bbox_dn_0: 0.1962 (0.2171)  loss_giou_dn_0: 0.7249 (0.7458)  loss_vfl_dn_1: 0.4191 (0.4170)  loss_bbox_dn_1: 0.1436 (0.1671)  loss_giou_dn_1: 0.5663 (0.5775)  loss_vfl_dn_2: 0.4087 (0.4061)  loss_bbox_dn_2: 0.1289 (0.1555)  loss_giou_dn_2: 0.5277 (0.5382)  loss_vfl_dn_3: 0.4074 (0.4022)  loss_bbox_dn_3: 0.1260 (0.1531)  loss_giou_dn_3: 0.5233 (0.5275)  loss_vfl_dn_4: 0.4048 (0.4010)  loss_bbox_dn_4: 0.1254 (0.1525)  loss_giou_dn_4: 0.5207 (0.5246)  loss_vfl_dn_5: 0.4006 (0.4009)  loss_bbox_dn_5: 0.1249 (0.1524)  loss_giou_dn_5: 0.5235 (0.5244)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8605  data: 0.5499  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4280  data: 0.1062  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4411 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.651\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.305\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.378\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            "best_stat:  {'epoch': 82, 'coco_eval_bbox': 0.34056821465340825}\n",
            "Epoch: [84]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 16.6313 (16.6313)  loss_vfl: 0.6407 (0.6407)  loss_bbox: 0.1193 (0.1193)  loss_giou: 0.5782 (0.5782)  loss_vfl_aux_0: 0.6307 (0.6307)  loss_bbox_aux_0: 0.1186 (0.1186)  loss_giou_aux_0: 0.6214 (0.6214)  loss_vfl_aux_1: 0.5930 (0.5930)  loss_bbox_aux_1: 0.1222 (0.1222)  loss_giou_aux_1: 0.5914 (0.5914)  loss_vfl_aux_2: 0.6109 (0.6109)  loss_bbox_aux_2: 0.1179 (0.1179)  loss_giou_aux_2: 0.5800 (0.5800)  loss_vfl_aux_3: 0.6110 (0.6110)  loss_bbox_aux_3: 0.1202 (0.1202)  loss_giou_aux_3: 0.5734 (0.5734)  loss_vfl_aux_4: 0.6353 (0.6353)  loss_bbox_aux_4: 0.1186 (0.1186)  loss_giou_aux_4: 0.5747 (0.5747)  loss_vfl_aux_5: 0.7258 (0.7258)  loss_bbox_aux_5: 0.1278 (0.1278)  loss_giou_aux_5: 0.6457 (0.6457)  loss_vfl_dn_0: 0.4298 (0.4298)  loss_bbox_dn_0: 0.1964 (0.1964)  loss_giou_dn_0: 0.7525 (0.7525)  loss_vfl_dn_1: 0.3987 (0.3987)  loss_bbox_dn_1: 0.1681 (0.1681)  loss_giou_dn_1: 0.6275 (0.6275)  loss_vfl_dn_2: 0.3884 (0.3884)  loss_bbox_dn_2: 0.1676 (0.1676)  loss_giou_dn_2: 0.6074 (0.6074)  loss_vfl_dn_3: 0.3821 (0.3821)  loss_bbox_dn_3: 0.1671 (0.1671)  loss_giou_dn_3: 0.5984 (0.5984)  loss_vfl_dn_4: 0.3830 (0.3830)  loss_bbox_dn_4: 0.1658 (0.1658)  loss_giou_dn_4: 0.5966 (0.5966)  loss_vfl_dn_5: 0.3803 (0.3803)  loss_bbox_dn_5: 0.1656 (0.1656)  loss_giou_dn_5: 0.5993 (0.5993)  time: 1.0512  data: 0.6475  max mem: 7790\n",
            "Epoch: [84]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.4050 (15.7598)  loss_vfl: 0.5888 (0.5964)  loss_bbox: 0.1143 (0.1271)  loss_giou: 0.4561 (0.4804)  loss_vfl_aux_0: 0.6123 (0.6155)  loss_bbox_aux_0: 0.1277 (0.1455)  loss_giou_aux_0: 0.5064 (0.5346)  loss_vfl_aux_1: 0.5680 (0.5938)  loss_bbox_aux_1: 0.1168 (0.1385)  loss_giou_aux_1: 0.4656 (0.5007)  loss_vfl_aux_2: 0.5645 (0.5914)  loss_bbox_aux_2: 0.1144 (0.1343)  loss_giou_aux_2: 0.4622 (0.4875)  loss_vfl_aux_3: 0.5676 (0.5890)  loss_bbox_aux_3: 0.1165 (0.1304)  loss_giou_aux_3: 0.4573 (0.4838)  loss_vfl_aux_4: 0.5888 (0.5945)  loss_bbox_aux_4: 0.1174 (0.1283)  loss_giou_aux_4: 0.4604 (0.4804)  loss_vfl_aux_5: 0.6329 (0.6512)  loss_bbox_aux_5: 0.1867 (0.1960)  loss_giou_aux_5: 0.6752 (0.6716)  loss_vfl_dn_0: 0.4435 (0.4439)  loss_bbox_dn_0: 0.2014 (0.2208)  loss_giou_dn_0: 0.7274 (0.7272)  loss_vfl_dn_1: 0.4260 (0.4250)  loss_bbox_dn_1: 0.1498 (0.1692)  loss_giou_dn_1: 0.5800 (0.5599)  loss_vfl_dn_2: 0.4244 (0.4179)  loss_bbox_dn_2: 0.1432 (0.1586)  loss_giou_dn_2: 0.5199 (0.5238)  loss_vfl_dn_3: 0.4214 (0.4151)  loss_bbox_dn_3: 0.1411 (0.1558)  loss_giou_dn_3: 0.5059 (0.5134)  loss_vfl_dn_4: 0.4182 (0.4140)  loss_bbox_dn_4: 0.1417 (0.1551)  loss_giou_dn_4: 0.5065 (0.5110)  loss_vfl_dn_5: 0.4181 (0.4133)  loss_bbox_dn_5: 0.1415 (0.1547)  loss_giou_dn_5: 0.5045 (0.5099)  time: 0.3191  data: 0.0140  max mem: 7790\n",
            "Epoch: [84] Total time: 0:00:11 (0.3518 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.4050 (15.7598)  loss_vfl: 0.5888 (0.5964)  loss_bbox: 0.1143 (0.1271)  loss_giou: 0.4561 (0.4804)  loss_vfl_aux_0: 0.6123 (0.6155)  loss_bbox_aux_0: 0.1277 (0.1455)  loss_giou_aux_0: 0.5064 (0.5346)  loss_vfl_aux_1: 0.5680 (0.5938)  loss_bbox_aux_1: 0.1168 (0.1385)  loss_giou_aux_1: 0.4656 (0.5007)  loss_vfl_aux_2: 0.5645 (0.5914)  loss_bbox_aux_2: 0.1144 (0.1343)  loss_giou_aux_2: 0.4622 (0.4875)  loss_vfl_aux_3: 0.5676 (0.5890)  loss_bbox_aux_3: 0.1165 (0.1304)  loss_giou_aux_3: 0.4573 (0.4838)  loss_vfl_aux_4: 0.5888 (0.5945)  loss_bbox_aux_4: 0.1174 (0.1283)  loss_giou_aux_4: 0.4604 (0.4804)  loss_vfl_aux_5: 0.6329 (0.6512)  loss_bbox_aux_5: 0.1867 (0.1960)  loss_giou_aux_5: 0.6752 (0.6716)  loss_vfl_dn_0: 0.4435 (0.4439)  loss_bbox_dn_0: 0.2014 (0.2208)  loss_giou_dn_0: 0.7274 (0.7272)  loss_vfl_dn_1: 0.4260 (0.4250)  loss_bbox_dn_1: 0.1498 (0.1692)  loss_giou_dn_1: 0.5800 (0.5599)  loss_vfl_dn_2: 0.4244 (0.4179)  loss_bbox_dn_2: 0.1432 (0.1586)  loss_giou_dn_2: 0.5199 (0.5238)  loss_vfl_dn_3: 0.4214 (0.4151)  loss_bbox_dn_3: 0.1411 (0.1558)  loss_giou_dn_3: 0.5059 (0.5134)  loss_vfl_dn_4: 0.4182 (0.4140)  loss_bbox_dn_4: 0.1417 (0.1551)  loss_giou_dn_4: 0.5065 (0.5110)  loss_vfl_dn_5: 0.4181 (0.4133)  loss_bbox_dn_5: 0.1415 (0.1547)  loss_giou_dn_5: 0.5045 (0.5099)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8868  data: 0.5662  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3875  data: 0.1128  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4017 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.652\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.373\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 82, 'coco_eval_bbox': 0.34056821465340825}\n",
            "Epoch: [85]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 13.2186 (13.2186)  loss_vfl: 0.5764 (0.5764)  loss_bbox: 0.0881 (0.0881)  loss_giou: 0.3345 (0.3345)  loss_vfl_aux_0: 0.7030 (0.7030)  loss_bbox_aux_0: 0.0996 (0.0996)  loss_giou_aux_0: 0.3997 (0.3997)  loss_vfl_aux_1: 0.6077 (0.6077)  loss_bbox_aux_1: 0.0853 (0.0853)  loss_giou_aux_1: 0.3396 (0.3396)  loss_vfl_aux_2: 0.5747 (0.5747)  loss_bbox_aux_2: 0.0812 (0.0812)  loss_giou_aux_2: 0.3239 (0.3239)  loss_vfl_aux_3: 0.5783 (0.5783)  loss_bbox_aux_3: 0.0856 (0.0856)  loss_giou_aux_3: 0.3319 (0.3319)  loss_vfl_aux_4: 0.5842 (0.5842)  loss_bbox_aux_4: 0.0876 (0.0876)  loss_giou_aux_4: 0.3310 (0.3310)  loss_vfl_aux_5: 0.7519 (0.7519)  loss_bbox_aux_5: 0.1467 (0.1467)  loss_giou_aux_5: 0.5311 (0.5311)  loss_vfl_dn_0: 0.4493 (0.4493)  loss_bbox_dn_0: 0.1713 (0.1713)  loss_giou_dn_0: 0.6309 (0.6309)  loss_vfl_dn_1: 0.4114 (0.4114)  loss_bbox_dn_1: 0.1033 (0.1033)  loss_giou_dn_1: 0.4144 (0.4144)  loss_vfl_dn_2: 0.4002 (0.4002)  loss_bbox_dn_2: 0.0856 (0.0856)  loss_giou_dn_2: 0.3663 (0.3663)  loss_vfl_dn_3: 0.4053 (0.4053)  loss_bbox_dn_3: 0.0861 (0.0861)  loss_giou_dn_3: 0.3602 (0.3602)  loss_vfl_dn_4: 0.4038 (0.4038)  loss_bbox_dn_4: 0.0859 (0.0859)  loss_giou_dn_4: 0.3549 (0.3549)  loss_vfl_dn_5: 0.4060 (0.4060)  loss_bbox_dn_5: 0.0862 (0.0862)  loss_giou_dn_5: 0.3554 (0.3554)  time: 0.9914  data: 0.6127  max mem: 7790\n",
            "Epoch: [85]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.9937 (15.1229)  loss_vfl: 0.5476 (0.5739)  loss_bbox: 0.1139 (0.1134)  loss_giou: 0.4797 (0.4615)  loss_vfl_aux_0: 0.5773 (0.5993)  loss_bbox_aux_0: 0.1114 (0.1275)  loss_giou_aux_0: 0.5298 (0.5180)  loss_vfl_aux_1: 0.5414 (0.5737)  loss_bbox_aux_1: 0.1094 (0.1184)  loss_giou_aux_1: 0.4957 (0.4805)  loss_vfl_aux_2: 0.5613 (0.5688)  loss_bbox_aux_2: 0.1067 (0.1125)  loss_giou_aux_2: 0.4752 (0.4649)  loss_vfl_aux_3: 0.5549 (0.5763)  loss_bbox_aux_3: 0.1144 (0.1122)  loss_giou_aux_3: 0.4812 (0.4625)  loss_vfl_aux_4: 0.5471 (0.5718)  loss_bbox_aux_4: 0.1140 (0.1136)  loss_giou_aux_4: 0.4810 (0.4623)  loss_vfl_aux_5: 0.6127 (0.6248)  loss_bbox_aux_5: 0.1775 (0.1830)  loss_giou_aux_5: 0.6760 (0.6755)  loss_vfl_dn_0: 0.4392 (0.4382)  loss_bbox_dn_0: 0.1693 (0.2029)  loss_giou_dn_0: 0.7276 (0.7249)  loss_vfl_dn_1: 0.4232 (0.4202)  loss_bbox_dn_1: 0.1295 (0.1511)  loss_giou_dn_1: 0.5597 (0.5437)  loss_vfl_dn_2: 0.4132 (0.4100)  loss_bbox_dn_2: 0.1224 (0.1398)  loss_giou_dn_2: 0.5090 (0.5018)  loss_vfl_dn_3: 0.4095 (0.4070)  loss_bbox_dn_3: 0.1144 (0.1373)  loss_giou_dn_3: 0.4926 (0.4896)  loss_vfl_dn_4: 0.4123 (0.4064)  loss_bbox_dn_4: 0.1149 (0.1373)  loss_giou_dn_4: 0.4907 (0.4872)  loss_vfl_dn_5: 0.4102 (0.4066)  loss_bbox_dn_5: 0.1150 (0.1376)  loss_giou_dn_5: 0.4906 (0.4871)  time: 0.3470  data: 0.0147  max mem: 7790\n",
            "Epoch: [85] Total time: 0:00:12 (0.3639 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.9937 (15.1229)  loss_vfl: 0.5476 (0.5739)  loss_bbox: 0.1139 (0.1134)  loss_giou: 0.4797 (0.4615)  loss_vfl_aux_0: 0.5773 (0.5993)  loss_bbox_aux_0: 0.1114 (0.1275)  loss_giou_aux_0: 0.5298 (0.5180)  loss_vfl_aux_1: 0.5414 (0.5737)  loss_bbox_aux_1: 0.1094 (0.1184)  loss_giou_aux_1: 0.4957 (0.4805)  loss_vfl_aux_2: 0.5613 (0.5688)  loss_bbox_aux_2: 0.1067 (0.1125)  loss_giou_aux_2: 0.4752 (0.4649)  loss_vfl_aux_3: 0.5549 (0.5763)  loss_bbox_aux_3: 0.1144 (0.1122)  loss_giou_aux_3: 0.4812 (0.4625)  loss_vfl_aux_4: 0.5471 (0.5718)  loss_bbox_aux_4: 0.1140 (0.1136)  loss_giou_aux_4: 0.4810 (0.4623)  loss_vfl_aux_5: 0.6127 (0.6248)  loss_bbox_aux_5: 0.1775 (0.1830)  loss_giou_aux_5: 0.6760 (0.6755)  loss_vfl_dn_0: 0.4392 (0.4382)  loss_bbox_dn_0: 0.1693 (0.2029)  loss_giou_dn_0: 0.7276 (0.7249)  loss_vfl_dn_1: 0.4232 (0.4202)  loss_bbox_dn_1: 0.1295 (0.1511)  loss_giou_dn_1: 0.5597 (0.5437)  loss_vfl_dn_2: 0.4132 (0.4100)  loss_bbox_dn_2: 0.1224 (0.1398)  loss_giou_dn_2: 0.5090 (0.5018)  loss_vfl_dn_3: 0.4095 (0.4070)  loss_bbox_dn_3: 0.1144 (0.1373)  loss_giou_dn_3: 0.4926 (0.4896)  loss_vfl_dn_4: 0.4123 (0.4064)  loss_bbox_dn_4: 0.1149 (0.1373)  loss_giou_dn_4: 0.4907 (0.4872)  loss_vfl_dn_5: 0.4102 (0.4066)  loss_bbox_dn_5: 0.1150 (0.1376)  loss_giou_dn_5: 0.4906 (0.4871)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8628  data: 0.5441  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3919  data: 0.1118  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4044 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "best_stat:  {'epoch': 82, 'coco_eval_bbox': 0.34056821465340825}\n",
            "Epoch: [86]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 15.3419 (15.3419)  loss_vfl: 0.6490 (0.6490)  loss_bbox: 0.1258 (0.1258)  loss_giou: 0.4627 (0.4627)  loss_vfl_aux_0: 0.6152 (0.6152)  loss_bbox_aux_0: 0.1539 (0.1539)  loss_giou_aux_0: 0.5217 (0.5217)  loss_vfl_aux_1: 0.6302 (0.6302)  loss_bbox_aux_1: 0.1356 (0.1356)  loss_giou_aux_1: 0.4776 (0.4776)  loss_vfl_aux_2: 0.6484 (0.6484)  loss_bbox_aux_2: 0.1269 (0.1269)  loss_giou_aux_2: 0.4602 (0.4602)  loss_vfl_aux_3: 0.6571 (0.6571)  loss_bbox_aux_3: 0.1255 (0.1255)  loss_giou_aux_3: 0.4615 (0.4615)  loss_vfl_aux_4: 0.6636 (0.6636)  loss_bbox_aux_4: 0.1259 (0.1259)  loss_giou_aux_4: 0.4624 (0.4624)  loss_vfl_aux_5: 0.6843 (0.6843)  loss_bbox_aux_5: 0.2158 (0.2158)  loss_giou_aux_5: 0.6659 (0.6659)  loss_vfl_dn_0: 0.4401 (0.4401)  loss_bbox_dn_0: 0.2216 (0.2216)  loss_giou_dn_0: 0.6946 (0.6946)  loss_vfl_dn_1: 0.4034 (0.4034)  loss_bbox_dn_1: 0.1439 (0.1439)  loss_giou_dn_1: 0.4967 (0.4967)  loss_vfl_dn_2: 0.3908 (0.3908)  loss_bbox_dn_2: 0.1311 (0.1311)  loss_giou_dn_2: 0.4593 (0.4593)  loss_vfl_dn_3: 0.3865 (0.3865)  loss_bbox_dn_3: 0.1287 (0.1287)  loss_giou_dn_3: 0.4528 (0.4528)  loss_vfl_dn_4: 0.3854 (0.3854)  loss_bbox_dn_4: 0.1277 (0.1277)  loss_giou_dn_4: 0.4495 (0.4495)  loss_vfl_dn_5: 0.3859 (0.3859)  loss_bbox_dn_5: 0.1271 (0.1271)  loss_giou_dn_5: 0.4474 (0.4474)  time: 0.9256  data: 0.5443  max mem: 7790\n",
            "Epoch: [86]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.3563 (15.4693)  loss_vfl: 0.5551 (0.5766)  loss_bbox: 0.1157 (0.1303)  loss_giou: 0.4976 (0.4795)  loss_vfl_aux_0: 0.5748 (0.5796)  loss_bbox_aux_0: 0.1197 (0.1472)  loss_giou_aux_0: 0.5676 (0.5350)  loss_vfl_aux_1: 0.5533 (0.5702)  loss_bbox_aux_1: 0.1168 (0.1361)  loss_giou_aux_1: 0.5201 (0.4963)  loss_vfl_aux_2: 0.5621 (0.5694)  loss_bbox_aux_2: 0.1137 (0.1300)  loss_giou_aux_2: 0.5084 (0.4842)  loss_vfl_aux_3: 0.5662 (0.5777)  loss_bbox_aux_3: 0.1162 (0.1287)  loss_giou_aux_3: 0.5025 (0.4802)  loss_vfl_aux_4: 0.5529 (0.5725)  loss_bbox_aux_4: 0.1148 (0.1306)  loss_giou_aux_4: 0.5002 (0.4806)  loss_vfl_aux_5: 0.6005 (0.6296)  loss_bbox_aux_5: 0.1746 (0.2043)  loss_giou_aux_5: 0.6621 (0.6801)  loss_vfl_dn_0: 0.4341 (0.4370)  loss_bbox_dn_0: 0.1923 (0.2195)  loss_giou_dn_0: 0.7508 (0.7316)  loss_vfl_dn_1: 0.4178 (0.4202)  loss_bbox_dn_1: 0.1380 (0.1634)  loss_giou_dn_1: 0.5651 (0.5552)  loss_vfl_dn_2: 0.4085 (0.4102)  loss_bbox_dn_2: 0.1228 (0.1502)  loss_giou_dn_2: 0.5092 (0.5118)  loss_vfl_dn_3: 0.4035 (0.4066)  loss_bbox_dn_3: 0.1178 (0.1466)  loss_giou_dn_3: 0.5054 (0.5009)  loss_vfl_dn_4: 0.4035 (0.4061)  loss_bbox_dn_4: 0.1165 (0.1458)  loss_giou_dn_4: 0.4987 (0.4974)  loss_vfl_dn_5: 0.4035 (0.4061)  loss_bbox_dn_5: 0.1163 (0.1454)  loss_giou_dn_5: 0.4969 (0.4964)  time: 0.3214  data: 0.0137  max mem: 7790\n",
            "Epoch: [86] Total time: 0:00:11 (0.3436 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.3563 (15.4693)  loss_vfl: 0.5551 (0.5766)  loss_bbox: 0.1157 (0.1303)  loss_giou: 0.4976 (0.4795)  loss_vfl_aux_0: 0.5748 (0.5796)  loss_bbox_aux_0: 0.1197 (0.1472)  loss_giou_aux_0: 0.5676 (0.5350)  loss_vfl_aux_1: 0.5533 (0.5702)  loss_bbox_aux_1: 0.1168 (0.1361)  loss_giou_aux_1: 0.5201 (0.4963)  loss_vfl_aux_2: 0.5621 (0.5694)  loss_bbox_aux_2: 0.1137 (0.1300)  loss_giou_aux_2: 0.5084 (0.4842)  loss_vfl_aux_3: 0.5662 (0.5777)  loss_bbox_aux_3: 0.1162 (0.1287)  loss_giou_aux_3: 0.5025 (0.4802)  loss_vfl_aux_4: 0.5529 (0.5725)  loss_bbox_aux_4: 0.1148 (0.1306)  loss_giou_aux_4: 0.5002 (0.4806)  loss_vfl_aux_5: 0.6005 (0.6296)  loss_bbox_aux_5: 0.1746 (0.2043)  loss_giou_aux_5: 0.6621 (0.6801)  loss_vfl_dn_0: 0.4341 (0.4370)  loss_bbox_dn_0: 0.1923 (0.2195)  loss_giou_dn_0: 0.7508 (0.7316)  loss_vfl_dn_1: 0.4178 (0.4202)  loss_bbox_dn_1: 0.1380 (0.1634)  loss_giou_dn_1: 0.5651 (0.5552)  loss_vfl_dn_2: 0.4085 (0.4102)  loss_bbox_dn_2: 0.1228 (0.1502)  loss_giou_dn_2: 0.5092 (0.5118)  loss_vfl_dn_3: 0.4035 (0.4066)  loss_bbox_dn_3: 0.1178 (0.1466)  loss_giou_dn_3: 0.5054 (0.5009)  loss_vfl_dn_4: 0.4035 (0.4061)  loss_bbox_dn_4: 0.1165 (0.1458)  loss_giou_dn_4: 0.4987 (0.4974)  loss_vfl_dn_5: 0.4035 (0.4061)  loss_bbox_dn_5: 0.1163 (0.1454)  loss_giou_dn_5: 0.4969 (0.4964)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8516  data: 0.5342  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3854  data: 0.1111  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4006 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.337\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            "best_stat:  {'epoch': 82, 'coco_eval_bbox': 0.34056821465340825}\n",
            "Epoch: [87]  [ 0/33]  eta: 0:00:28  lr: 0.000001  loss: 13.2443 (13.2443)  loss_vfl: 0.5577 (0.5577)  loss_bbox: 0.1108 (0.1108)  loss_giou: 0.3115 (0.3115)  loss_vfl_aux_0: 0.5745 (0.5745)  loss_bbox_aux_0: 0.1335 (0.1335)  loss_giou_aux_0: 0.3950 (0.3950)  loss_vfl_aux_1: 0.5237 (0.5237)  loss_bbox_aux_1: 0.1229 (0.1229)  loss_giou_aux_1: 0.3404 (0.3404)  loss_vfl_aux_2: 0.5359 (0.5359)  loss_bbox_aux_2: 0.1132 (0.1132)  loss_giou_aux_2: 0.3105 (0.3105)  loss_vfl_aux_3: 0.5409 (0.5409)  loss_bbox_aux_3: 0.1109 (0.1109)  loss_giou_aux_3: 0.3083 (0.3083)  loss_vfl_aux_4: 0.5465 (0.5465)  loss_bbox_aux_4: 0.1106 (0.1106)  loss_giou_aux_4: 0.3084 (0.3084)  loss_vfl_aux_5: 0.6547 (0.6547)  loss_bbox_aux_5: 0.1703 (0.1703)  loss_giou_aux_5: 0.5017 (0.5017)  loss_vfl_dn_0: 0.4601 (0.4601)  loss_bbox_dn_0: 0.2506 (0.2506)  loss_giou_dn_0: 0.6413 (0.6413)  loss_vfl_dn_1: 0.4206 (0.4206)  loss_bbox_dn_1: 0.1702 (0.1702)  loss_giou_dn_1: 0.4146 (0.4146)  loss_vfl_dn_2: 0.4005 (0.4005)  loss_bbox_dn_2: 0.1485 (0.1485)  loss_giou_dn_2: 0.3645 (0.3645)  loss_vfl_dn_3: 0.3947 (0.3947)  loss_bbox_dn_3: 0.1466 (0.1466)  loss_giou_dn_3: 0.3556 (0.3556)  loss_vfl_dn_4: 0.3978 (0.3978)  loss_bbox_dn_4: 0.1459 (0.1459)  loss_giou_dn_4: 0.3524 (0.3524)  loss_vfl_dn_5: 0.4017 (0.4017)  loss_bbox_dn_5: 0.1449 (0.1449)  loss_giou_dn_5: 0.3518 (0.3518)  time: 0.8755  data: 0.4899  max mem: 7790\n",
            "Epoch: [87]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.0265 (15.6446)  loss_vfl: 0.5607 (0.6100)  loss_bbox: 0.1134 (0.1285)  loss_giou: 0.4614 (0.4732)  loss_vfl_aux_0: 0.5941 (0.6111)  loss_bbox_aux_0: 0.1300 (0.1460)  loss_giou_aux_0: 0.5039 (0.5235)  loss_vfl_aux_1: 0.5513 (0.6019)  loss_bbox_aux_1: 0.1154 (0.1356)  loss_giou_aux_1: 0.4846 (0.4904)  loss_vfl_aux_2: 0.5600 (0.6062)  loss_bbox_aux_2: 0.1123 (0.1300)  loss_giou_aux_2: 0.4598 (0.4762)  loss_vfl_aux_3: 0.5510 (0.6007)  loss_bbox_aux_3: 0.1134 (0.1307)  loss_giou_aux_3: 0.4580 (0.4769)  loss_vfl_aux_4: 0.5526 (0.6067)  loss_bbox_aux_4: 0.1130 (0.1293)  loss_giou_aux_4: 0.4680 (0.4742)  loss_vfl_aux_5: 0.6257 (0.6682)  loss_bbox_aux_5: 0.1634 (0.1825)  loss_giou_aux_5: 0.6162 (0.6277)  loss_vfl_dn_0: 0.4446 (0.4425)  loss_bbox_dn_0: 0.1923 (0.2226)  loss_giou_dn_0: 0.7270 (0.7173)  loss_vfl_dn_1: 0.4223 (0.4244)  loss_bbox_dn_1: 0.1379 (0.1683)  loss_giou_dn_1: 0.5390 (0.5494)  loss_vfl_dn_2: 0.4111 (0.4164)  loss_bbox_dn_2: 0.1222 (0.1574)  loss_giou_dn_2: 0.4999 (0.5116)  loss_vfl_dn_3: 0.4114 (0.4133)  loss_bbox_dn_3: 0.1212 (0.1552)  loss_giou_dn_3: 0.4859 (0.5011)  loss_vfl_dn_4: 0.4101 (0.4126)  loss_bbox_dn_4: 0.1220 (0.1553)  loss_giou_dn_4: 0.4846 (0.4999)  loss_vfl_dn_5: 0.4079 (0.4132)  loss_bbox_dn_5: 0.1224 (0.1552)  loss_giou_dn_5: 0.4865 (0.4995)  time: 0.3261  data: 0.0138  max mem: 7790\n",
            "Epoch: [87] Total time: 0:00:11 (0.3453 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.0265 (15.6446)  loss_vfl: 0.5607 (0.6100)  loss_bbox: 0.1134 (0.1285)  loss_giou: 0.4614 (0.4732)  loss_vfl_aux_0: 0.5941 (0.6111)  loss_bbox_aux_0: 0.1300 (0.1460)  loss_giou_aux_0: 0.5039 (0.5235)  loss_vfl_aux_1: 0.5513 (0.6019)  loss_bbox_aux_1: 0.1154 (0.1356)  loss_giou_aux_1: 0.4846 (0.4904)  loss_vfl_aux_2: 0.5600 (0.6062)  loss_bbox_aux_2: 0.1123 (0.1300)  loss_giou_aux_2: 0.4598 (0.4762)  loss_vfl_aux_3: 0.5510 (0.6007)  loss_bbox_aux_3: 0.1134 (0.1307)  loss_giou_aux_3: 0.4580 (0.4769)  loss_vfl_aux_4: 0.5526 (0.6067)  loss_bbox_aux_4: 0.1130 (0.1293)  loss_giou_aux_4: 0.4680 (0.4742)  loss_vfl_aux_5: 0.6257 (0.6682)  loss_bbox_aux_5: 0.1634 (0.1825)  loss_giou_aux_5: 0.6162 (0.6277)  loss_vfl_dn_0: 0.4446 (0.4425)  loss_bbox_dn_0: 0.1923 (0.2226)  loss_giou_dn_0: 0.7270 (0.7173)  loss_vfl_dn_1: 0.4223 (0.4244)  loss_bbox_dn_1: 0.1379 (0.1683)  loss_giou_dn_1: 0.5390 (0.5494)  loss_vfl_dn_2: 0.4111 (0.4164)  loss_bbox_dn_2: 0.1222 (0.1574)  loss_giou_dn_2: 0.4999 (0.5116)  loss_vfl_dn_3: 0.4114 (0.4133)  loss_bbox_dn_3: 0.1212 (0.1552)  loss_giou_dn_3: 0.4859 (0.5011)  loss_vfl_dn_4: 0.4101 (0.4126)  loss_bbox_dn_4: 0.1220 (0.1553)  loss_giou_dn_4: 0.4846 (0.4999)  loss_vfl_dn_5: 0.4079 (0.4132)  loss_bbox_dn_5: 0.1224 (0.1552)  loss_giou_dn_5: 0.4865 (0.4995)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8516  data: 0.5409  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3858  data: 0.1139  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3990 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.554\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [88]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 17.2116 (17.2116)  loss_vfl: 0.5723 (0.5723)  loss_bbox: 0.0936 (0.0936)  loss_giou: 0.6317 (0.6317)  loss_vfl_aux_0: 0.5465 (0.5465)  loss_bbox_aux_0: 0.1057 (0.1057)  loss_giou_aux_0: 0.6788 (0.6788)  loss_vfl_aux_1: 0.5622 (0.5622)  loss_bbox_aux_1: 0.0997 (0.0997)  loss_giou_aux_1: 0.6467 (0.6467)  loss_vfl_aux_2: 0.5668 (0.5668)  loss_bbox_aux_2: 0.0962 (0.0962)  loss_giou_aux_2: 0.6367 (0.6367)  loss_vfl_aux_3: 0.5828 (0.5828)  loss_bbox_aux_3: 0.0944 (0.0944)  loss_giou_aux_3: 0.6204 (0.6204)  loss_vfl_aux_4: 0.5638 (0.5638)  loss_bbox_aux_4: 0.0948 (0.0948)  loss_giou_aux_4: 0.6357 (0.6357)  loss_vfl_aux_5: 0.5585 (0.5585)  loss_bbox_aux_5: 0.1178 (0.1178)  loss_giou_aux_5: 0.7726 (0.7726)  loss_vfl_dn_0: 0.4175 (0.4175)  loss_bbox_dn_0: 0.1387 (0.1387)  loss_giou_dn_0: 0.9028 (0.9028)  loss_vfl_dn_1: 0.4139 (0.4139)  loss_bbox_dn_1: 0.1201 (0.1201)  loss_giou_dn_1: 0.7917 (0.7917)  loss_vfl_dn_2: 0.4117 (0.4117)  loss_bbox_dn_2: 0.1163 (0.1163)  loss_giou_dn_2: 0.7694 (0.7694)  loss_vfl_dn_3: 0.4071 (0.4071)  loss_bbox_dn_3: 0.1167 (0.1167)  loss_giou_dn_3: 0.7596 (0.7596)  loss_vfl_dn_4: 0.4074 (0.4074)  loss_bbox_dn_4: 0.1168 (0.1168)  loss_giou_dn_4: 0.7587 (0.7587)  loss_vfl_dn_5: 0.4093 (0.4093)  loss_bbox_dn_5: 0.1173 (0.1173)  loss_giou_dn_5: 0.7587 (0.7587)  time: 0.9933  data: 0.5955  max mem: 7790\n",
            "Epoch: [88]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.2097 (15.5658)  loss_vfl: 0.5986 (0.5940)  loss_bbox: 0.1102 (0.1115)  loss_giou: 0.4644 (0.4869)  loss_vfl_aux_0: 0.6077 (0.5911)  loss_bbox_aux_0: 0.1288 (0.1289)  loss_giou_aux_0: 0.5154 (0.5434)  loss_vfl_aux_1: 0.5838 (0.5830)  loss_bbox_aux_1: 0.1171 (0.1174)  loss_giou_aux_1: 0.4954 (0.5059)  loss_vfl_aux_2: 0.5810 (0.5856)  loss_bbox_aux_2: 0.1133 (0.1142)  loss_giou_aux_2: 0.4652 (0.4928)  loss_vfl_aux_3: 0.5832 (0.5832)  loss_bbox_aux_3: 0.1130 (0.1137)  loss_giou_aux_3: 0.4630 (0.4908)  loss_vfl_aux_4: 0.5861 (0.5922)  loss_bbox_aux_4: 0.1099 (0.1119)  loss_giou_aux_4: 0.4648 (0.4874)  loss_vfl_aux_5: 0.6356 (0.6251)  loss_bbox_aux_5: 0.1803 (0.1769)  loss_giou_aux_5: 0.6418 (0.6835)  loss_vfl_dn_0: 0.4381 (0.4414)  loss_bbox_dn_0: 0.1929 (0.1961)  loss_giou_dn_0: 0.6898 (0.7354)  loss_vfl_dn_1: 0.4194 (0.4262)  loss_bbox_dn_1: 0.1416 (0.1467)  loss_giou_dn_1: 0.5337 (0.5738)  loss_vfl_dn_2: 0.4110 (0.4179)  loss_bbox_dn_2: 0.1280 (0.1362)  loss_giou_dn_2: 0.4975 (0.5386)  loss_vfl_dn_3: 0.4114 (0.4158)  loss_bbox_dn_3: 0.1261 (0.1342)  loss_giou_dn_3: 0.4865 (0.5299)  loss_vfl_dn_4: 0.4092 (0.4150)  loss_bbox_dn_4: 0.1253 (0.1337)  loss_giou_dn_4: 0.4855 (0.5287)  loss_vfl_dn_5: 0.4106 (0.4152)  loss_bbox_dn_5: 0.1254 (0.1334)  loss_giou_dn_5: 0.4831 (0.5278)  time: 0.3231  data: 0.0153  max mem: 7790\n",
            "Epoch: [88] Total time: 0:00:11 (0.3479 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.2097 (15.5658)  loss_vfl: 0.5986 (0.5940)  loss_bbox: 0.1102 (0.1115)  loss_giou: 0.4644 (0.4869)  loss_vfl_aux_0: 0.6077 (0.5911)  loss_bbox_aux_0: 0.1288 (0.1289)  loss_giou_aux_0: 0.5154 (0.5434)  loss_vfl_aux_1: 0.5838 (0.5830)  loss_bbox_aux_1: 0.1171 (0.1174)  loss_giou_aux_1: 0.4954 (0.5059)  loss_vfl_aux_2: 0.5810 (0.5856)  loss_bbox_aux_2: 0.1133 (0.1142)  loss_giou_aux_2: 0.4652 (0.4928)  loss_vfl_aux_3: 0.5832 (0.5832)  loss_bbox_aux_3: 0.1130 (0.1137)  loss_giou_aux_3: 0.4630 (0.4908)  loss_vfl_aux_4: 0.5861 (0.5922)  loss_bbox_aux_4: 0.1099 (0.1119)  loss_giou_aux_4: 0.4648 (0.4874)  loss_vfl_aux_5: 0.6356 (0.6251)  loss_bbox_aux_5: 0.1803 (0.1769)  loss_giou_aux_5: 0.6418 (0.6835)  loss_vfl_dn_0: 0.4381 (0.4414)  loss_bbox_dn_0: 0.1929 (0.1961)  loss_giou_dn_0: 0.6898 (0.7354)  loss_vfl_dn_1: 0.4194 (0.4262)  loss_bbox_dn_1: 0.1416 (0.1467)  loss_giou_dn_1: 0.5337 (0.5738)  loss_vfl_dn_2: 0.4110 (0.4179)  loss_bbox_dn_2: 0.1280 (0.1362)  loss_giou_dn_2: 0.4975 (0.5386)  loss_vfl_dn_3: 0.4114 (0.4158)  loss_bbox_dn_3: 0.1261 (0.1342)  loss_giou_dn_3: 0.4865 (0.5299)  loss_vfl_dn_4: 0.4092 (0.4150)  loss_bbox_dn_4: 0.1253 (0.1337)  loss_giou_dn_4: 0.4855 (0.5287)  loss_vfl_dn_5: 0.4106 (0.4152)  loss_bbox_dn_5: 0.1254 (0.1334)  loss_giou_dn_5: 0.4831 (0.5278)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8492  data: 0.5386  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4365  data: 0.1137  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4525 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.655\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.383\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.363\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [89]  [ 0/33]  eta: 0:00:29  lr: 0.000001  loss: 14.5736 (14.5736)  loss_vfl: 0.5396 (0.5396)  loss_bbox: 0.0776 (0.0776)  loss_giou: 0.4532 (0.4532)  loss_vfl_aux_0: 0.5447 (0.5447)  loss_bbox_aux_0: 0.0850 (0.0850)  loss_giou_aux_0: 0.5044 (0.5044)  loss_vfl_aux_1: 0.5703 (0.5703)  loss_bbox_aux_1: 0.0752 (0.0752)  loss_giou_aux_1: 0.4566 (0.4566)  loss_vfl_aux_2: 0.5414 (0.5414)  loss_bbox_aux_2: 0.0751 (0.0751)  loss_giou_aux_2: 0.4589 (0.4589)  loss_vfl_aux_3: 0.5371 (0.5371)  loss_bbox_aux_3: 0.0764 (0.0764)  loss_giou_aux_3: 0.4528 (0.4528)  loss_vfl_aux_4: 0.5407 (0.5407)  loss_bbox_aux_4: 0.0776 (0.0776)  loss_giou_aux_4: 0.4533 (0.4533)  loss_vfl_aux_5: 0.5938 (0.5938)  loss_bbox_aux_5: 0.1365 (0.1365)  loss_giou_aux_5: 0.6514 (0.6514)  loss_vfl_dn_0: 0.4662 (0.4662)  loss_bbox_dn_0: 0.1566 (0.1566)  loss_giou_dn_0: 0.7660 (0.7660)  loss_vfl_dn_1: 0.4444 (0.4444)  loss_bbox_dn_1: 0.1082 (0.1082)  loss_giou_dn_1: 0.5592 (0.5592)  loss_vfl_dn_2: 0.4419 (0.4419)  loss_bbox_dn_2: 0.0948 (0.0948)  loss_giou_dn_2: 0.5246 (0.5246)  loss_vfl_dn_3: 0.4405 (0.4405)  loss_bbox_dn_3: 0.0900 (0.0900)  loss_giou_dn_3: 0.5076 (0.5076)  loss_vfl_dn_4: 0.4419 (0.4419)  loss_bbox_dn_4: 0.0894 (0.0894)  loss_giou_dn_4: 0.5068 (0.5068)  loss_vfl_dn_5: 0.4393 (0.4393)  loss_bbox_dn_5: 0.0889 (0.0889)  loss_giou_dn_5: 0.5056 (0.5056)  time: 0.8970  data: 0.5084  max mem: 7790\n",
            "Epoch: [89]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.5442 (15.2091)  loss_vfl: 0.5510 (0.5605)  loss_bbox: 0.0998 (0.1223)  loss_giou: 0.4412 (0.4768)  loss_vfl_aux_0: 0.5755 (0.5737)  loss_bbox_aux_0: 0.1149 (0.1379)  loss_giou_aux_0: 0.4876 (0.5377)  loss_vfl_aux_1: 0.5624 (0.5612)  loss_bbox_aux_1: 0.1031 (0.1245)  loss_giou_aux_1: 0.4500 (0.4951)  loss_vfl_aux_2: 0.5440 (0.5587)  loss_bbox_aux_2: 0.1004 (0.1261)  loss_giou_aux_2: 0.4473 (0.4851)  loss_vfl_aux_3: 0.5423 (0.5535)  loss_bbox_aux_3: 0.1013 (0.1257)  loss_giou_aux_3: 0.4430 (0.4827)  loss_vfl_aux_4: 0.5477 (0.5588)  loss_bbox_aux_4: 0.0992 (0.1221)  loss_giou_aux_4: 0.4392 (0.4773)  loss_vfl_aux_5: 0.6319 (0.6244)  loss_bbox_aux_5: 0.1794 (0.1910)  loss_giou_aux_5: 0.6216 (0.6820)  loss_vfl_dn_0: 0.4466 (0.4439)  loss_bbox_dn_0: 0.1854 (0.2052)  loss_giou_dn_0: 0.6617 (0.7101)  loss_vfl_dn_1: 0.4173 (0.4216)  loss_bbox_dn_1: 0.1270 (0.1508)  loss_giou_dn_1: 0.4771 (0.5379)  loss_vfl_dn_2: 0.4124 (0.4112)  loss_bbox_dn_2: 0.1135 (0.1393)  loss_giou_dn_2: 0.4474 (0.5028)  loss_vfl_dn_3: 0.4056 (0.4068)  loss_bbox_dn_3: 0.1084 (0.1365)  loss_giou_dn_3: 0.4406 (0.4940)  loss_vfl_dn_4: 0.4013 (0.4065)  loss_bbox_dn_4: 0.1083 (0.1364)  loss_giou_dn_4: 0.4366 (0.4925)  loss_vfl_dn_5: 0.4034 (0.4068)  loss_bbox_dn_5: 0.1079 (0.1365)  loss_giou_dn_5: 0.4369 (0.4930)  time: 0.3259  data: 0.0139  max mem: 7790\n",
            "Epoch: [89] Total time: 0:00:11 (0.3443 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.5442 (15.2091)  loss_vfl: 0.5510 (0.5605)  loss_bbox: 0.0998 (0.1223)  loss_giou: 0.4412 (0.4768)  loss_vfl_aux_0: 0.5755 (0.5737)  loss_bbox_aux_0: 0.1149 (0.1379)  loss_giou_aux_0: 0.4876 (0.5377)  loss_vfl_aux_1: 0.5624 (0.5612)  loss_bbox_aux_1: 0.1031 (0.1245)  loss_giou_aux_1: 0.4500 (0.4951)  loss_vfl_aux_2: 0.5440 (0.5587)  loss_bbox_aux_2: 0.1004 (0.1261)  loss_giou_aux_2: 0.4473 (0.4851)  loss_vfl_aux_3: 0.5423 (0.5535)  loss_bbox_aux_3: 0.1013 (0.1257)  loss_giou_aux_3: 0.4430 (0.4827)  loss_vfl_aux_4: 0.5477 (0.5588)  loss_bbox_aux_4: 0.0992 (0.1221)  loss_giou_aux_4: 0.4392 (0.4773)  loss_vfl_aux_5: 0.6319 (0.6244)  loss_bbox_aux_5: 0.1794 (0.1910)  loss_giou_aux_5: 0.6216 (0.6820)  loss_vfl_dn_0: 0.4466 (0.4439)  loss_bbox_dn_0: 0.1854 (0.2052)  loss_giou_dn_0: 0.6617 (0.7101)  loss_vfl_dn_1: 0.4173 (0.4216)  loss_bbox_dn_1: 0.1270 (0.1508)  loss_giou_dn_1: 0.4771 (0.5379)  loss_vfl_dn_2: 0.4124 (0.4112)  loss_bbox_dn_2: 0.1135 (0.1393)  loss_giou_dn_2: 0.4474 (0.5028)  loss_vfl_dn_3: 0.4056 (0.4068)  loss_bbox_dn_3: 0.1084 (0.1365)  loss_giou_dn_3: 0.4406 (0.4940)  loss_vfl_dn_4: 0.4013 (0.4065)  loss_bbox_dn_4: 0.1083 (0.1364)  loss_giou_dn_4: 0.4366 (0.4925)  loss_vfl_dn_5: 0.4034 (0.4068)  loss_bbox_dn_5: 0.1079 (0.1365)  loss_giou_dn_5: 0.4369 (0.4930)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8901  data: 0.5829  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4392  data: 0.1135  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4527 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.651\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [90]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 16.9909 (16.9909)  loss_vfl: 0.5894 (0.5894)  loss_bbox: 0.0969 (0.0969)  loss_giou: 0.6842 (0.6842)  loss_vfl_aux_0: 0.5493 (0.5493)  loss_bbox_aux_0: 0.1045 (0.1045)  loss_giou_aux_0: 0.7216 (0.7216)  loss_vfl_aux_1: 0.5767 (0.5767)  loss_bbox_aux_1: 0.0992 (0.0992)  loss_giou_aux_1: 0.6929 (0.6929)  loss_vfl_aux_2: 0.5781 (0.5781)  loss_bbox_aux_2: 0.0974 (0.0974)  loss_giou_aux_2: 0.6914 (0.6914)  loss_vfl_aux_3: 0.5841 (0.5841)  loss_bbox_aux_3: 0.0966 (0.0966)  loss_giou_aux_3: 0.6827 (0.6827)  loss_vfl_aux_4: 0.5862 (0.5862)  loss_bbox_aux_4: 0.0986 (0.0986)  loss_giou_aux_4: 0.6684 (0.6684)  loss_vfl_aux_5: 0.5533 (0.5533)  loss_bbox_aux_5: 0.1308 (0.1308)  loss_giou_aux_5: 0.8679 (0.8679)  loss_vfl_dn_0: 0.4339 (0.4339)  loss_bbox_dn_0: 0.1146 (0.1146)  loss_giou_dn_0: 0.8209 (0.8209)  loss_vfl_dn_1: 0.4271 (0.4271)  loss_bbox_dn_1: 0.0940 (0.0940)  loss_giou_dn_1: 0.6957 (0.6957)  loss_vfl_dn_2: 0.4199 (0.4199)  loss_bbox_dn_2: 0.0896 (0.0896)  loss_giou_dn_2: 0.6635 (0.6635)  loss_vfl_dn_3: 0.4192 (0.4192)  loss_bbox_dn_3: 0.0880 (0.0880)  loss_giou_dn_3: 0.6550 (0.6550)  loss_vfl_dn_4: 0.4173 (0.4173)  loss_bbox_dn_4: 0.0880 (0.0880)  loss_giou_dn_4: 0.6543 (0.6543)  loss_vfl_dn_5: 0.4196 (0.4196)  loss_bbox_dn_5: 0.0881 (0.0881)  loss_giou_dn_5: 0.6522 (0.6522)  time: 0.9603  data: 0.6021  max mem: 7790\n",
            "Epoch: [90]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.7613 (15.4033)  loss_vfl: 0.5614 (0.5661)  loss_bbox: 0.1083 (0.1209)  loss_giou: 0.4378 (0.4892)  loss_vfl_aux_0: 0.5909 (0.5807)  loss_bbox_aux_0: 0.1264 (0.1403)  loss_giou_aux_0: 0.5043 (0.5444)  loss_vfl_aux_1: 0.5709 (0.5734)  loss_bbox_aux_1: 0.1088 (0.1270)  loss_giou_aux_1: 0.4682 (0.5051)  loss_vfl_aux_2: 0.5756 (0.5761)  loss_bbox_aux_2: 0.1087 (0.1192)  loss_giou_aux_2: 0.4502 (0.4920)  loss_vfl_aux_3: 0.5665 (0.5736)  loss_bbox_aux_3: 0.1123 (0.1195)  loss_giou_aux_3: 0.4462 (0.4880)  loss_vfl_aux_4: 0.5587 (0.5718)  loss_bbox_aux_4: 0.1084 (0.1204)  loss_giou_aux_4: 0.4394 (0.4877)  loss_vfl_aux_5: 0.6390 (0.6427)  loss_bbox_aux_5: 0.1733 (0.1853)  loss_giou_aux_5: 0.6592 (0.6799)  loss_vfl_dn_0: 0.4412 (0.4372)  loss_bbox_dn_0: 0.1756 (0.2009)  loss_giou_dn_0: 0.7123 (0.7303)  loss_vfl_dn_1: 0.4161 (0.4199)  loss_bbox_dn_1: 0.1269 (0.1479)  loss_giou_dn_1: 0.5238 (0.5568)  loss_vfl_dn_2: 0.4084 (0.4115)  loss_bbox_dn_2: 0.1151 (0.1363)  loss_giou_dn_2: 0.4889 (0.5186)  loss_vfl_dn_3: 0.4034 (0.4075)  loss_bbox_dn_3: 0.1152 (0.1338)  loss_giou_dn_3: 0.4772 (0.5088)  loss_vfl_dn_4: 0.4001 (0.4065)  loss_bbox_dn_4: 0.1142 (0.1335)  loss_giou_dn_4: 0.4739 (0.5058)  loss_vfl_dn_5: 0.3997 (0.4062)  loss_bbox_dn_5: 0.1142 (0.1334)  loss_giou_dn_5: 0.4740 (0.5052)  time: 0.3270  data: 0.0145  max mem: 7790\n",
            "Epoch: [90] Total time: 0:00:11 (0.3474 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.7613 (15.4033)  loss_vfl: 0.5614 (0.5661)  loss_bbox: 0.1083 (0.1209)  loss_giou: 0.4378 (0.4892)  loss_vfl_aux_0: 0.5909 (0.5807)  loss_bbox_aux_0: 0.1264 (0.1403)  loss_giou_aux_0: 0.5043 (0.5444)  loss_vfl_aux_1: 0.5709 (0.5734)  loss_bbox_aux_1: 0.1088 (0.1270)  loss_giou_aux_1: 0.4682 (0.5051)  loss_vfl_aux_2: 0.5756 (0.5761)  loss_bbox_aux_2: 0.1087 (0.1192)  loss_giou_aux_2: 0.4502 (0.4920)  loss_vfl_aux_3: 0.5665 (0.5736)  loss_bbox_aux_3: 0.1123 (0.1195)  loss_giou_aux_3: 0.4462 (0.4880)  loss_vfl_aux_4: 0.5587 (0.5718)  loss_bbox_aux_4: 0.1084 (0.1204)  loss_giou_aux_4: 0.4394 (0.4877)  loss_vfl_aux_5: 0.6390 (0.6427)  loss_bbox_aux_5: 0.1733 (0.1853)  loss_giou_aux_5: 0.6592 (0.6799)  loss_vfl_dn_0: 0.4412 (0.4372)  loss_bbox_dn_0: 0.1756 (0.2009)  loss_giou_dn_0: 0.7123 (0.7303)  loss_vfl_dn_1: 0.4161 (0.4199)  loss_bbox_dn_1: 0.1269 (0.1479)  loss_giou_dn_1: 0.5238 (0.5568)  loss_vfl_dn_2: 0.4084 (0.4115)  loss_bbox_dn_2: 0.1151 (0.1363)  loss_giou_dn_2: 0.4889 (0.5186)  loss_vfl_dn_3: 0.4034 (0.4075)  loss_bbox_dn_3: 0.1152 (0.1338)  loss_giou_dn_3: 0.4772 (0.5088)  loss_vfl_dn_4: 0.4001 (0.4065)  loss_bbox_dn_4: 0.1142 (0.1335)  loss_giou_dn_4: 0.4739 (0.5058)  loss_vfl_dn_5: 0.3997 (0.4062)  loss_bbox_dn_5: 0.1142 (0.1334)  loss_giou_dn_5: 0.4740 (0.5052)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9004  data: 0.5773  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4033  data: 0.1151  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4189 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [91]  [ 0/33]  eta: 0:00:37  lr: 0.000001  loss: 16.1664 (16.1664)  loss_vfl: 0.5863 (0.5863)  loss_bbox: 0.1484 (0.1484)  loss_giou: 0.4787 (0.4787)  loss_vfl_aux_0: 0.5764 (0.5764)  loss_bbox_aux_0: 0.2656 (0.2656)  loss_giou_aux_0: 0.6823 (0.6823)  loss_vfl_aux_1: 0.5874 (0.5874)  loss_bbox_aux_1: 0.2054 (0.2054)  loss_giou_aux_1: 0.5796 (0.5796)  loss_vfl_aux_2: 0.6097 (0.6097)  loss_bbox_aux_2: 0.1928 (0.1928)  loss_giou_aux_2: 0.5291 (0.5291)  loss_vfl_aux_3: 0.5990 (0.5990)  loss_bbox_aux_3: 0.1925 (0.1925)  loss_giou_aux_3: 0.5233 (0.5233)  loss_vfl_aux_4: 0.5988 (0.5988)  loss_bbox_aux_4: 0.1492 (0.1492)  loss_giou_aux_4: 0.4836 (0.4836)  loss_vfl_aux_5: 0.5597 (0.5597)  loss_bbox_aux_5: 0.4862 (0.4862)  loss_giou_aux_5: 1.1433 (1.1433)  loss_vfl_dn_0: 0.4293 (0.4293)  loss_bbox_dn_0: 0.2822 (0.2822)  loss_giou_dn_0: 0.6797 (0.6797)  loss_vfl_dn_1: 0.3921 (0.3921)  loss_bbox_dn_1: 0.1825 (0.1825)  loss_giou_dn_1: 0.4709 (0.4709)  loss_vfl_dn_2: 0.3768 (0.3768)  loss_bbox_dn_2: 0.1532 (0.1532)  loss_giou_dn_2: 0.4123 (0.4123)  loss_vfl_dn_3: 0.3640 (0.3640)  loss_bbox_dn_3: 0.1387 (0.1387)  loss_giou_dn_3: 0.3759 (0.3759)  loss_vfl_dn_4: 0.3606 (0.3606)  loss_bbox_dn_4: 0.1357 (0.1357)  loss_giou_dn_4: 0.3709 (0.3709)  loss_vfl_dn_5: 0.3617 (0.3617)  loss_bbox_dn_5: 0.1349 (0.1349)  loss_giou_dn_5: 0.3679 (0.3679)  time: 1.1243  data: 0.7403  max mem: 7790\n",
            "Epoch: [91]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.6587 (15.5279)  loss_vfl: 0.6127 (0.6187)  loss_bbox: 0.1165 (0.1225)  loss_giou: 0.3977 (0.4671)  loss_vfl_aux_0: 0.6182 (0.6124)  loss_bbox_aux_0: 0.1404 (0.1458)  loss_giou_aux_0: 0.4603 (0.5300)  loss_vfl_aux_1: 0.5912 (0.5997)  loss_bbox_aux_1: 0.1237 (0.1330)  loss_giou_aux_1: 0.4285 (0.4925)  loss_vfl_aux_2: 0.6042 (0.6138)  loss_bbox_aux_2: 0.1232 (0.1262)  loss_giou_aux_2: 0.4070 (0.4735)  loss_vfl_aux_3: 0.6068 (0.6159)  loss_bbox_aux_3: 0.1213 (0.1246)  loss_giou_aux_3: 0.3964 (0.4686)  loss_vfl_aux_4: 0.6077 (0.6130)  loss_bbox_aux_4: 0.1210 (0.1239)  loss_giou_aux_4: 0.3976 (0.4668)  loss_vfl_aux_5: 0.6757 (0.6563)  loss_bbox_aux_5: 0.1759 (0.1935)  loss_giou_aux_5: 0.5727 (0.6615)  loss_vfl_dn_0: 0.4487 (0.4430)  loss_bbox_dn_0: 0.2244 (0.2109)  loss_giou_dn_0: 0.6870 (0.7138)  loss_vfl_dn_1: 0.4174 (0.4215)  loss_bbox_dn_1: 0.1628 (0.1571)  loss_giou_dn_1: 0.4959 (0.5410)  loss_vfl_dn_2: 0.4062 (0.4131)  loss_bbox_dn_2: 0.1468 (0.1452)  loss_giou_dn_2: 0.4555 (0.5026)  loss_vfl_dn_3: 0.4044 (0.4091)  loss_bbox_dn_3: 0.1417 (0.1423)  loss_giou_dn_3: 0.4260 (0.4916)  loss_vfl_dn_4: 0.4044 (0.4079)  loss_bbox_dn_4: 0.1406 (0.1416)  loss_giou_dn_4: 0.4199 (0.4889)  loss_vfl_dn_5: 0.3997 (0.4091)  loss_bbox_dn_5: 0.1407 (0.1415)  loss_giou_dn_5: 0.4141 (0.4884)  time: 0.3309  data: 0.0147  max mem: 7790\n",
            "Epoch: [91] Total time: 0:00:11 (0.3616 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.6587 (15.5279)  loss_vfl: 0.6127 (0.6187)  loss_bbox: 0.1165 (0.1225)  loss_giou: 0.3977 (0.4671)  loss_vfl_aux_0: 0.6182 (0.6124)  loss_bbox_aux_0: 0.1404 (0.1458)  loss_giou_aux_0: 0.4603 (0.5300)  loss_vfl_aux_1: 0.5912 (0.5997)  loss_bbox_aux_1: 0.1237 (0.1330)  loss_giou_aux_1: 0.4285 (0.4925)  loss_vfl_aux_2: 0.6042 (0.6138)  loss_bbox_aux_2: 0.1232 (0.1262)  loss_giou_aux_2: 0.4070 (0.4735)  loss_vfl_aux_3: 0.6068 (0.6159)  loss_bbox_aux_3: 0.1213 (0.1246)  loss_giou_aux_3: 0.3964 (0.4686)  loss_vfl_aux_4: 0.6077 (0.6130)  loss_bbox_aux_4: 0.1210 (0.1239)  loss_giou_aux_4: 0.3976 (0.4668)  loss_vfl_aux_5: 0.6757 (0.6563)  loss_bbox_aux_5: 0.1759 (0.1935)  loss_giou_aux_5: 0.5727 (0.6615)  loss_vfl_dn_0: 0.4487 (0.4430)  loss_bbox_dn_0: 0.2244 (0.2109)  loss_giou_dn_0: 0.6870 (0.7138)  loss_vfl_dn_1: 0.4174 (0.4215)  loss_bbox_dn_1: 0.1628 (0.1571)  loss_giou_dn_1: 0.4959 (0.5410)  loss_vfl_dn_2: 0.4062 (0.4131)  loss_bbox_dn_2: 0.1468 (0.1452)  loss_giou_dn_2: 0.4555 (0.5026)  loss_vfl_dn_3: 0.4044 (0.4091)  loss_bbox_dn_3: 0.1417 (0.1423)  loss_giou_dn_3: 0.4260 (0.4916)  loss_vfl_dn_4: 0.4044 (0.4079)  loss_bbox_dn_4: 0.1406 (0.1416)  loss_giou_dn_4: 0.4199 (0.4889)  loss_vfl_dn_5: 0.3997 (0.4091)  loss_bbox_dn_5: 0.1407 (0.1415)  loss_giou_dn_5: 0.4141 (0.4884)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9642  data: 0.6542  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4010  data: 0.1298  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4136 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [92]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 14.6412 (14.6412)  loss_vfl: 0.5993 (0.5993)  loss_bbox: 0.0827 (0.0827)  loss_giou: 0.5227 (0.5227)  loss_vfl_aux_0: 0.5753 (0.5753)  loss_bbox_aux_0: 0.0761 (0.0761)  loss_giou_aux_0: 0.5405 (0.5405)  loss_vfl_aux_1: 0.6029 (0.6029)  loss_bbox_aux_1: 0.0745 (0.0745)  loss_giou_aux_1: 0.4986 (0.4986)  loss_vfl_aux_2: 0.5786 (0.5786)  loss_bbox_aux_2: 0.0820 (0.0820)  loss_giou_aux_2: 0.5234 (0.5234)  loss_vfl_aux_3: 0.5905 (0.5905)  loss_bbox_aux_3: 0.0810 (0.0810)  loss_giou_aux_3: 0.5189 (0.5189)  loss_vfl_aux_4: 0.5918 (0.5918)  loss_bbox_aux_4: 0.0824 (0.0824)  loss_giou_aux_4: 0.5217 (0.5217)  loss_vfl_aux_5: 0.6339 (0.6339)  loss_bbox_aux_5: 0.0982 (0.0982)  loss_giou_aux_5: 0.6471 (0.6471)  loss_vfl_dn_0: 0.4366 (0.4366)  loss_bbox_dn_0: 0.1048 (0.1048)  loss_giou_dn_0: 0.7119 (0.7119)  loss_vfl_dn_1: 0.4137 (0.4137)  loss_bbox_dn_1: 0.0760 (0.0760)  loss_giou_dn_1: 0.5225 (0.5225)  loss_vfl_dn_2: 0.4013 (0.4013)  loss_bbox_dn_2: 0.0727 (0.0727)  loss_giou_dn_2: 0.4953 (0.4953)  loss_vfl_dn_3: 0.4050 (0.4050)  loss_bbox_dn_3: 0.0714 (0.0714)  loss_giou_dn_3: 0.4871 (0.4871)  loss_vfl_dn_4: 0.4034 (0.4034)  loss_bbox_dn_4: 0.0714 (0.0714)  loss_giou_dn_4: 0.4859 (0.4859)  loss_vfl_dn_5: 0.4039 (0.4039)  loss_bbox_dn_5: 0.0712 (0.0712)  loss_giou_dn_5: 0.4849 (0.4849)  time: 0.9459  data: 0.5197  max mem: 7790\n",
            "Epoch: [92]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.0553 (15.0456)  loss_vfl: 0.5417 (0.5499)  loss_bbox: 0.1104 (0.1181)  loss_giou: 0.4383 (0.4720)  loss_vfl_aux_0: 0.5636 (0.5647)  loss_bbox_aux_0: 0.1327 (0.1348)  loss_giou_aux_0: 0.4923 (0.5292)  loss_vfl_aux_1: 0.5363 (0.5537)  loss_bbox_aux_1: 0.1180 (0.1221)  loss_giou_aux_1: 0.4553 (0.4889)  loss_vfl_aux_2: 0.5507 (0.5527)  loss_bbox_aux_2: 0.1118 (0.1189)  loss_giou_aux_2: 0.4411 (0.4766)  loss_vfl_aux_3: 0.5348 (0.5536)  loss_bbox_aux_3: 0.1126 (0.1176)  loss_giou_aux_3: 0.4354 (0.4713)  loss_vfl_aux_4: 0.5502 (0.5509)  loss_bbox_aux_4: 0.1121 (0.1177)  loss_giou_aux_4: 0.4373 (0.4712)  loss_vfl_aux_5: 0.6132 (0.6187)  loss_bbox_aux_5: 0.1713 (0.1766)  loss_giou_aux_5: 0.6511 (0.6644)  loss_vfl_dn_0: 0.4394 (0.4395)  loss_bbox_dn_0: 0.1852 (0.1996)  loss_giou_dn_0: 0.7073 (0.7129)  loss_vfl_dn_1: 0.4175 (0.4202)  loss_bbox_dn_1: 0.1303 (0.1490)  loss_giou_dn_1: 0.5618 (0.5430)  loss_vfl_dn_2: 0.4154 (0.4118)  loss_bbox_dn_2: 0.1154 (0.1374)  loss_giou_dn_2: 0.5182 (0.5048)  loss_vfl_dn_3: 0.4116 (0.4084)  loss_bbox_dn_3: 0.1096 (0.1343)  loss_giou_dn_3: 0.5054 (0.4948)  loss_vfl_dn_4: 0.4122 (0.4071)  loss_bbox_dn_4: 0.1084 (0.1338)  loss_giou_dn_4: 0.5032 (0.4920)  loss_vfl_dn_5: 0.4134 (0.4086)  loss_bbox_dn_5: 0.1070 (0.1334)  loss_giou_dn_5: 0.5059 (0.4915)  time: 0.3441  data: 0.0142  max mem: 7790\n",
            "Epoch: [92] Total time: 0:00:11 (0.3616 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.0553 (15.0456)  loss_vfl: 0.5417 (0.5499)  loss_bbox: 0.1104 (0.1181)  loss_giou: 0.4383 (0.4720)  loss_vfl_aux_0: 0.5636 (0.5647)  loss_bbox_aux_0: 0.1327 (0.1348)  loss_giou_aux_0: 0.4923 (0.5292)  loss_vfl_aux_1: 0.5363 (0.5537)  loss_bbox_aux_1: 0.1180 (0.1221)  loss_giou_aux_1: 0.4553 (0.4889)  loss_vfl_aux_2: 0.5507 (0.5527)  loss_bbox_aux_2: 0.1118 (0.1189)  loss_giou_aux_2: 0.4411 (0.4766)  loss_vfl_aux_3: 0.5348 (0.5536)  loss_bbox_aux_3: 0.1126 (0.1176)  loss_giou_aux_3: 0.4354 (0.4713)  loss_vfl_aux_4: 0.5502 (0.5509)  loss_bbox_aux_4: 0.1121 (0.1177)  loss_giou_aux_4: 0.4373 (0.4712)  loss_vfl_aux_5: 0.6132 (0.6187)  loss_bbox_aux_5: 0.1713 (0.1766)  loss_giou_aux_5: 0.6511 (0.6644)  loss_vfl_dn_0: 0.4394 (0.4395)  loss_bbox_dn_0: 0.1852 (0.1996)  loss_giou_dn_0: 0.7073 (0.7129)  loss_vfl_dn_1: 0.4175 (0.4202)  loss_bbox_dn_1: 0.1303 (0.1490)  loss_giou_dn_1: 0.5618 (0.5430)  loss_vfl_dn_2: 0.4154 (0.4118)  loss_bbox_dn_2: 0.1154 (0.1374)  loss_giou_dn_2: 0.5182 (0.5048)  loss_vfl_dn_3: 0.4116 (0.4084)  loss_bbox_dn_3: 0.1096 (0.1343)  loss_giou_dn_3: 0.5054 (0.4948)  loss_vfl_dn_4: 0.4122 (0.4071)  loss_bbox_dn_4: 0.1084 (0.1338)  loss_giou_dn_4: 0.5032 (0.4920)  loss_vfl_dn_5: 0.4134 (0.4086)  loss_bbox_dn_5: 0.1070 (0.1334)  loss_giou_dn_5: 0.5059 (0.4915)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9331  data: 0.6192  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3951  data: 0.1220  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4080 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.659\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.551\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.343\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [93]  [ 0/33]  eta: 0:00:38  lr: 0.000001  loss: 14.5880 (14.5880)  loss_vfl: 0.5170 (0.5170)  loss_bbox: 0.0934 (0.0934)  loss_giou: 0.4927 (0.4927)  loss_vfl_aux_0: 0.5159 (0.5159)  loss_bbox_aux_0: 0.1049 (0.1049)  loss_giou_aux_0: 0.5708 (0.5708)  loss_vfl_aux_1: 0.5204 (0.5204)  loss_bbox_aux_1: 0.0971 (0.0971)  loss_giou_aux_1: 0.5231 (0.5231)  loss_vfl_aux_2: 0.5341 (0.5341)  loss_bbox_aux_2: 0.0936 (0.0936)  loss_giou_aux_2: 0.5027 (0.5027)  loss_vfl_aux_3: 0.5249 (0.5249)  loss_bbox_aux_3: 0.0930 (0.0930)  loss_giou_aux_3: 0.4885 (0.4885)  loss_vfl_aux_4: 0.5225 (0.5225)  loss_bbox_aux_4: 0.0888 (0.0888)  loss_giou_aux_4: 0.4948 (0.4948)  loss_vfl_aux_5: 0.6077 (0.6077)  loss_bbox_aux_5: 0.1358 (0.1358)  loss_giou_aux_5: 0.6652 (0.6652)  loss_vfl_dn_0: 0.4273 (0.4273)  loss_bbox_dn_0: 0.1426 (0.1426)  loss_giou_dn_0: 0.7140 (0.7140)  loss_vfl_dn_1: 0.4104 (0.4104)  loss_bbox_dn_1: 0.1059 (0.1059)  loss_giou_dn_1: 0.5559 (0.5559)  loss_vfl_dn_2: 0.4181 (0.4181)  loss_bbox_dn_2: 0.0982 (0.0982)  loss_giou_dn_2: 0.5128 (0.5128)  loss_vfl_dn_3: 0.4109 (0.4109)  loss_bbox_dn_3: 0.0969 (0.0969)  loss_giou_dn_3: 0.5005 (0.5005)  loss_vfl_dn_4: 0.4139 (0.4139)  loss_bbox_dn_4: 0.0962 (0.0962)  loss_giou_dn_4: 0.4959 (0.4959)  loss_vfl_dn_5: 0.4083 (0.4083)  loss_bbox_dn_5: 0.0963 (0.0963)  loss_giou_dn_5: 0.4971 (0.4971)  time: 1.1531  data: 0.7043  max mem: 7790\n",
            "Epoch: [93]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.0171 (15.4167)  loss_vfl: 0.5479 (0.5699)  loss_bbox: 0.1097 (0.1152)  loss_giou: 0.4865 (0.4894)  loss_vfl_aux_0: 0.5330 (0.5806)  loss_bbox_aux_0: 0.1290 (0.1326)  loss_giou_aux_0: 0.5505 (0.5437)  loss_vfl_aux_1: 0.5454 (0.5743)  loss_bbox_aux_1: 0.1161 (0.1202)  loss_giou_aux_1: 0.4935 (0.5052)  loss_vfl_aux_2: 0.5439 (0.5751)  loss_bbox_aux_2: 0.1111 (0.1162)  loss_giou_aux_2: 0.4646 (0.4912)  loss_vfl_aux_3: 0.5425 (0.5706)  loss_bbox_aux_3: 0.1060 (0.1158)  loss_giou_aux_3: 0.4674 (0.4903)  loss_vfl_aux_4: 0.5407 (0.5752)  loss_bbox_aux_4: 0.1071 (0.1144)  loss_giou_aux_4: 0.4839 (0.4873)  loss_vfl_aux_5: 0.5996 (0.6296)  loss_bbox_aux_5: 0.1657 (0.1862)  loss_giou_aux_5: 0.6639 (0.6798)  loss_vfl_dn_0: 0.4364 (0.4331)  loss_bbox_dn_0: 0.1895 (0.1999)  loss_giou_dn_0: 0.7184 (0.7360)  loss_vfl_dn_1: 0.4159 (0.4179)  loss_bbox_dn_1: 0.1318 (0.1471)  loss_giou_dn_1: 0.5440 (0.5682)  loss_vfl_dn_2: 0.4103 (0.4115)  loss_bbox_dn_2: 0.1230 (0.1353)  loss_giou_dn_2: 0.5082 (0.5305)  loss_vfl_dn_3: 0.4099 (0.4085)  loss_bbox_dn_3: 0.1225 (0.1322)  loss_giou_dn_3: 0.4909 (0.5201)  loss_vfl_dn_4: 0.4087 (0.4072)  loss_bbox_dn_4: 0.1228 (0.1318)  loss_giou_dn_4: 0.4874 (0.5182)  loss_vfl_dn_5: 0.4111 (0.4069)  loss_bbox_dn_5: 0.1232 (0.1315)  loss_giou_dn_5: 0.4823 (0.5181)  time: 0.3331  data: 0.0140  max mem: 7790\n",
            "Epoch: [93] Total time: 0:00:11 (0.3567 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.0171 (15.4167)  loss_vfl: 0.5479 (0.5699)  loss_bbox: 0.1097 (0.1152)  loss_giou: 0.4865 (0.4894)  loss_vfl_aux_0: 0.5330 (0.5806)  loss_bbox_aux_0: 0.1290 (0.1326)  loss_giou_aux_0: 0.5505 (0.5437)  loss_vfl_aux_1: 0.5454 (0.5743)  loss_bbox_aux_1: 0.1161 (0.1202)  loss_giou_aux_1: 0.4935 (0.5052)  loss_vfl_aux_2: 0.5439 (0.5751)  loss_bbox_aux_2: 0.1111 (0.1162)  loss_giou_aux_2: 0.4646 (0.4912)  loss_vfl_aux_3: 0.5425 (0.5706)  loss_bbox_aux_3: 0.1060 (0.1158)  loss_giou_aux_3: 0.4674 (0.4903)  loss_vfl_aux_4: 0.5407 (0.5752)  loss_bbox_aux_4: 0.1071 (0.1144)  loss_giou_aux_4: 0.4839 (0.4873)  loss_vfl_aux_5: 0.5996 (0.6296)  loss_bbox_aux_5: 0.1657 (0.1862)  loss_giou_aux_5: 0.6639 (0.6798)  loss_vfl_dn_0: 0.4364 (0.4331)  loss_bbox_dn_0: 0.1895 (0.1999)  loss_giou_dn_0: 0.7184 (0.7360)  loss_vfl_dn_1: 0.4159 (0.4179)  loss_bbox_dn_1: 0.1318 (0.1471)  loss_giou_dn_1: 0.5440 (0.5682)  loss_vfl_dn_2: 0.4103 (0.4115)  loss_bbox_dn_2: 0.1230 (0.1353)  loss_giou_dn_2: 0.5082 (0.5305)  loss_vfl_dn_3: 0.4099 (0.4085)  loss_bbox_dn_3: 0.1225 (0.1322)  loss_giou_dn_3: 0.4909 (0.5201)  loss_vfl_dn_4: 0.4087 (0.4072)  loss_bbox_dn_4: 0.1228 (0.1318)  loss_giou_dn_4: 0.4874 (0.5182)  loss_vfl_dn_5: 0.4111 (0.4069)  loss_bbox_dn_5: 0.1232 (0.1315)  loss_giou_dn_5: 0.4823 (0.5181)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9176  data: 0.6049  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3909  data: 0.1134  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4036 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.634\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.601\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [94]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 12.2568 (12.2568)  loss_vfl: 0.5149 (0.5149)  loss_bbox: 0.0685 (0.0685)  loss_giou: 0.3605 (0.3605)  loss_vfl_aux_0: 0.5055 (0.5055)  loss_bbox_aux_0: 0.0828 (0.0828)  loss_giou_aux_0: 0.4284 (0.4284)  loss_vfl_aux_1: 0.5257 (0.5257)  loss_bbox_aux_1: 0.0714 (0.0714)  loss_giou_aux_1: 0.3776 (0.3776)  loss_vfl_aux_2: 0.5215 (0.5215)  loss_bbox_aux_2: 0.0696 (0.0696)  loss_giou_aux_2: 0.3632 (0.3632)  loss_vfl_aux_3: 0.5159 (0.5159)  loss_bbox_aux_3: 0.0682 (0.0682)  loss_giou_aux_3: 0.3558 (0.3558)  loss_vfl_aux_4: 0.5121 (0.5121)  loss_bbox_aux_4: 0.0680 (0.0680)  loss_giou_aux_4: 0.3538 (0.3538)  loss_vfl_aux_5: 0.5687 (0.5687)  loss_bbox_aux_5: 0.1349 (0.1349)  loss_giou_aux_5: 0.6133 (0.6133)  loss_vfl_dn_0: 0.4409 (0.4409)  loss_bbox_dn_0: 0.1056 (0.1056)  loss_giou_dn_0: 0.5867 (0.5867)  loss_vfl_dn_1: 0.4129 (0.4129)  loss_bbox_dn_1: 0.0702 (0.0702)  loss_giou_dn_1: 0.3913 (0.3913)  loss_vfl_dn_2: 0.3953 (0.3953)  loss_bbox_dn_2: 0.0613 (0.0613)  loss_giou_dn_2: 0.3436 (0.3436)  loss_vfl_dn_3: 0.3915 (0.3915)  loss_bbox_dn_3: 0.0586 (0.0586)  loss_giou_dn_3: 0.3376 (0.3376)  loss_vfl_dn_4: 0.3920 (0.3920)  loss_bbox_dn_4: 0.0582 (0.0582)  loss_giou_dn_4: 0.3363 (0.3363)  loss_vfl_dn_5: 0.3948 (0.3948)  loss_bbox_dn_5: 0.0583 (0.0583)  loss_giou_dn_5: 0.3412 (0.3412)  time: 1.0528  data: 0.6572  max mem: 7790\n",
            "Epoch: [94]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.7912 (15.2374)  loss_vfl: 0.5227 (0.5655)  loss_bbox: 0.0989 (0.1145)  loss_giou: 0.4344 (0.4833)  loss_vfl_aux_0: 0.5535 (0.5718)  loss_bbox_aux_0: 0.1267 (0.1389)  loss_giou_aux_0: 0.5164 (0.5439)  loss_vfl_aux_1: 0.5512 (0.5753)  loss_bbox_aux_1: 0.1132 (0.1202)  loss_giou_aux_1: 0.4615 (0.5016)  loss_vfl_aux_2: 0.5353 (0.5624)  loss_bbox_aux_2: 0.1099 (0.1176)  loss_giou_aux_2: 0.4505 (0.4885)  loss_vfl_aux_3: 0.5216 (0.5596)  loss_bbox_aux_3: 0.1059 (0.1161)  loss_giou_aux_3: 0.4416 (0.4859)  loss_vfl_aux_4: 0.5270 (0.5651)  loss_bbox_aux_4: 0.0976 (0.1142)  loss_giou_aux_4: 0.4351 (0.4823)  loss_vfl_aux_5: 0.6285 (0.6337)  loss_bbox_aux_5: 0.1678 (0.1782)  loss_giou_aux_5: 0.6854 (0.6656)  loss_vfl_dn_0: 0.4314 (0.4391)  loss_bbox_dn_0: 0.1861 (0.2069)  loss_giou_dn_0: 0.6930 (0.7178)  loss_vfl_dn_1: 0.4130 (0.4145)  loss_bbox_dn_1: 0.1345 (0.1516)  loss_giou_dn_1: 0.5289 (0.5487)  loss_vfl_dn_2: 0.4007 (0.4047)  loss_bbox_dn_2: 0.1200 (0.1406)  loss_giou_dn_2: 0.4912 (0.5138)  loss_vfl_dn_3: 0.3935 (0.4003)  loss_bbox_dn_3: 0.1177 (0.1372)  loss_giou_dn_3: 0.4777 (0.5034)  loss_vfl_dn_4: 0.3940 (0.3994)  loss_bbox_dn_4: 0.1179 (0.1367)  loss_giou_dn_4: 0.4751 (0.5009)  loss_vfl_dn_5: 0.3950 (0.4000)  loss_bbox_dn_5: 0.1185 (0.1366)  loss_giou_dn_5: 0.4749 (0.5008)  time: 0.3253  data: 0.0139  max mem: 7790\n",
            "Epoch: [94] Total time: 0:00:11 (0.3522 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.7912 (15.2374)  loss_vfl: 0.5227 (0.5655)  loss_bbox: 0.0989 (0.1145)  loss_giou: 0.4344 (0.4833)  loss_vfl_aux_0: 0.5535 (0.5718)  loss_bbox_aux_0: 0.1267 (0.1389)  loss_giou_aux_0: 0.5164 (0.5439)  loss_vfl_aux_1: 0.5512 (0.5753)  loss_bbox_aux_1: 0.1132 (0.1202)  loss_giou_aux_1: 0.4615 (0.5016)  loss_vfl_aux_2: 0.5353 (0.5624)  loss_bbox_aux_2: 0.1099 (0.1176)  loss_giou_aux_2: 0.4505 (0.4885)  loss_vfl_aux_3: 0.5216 (0.5596)  loss_bbox_aux_3: 0.1059 (0.1161)  loss_giou_aux_3: 0.4416 (0.4859)  loss_vfl_aux_4: 0.5270 (0.5651)  loss_bbox_aux_4: 0.0976 (0.1142)  loss_giou_aux_4: 0.4351 (0.4823)  loss_vfl_aux_5: 0.6285 (0.6337)  loss_bbox_aux_5: 0.1678 (0.1782)  loss_giou_aux_5: 0.6854 (0.6656)  loss_vfl_dn_0: 0.4314 (0.4391)  loss_bbox_dn_0: 0.1861 (0.2069)  loss_giou_dn_0: 0.6930 (0.7178)  loss_vfl_dn_1: 0.4130 (0.4145)  loss_bbox_dn_1: 0.1345 (0.1516)  loss_giou_dn_1: 0.5289 (0.5487)  loss_vfl_dn_2: 0.4007 (0.4047)  loss_bbox_dn_2: 0.1200 (0.1406)  loss_giou_dn_2: 0.4912 (0.5138)  loss_vfl_dn_3: 0.3935 (0.4003)  loss_bbox_dn_3: 0.1177 (0.1372)  loss_giou_dn_3: 0.4777 (0.5034)  loss_vfl_dn_4: 0.3940 (0.3994)  loss_bbox_dn_4: 0.1179 (0.1367)  loss_giou_dn_4: 0.4751 (0.5009)  loss_vfl_dn_5: 0.3950 (0.4000)  loss_bbox_dn_5: 0.1185 (0.1366)  loss_giou_dn_5: 0.4749 (0.5008)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8807  data: 0.5685  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4455  data: 0.1672  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4616 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.614\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [95]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 14.0366 (14.0366)  loss_vfl: 0.5911 (0.5911)  loss_bbox: 0.0777 (0.0777)  loss_giou: 0.3927 (0.3927)  loss_vfl_aux_0: 0.6525 (0.6525)  loss_bbox_aux_0: 0.0904 (0.0904)  loss_giou_aux_0: 0.4050 (0.4050)  loss_vfl_aux_1: 0.6701 (0.6701)  loss_bbox_aux_1: 0.0655 (0.0655)  loss_giou_aux_1: 0.3306 (0.3306)  loss_vfl_aux_2: 0.6519 (0.6519)  loss_bbox_aux_2: 0.0641 (0.0641)  loss_giou_aux_2: 0.3287 (0.3287)  loss_vfl_aux_3: 0.5868 (0.5868)  loss_bbox_aux_3: 0.0789 (0.0789)  loss_giou_aux_3: 0.3903 (0.3903)  loss_vfl_aux_4: 0.5863 (0.5863)  loss_bbox_aux_4: 0.0779 (0.0779)  loss_giou_aux_4: 0.3912 (0.3912)  loss_vfl_aux_5: 0.7530 (0.7530)  loss_bbox_aux_5: 0.1334 (0.1334)  loss_giou_aux_5: 0.5245 (0.5245)  loss_vfl_dn_0: 0.4454 (0.4454)  loss_bbox_dn_0: 0.1779 (0.1779)  loss_giou_dn_0: 0.7005 (0.7005)  loss_vfl_dn_1: 0.4140 (0.4140)  loss_bbox_dn_1: 0.1229 (0.1229)  loss_giou_dn_1: 0.5180 (0.5180)  loss_vfl_dn_2: 0.4002 (0.4002)  loss_bbox_dn_2: 0.1116 (0.1116)  loss_giou_dn_2: 0.4695 (0.4695)  loss_vfl_dn_3: 0.3919 (0.3919)  loss_bbox_dn_3: 0.1076 (0.1076)  loss_giou_dn_3: 0.4508 (0.4508)  loss_vfl_dn_4: 0.3920 (0.3920)  loss_bbox_dn_4: 0.1058 (0.1058)  loss_giou_dn_4: 0.4443 (0.4443)  loss_vfl_dn_5: 0.3915 (0.3915)  loss_bbox_dn_5: 0.1056 (0.1056)  loss_giou_dn_5: 0.4449 (0.4449)  time: 0.9870  data: 0.5803  max mem: 7790\n",
            "Epoch: [95]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.6171 (14.7532)  loss_vfl: 0.5439 (0.5678)  loss_bbox: 0.1154 (0.1048)  loss_giou: 0.3975 (0.4468)  loss_vfl_aux_0: 0.5705 (0.5992)  loss_bbox_aux_0: 0.1318 (0.1260)  loss_giou_aux_0: 0.4875 (0.5093)  loss_vfl_aux_1: 0.5483 (0.5705)  loss_bbox_aux_1: 0.1158 (0.1117)  loss_giou_aux_1: 0.4131 (0.4681)  loss_vfl_aux_2: 0.5506 (0.5661)  loss_bbox_aux_2: 0.1098 (0.1073)  loss_giou_aux_2: 0.4031 (0.4541)  loss_vfl_aux_3: 0.5461 (0.5628)  loss_bbox_aux_3: 0.1234 (0.1057)  loss_giou_aux_3: 0.4051 (0.4504)  loss_vfl_aux_4: 0.5554 (0.5674)  loss_bbox_aux_4: 0.1278 (0.1047)  loss_giou_aux_4: 0.3998 (0.4471)  loss_vfl_aux_5: 0.6337 (0.6367)  loss_bbox_aux_5: 0.1755 (0.1829)  loss_giou_aux_5: 0.6512 (0.6615)  loss_vfl_dn_0: 0.4368 (0.4423)  loss_bbox_dn_0: 0.1855 (0.1900)  loss_giou_dn_0: 0.6728 (0.6973)  loss_vfl_dn_1: 0.4156 (0.4196)  loss_bbox_dn_1: 0.1381 (0.1351)  loss_giou_dn_1: 0.4811 (0.5178)  loss_vfl_dn_2: 0.4064 (0.4089)  loss_bbox_dn_2: 0.1221 (0.1236)  loss_giou_dn_2: 0.4484 (0.4824)  loss_vfl_dn_3: 0.3979 (0.4044)  loss_bbox_dn_3: 0.1225 (0.1205)  loss_giou_dn_3: 0.4452 (0.4729)  loss_vfl_dn_4: 0.3960 (0.4036)  loss_bbox_dn_4: 0.1215 (0.1200)  loss_giou_dn_4: 0.4427 (0.4705)  loss_vfl_dn_5: 0.3943 (0.4034)  loss_bbox_dn_5: 0.1219 (0.1198)  loss_giou_dn_5: 0.4416 (0.4701)  time: 0.3280  data: 0.0139  max mem: 7790\n",
            "Epoch: [95] Total time: 0:00:11 (0.3512 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.6171 (14.7532)  loss_vfl: 0.5439 (0.5678)  loss_bbox: 0.1154 (0.1048)  loss_giou: 0.3975 (0.4468)  loss_vfl_aux_0: 0.5705 (0.5992)  loss_bbox_aux_0: 0.1318 (0.1260)  loss_giou_aux_0: 0.4875 (0.5093)  loss_vfl_aux_1: 0.5483 (0.5705)  loss_bbox_aux_1: 0.1158 (0.1117)  loss_giou_aux_1: 0.4131 (0.4681)  loss_vfl_aux_2: 0.5506 (0.5661)  loss_bbox_aux_2: 0.1098 (0.1073)  loss_giou_aux_2: 0.4031 (0.4541)  loss_vfl_aux_3: 0.5461 (0.5628)  loss_bbox_aux_3: 0.1234 (0.1057)  loss_giou_aux_3: 0.4051 (0.4504)  loss_vfl_aux_4: 0.5554 (0.5674)  loss_bbox_aux_4: 0.1278 (0.1047)  loss_giou_aux_4: 0.3998 (0.4471)  loss_vfl_aux_5: 0.6337 (0.6367)  loss_bbox_aux_5: 0.1755 (0.1829)  loss_giou_aux_5: 0.6512 (0.6615)  loss_vfl_dn_0: 0.4368 (0.4423)  loss_bbox_dn_0: 0.1855 (0.1900)  loss_giou_dn_0: 0.6728 (0.6973)  loss_vfl_dn_1: 0.4156 (0.4196)  loss_bbox_dn_1: 0.1381 (0.1351)  loss_giou_dn_1: 0.4811 (0.5178)  loss_vfl_dn_2: 0.4064 (0.4089)  loss_bbox_dn_2: 0.1221 (0.1236)  loss_giou_dn_2: 0.4484 (0.4824)  loss_vfl_dn_3: 0.3979 (0.4044)  loss_bbox_dn_3: 0.1225 (0.1205)  loss_giou_dn_3: 0.4452 (0.4729)  loss_vfl_dn_4: 0.3960 (0.4036)  loss_bbox_dn_4: 0.1215 (0.1200)  loss_giou_dn_4: 0.4427 (0.4705)  loss_vfl_dn_5: 0.3943 (0.4034)  loss_bbox_dn_5: 0.1219 (0.1198)  loss_giou_dn_5: 0.4416 (0.4701)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9063  data: 0.5974  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4363  data: 0.1118  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4502 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.651\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [96]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 17.1297 (17.1297)  loss_vfl: 0.6867 (0.6867)  loss_bbox: 0.1734 (0.1734)  loss_giou: 0.5353 (0.5353)  loss_vfl_aux_0: 0.5975 (0.5975)  loss_bbox_aux_0: 0.1818 (0.1818)  loss_giou_aux_0: 0.6376 (0.6376)  loss_vfl_aux_1: 0.6402 (0.6402)  loss_bbox_aux_1: 0.1661 (0.1661)  loss_giou_aux_1: 0.5580 (0.5580)  loss_vfl_aux_2: 0.6455 (0.6455)  loss_bbox_aux_2: 0.1767 (0.1767)  loss_giou_aux_2: 0.5503 (0.5503)  loss_vfl_aux_3: 0.6746 (0.6746)  loss_bbox_aux_3: 0.1745 (0.1745)  loss_giou_aux_3: 0.5419 (0.5419)  loss_vfl_aux_4: 0.7013 (0.7013)  loss_bbox_aux_4: 0.1489 (0.1489)  loss_giou_aux_4: 0.5130 (0.5130)  loss_vfl_aux_5: 0.6986 (0.6986)  loss_bbox_aux_5: 0.2290 (0.2290)  loss_giou_aux_5: 0.8317 (0.8317)  loss_vfl_dn_0: 0.4444 (0.4444)  loss_bbox_dn_0: 0.1913 (0.1913)  loss_giou_dn_0: 0.7573 (0.7573)  loss_vfl_dn_1: 0.4322 (0.4322)  loss_bbox_dn_1: 0.1548 (0.1548)  loss_giou_dn_1: 0.5986 (0.5986)  loss_vfl_dn_2: 0.4291 (0.4291)  loss_bbox_dn_2: 0.1438 (0.1438)  loss_giou_dn_2: 0.5637 (0.5637)  loss_vfl_dn_3: 0.4289 (0.4289)  loss_bbox_dn_3: 0.1434 (0.1434)  loss_giou_dn_3: 0.5514 (0.5514)  loss_vfl_dn_4: 0.4287 (0.4287)  loss_bbox_dn_4: 0.1412 (0.1412)  loss_giou_dn_4: 0.5451 (0.5451)  loss_vfl_dn_5: 0.4289 (0.4289)  loss_bbox_dn_5: 0.1402 (0.1402)  loss_giou_dn_5: 0.5439 (0.5439)  time: 1.0532  data: 0.6304  max mem: 7790\n",
            "Epoch: [96]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 15.1783 (14.9242)  loss_vfl: 0.5545 (0.5738)  loss_bbox: 0.0981 (0.1115)  loss_giou: 0.4127 (0.4508)  loss_vfl_aux_0: 0.5834 (0.5828)  loss_bbox_aux_0: 0.1199 (0.1358)  loss_giou_aux_0: 0.4784 (0.5190)  loss_vfl_aux_1: 0.5608 (0.5668)  loss_bbox_aux_1: 0.1062 (0.1205)  loss_giou_aux_1: 0.4280 (0.4732)  loss_vfl_aux_2: 0.5452 (0.5632)  loss_bbox_aux_2: 0.1104 (0.1180)  loss_giou_aux_2: 0.4190 (0.4610)  loss_vfl_aux_3: 0.5414 (0.5666)  loss_bbox_aux_3: 0.0981 (0.1142)  loss_giou_aux_3: 0.4100 (0.4543)  loss_vfl_aux_4: 0.5550 (0.5704)  loss_bbox_aux_4: 0.0974 (0.1116)  loss_giou_aux_4: 0.4156 (0.4512)  loss_vfl_aux_5: 0.6067 (0.6346)  loss_bbox_aux_5: 0.1726 (0.1857)  loss_giou_aux_5: 0.6572 (0.6554)  loss_vfl_dn_0: 0.4434 (0.4407)  loss_bbox_dn_0: 0.1616 (0.1995)  loss_giou_dn_0: 0.6868 (0.7087)  loss_vfl_dn_1: 0.4203 (0.4193)  loss_bbox_dn_1: 0.1190 (0.1462)  loss_giou_dn_1: 0.4813 (0.5263)  loss_vfl_dn_2: 0.4103 (0.4091)  loss_bbox_dn_2: 0.1079 (0.1347)  loss_giou_dn_2: 0.4566 (0.4876)  loss_vfl_dn_3: 0.4050 (0.4056)  loss_bbox_dn_3: 0.1081 (0.1318)  loss_giou_dn_3: 0.4498 (0.4765)  loss_vfl_dn_4: 0.4039 (0.4048)  loss_bbox_dn_4: 0.1072 (0.1309)  loss_giou_dn_4: 0.4446 (0.4733)  loss_vfl_dn_5: 0.4042 (0.4051)  loss_bbox_dn_5: 0.1075 (0.1307)  loss_giou_dn_5: 0.4441 (0.4728)  time: 0.3321  data: 0.0154  max mem: 7790\n",
            "Epoch: [96] Total time: 0:00:11 (0.3555 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 15.1783 (14.9242)  loss_vfl: 0.5545 (0.5738)  loss_bbox: 0.0981 (0.1115)  loss_giou: 0.4127 (0.4508)  loss_vfl_aux_0: 0.5834 (0.5828)  loss_bbox_aux_0: 0.1199 (0.1358)  loss_giou_aux_0: 0.4784 (0.5190)  loss_vfl_aux_1: 0.5608 (0.5668)  loss_bbox_aux_1: 0.1062 (0.1205)  loss_giou_aux_1: 0.4280 (0.4732)  loss_vfl_aux_2: 0.5452 (0.5632)  loss_bbox_aux_2: 0.1104 (0.1180)  loss_giou_aux_2: 0.4190 (0.4610)  loss_vfl_aux_3: 0.5414 (0.5666)  loss_bbox_aux_3: 0.0981 (0.1142)  loss_giou_aux_3: 0.4100 (0.4543)  loss_vfl_aux_4: 0.5550 (0.5704)  loss_bbox_aux_4: 0.0974 (0.1116)  loss_giou_aux_4: 0.4156 (0.4512)  loss_vfl_aux_5: 0.6067 (0.6346)  loss_bbox_aux_5: 0.1726 (0.1857)  loss_giou_aux_5: 0.6572 (0.6554)  loss_vfl_dn_0: 0.4434 (0.4407)  loss_bbox_dn_0: 0.1616 (0.1995)  loss_giou_dn_0: 0.6868 (0.7087)  loss_vfl_dn_1: 0.4203 (0.4193)  loss_bbox_dn_1: 0.1190 (0.1462)  loss_giou_dn_1: 0.4813 (0.5263)  loss_vfl_dn_2: 0.4103 (0.4091)  loss_bbox_dn_2: 0.1079 (0.1347)  loss_giou_dn_2: 0.4566 (0.4876)  loss_vfl_dn_3: 0.4050 (0.4056)  loss_bbox_dn_3: 0.1081 (0.1318)  loss_giou_dn_3: 0.4498 (0.4765)  loss_vfl_dn_4: 0.4039 (0.4048)  loss_bbox_dn_4: 0.1072 (0.1309)  loss_giou_dn_4: 0.4446 (0.4733)  loss_vfl_dn_5: 0.4042 (0.4051)  loss_bbox_dn_5: 0.1075 (0.1307)  loss_giou_dn_5: 0.4441 (0.4728)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8990  data: 0.5776  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3945  data: 0.1169  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4073 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.601\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [97]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 16.4148 (16.4148)  loss_vfl: 0.6022 (0.6022)  loss_bbox: 0.1284 (0.1284)  loss_giou: 0.5168 (0.5168)  loss_vfl_aux_0: 0.5986 (0.5986)  loss_bbox_aux_0: 0.1538 (0.1538)  loss_giou_aux_0: 0.5781 (0.5781)  loss_vfl_aux_1: 0.5839 (0.5839)  loss_bbox_aux_1: 0.1314 (0.1314)  loss_giou_aux_1: 0.5105 (0.5105)  loss_vfl_aux_2: 0.5860 (0.5860)  loss_bbox_aux_2: 0.1301 (0.1301)  loss_giou_aux_2: 0.5163 (0.5163)  loss_vfl_aux_3: 0.6003 (0.6003)  loss_bbox_aux_3: 0.1319 (0.1319)  loss_giou_aux_3: 0.5126 (0.5126)  loss_vfl_aux_4: 0.5869 (0.5869)  loss_bbox_aux_4: 0.1292 (0.1292)  loss_giou_aux_4: 0.5169 (0.5169)  loss_vfl_aux_5: 0.6330 (0.6330)  loss_bbox_aux_5: 0.2623 (0.2623)  loss_giou_aux_5: 0.7766 (0.7766)  loss_vfl_dn_0: 0.4230 (0.4230)  loss_bbox_dn_0: 0.2744 (0.2744)  loss_giou_dn_0: 0.8131 (0.8131)  loss_vfl_dn_1: 0.4200 (0.4200)  loss_bbox_dn_1: 0.1754 (0.1754)  loss_giou_dn_1: 0.6023 (0.6023)  loss_vfl_dn_2: 0.4157 (0.4157)  loss_bbox_dn_2: 0.1612 (0.1612)  loss_giou_dn_2: 0.5641 (0.5641)  loss_vfl_dn_3: 0.4169 (0.4169)  loss_bbox_dn_3: 0.1622 (0.1622)  loss_giou_dn_3: 0.5513 (0.5513)  loss_vfl_dn_4: 0.4168 (0.4168)  loss_bbox_dn_4: 0.1631 (0.1631)  loss_giou_dn_4: 0.5462 (0.5462)  loss_vfl_dn_5: 0.4194 (0.4194)  loss_bbox_dn_5: 0.1625 (0.1625)  loss_giou_dn_5: 0.5418 (0.5418)  time: 0.9603  data: 0.5802  max mem: 7790\n",
            "Epoch: [97]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.1977 (14.5609)  loss_vfl: 0.5395 (0.5530)  loss_bbox: 0.0997 (0.1058)  loss_giou: 0.4155 (0.4436)  loss_vfl_aux_0: 0.5443 (0.5724)  loss_bbox_aux_0: 0.1127 (0.1263)  loss_giou_aux_0: 0.4638 (0.4947)  loss_vfl_aux_1: 0.5442 (0.5547)  loss_bbox_aux_1: 0.1044 (0.1119)  loss_giou_aux_1: 0.4306 (0.4582)  loss_vfl_aux_2: 0.5416 (0.5547)  loss_bbox_aux_2: 0.1001 (0.1076)  loss_giou_aux_2: 0.4391 (0.4488)  loss_vfl_aux_3: 0.5390 (0.5520)  loss_bbox_aux_3: 0.1011 (0.1073)  loss_giou_aux_3: 0.4217 (0.4470)  loss_vfl_aux_4: 0.5409 (0.5527)  loss_bbox_aux_4: 0.0991 (0.1055)  loss_giou_aux_4: 0.4161 (0.4438)  loss_vfl_aux_5: 0.6076 (0.6374)  loss_bbox_aux_5: 0.1403 (0.1682)  loss_giou_aux_5: 0.5867 (0.6159)  loss_vfl_dn_0: 0.4391 (0.4399)  loss_bbox_dn_0: 0.1734 (0.1941)  loss_giou_dn_0: 0.6793 (0.6927)  loss_vfl_dn_1: 0.4119 (0.4172)  loss_bbox_dn_1: 0.1145 (0.1392)  loss_giou_dn_1: 0.4918 (0.5157)  loss_vfl_dn_2: 0.4017 (0.4071)  loss_bbox_dn_2: 0.0996 (0.1276)  loss_giou_dn_2: 0.4538 (0.4788)  loss_vfl_dn_3: 0.3958 (0.4027)  loss_bbox_dn_3: 0.0958 (0.1251)  loss_giou_dn_3: 0.4527 (0.4703)  loss_vfl_dn_4: 0.3955 (0.4017)  loss_bbox_dn_4: 0.0939 (0.1244)  loss_giou_dn_4: 0.4469 (0.4679)  loss_vfl_dn_5: 0.3958 (0.4028)  loss_bbox_dn_5: 0.0934 (0.1242)  loss_giou_dn_5: 0.4479 (0.4679)  time: 0.3272  data: 0.0148  max mem: 7790\n",
            "Epoch: [97] Total time: 0:00:11 (0.3609 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.1977 (14.5609)  loss_vfl: 0.5395 (0.5530)  loss_bbox: 0.0997 (0.1058)  loss_giou: 0.4155 (0.4436)  loss_vfl_aux_0: 0.5443 (0.5724)  loss_bbox_aux_0: 0.1127 (0.1263)  loss_giou_aux_0: 0.4638 (0.4947)  loss_vfl_aux_1: 0.5442 (0.5547)  loss_bbox_aux_1: 0.1044 (0.1119)  loss_giou_aux_1: 0.4306 (0.4582)  loss_vfl_aux_2: 0.5416 (0.5547)  loss_bbox_aux_2: 0.1001 (0.1076)  loss_giou_aux_2: 0.4391 (0.4488)  loss_vfl_aux_3: 0.5390 (0.5520)  loss_bbox_aux_3: 0.1011 (0.1073)  loss_giou_aux_3: 0.4217 (0.4470)  loss_vfl_aux_4: 0.5409 (0.5527)  loss_bbox_aux_4: 0.0991 (0.1055)  loss_giou_aux_4: 0.4161 (0.4438)  loss_vfl_aux_5: 0.6076 (0.6374)  loss_bbox_aux_5: 0.1403 (0.1682)  loss_giou_aux_5: 0.5867 (0.6159)  loss_vfl_dn_0: 0.4391 (0.4399)  loss_bbox_dn_0: 0.1734 (0.1941)  loss_giou_dn_0: 0.6793 (0.6927)  loss_vfl_dn_1: 0.4119 (0.4172)  loss_bbox_dn_1: 0.1145 (0.1392)  loss_giou_dn_1: 0.4918 (0.5157)  loss_vfl_dn_2: 0.4017 (0.4071)  loss_bbox_dn_2: 0.0996 (0.1276)  loss_giou_dn_2: 0.4538 (0.4788)  loss_vfl_dn_3: 0.3958 (0.4027)  loss_bbox_dn_3: 0.0958 (0.1251)  loss_giou_dn_3: 0.4527 (0.4703)  loss_vfl_dn_4: 0.3955 (0.4017)  loss_bbox_dn_4: 0.0939 (0.1244)  loss_giou_dn_4: 0.4469 (0.4679)  loss_vfl_dn_5: 0.3958 (0.4028)  loss_bbox_dn_5: 0.0934 (0.1242)  loss_giou_dn_5: 0.4479 (0.4679)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8471  data: 0.5345  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3851  data: 0.1106  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3990 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [98]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 16.7644 (16.7644)  loss_vfl: 0.7960 (0.7960)  loss_bbox: 0.1555 (0.1555)  loss_giou: 0.3061 (0.3061)  loss_vfl_aux_0: 0.6156 (0.6156)  loss_bbox_aux_0: 0.2833 (0.2833)  loss_giou_aux_0: 0.4411 (0.4411)  loss_vfl_aux_1: 0.6087 (0.6087)  loss_bbox_aux_1: 0.2139 (0.2139)  loss_giou_aux_1: 0.3635 (0.3635)  loss_vfl_aux_2: 0.6594 (0.6594)  loss_bbox_aux_2: 0.1754 (0.1754)  loss_giou_aux_2: 0.3245 (0.3245)  loss_vfl_aux_3: 0.7269 (0.7269)  loss_bbox_aux_3: 0.1598 (0.1598)  loss_giou_aux_3: 0.3162 (0.3162)  loss_vfl_aux_4: 0.7494 (0.7494)  loss_bbox_aux_4: 0.1574 (0.1574)  loss_giou_aux_4: 0.3063 (0.3063)  loss_vfl_aux_5: 0.6023 (0.6023)  loss_bbox_aux_5: 0.5453 (0.5453)  loss_giou_aux_5: 0.8209 (0.8209)  loss_vfl_dn_0: 0.4456 (0.4456)  loss_bbox_dn_0: 0.4872 (0.4872)  loss_giou_dn_0: 0.7069 (0.7069)  loss_vfl_dn_1: 0.4306 (0.4306)  loss_bbox_dn_1: 0.3412 (0.3412)  loss_giou_dn_1: 0.4938 (0.4938)  loss_vfl_dn_2: 0.4137 (0.4137)  loss_bbox_dn_2: 0.3039 (0.3039)  loss_giou_dn_2: 0.4413 (0.4413)  loss_vfl_dn_3: 0.4112 (0.4112)  loss_bbox_dn_3: 0.2958 (0.2958)  loss_giou_dn_3: 0.4271 (0.4271)  loss_vfl_dn_4: 0.4051 (0.4051)  loss_bbox_dn_4: 0.2939 (0.2939)  loss_giou_dn_4: 0.4211 (0.4211)  loss_vfl_dn_5: 0.4081 (0.4081)  loss_bbox_dn_5: 0.2923 (0.2923)  loss_giou_dn_5: 0.4179 (0.4179)  time: 0.9356  data: 0.5654  max mem: 7790\n",
            "Epoch: [98]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.5692 (14.6886)  loss_vfl: 0.5620 (0.5703)  loss_bbox: 0.0921 (0.1082)  loss_giou: 0.4240 (0.4396)  loss_vfl_aux_0: 0.5563 (0.5739)  loss_bbox_aux_0: 0.1109 (0.1321)  loss_giou_aux_0: 0.4921 (0.4993)  loss_vfl_aux_1: 0.5516 (0.5628)  loss_bbox_aux_1: 0.0912 (0.1129)  loss_giou_aux_1: 0.4393 (0.4577)  loss_vfl_aux_2: 0.5671 (0.5634)  loss_bbox_aux_2: 0.0910 (0.1085)  loss_giou_aux_2: 0.4362 (0.4463)  loss_vfl_aux_3: 0.5672 (0.5661)  loss_bbox_aux_3: 0.0915 (0.1076)  loss_giou_aux_3: 0.4388 (0.4423)  loss_vfl_aux_4: 0.5614 (0.5653)  loss_bbox_aux_4: 0.0924 (0.1092)  loss_giou_aux_4: 0.4359 (0.4413)  loss_vfl_aux_5: 0.6063 (0.6209)  loss_bbox_aux_5: 0.1454 (0.1940)  loss_giou_aux_5: 0.6047 (0.6580)  loss_vfl_dn_0: 0.4405 (0.4396)  loss_bbox_dn_0: 0.1667 (0.1965)  loss_giou_dn_0: 0.6880 (0.6975)  loss_vfl_dn_1: 0.4100 (0.4150)  loss_bbox_dn_1: 0.1185 (0.1402)  loss_giou_dn_1: 0.5061 (0.5173)  loss_vfl_dn_2: 0.4069 (0.4045)  loss_bbox_dn_2: 0.1158 (0.1285)  loss_giou_dn_2: 0.4742 (0.4817)  loss_vfl_dn_3: 0.4023 (0.4008)  loss_bbox_dn_3: 0.1144 (0.1260)  loss_giou_dn_3: 0.4662 (0.4726)  loss_vfl_dn_4: 0.4011 (0.3996)  loss_bbox_dn_4: 0.1116 (0.1254)  loss_giou_dn_4: 0.4586 (0.4695)  loss_vfl_dn_5: 0.4044 (0.4000)  loss_bbox_dn_5: 0.1116 (0.1251)  loss_giou_dn_5: 0.4577 (0.4692)  time: 0.3452  data: 0.0142  max mem: 7790\n",
            "Epoch: [98] Total time: 0:00:11 (0.3619 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.5692 (14.6886)  loss_vfl: 0.5620 (0.5703)  loss_bbox: 0.0921 (0.1082)  loss_giou: 0.4240 (0.4396)  loss_vfl_aux_0: 0.5563 (0.5739)  loss_bbox_aux_0: 0.1109 (0.1321)  loss_giou_aux_0: 0.4921 (0.4993)  loss_vfl_aux_1: 0.5516 (0.5628)  loss_bbox_aux_1: 0.0912 (0.1129)  loss_giou_aux_1: 0.4393 (0.4577)  loss_vfl_aux_2: 0.5671 (0.5634)  loss_bbox_aux_2: 0.0910 (0.1085)  loss_giou_aux_2: 0.4362 (0.4463)  loss_vfl_aux_3: 0.5672 (0.5661)  loss_bbox_aux_3: 0.0915 (0.1076)  loss_giou_aux_3: 0.4388 (0.4423)  loss_vfl_aux_4: 0.5614 (0.5653)  loss_bbox_aux_4: 0.0924 (0.1092)  loss_giou_aux_4: 0.4359 (0.4413)  loss_vfl_aux_5: 0.6063 (0.6209)  loss_bbox_aux_5: 0.1454 (0.1940)  loss_giou_aux_5: 0.6047 (0.6580)  loss_vfl_dn_0: 0.4405 (0.4396)  loss_bbox_dn_0: 0.1667 (0.1965)  loss_giou_dn_0: 0.6880 (0.6975)  loss_vfl_dn_1: 0.4100 (0.4150)  loss_bbox_dn_1: 0.1185 (0.1402)  loss_giou_dn_1: 0.5061 (0.5173)  loss_vfl_dn_2: 0.4069 (0.4045)  loss_bbox_dn_2: 0.1158 (0.1285)  loss_giou_dn_2: 0.4742 (0.4817)  loss_vfl_dn_3: 0.4023 (0.4008)  loss_bbox_dn_3: 0.1144 (0.1260)  loss_giou_dn_3: 0.4662 (0.4726)  loss_vfl_dn_4: 0.4011 (0.3996)  loss_bbox_dn_4: 0.1116 (0.1254)  loss_giou_dn_4: 0.4586 (0.4695)  loss_vfl_dn_5: 0.4044 (0.4000)  loss_bbox_dn_5: 0.1116 (0.1251)  loss_giou_dn_5: 0.4577 (0.4692)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8834  data: 0.5735  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3824  data: 0.1108  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3964 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [99]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 14.5968 (14.5968)  loss_vfl: 0.5541 (0.5541)  loss_bbox: 0.1404 (0.1404)  loss_giou: 0.4117 (0.4117)  loss_vfl_aux_0: 0.5814 (0.5814)  loss_bbox_aux_0: 0.1601 (0.1601)  loss_giou_aux_0: 0.4544 (0.4544)  loss_vfl_aux_1: 0.5767 (0.5767)  loss_bbox_aux_1: 0.1475 (0.1475)  loss_giou_aux_1: 0.4201 (0.4201)  loss_vfl_aux_2: 0.5491 (0.5491)  loss_bbox_aux_2: 0.1464 (0.1464)  loss_giou_aux_2: 0.4233 (0.4233)  loss_vfl_aux_3: 0.5417 (0.5417)  loss_bbox_aux_3: 0.1449 (0.1449)  loss_giou_aux_3: 0.4174 (0.4174)  loss_vfl_aux_4: 0.5515 (0.5515)  loss_bbox_aux_4: 0.1433 (0.1433)  loss_giou_aux_4: 0.4145 (0.4145)  loss_vfl_aux_5: 0.6273 (0.6273)  loss_bbox_aux_5: 0.2480 (0.2480)  loss_giou_aux_5: 0.6782 (0.6782)  loss_vfl_dn_0: 0.4556 (0.4556)  loss_bbox_dn_0: 0.2092 (0.2092)  loss_giou_dn_0: 0.6387 (0.6387)  loss_vfl_dn_1: 0.4243 (0.4243)  loss_bbox_dn_1: 0.1563 (0.1563)  loss_giou_dn_1: 0.4687 (0.4687)  loss_vfl_dn_2: 0.4164 (0.4164)  loss_bbox_dn_2: 0.1465 (0.1465)  loss_giou_dn_2: 0.4285 (0.4285)  loss_vfl_dn_3: 0.4141 (0.4141)  loss_bbox_dn_3: 0.1439 (0.1439)  loss_giou_dn_3: 0.4160 (0.4160)  loss_vfl_dn_4: 0.4136 (0.4136)  loss_bbox_dn_4: 0.1434 (0.1434)  loss_giou_dn_4: 0.4162 (0.4162)  loss_vfl_dn_5: 0.4146 (0.4146)  loss_bbox_dn_5: 0.1432 (0.1432)  loss_giou_dn_5: 0.4156 (0.4156)  time: 0.9443  data: 0.5338  max mem: 7790\n",
            "Epoch: [99]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.3973 (14.5949)  loss_vfl: 0.5423 (0.5634)  loss_bbox: 0.1051 (0.1085)  loss_giou: 0.4631 (0.4439)  loss_vfl_aux_0: 0.5421 (0.5749)  loss_bbox_aux_0: 0.1169 (0.1241)  loss_giou_aux_0: 0.5054 (0.4934)  loss_vfl_aux_1: 0.5384 (0.5587)  loss_bbox_aux_1: 0.1039 (0.1156)  loss_giou_aux_1: 0.4649 (0.4595)  loss_vfl_aux_2: 0.5372 (0.5584)  loss_bbox_aux_2: 0.1088 (0.1121)  loss_giou_aux_2: 0.4696 (0.4503)  loss_vfl_aux_3: 0.5393 (0.5583)  loss_bbox_aux_3: 0.1065 (0.1102)  loss_giou_aux_3: 0.4698 (0.4477)  loss_vfl_aux_4: 0.5432 (0.5635)  loss_bbox_aux_4: 0.1044 (0.1090)  loss_giou_aux_4: 0.4611 (0.4446)  loss_vfl_aux_5: 0.6214 (0.6296)  loss_bbox_aux_5: 0.1557 (0.1701)  loss_giou_aux_5: 0.6087 (0.6270)  loss_vfl_dn_0: 0.4379 (0.4405)  loss_bbox_dn_0: 0.1703 (0.1911)  loss_giou_dn_0: 0.6861 (0.6853)  loss_vfl_dn_1: 0.4153 (0.4138)  loss_bbox_dn_1: 0.1279 (0.1398)  loss_giou_dn_1: 0.5223 (0.5146)  loss_vfl_dn_2: 0.4081 (0.4018)  loss_bbox_dn_2: 0.1179 (0.1292)  loss_giou_dn_2: 0.4920 (0.4784)  loss_vfl_dn_3: 0.4060 (0.3977)  loss_bbox_dn_3: 0.1154 (0.1267)  loss_giou_dn_3: 0.4802 (0.4699)  loss_vfl_dn_4: 0.4039 (0.3977)  loss_bbox_dn_4: 0.1163 (0.1263)  loss_giou_dn_4: 0.4788 (0.4681)  loss_vfl_dn_5: 0.4051 (0.3974)  loss_bbox_dn_5: 0.1162 (0.1260)  loss_giou_dn_5: 0.4790 (0.4677)  time: 0.3262  data: 0.0145  max mem: 7790\n",
            "Epoch: [99] Total time: 0:00:11 (0.3477 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.3973 (14.5949)  loss_vfl: 0.5423 (0.5634)  loss_bbox: 0.1051 (0.1085)  loss_giou: 0.4631 (0.4439)  loss_vfl_aux_0: 0.5421 (0.5749)  loss_bbox_aux_0: 0.1169 (0.1241)  loss_giou_aux_0: 0.5054 (0.4934)  loss_vfl_aux_1: 0.5384 (0.5587)  loss_bbox_aux_1: 0.1039 (0.1156)  loss_giou_aux_1: 0.4649 (0.4595)  loss_vfl_aux_2: 0.5372 (0.5584)  loss_bbox_aux_2: 0.1088 (0.1121)  loss_giou_aux_2: 0.4696 (0.4503)  loss_vfl_aux_3: 0.5393 (0.5583)  loss_bbox_aux_3: 0.1065 (0.1102)  loss_giou_aux_3: 0.4698 (0.4477)  loss_vfl_aux_4: 0.5432 (0.5635)  loss_bbox_aux_4: 0.1044 (0.1090)  loss_giou_aux_4: 0.4611 (0.4446)  loss_vfl_aux_5: 0.6214 (0.6296)  loss_bbox_aux_5: 0.1557 (0.1701)  loss_giou_aux_5: 0.6087 (0.6270)  loss_vfl_dn_0: 0.4379 (0.4405)  loss_bbox_dn_0: 0.1703 (0.1911)  loss_giou_dn_0: 0.6861 (0.6853)  loss_vfl_dn_1: 0.4153 (0.4138)  loss_bbox_dn_1: 0.1279 (0.1398)  loss_giou_dn_1: 0.5223 (0.5146)  loss_vfl_dn_2: 0.4081 (0.4018)  loss_bbox_dn_2: 0.1179 (0.1292)  loss_giou_dn_2: 0.4920 (0.4784)  loss_vfl_dn_3: 0.4060 (0.3977)  loss_bbox_dn_3: 0.1154 (0.1267)  loss_giou_dn_3: 0.4802 (0.4699)  loss_vfl_dn_4: 0.4039 (0.3977)  loss_bbox_dn_4: 0.1163 (0.1263)  loss_giou_dn_4: 0.4788 (0.4681)  loss_vfl_dn_5: 0.4051 (0.3974)  loss_bbox_dn_5: 0.1162 (0.1260)  loss_giou_dn_5: 0.4790 (0.4677)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9393  data: 0.6122  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3993  data: 0.1152  max mem: 7790\n",
            "Test: Total time: 0:00:04 (0.7030 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.618\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [100]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 12.1555 (12.1555)  loss_vfl: 0.4731 (0.4731)  loss_bbox: 0.0878 (0.0878)  loss_giou: 0.2949 (0.2949)  loss_vfl_aux_0: 0.5871 (0.5871)  loss_bbox_aux_0: 0.0908 (0.0908)  loss_giou_aux_0: 0.3409 (0.3409)  loss_vfl_aux_1: 0.5076 (0.5076)  loss_bbox_aux_1: 0.0815 (0.0815)  loss_giou_aux_1: 0.2950 (0.2950)  loss_vfl_aux_2: 0.4858 (0.4858)  loss_bbox_aux_2: 0.0870 (0.0870)  loss_giou_aux_2: 0.2959 (0.2959)  loss_vfl_aux_3: 0.4747 (0.4747)  loss_bbox_aux_3: 0.0873 (0.0873)  loss_giou_aux_3: 0.2947 (0.2947)  loss_vfl_aux_4: 0.4798 (0.4798)  loss_bbox_aux_4: 0.0875 (0.0875)  loss_giou_aux_4: 0.2938 (0.2938)  loss_vfl_aux_5: 0.7294 (0.7294)  loss_bbox_aux_5: 0.1678 (0.1678)  loss_giou_aux_5: 0.5427 (0.5427)  loss_vfl_dn_0: 0.4548 (0.4548)  loss_bbox_dn_0: 0.1626 (0.1626)  loss_giou_dn_0: 0.5931 (0.5931)  loss_vfl_dn_1: 0.4120 (0.4120)  loss_bbox_dn_1: 0.1124 (0.1124)  loss_giou_dn_1: 0.3845 (0.3845)  loss_vfl_dn_2: 0.3924 (0.3924)  loss_bbox_dn_2: 0.1020 (0.1020)  loss_giou_dn_2: 0.3304 (0.3304)  loss_vfl_dn_3: 0.3843 (0.3843)  loss_bbox_dn_3: 0.1012 (0.1012)  loss_giou_dn_3: 0.3213 (0.3213)  loss_vfl_dn_4: 0.3874 (0.3874)  loss_bbox_dn_4: 0.1015 (0.1015)  loss_giou_dn_4: 0.3216 (0.3216)  loss_vfl_dn_5: 0.3855 (0.3855)  loss_bbox_dn_5: 0.1013 (0.1013)  loss_giou_dn_5: 0.3222 (0.3222)  time: 1.0331  data: 0.6158  max mem: 7790\n",
            "Epoch: [100]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.9168 (14.4095)  loss_vfl: 0.5656 (0.5618)  loss_bbox: 0.0911 (0.1125)  loss_giou: 0.4704 (0.4181)  loss_vfl_aux_0: 0.5544 (0.5683)  loss_bbox_aux_0: 0.1069 (0.1338)  loss_giou_aux_0: 0.5268 (0.4840)  loss_vfl_aux_1: 0.5358 (0.5519)  loss_bbox_aux_1: 0.1000 (0.1207)  loss_giou_aux_1: 0.4768 (0.4405)  loss_vfl_aux_2: 0.5375 (0.5579)  loss_bbox_aux_2: 0.0940 (0.1152)  loss_giou_aux_2: 0.4718 (0.4264)  loss_vfl_aux_3: 0.5500 (0.5592)  loss_bbox_aux_3: 0.0913 (0.1130)  loss_giou_aux_3: 0.4613 (0.4220)  loss_vfl_aux_4: 0.5766 (0.5610)  loss_bbox_aux_4: 0.0910 (0.1130)  loss_giou_aux_4: 0.4703 (0.4196)  loss_vfl_aux_5: 0.5939 (0.6286)  loss_bbox_aux_5: 0.1478 (0.1819)  loss_giou_aux_5: 0.6013 (0.6121)  loss_vfl_dn_0: 0.4356 (0.4422)  loss_bbox_dn_0: 0.1689 (0.2079)  loss_giou_dn_0: 0.7084 (0.6757)  loss_vfl_dn_1: 0.4088 (0.4128)  loss_bbox_dn_1: 0.1149 (0.1494)  loss_giou_dn_1: 0.5300 (0.4965)  loss_vfl_dn_2: 0.3985 (0.4005)  loss_bbox_dn_2: 0.1020 (0.1366)  loss_giou_dn_2: 0.4979 (0.4584)  loss_vfl_dn_3: 0.3971 (0.3971)  loss_bbox_dn_3: 0.1001 (0.1335)  loss_giou_dn_3: 0.4949 (0.4486)  loss_vfl_dn_4: 0.3954 (0.3974)  loss_bbox_dn_4: 0.1007 (0.1321)  loss_giou_dn_4: 0.4938 (0.4457)  loss_vfl_dn_5: 0.3965 (0.3971)  loss_bbox_dn_5: 0.0996 (0.1316)  loss_giou_dn_5: 0.4967 (0.4448)  time: 0.3201  data: 0.0142  max mem: 7790\n",
            "Epoch: [100] Total time: 0:00:11 (0.3458 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.9168 (14.4095)  loss_vfl: 0.5656 (0.5618)  loss_bbox: 0.0911 (0.1125)  loss_giou: 0.4704 (0.4181)  loss_vfl_aux_0: 0.5544 (0.5683)  loss_bbox_aux_0: 0.1069 (0.1338)  loss_giou_aux_0: 0.5268 (0.4840)  loss_vfl_aux_1: 0.5358 (0.5519)  loss_bbox_aux_1: 0.1000 (0.1207)  loss_giou_aux_1: 0.4768 (0.4405)  loss_vfl_aux_2: 0.5375 (0.5579)  loss_bbox_aux_2: 0.0940 (0.1152)  loss_giou_aux_2: 0.4718 (0.4264)  loss_vfl_aux_3: 0.5500 (0.5592)  loss_bbox_aux_3: 0.0913 (0.1130)  loss_giou_aux_3: 0.4613 (0.4220)  loss_vfl_aux_4: 0.5766 (0.5610)  loss_bbox_aux_4: 0.0910 (0.1130)  loss_giou_aux_4: 0.4703 (0.4196)  loss_vfl_aux_5: 0.5939 (0.6286)  loss_bbox_aux_5: 0.1478 (0.1819)  loss_giou_aux_5: 0.6013 (0.6121)  loss_vfl_dn_0: 0.4356 (0.4422)  loss_bbox_dn_0: 0.1689 (0.2079)  loss_giou_dn_0: 0.7084 (0.6757)  loss_vfl_dn_1: 0.4088 (0.4128)  loss_bbox_dn_1: 0.1149 (0.1494)  loss_giou_dn_1: 0.5300 (0.4965)  loss_vfl_dn_2: 0.3985 (0.4005)  loss_bbox_dn_2: 0.1020 (0.1366)  loss_giou_dn_2: 0.4979 (0.4584)  loss_vfl_dn_3: 0.3971 (0.3971)  loss_bbox_dn_3: 0.1001 (0.1335)  loss_giou_dn_3: 0.4949 (0.4486)  loss_vfl_dn_4: 0.3954 (0.3974)  loss_bbox_dn_4: 0.1007 (0.1321)  loss_giou_dn_4: 0.4938 (0.4457)  loss_vfl_dn_5: 0.3965 (0.3971)  loss_bbox_dn_5: 0.0996 (0.1316)  loss_giou_dn_5: 0.4967 (0.4448)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8870  data: 0.5708  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3938  data: 0.1111  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4066 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [101]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 14.4634 (14.4634)  loss_vfl: 0.5210 (0.5210)  loss_bbox: 0.0768 (0.0768)  loss_giou: 0.4643 (0.4643)  loss_vfl_aux_0: 0.5372 (0.5372)  loss_bbox_aux_0: 0.0846 (0.0846)  loss_giou_aux_0: 0.4724 (0.4724)  loss_vfl_aux_1: 0.5271 (0.5271)  loss_bbox_aux_1: 0.0779 (0.0779)  loss_giou_aux_1: 0.4596 (0.4596)  loss_vfl_aux_2: 0.5265 (0.5265)  loss_bbox_aux_2: 0.0773 (0.0773)  loss_giou_aux_2: 0.4575 (0.4575)  loss_vfl_aux_3: 0.5273 (0.5273)  loss_bbox_aux_3: 0.0785 (0.0785)  loss_giou_aux_3: 0.4601 (0.4601)  loss_vfl_aux_4: 0.5215 (0.5215)  loss_bbox_aux_4: 0.0766 (0.0766)  loss_giou_aux_4: 0.4638 (0.4638)  loss_vfl_aux_5: 0.5936 (0.5936)  loss_bbox_aux_5: 0.1133 (0.1133)  loss_giou_aux_5: 0.6022 (0.6022)  loss_vfl_dn_0: 0.4436 (0.4436)  loss_bbox_dn_0: 0.1606 (0.1606)  loss_giou_dn_0: 0.7404 (0.7404)  loss_vfl_dn_1: 0.4229 (0.4229)  loss_bbox_dn_1: 0.1178 (0.1178)  loss_giou_dn_1: 0.5838 (0.5838)  loss_vfl_dn_2: 0.4145 (0.4145)  loss_bbox_dn_2: 0.1089 (0.1089)  loss_giou_dn_2: 0.5573 (0.5573)  loss_vfl_dn_3: 0.4094 (0.4094)  loss_bbox_dn_3: 0.1074 (0.1074)  loss_giou_dn_3: 0.5517 (0.5517)  loss_vfl_dn_4: 0.4038 (0.4038)  loss_bbox_dn_4: 0.1077 (0.1077)  loss_giou_dn_4: 0.5519 (0.5519)  loss_vfl_dn_5: 0.4022 (0.4022)  loss_bbox_dn_5: 0.1077 (0.1077)  loss_giou_dn_5: 0.5523 (0.5523)  time: 0.9682  data: 0.5554  max mem: 7790\n",
            "Epoch: [101]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.8715 (15.0705)  loss_vfl: 0.5324 (0.5609)  loss_bbox: 0.0843 (0.1134)  loss_giou: 0.4751 (0.4758)  loss_vfl_aux_0: 0.5403 (0.5633)  loss_bbox_aux_0: 0.1014 (0.1353)  loss_giou_aux_0: 0.5313 (0.5299)  loss_vfl_aux_1: 0.5427 (0.5651)  loss_bbox_aux_1: 0.0870 (0.1208)  loss_giou_aux_1: 0.5010 (0.4908)  loss_vfl_aux_2: 0.5323 (0.5619)  loss_bbox_aux_2: 0.0922 (0.1174)  loss_giou_aux_2: 0.4919 (0.4799)  loss_vfl_aux_3: 0.5387 (0.5632)  loss_bbox_aux_3: 0.0845 (0.1152)  loss_giou_aux_3: 0.4855 (0.4763)  loss_vfl_aux_4: 0.5336 (0.5633)  loss_bbox_aux_4: 0.0850 (0.1132)  loss_giou_aux_4: 0.4856 (0.4748)  loss_vfl_aux_5: 0.6006 (0.6143)  loss_bbox_aux_5: 0.1269 (0.1723)  loss_giou_aux_5: 0.6399 (0.6527)  loss_vfl_dn_0: 0.4388 (0.4419)  loss_bbox_dn_0: 0.1441 (0.1932)  loss_giou_dn_0: 0.7255 (0.7072)  loss_vfl_dn_1: 0.4190 (0.4185)  loss_bbox_dn_1: 0.0996 (0.1446)  loss_giou_dn_1: 0.5405 (0.5404)  loss_vfl_dn_2: 0.4130 (0.4107)  loss_bbox_dn_2: 0.0931 (0.1340)  loss_giou_dn_2: 0.5136 (0.5082)  loss_vfl_dn_3: 0.4090 (0.4077)  loss_bbox_dn_3: 0.0897 (0.1317)  loss_giou_dn_3: 0.5080 (0.4995)  loss_vfl_dn_4: 0.4080 (0.4069)  loss_bbox_dn_4: 0.0885 (0.1317)  loss_giou_dn_4: 0.5049 (0.4980)  loss_vfl_dn_5: 0.4054 (0.4070)  loss_bbox_dn_5: 0.0883 (0.1316)  loss_giou_dn_5: 0.5069 (0.4981)  time: 0.3302  data: 0.0142  max mem: 7790\n",
            "Epoch: [101] Total time: 0:00:11 (0.3514 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.8715 (15.0705)  loss_vfl: 0.5324 (0.5609)  loss_bbox: 0.0843 (0.1134)  loss_giou: 0.4751 (0.4758)  loss_vfl_aux_0: 0.5403 (0.5633)  loss_bbox_aux_0: 0.1014 (0.1353)  loss_giou_aux_0: 0.5313 (0.5299)  loss_vfl_aux_1: 0.5427 (0.5651)  loss_bbox_aux_1: 0.0870 (0.1208)  loss_giou_aux_1: 0.5010 (0.4908)  loss_vfl_aux_2: 0.5323 (0.5619)  loss_bbox_aux_2: 0.0922 (0.1174)  loss_giou_aux_2: 0.4919 (0.4799)  loss_vfl_aux_3: 0.5387 (0.5632)  loss_bbox_aux_3: 0.0845 (0.1152)  loss_giou_aux_3: 0.4855 (0.4763)  loss_vfl_aux_4: 0.5336 (0.5633)  loss_bbox_aux_4: 0.0850 (0.1132)  loss_giou_aux_4: 0.4856 (0.4748)  loss_vfl_aux_5: 0.6006 (0.6143)  loss_bbox_aux_5: 0.1269 (0.1723)  loss_giou_aux_5: 0.6399 (0.6527)  loss_vfl_dn_0: 0.4388 (0.4419)  loss_bbox_dn_0: 0.1441 (0.1932)  loss_giou_dn_0: 0.7255 (0.7072)  loss_vfl_dn_1: 0.4190 (0.4185)  loss_bbox_dn_1: 0.0996 (0.1446)  loss_giou_dn_1: 0.5405 (0.5404)  loss_vfl_dn_2: 0.4130 (0.4107)  loss_bbox_dn_2: 0.0931 (0.1340)  loss_giou_dn_2: 0.5136 (0.5082)  loss_vfl_dn_3: 0.4090 (0.4077)  loss_bbox_dn_3: 0.0897 (0.1317)  loss_giou_dn_3: 0.5080 (0.4995)  loss_vfl_dn_4: 0.4080 (0.4069)  loss_bbox_dn_4: 0.0885 (0.1317)  loss_giou_dn_4: 0.5049 (0.4980)  loss_vfl_dn_5: 0.4054 (0.4070)  loss_bbox_dn_5: 0.0883 (0.1316)  loss_giou_dn_5: 0.5069 (0.4981)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8552  data: 0.5443  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4336  data: 0.1088  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4471 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.596\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.352\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [102]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 15.1322 (15.1322)  loss_vfl: 0.5542 (0.5542)  loss_bbox: 0.1193 (0.1193)  loss_giou: 0.4324 (0.4324)  loss_vfl_aux_0: 0.6172 (0.6172)  loss_bbox_aux_0: 0.1315 (0.1315)  loss_giou_aux_0: 0.4403 (0.4403)  loss_vfl_aux_1: 0.5913 (0.5913)  loss_bbox_aux_1: 0.1263 (0.1263)  loss_giou_aux_1: 0.4197 (0.4197)  loss_vfl_aux_2: 0.5693 (0.5693)  loss_bbox_aux_2: 0.1128 (0.1128)  loss_giou_aux_2: 0.4142 (0.4142)  loss_vfl_aux_3: 0.5640 (0.5640)  loss_bbox_aux_3: 0.1178 (0.1178)  loss_giou_aux_3: 0.4147 (0.4147)  loss_vfl_aux_4: 0.5723 (0.5723)  loss_bbox_aux_4: 0.1164 (0.1164)  loss_giou_aux_4: 0.4095 (0.4095)  loss_vfl_aux_5: 0.6360 (0.6360)  loss_bbox_aux_5: 0.1908 (0.1908)  loss_giou_aux_5: 0.5906 (0.5906)  loss_vfl_dn_0: 0.4585 (0.4585)  loss_bbox_dn_0: 0.2534 (0.2534)  loss_giou_dn_0: 0.7099 (0.7099)  loss_vfl_dn_1: 0.4457 (0.4457)  loss_bbox_dn_1: 0.1795 (0.1795)  loss_giou_dn_1: 0.5221 (0.5221)  loss_vfl_dn_2: 0.4428 (0.4428)  loss_bbox_dn_2: 0.1769 (0.1769)  loss_giou_dn_2: 0.4890 (0.4890)  loss_vfl_dn_3: 0.4367 (0.4367)  loss_bbox_dn_3: 0.1771 (0.1771)  loss_giou_dn_3: 0.4851 (0.4851)  loss_vfl_dn_4: 0.4418 (0.4418)  loss_bbox_dn_4: 0.1811 (0.1811)  loss_giou_dn_4: 0.4853 (0.4853)  loss_vfl_dn_5: 0.4370 (0.4370)  loss_bbox_dn_5: 0.1824 (0.1824)  loss_giou_dn_5: 0.4872 (0.4872)  time: 0.9105  data: 0.5299  max mem: 7790\n",
            "Epoch: [102]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.3830 (14.6034)  loss_vfl: 0.5453 (0.5447)  loss_bbox: 0.0904 (0.1059)  loss_giou: 0.4455 (0.4584)  loss_vfl_aux_0: 0.5533 (0.5630)  loss_bbox_aux_0: 0.1058 (0.1225)  loss_giou_aux_0: 0.5011 (0.5066)  loss_vfl_aux_1: 0.5379 (0.5493)  loss_bbox_aux_1: 0.0920 (0.1112)  loss_giou_aux_1: 0.4571 (0.4718)  loss_vfl_aux_2: 0.5393 (0.5427)  loss_bbox_aux_2: 0.0928 (0.1086)  loss_giou_aux_2: 0.4729 (0.4627)  loss_vfl_aux_3: 0.5354 (0.5411)  loss_bbox_aux_3: 0.0895 (0.1057)  loss_giou_aux_3: 0.4758 (0.4588)  loss_vfl_aux_4: 0.5436 (0.5428)  loss_bbox_aux_4: 0.0906 (0.1058)  loss_giou_aux_4: 0.4500 (0.4591)  loss_vfl_aux_5: 0.6159 (0.6198)  loss_bbox_aux_5: 0.1482 (0.1658)  loss_giou_aux_5: 0.5853 (0.6384)  loss_vfl_dn_0: 0.4365 (0.4405)  loss_bbox_dn_0: 0.1440 (0.1869)  loss_giou_dn_0: 0.6999 (0.6902)  loss_vfl_dn_1: 0.4138 (0.4144)  loss_bbox_dn_1: 0.1008 (0.1358)  loss_giou_dn_1: 0.5281 (0.5192)  loss_vfl_dn_2: 0.4102 (0.4041)  loss_bbox_dn_2: 0.0940 (0.1278)  loss_giou_dn_2: 0.5009 (0.4862)  loss_vfl_dn_3: 0.4042 (0.4004)  loss_bbox_dn_3: 0.0941 (0.1262)  loss_giou_dn_3: 0.4922 (0.4790)  loss_vfl_dn_4: 0.4034 (0.4006)  loss_bbox_dn_4: 0.0933 (0.1263)  loss_giou_dn_4: 0.4886 (0.4776)  loss_vfl_dn_5: 0.4061 (0.4001)  loss_bbox_dn_5: 0.0921 (0.1262)  loss_giou_dn_5: 0.4888 (0.4770)  time: 0.3317  data: 0.0137  max mem: 7790\n",
            "Epoch: [102] Total time: 0:00:11 (0.3484 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.3830 (14.6034)  loss_vfl: 0.5453 (0.5447)  loss_bbox: 0.0904 (0.1059)  loss_giou: 0.4455 (0.4584)  loss_vfl_aux_0: 0.5533 (0.5630)  loss_bbox_aux_0: 0.1058 (0.1225)  loss_giou_aux_0: 0.5011 (0.5066)  loss_vfl_aux_1: 0.5379 (0.5493)  loss_bbox_aux_1: 0.0920 (0.1112)  loss_giou_aux_1: 0.4571 (0.4718)  loss_vfl_aux_2: 0.5393 (0.5427)  loss_bbox_aux_2: 0.0928 (0.1086)  loss_giou_aux_2: 0.4729 (0.4627)  loss_vfl_aux_3: 0.5354 (0.5411)  loss_bbox_aux_3: 0.0895 (0.1057)  loss_giou_aux_3: 0.4758 (0.4588)  loss_vfl_aux_4: 0.5436 (0.5428)  loss_bbox_aux_4: 0.0906 (0.1058)  loss_giou_aux_4: 0.4500 (0.4591)  loss_vfl_aux_5: 0.6159 (0.6198)  loss_bbox_aux_5: 0.1482 (0.1658)  loss_giou_aux_5: 0.5853 (0.6384)  loss_vfl_dn_0: 0.4365 (0.4405)  loss_bbox_dn_0: 0.1440 (0.1869)  loss_giou_dn_0: 0.6999 (0.6902)  loss_vfl_dn_1: 0.4138 (0.4144)  loss_bbox_dn_1: 0.1008 (0.1358)  loss_giou_dn_1: 0.5281 (0.5192)  loss_vfl_dn_2: 0.4102 (0.4041)  loss_bbox_dn_2: 0.0940 (0.1278)  loss_giou_dn_2: 0.5009 (0.4862)  loss_vfl_dn_3: 0.4042 (0.4004)  loss_bbox_dn_3: 0.0941 (0.1262)  loss_giou_dn_3: 0.4922 (0.4790)  loss_vfl_dn_4: 0.4034 (0.4006)  loss_bbox_dn_4: 0.0933 (0.1263)  loss_giou_dn_4: 0.4886 (0.4776)  loss_vfl_dn_5: 0.4061 (0.4001)  loss_bbox_dn_5: 0.0921 (0.1262)  loss_giou_dn_5: 0.4888 (0.4770)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9199  data: 0.6103  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4393  data: 0.1142  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4530 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [103]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 17.2114 (17.2114)  loss_vfl: 0.5445 (0.5445)  loss_bbox: 0.0749 (0.0749)  loss_giou: 0.7005 (0.7005)  loss_vfl_aux_0: 0.5564 (0.5564)  loss_bbox_aux_0: 0.0833 (0.0833)  loss_giou_aux_0: 0.7374 (0.7374)  loss_vfl_aux_1: 0.5569 (0.5569)  loss_bbox_aux_1: 0.0700 (0.0700)  loss_giou_aux_1: 0.6869 (0.6869)  loss_vfl_aux_2: 0.5751 (0.5751)  loss_bbox_aux_2: 0.0764 (0.0764)  loss_giou_aux_2: 0.6876 (0.6876)  loss_vfl_aux_3: 0.5454 (0.5454)  loss_bbox_aux_3: 0.0746 (0.0746)  loss_giou_aux_3: 0.6949 (0.6949)  loss_vfl_aux_4: 0.5595 (0.5595)  loss_bbox_aux_4: 0.0746 (0.0746)  loss_giou_aux_4: 0.6959 (0.6959)  loss_vfl_aux_5: 0.6023 (0.6023)  loss_bbox_aux_5: 0.1071 (0.1071)  loss_giou_aux_5: 0.8388 (0.8388)  loss_vfl_dn_0: 0.4146 (0.4146)  loss_bbox_dn_0: 0.1162 (0.1162)  loss_giou_dn_0: 0.9104 (0.9104)  loss_vfl_dn_1: 0.4109 (0.4109)  loss_bbox_dn_1: 0.0930 (0.0930)  loss_giou_dn_1: 0.7803 (0.7803)  loss_vfl_dn_2: 0.4109 (0.4109)  loss_bbox_dn_2: 0.0881 (0.0881)  loss_giou_dn_2: 0.7456 (0.7456)  loss_vfl_dn_3: 0.4049 (0.4049)  loss_bbox_dn_3: 0.0874 (0.0874)  loss_giou_dn_3: 0.7397 (0.7397)  loss_vfl_dn_4: 0.4019 (0.4019)  loss_bbox_dn_4: 0.0878 (0.0878)  loss_giou_dn_4: 0.7399 (0.7399)  loss_vfl_dn_5: 0.3981 (0.3981)  loss_bbox_dn_5: 0.0880 (0.0880)  loss_giou_dn_5: 0.7510 (0.7510)  time: 0.9557  data: 0.5551  max mem: 7790\n",
            "Epoch: [103]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.7376 (14.6531)  loss_vfl: 0.5511 (0.5732)  loss_bbox: 0.1090 (0.1101)  loss_giou: 0.4243 (0.4404)  loss_vfl_aux_0: 0.5404 (0.5680)  loss_bbox_aux_0: 0.1095 (0.1273)  loss_giou_aux_0: 0.4793 (0.4926)  loss_vfl_aux_1: 0.5419 (0.5611)  loss_bbox_aux_1: 0.1111 (0.1164)  loss_giou_aux_1: 0.4302 (0.4597)  loss_vfl_aux_2: 0.5418 (0.5653)  loss_bbox_aux_2: 0.1064 (0.1122)  loss_giou_aux_2: 0.4251 (0.4462)  loss_vfl_aux_3: 0.5469 (0.5625)  loss_bbox_aux_3: 0.1057 (0.1116)  loss_giou_aux_3: 0.4233 (0.4444)  loss_vfl_aux_4: 0.5480 (0.5676)  loss_bbox_aux_4: 0.1091 (0.1109)  loss_giou_aux_4: 0.4243 (0.4426)  loss_vfl_aux_5: 0.5878 (0.6230)  loss_bbox_aux_5: 0.1516 (0.1737)  loss_giou_aux_5: 0.6075 (0.6241)  loss_vfl_dn_0: 0.4416 (0.4417)  loss_bbox_dn_0: 0.1650 (0.1973)  loss_giou_dn_0: 0.6655 (0.6797)  loss_vfl_dn_1: 0.4180 (0.4170)  loss_bbox_dn_1: 0.1318 (0.1446)  loss_giou_dn_1: 0.4705 (0.5120)  loss_vfl_dn_2: 0.4048 (0.4064)  loss_bbox_dn_2: 0.1283 (0.1344)  loss_giou_dn_2: 0.4491 (0.4776)  loss_vfl_dn_3: 0.4010 (0.4039)  loss_bbox_dn_3: 0.1260 (0.1321)  loss_giou_dn_3: 0.4426 (0.4691)  loss_vfl_dn_4: 0.4023 (0.4033)  loss_bbox_dn_4: 0.1248 (0.1317)  loss_giou_dn_4: 0.4405 (0.4672)  loss_vfl_dn_5: 0.4023 (0.4035)  loss_bbox_dn_5: 0.1252 (0.1317)  loss_giou_dn_5: 0.4398 (0.4673)  time: 0.3323  data: 0.0148  max mem: 7790\n",
            "Epoch: [103] Total time: 0:00:11 (0.3549 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.7376 (14.6531)  loss_vfl: 0.5511 (0.5732)  loss_bbox: 0.1090 (0.1101)  loss_giou: 0.4243 (0.4404)  loss_vfl_aux_0: 0.5404 (0.5680)  loss_bbox_aux_0: 0.1095 (0.1273)  loss_giou_aux_0: 0.4793 (0.4926)  loss_vfl_aux_1: 0.5419 (0.5611)  loss_bbox_aux_1: 0.1111 (0.1164)  loss_giou_aux_1: 0.4302 (0.4597)  loss_vfl_aux_2: 0.5418 (0.5653)  loss_bbox_aux_2: 0.1064 (0.1122)  loss_giou_aux_2: 0.4251 (0.4462)  loss_vfl_aux_3: 0.5469 (0.5625)  loss_bbox_aux_3: 0.1057 (0.1116)  loss_giou_aux_3: 0.4233 (0.4444)  loss_vfl_aux_4: 0.5480 (0.5676)  loss_bbox_aux_4: 0.1091 (0.1109)  loss_giou_aux_4: 0.4243 (0.4426)  loss_vfl_aux_5: 0.5878 (0.6230)  loss_bbox_aux_5: 0.1516 (0.1737)  loss_giou_aux_5: 0.6075 (0.6241)  loss_vfl_dn_0: 0.4416 (0.4417)  loss_bbox_dn_0: 0.1650 (0.1973)  loss_giou_dn_0: 0.6655 (0.6797)  loss_vfl_dn_1: 0.4180 (0.4170)  loss_bbox_dn_1: 0.1318 (0.1446)  loss_giou_dn_1: 0.4705 (0.5120)  loss_vfl_dn_2: 0.4048 (0.4064)  loss_bbox_dn_2: 0.1283 (0.1344)  loss_giou_dn_2: 0.4491 (0.4776)  loss_vfl_dn_3: 0.4010 (0.4039)  loss_bbox_dn_3: 0.1260 (0.1321)  loss_giou_dn_3: 0.4426 (0.4691)  loss_vfl_dn_4: 0.4023 (0.4033)  loss_bbox_dn_4: 0.1248 (0.1317)  loss_giou_dn_4: 0.4405 (0.4672)  loss_vfl_dn_5: 0.4023 (0.4035)  loss_bbox_dn_5: 0.1252 (0.1317)  loss_giou_dn_5: 0.4398 (0.4673)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8633  data: 0.5433  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3877  data: 0.1140  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4013 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.673\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.293\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [104]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 16.5928 (16.5928)  loss_vfl: 0.6240 (0.6240)  loss_bbox: 0.1058 (0.1058)  loss_giou: 0.5660 (0.5660)  loss_vfl_aux_0: 0.6087 (0.6087)  loss_bbox_aux_0: 0.1171 (0.1171)  loss_giou_aux_0: 0.6157 (0.6157)  loss_vfl_aux_1: 0.6528 (0.6528)  loss_bbox_aux_1: 0.1095 (0.1095)  loss_giou_aux_1: 0.5861 (0.5861)  loss_vfl_aux_2: 0.6379 (0.6379)  loss_bbox_aux_2: 0.1085 (0.1085)  loss_giou_aux_2: 0.5737 (0.5737)  loss_vfl_aux_3: 0.6180 (0.6180)  loss_bbox_aux_3: 0.1102 (0.1102)  loss_giou_aux_3: 0.5846 (0.5846)  loss_vfl_aux_4: 0.6083 (0.6083)  loss_bbox_aux_4: 0.1098 (0.1098)  loss_giou_aux_4: 0.5796 (0.5796)  loss_vfl_aux_5: 0.6544 (0.6544)  loss_bbox_aux_5: 0.1378 (0.1378)  loss_giou_aux_5: 0.6994 (0.6994)  loss_vfl_dn_0: 0.4434 (0.4434)  loss_bbox_dn_0: 0.1485 (0.1485)  loss_giou_dn_0: 0.7786 (0.7786)  loss_vfl_dn_1: 0.4350 (0.4350)  loss_bbox_dn_1: 0.1226 (0.1226)  loss_giou_dn_1: 0.6603 (0.6603)  loss_vfl_dn_2: 0.4243 (0.4243)  loss_bbox_dn_2: 0.1156 (0.1156)  loss_giou_dn_2: 0.6263 (0.6263)  loss_vfl_dn_3: 0.4198 (0.4198)  loss_bbox_dn_3: 0.1138 (0.1138)  loss_giou_dn_3: 0.6162 (0.6162)  loss_vfl_dn_4: 0.4163 (0.4163)  loss_bbox_dn_4: 0.1135 (0.1135)  loss_giou_dn_4: 0.6122 (0.6122)  loss_vfl_dn_5: 0.4149 (0.4149)  loss_bbox_dn_5: 0.1132 (0.1132)  loss_giou_dn_5: 0.6102 (0.6102)  time: 1.0459  data: 0.6900  max mem: 7790\n",
            "Epoch: [104]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.8726 (14.9918)  loss_vfl: 0.5528 (0.5636)  loss_bbox: 0.1040 (0.1228)  loss_giou: 0.4919 (0.4584)  loss_vfl_aux_0: 0.5604 (0.5751)  loss_bbox_aux_0: 0.1215 (0.1438)  loss_giou_aux_0: 0.5189 (0.5130)  loss_vfl_aux_1: 0.5577 (0.5670)  loss_bbox_aux_1: 0.1096 (0.1305)  loss_giou_aux_1: 0.4866 (0.4750)  loss_vfl_aux_2: 0.5534 (0.5681)  loss_bbox_aux_2: 0.1061 (0.1241)  loss_giou_aux_2: 0.4598 (0.4625)  loss_vfl_aux_3: 0.5590 (0.5612)  loss_bbox_aux_3: 0.1048 (0.1254)  loss_giou_aux_3: 0.4861 (0.4614)  loss_vfl_aux_4: 0.5507 (0.5613)  loss_bbox_aux_4: 0.1022 (0.1244)  loss_giou_aux_4: 0.4849 (0.4598)  loss_vfl_aux_5: 0.5935 (0.6186)  loss_bbox_aux_5: 0.1819 (0.1930)  loss_giou_aux_5: 0.6356 (0.6490)  loss_vfl_dn_0: 0.4383 (0.4443)  loss_bbox_dn_0: 0.1826 (0.2059)  loss_giou_dn_0: 0.6864 (0.6852)  loss_vfl_dn_1: 0.4158 (0.4195)  loss_bbox_dn_1: 0.1282 (0.1534)  loss_giou_dn_1: 0.5109 (0.5209)  loss_vfl_dn_2: 0.4021 (0.4078)  loss_bbox_dn_2: 0.1169 (0.1424)  loss_giou_dn_2: 0.4789 (0.4874)  loss_vfl_dn_3: 0.4006 (0.4048)  loss_bbox_dn_3: 0.1166 (0.1398)  loss_giou_dn_3: 0.4622 (0.4796)  loss_vfl_dn_4: 0.3997 (0.4034)  loss_bbox_dn_4: 0.1158 (0.1394)  loss_giou_dn_4: 0.4594 (0.4780)  loss_vfl_dn_5: 0.4020 (0.4040)  loss_bbox_dn_5: 0.1162 (0.1394)  loss_giou_dn_5: 0.4626 (0.4786)  time: 0.3398  data: 0.0144  max mem: 7790\n",
            "Epoch: [104] Total time: 0:00:11 (0.3595 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.8726 (14.9918)  loss_vfl: 0.5528 (0.5636)  loss_bbox: 0.1040 (0.1228)  loss_giou: 0.4919 (0.4584)  loss_vfl_aux_0: 0.5604 (0.5751)  loss_bbox_aux_0: 0.1215 (0.1438)  loss_giou_aux_0: 0.5189 (0.5130)  loss_vfl_aux_1: 0.5577 (0.5670)  loss_bbox_aux_1: 0.1096 (0.1305)  loss_giou_aux_1: 0.4866 (0.4750)  loss_vfl_aux_2: 0.5534 (0.5681)  loss_bbox_aux_2: 0.1061 (0.1241)  loss_giou_aux_2: 0.4598 (0.4625)  loss_vfl_aux_3: 0.5590 (0.5612)  loss_bbox_aux_3: 0.1048 (0.1254)  loss_giou_aux_3: 0.4861 (0.4614)  loss_vfl_aux_4: 0.5507 (0.5613)  loss_bbox_aux_4: 0.1022 (0.1244)  loss_giou_aux_4: 0.4849 (0.4598)  loss_vfl_aux_5: 0.5935 (0.6186)  loss_bbox_aux_5: 0.1819 (0.1930)  loss_giou_aux_5: 0.6356 (0.6490)  loss_vfl_dn_0: 0.4383 (0.4443)  loss_bbox_dn_0: 0.1826 (0.2059)  loss_giou_dn_0: 0.6864 (0.6852)  loss_vfl_dn_1: 0.4158 (0.4195)  loss_bbox_dn_1: 0.1282 (0.1534)  loss_giou_dn_1: 0.5109 (0.5209)  loss_vfl_dn_2: 0.4021 (0.4078)  loss_bbox_dn_2: 0.1169 (0.1424)  loss_giou_dn_2: 0.4789 (0.4874)  loss_vfl_dn_3: 0.4006 (0.4048)  loss_bbox_dn_3: 0.1166 (0.1398)  loss_giou_dn_3: 0.4622 (0.4796)  loss_vfl_dn_4: 0.3997 (0.4034)  loss_bbox_dn_4: 0.1158 (0.1394)  loss_giou_dn_4: 0.4594 (0.4780)  loss_vfl_dn_5: 0.4020 (0.4040)  loss_bbox_dn_5: 0.1162 (0.1394)  loss_giou_dn_5: 0.4626 (0.4786)\n",
            "Test:  [0/6]  eta: 0:00:04    time: 0.8331  data: 0.5160  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3923  data: 0.1084  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4051 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.652\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [105]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 13.5468 (13.5468)  loss_vfl: 0.5989 (0.5989)  loss_bbox: 0.0686 (0.0686)  loss_giou: 0.3658 (0.3658)  loss_vfl_aux_0: 0.6030 (0.6030)  loss_bbox_aux_0: 0.0980 (0.0980)  loss_giou_aux_0: 0.4218 (0.4218)  loss_vfl_aux_1: 0.5645 (0.5645)  loss_bbox_aux_1: 0.0837 (0.0837)  loss_giou_aux_1: 0.3756 (0.3756)  loss_vfl_aux_2: 0.6012 (0.6012)  loss_bbox_aux_2: 0.0666 (0.0666)  loss_giou_aux_2: 0.3572 (0.3572)  loss_vfl_aux_3: 0.5928 (0.5928)  loss_bbox_aux_3: 0.0686 (0.0686)  loss_giou_aux_3: 0.3698 (0.3698)  loss_vfl_aux_4: 0.6033 (0.6033)  loss_bbox_aux_4: 0.0687 (0.0687)  loss_giou_aux_4: 0.3661 (0.3661)  loss_vfl_aux_5: 0.7013 (0.7013)  loss_bbox_aux_5: 0.1355 (0.1355)  loss_giou_aux_5: 0.5911 (0.5911)  loss_vfl_dn_0: 0.4371 (0.4371)  loss_bbox_dn_0: 0.1451 (0.1451)  loss_giou_dn_0: 0.6303 (0.6303)  loss_vfl_dn_1: 0.4051 (0.4051)  loss_bbox_dn_1: 0.1067 (0.1067)  loss_giou_dn_1: 0.4601 (0.4601)  loss_vfl_dn_2: 0.4049 (0.4049)  loss_bbox_dn_2: 0.0974 (0.0974)  loss_giou_dn_2: 0.4333 (0.4333)  loss_vfl_dn_3: 0.4038 (0.4038)  loss_bbox_dn_3: 0.0936 (0.0936)  loss_giou_dn_3: 0.4155 (0.4155)  loss_vfl_dn_4: 0.4030 (0.4030)  loss_bbox_dn_4: 0.0922 (0.0922)  loss_giou_dn_4: 0.4123 (0.4123)  loss_vfl_dn_5: 0.4029 (0.4029)  loss_bbox_dn_5: 0.0915 (0.0915)  loss_giou_dn_5: 0.4096 (0.4096)  time: 1.0448  data: 0.6239  max mem: 7790\n",
            "Epoch: [105]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.9690 (14.8351)  loss_vfl: 0.5296 (0.5569)  loss_bbox: 0.1018 (0.1080)  loss_giou: 0.4241 (0.4703)  loss_vfl_aux_0: 0.5465 (0.5762)  loss_bbox_aux_0: 0.1195 (0.1255)  loss_giou_aux_0: 0.4828 (0.5235)  loss_vfl_aux_1: 0.5271 (0.5606)  loss_bbox_aux_1: 0.1077 (0.1108)  loss_giou_aux_1: 0.4530 (0.4837)  loss_vfl_aux_2: 0.5267 (0.5570)  loss_bbox_aux_2: 0.1070 (0.1094)  loss_giou_aux_2: 0.4383 (0.4750)  loss_vfl_aux_3: 0.5283 (0.5472)  loss_bbox_aux_3: 0.1061 (0.1098)  loss_giou_aux_3: 0.4308 (0.4760)  loss_vfl_aux_4: 0.5112 (0.5530)  loss_bbox_aux_4: 0.1014 (0.1081)  loss_giou_aux_4: 0.4264 (0.4724)  loss_vfl_aux_5: 0.5992 (0.6174)  loss_bbox_aux_5: 0.1524 (0.1784)  loss_giou_aux_5: 0.6118 (0.6687)  loss_vfl_dn_0: 0.4437 (0.4408)  loss_bbox_dn_0: 0.1675 (0.1848)  loss_giou_dn_0: 0.6943 (0.6939)  loss_vfl_dn_1: 0.4108 (0.4143)  loss_bbox_dn_1: 0.1105 (0.1358)  loss_giou_dn_1: 0.5016 (0.5266)  loss_vfl_dn_2: 0.4020 (0.4049)  loss_bbox_dn_2: 0.1065 (0.1260)  loss_giou_dn_2: 0.4544 (0.4936)  loss_vfl_dn_3: 0.3946 (0.4012)  loss_bbox_dn_3: 0.1040 (0.1239)  loss_giou_dn_3: 0.4479 (0.4854)  loss_vfl_dn_4: 0.3952 (0.4009)  loss_bbox_dn_4: 0.1043 (0.1236)  loss_giou_dn_4: 0.4455 (0.4838)  loss_vfl_dn_5: 0.3947 (0.4006)  loss_bbox_dn_5: 0.1042 (0.1234)  loss_giou_dn_5: 0.4463 (0.4834)  time: 0.3378  data: 0.0137  max mem: 7790\n",
            "Epoch: [105] Total time: 0:00:11 (0.3581 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.9690 (14.8351)  loss_vfl: 0.5296 (0.5569)  loss_bbox: 0.1018 (0.1080)  loss_giou: 0.4241 (0.4703)  loss_vfl_aux_0: 0.5465 (0.5762)  loss_bbox_aux_0: 0.1195 (0.1255)  loss_giou_aux_0: 0.4828 (0.5235)  loss_vfl_aux_1: 0.5271 (0.5606)  loss_bbox_aux_1: 0.1077 (0.1108)  loss_giou_aux_1: 0.4530 (0.4837)  loss_vfl_aux_2: 0.5267 (0.5570)  loss_bbox_aux_2: 0.1070 (0.1094)  loss_giou_aux_2: 0.4383 (0.4750)  loss_vfl_aux_3: 0.5283 (0.5472)  loss_bbox_aux_3: 0.1061 (0.1098)  loss_giou_aux_3: 0.4308 (0.4760)  loss_vfl_aux_4: 0.5112 (0.5530)  loss_bbox_aux_4: 0.1014 (0.1081)  loss_giou_aux_4: 0.4264 (0.4724)  loss_vfl_aux_5: 0.5992 (0.6174)  loss_bbox_aux_5: 0.1524 (0.1784)  loss_giou_aux_5: 0.6118 (0.6687)  loss_vfl_dn_0: 0.4437 (0.4408)  loss_bbox_dn_0: 0.1675 (0.1848)  loss_giou_dn_0: 0.6943 (0.6939)  loss_vfl_dn_1: 0.4108 (0.4143)  loss_bbox_dn_1: 0.1105 (0.1358)  loss_giou_dn_1: 0.5016 (0.5266)  loss_vfl_dn_2: 0.4020 (0.4049)  loss_bbox_dn_2: 0.1065 (0.1260)  loss_giou_dn_2: 0.4544 (0.4936)  loss_vfl_dn_3: 0.3946 (0.4012)  loss_bbox_dn_3: 0.1040 (0.1239)  loss_giou_dn_3: 0.4479 (0.4854)  loss_vfl_dn_4: 0.3952 (0.4009)  loss_bbox_dn_4: 0.1043 (0.1236)  loss_giou_dn_4: 0.4455 (0.4838)  loss_vfl_dn_5: 0.3947 (0.4006)  loss_bbox_dn_5: 0.1042 (0.1234)  loss_giou_dn_5: 0.4463 (0.4834)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8792  data: 0.5667  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3848  data: 0.1106  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3990 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [106]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 15.2630 (15.2630)  loss_vfl: 0.5083 (0.5083)  loss_bbox: 0.0963 (0.0963)  loss_giou: 0.6097 (0.6097)  loss_vfl_aux_0: 0.5042 (0.5042)  loss_bbox_aux_0: 0.1071 (0.1071)  loss_giou_aux_0: 0.6689 (0.6689)  loss_vfl_aux_1: 0.4938 (0.4938)  loss_bbox_aux_1: 0.1010 (0.1010)  loss_giou_aux_1: 0.6231 (0.6231)  loss_vfl_aux_2: 0.4916 (0.4916)  loss_bbox_aux_2: 0.0978 (0.0978)  loss_giou_aux_2: 0.6108 (0.6108)  loss_vfl_aux_3: 0.4936 (0.4936)  loss_bbox_aux_3: 0.0970 (0.0970)  loss_giou_aux_3: 0.6142 (0.6142)  loss_vfl_aux_4: 0.5033 (0.5033)  loss_bbox_aux_4: 0.0967 (0.0967)  loss_giou_aux_4: 0.6116 (0.6116)  loss_vfl_aux_5: 0.5620 (0.5620)  loss_bbox_aux_5: 0.1279 (0.1279)  loss_giou_aux_5: 0.7211 (0.7211)  loss_vfl_dn_0: 0.4268 (0.4268)  loss_bbox_dn_0: 0.1238 (0.1238)  loss_giou_dn_0: 0.7284 (0.7284)  loss_vfl_dn_1: 0.4129 (0.4129)  loss_bbox_dn_1: 0.0907 (0.0907)  loss_giou_dn_1: 0.5889 (0.5889)  loss_vfl_dn_2: 0.4068 (0.4068)  loss_bbox_dn_2: 0.0834 (0.0834)  loss_giou_dn_2: 0.5563 (0.5563)  loss_vfl_dn_3: 0.4056 (0.4056)  loss_bbox_dn_3: 0.0827 (0.0827)  loss_giou_dn_3: 0.5512 (0.5512)  loss_vfl_dn_4: 0.4033 (0.4033)  loss_bbox_dn_4: 0.0826 (0.0826)  loss_giou_dn_4: 0.5492 (0.5492)  loss_vfl_dn_5: 0.4033 (0.4033)  loss_bbox_dn_5: 0.0819 (0.0819)  loss_giou_dn_5: 0.5453 (0.5453)  time: 0.9637  data: 0.5751  max mem: 7790\n",
            "Epoch: [106]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.8108 (14.8106)  loss_vfl: 0.5422 (0.5713)  loss_bbox: 0.0978 (0.1097)  loss_giou: 0.4229 (0.4489)  loss_vfl_aux_0: 0.5593 (0.5834)  loss_bbox_aux_0: 0.1072 (0.1246)  loss_giou_aux_0: 0.4756 (0.5027)  loss_vfl_aux_1: 0.5428 (0.5733)  loss_bbox_aux_1: 0.1031 (0.1145)  loss_giou_aux_1: 0.4450 (0.4644)  loss_vfl_aux_2: 0.5493 (0.5688)  loss_bbox_aux_2: 0.1005 (0.1136)  loss_giou_aux_2: 0.4302 (0.4568)  loss_vfl_aux_3: 0.5434 (0.5660)  loss_bbox_aux_3: 0.0982 (0.1121)  loss_giou_aux_3: 0.4288 (0.4552)  loss_vfl_aux_4: 0.5539 (0.5693)  loss_bbox_aux_4: 0.0981 (0.1114)  loss_giou_aux_4: 0.4228 (0.4509)  loss_vfl_aux_5: 0.6128 (0.6330)  loss_bbox_aux_5: 0.1373 (0.1729)  loss_giou_aux_5: 0.6553 (0.6302)  loss_vfl_dn_0: 0.4416 (0.4401)  loss_bbox_dn_0: 0.1672 (0.2051)  loss_giou_dn_0: 0.6860 (0.6900)  loss_vfl_dn_1: 0.4174 (0.4125)  loss_bbox_dn_1: 0.1346 (0.1499)  loss_giou_dn_1: 0.5369 (0.5233)  loss_vfl_dn_2: 0.4098 (0.4029)  loss_bbox_dn_2: 0.1255 (0.1377)  loss_giou_dn_2: 0.5084 (0.4886)  loss_vfl_dn_3: 0.4005 (0.3983)  loss_bbox_dn_3: 0.1210 (0.1344)  loss_giou_dn_3: 0.4969 (0.4792)  loss_vfl_dn_4: 0.4017 (0.3981)  loss_bbox_dn_4: 0.1204 (0.1333)  loss_giou_dn_4: 0.4954 (0.4765)  loss_vfl_dn_5: 0.4017 (0.3982)  loss_bbox_dn_5: 0.1202 (0.1330)  loss_giou_dn_5: 0.4978 (0.4764)  time: 0.3217  data: 0.0151  max mem: 7790\n",
            "Epoch: [106] Total time: 0:00:11 (0.3451 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.8108 (14.8106)  loss_vfl: 0.5422 (0.5713)  loss_bbox: 0.0978 (0.1097)  loss_giou: 0.4229 (0.4489)  loss_vfl_aux_0: 0.5593 (0.5834)  loss_bbox_aux_0: 0.1072 (0.1246)  loss_giou_aux_0: 0.4756 (0.5027)  loss_vfl_aux_1: 0.5428 (0.5733)  loss_bbox_aux_1: 0.1031 (0.1145)  loss_giou_aux_1: 0.4450 (0.4644)  loss_vfl_aux_2: 0.5493 (0.5688)  loss_bbox_aux_2: 0.1005 (0.1136)  loss_giou_aux_2: 0.4302 (0.4568)  loss_vfl_aux_3: 0.5434 (0.5660)  loss_bbox_aux_3: 0.0982 (0.1121)  loss_giou_aux_3: 0.4288 (0.4552)  loss_vfl_aux_4: 0.5539 (0.5693)  loss_bbox_aux_4: 0.0981 (0.1114)  loss_giou_aux_4: 0.4228 (0.4509)  loss_vfl_aux_5: 0.6128 (0.6330)  loss_bbox_aux_5: 0.1373 (0.1729)  loss_giou_aux_5: 0.6553 (0.6302)  loss_vfl_dn_0: 0.4416 (0.4401)  loss_bbox_dn_0: 0.1672 (0.2051)  loss_giou_dn_0: 0.6860 (0.6900)  loss_vfl_dn_1: 0.4174 (0.4125)  loss_bbox_dn_1: 0.1346 (0.1499)  loss_giou_dn_1: 0.5369 (0.5233)  loss_vfl_dn_2: 0.4098 (0.4029)  loss_bbox_dn_2: 0.1255 (0.1377)  loss_giou_dn_2: 0.5084 (0.4886)  loss_vfl_dn_3: 0.4005 (0.3983)  loss_bbox_dn_3: 0.1210 (0.1344)  loss_giou_dn_3: 0.4969 (0.4792)  loss_vfl_dn_4: 0.4017 (0.3981)  loss_bbox_dn_4: 0.1204 (0.1333)  loss_giou_dn_4: 0.4954 (0.4765)  loss_vfl_dn_5: 0.4017 (0.3982)  loss_bbox_dn_5: 0.1202 (0.1330)  loss_giou_dn_5: 0.4978 (0.4764)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8953  data: 0.5646  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3958  data: 0.1130  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4094 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [107]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 14.1080 (14.1080)  loss_vfl: 0.4252 (0.4252)  loss_bbox: 0.1434 (0.1434)  loss_giou: 0.4856 (0.4856)  loss_vfl_aux_0: 0.4538 (0.4538)  loss_bbox_aux_0: 0.1526 (0.1526)  loss_giou_aux_0: 0.5270 (0.5270)  loss_vfl_aux_1: 0.4289 (0.4289)  loss_bbox_aux_1: 0.1442 (0.1442)  loss_giou_aux_1: 0.5078 (0.5078)  loss_vfl_aux_2: 0.4274 (0.4274)  loss_bbox_aux_2: 0.1419 (0.1419)  loss_giou_aux_2: 0.4923 (0.4923)  loss_vfl_aux_3: 0.4234 (0.4234)  loss_bbox_aux_3: 0.1427 (0.1427)  loss_giou_aux_3: 0.4847 (0.4847)  loss_vfl_aux_4: 0.4248 (0.4248)  loss_bbox_aux_4: 0.1426 (0.1426)  loss_giou_aux_4: 0.4852 (0.4852)  loss_vfl_aux_5: 0.5498 (0.5498)  loss_bbox_aux_5: 0.1873 (0.1873)  loss_giou_aux_5: 0.6352 (0.6352)  loss_vfl_dn_0: 0.4486 (0.4486)  loss_bbox_dn_0: 0.2010 (0.2010)  loss_giou_dn_0: 0.6317 (0.6317)  loss_vfl_dn_1: 0.4133 (0.4133)  loss_bbox_dn_1: 0.1494 (0.1494)  loss_giou_dn_1: 0.4854 (0.4854)  loss_vfl_dn_2: 0.3994 (0.3994)  loss_bbox_dn_2: 0.1441 (0.1441)  loss_giou_dn_2: 0.4608 (0.4608)  loss_vfl_dn_3: 0.3950 (0.3950)  loss_bbox_dn_3: 0.1457 (0.1457)  loss_giou_dn_3: 0.4502 (0.4502)  loss_vfl_dn_4: 0.3925 (0.3925)  loss_bbox_dn_4: 0.1462 (0.1462)  loss_giou_dn_4: 0.4490 (0.4490)  loss_vfl_dn_5: 0.3938 (0.3938)  loss_bbox_dn_5: 0.1468 (0.1468)  loss_giou_dn_5: 0.4493 (0.4493)  time: 1.0384  data: 0.6732  max mem: 7790\n",
            "Epoch: [107]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.6541 (14.7296)  loss_vfl: 0.5469 (0.5395)  loss_bbox: 0.1032 (0.1067)  loss_giou: 0.4446 (0.4674)  loss_vfl_aux_0: 0.5384 (0.5497)  loss_bbox_aux_0: 0.1200 (0.1287)  loss_giou_aux_0: 0.5072 (0.5260)  loss_vfl_aux_1: 0.5336 (0.5420)  loss_bbox_aux_1: 0.1094 (0.1169)  loss_giou_aux_1: 0.4697 (0.4864)  loss_vfl_aux_2: 0.5340 (0.5454)  loss_bbox_aux_2: 0.1049 (0.1115)  loss_giou_aux_2: 0.4579 (0.4730)  loss_vfl_aux_3: 0.5344 (0.5389)  loss_bbox_aux_3: 0.1040 (0.1099)  loss_giou_aux_3: 0.4497 (0.4705)  loss_vfl_aux_4: 0.5079 (0.5371)  loss_bbox_aux_4: 0.1041 (0.1094)  loss_giou_aux_4: 0.4474 (0.4680)  loss_vfl_aux_5: 0.6039 (0.6112)  loss_bbox_aux_5: 0.1588 (0.1677)  loss_giou_aux_5: 0.6223 (0.6491)  loss_vfl_dn_0: 0.4444 (0.4411)  loss_bbox_dn_0: 0.1885 (0.1886)  loss_giou_dn_0: 0.6749 (0.6914)  loss_vfl_dn_1: 0.4138 (0.4137)  loss_bbox_dn_1: 0.1306 (0.1358)  loss_giou_dn_1: 0.5214 (0.5315)  loss_vfl_dn_2: 0.4056 (0.4054)  loss_bbox_dn_2: 0.1208 (0.1265)  loss_giou_dn_2: 0.4891 (0.4994)  loss_vfl_dn_3: 0.4069 (0.4018)  loss_bbox_dn_3: 0.1191 (0.1237)  loss_giou_dn_3: 0.4837 (0.4906)  loss_vfl_dn_4: 0.4077 (0.4013)  loss_bbox_dn_4: 0.1194 (0.1229)  loss_giou_dn_4: 0.4804 (0.4882)  loss_vfl_dn_5: 0.4062 (0.4012)  loss_bbox_dn_5: 0.1193 (0.1227)  loss_giou_dn_5: 0.4797 (0.4885)  time: 0.3313  data: 0.0145  max mem: 7790\n",
            "Epoch: [107] Total time: 0:00:11 (0.3535 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.6541 (14.7296)  loss_vfl: 0.5469 (0.5395)  loss_bbox: 0.1032 (0.1067)  loss_giou: 0.4446 (0.4674)  loss_vfl_aux_0: 0.5384 (0.5497)  loss_bbox_aux_0: 0.1200 (0.1287)  loss_giou_aux_0: 0.5072 (0.5260)  loss_vfl_aux_1: 0.5336 (0.5420)  loss_bbox_aux_1: 0.1094 (0.1169)  loss_giou_aux_1: 0.4697 (0.4864)  loss_vfl_aux_2: 0.5340 (0.5454)  loss_bbox_aux_2: 0.1049 (0.1115)  loss_giou_aux_2: 0.4579 (0.4730)  loss_vfl_aux_3: 0.5344 (0.5389)  loss_bbox_aux_3: 0.1040 (0.1099)  loss_giou_aux_3: 0.4497 (0.4705)  loss_vfl_aux_4: 0.5079 (0.5371)  loss_bbox_aux_4: 0.1041 (0.1094)  loss_giou_aux_4: 0.4474 (0.4680)  loss_vfl_aux_5: 0.6039 (0.6112)  loss_bbox_aux_5: 0.1588 (0.1677)  loss_giou_aux_5: 0.6223 (0.6491)  loss_vfl_dn_0: 0.4444 (0.4411)  loss_bbox_dn_0: 0.1885 (0.1886)  loss_giou_dn_0: 0.6749 (0.6914)  loss_vfl_dn_1: 0.4138 (0.4137)  loss_bbox_dn_1: 0.1306 (0.1358)  loss_giou_dn_1: 0.5214 (0.5315)  loss_vfl_dn_2: 0.4056 (0.4054)  loss_bbox_dn_2: 0.1208 (0.1265)  loss_giou_dn_2: 0.4891 (0.4994)  loss_vfl_dn_3: 0.4069 (0.4018)  loss_bbox_dn_3: 0.1191 (0.1237)  loss_giou_dn_3: 0.4837 (0.4906)  loss_vfl_dn_4: 0.4077 (0.4013)  loss_bbox_dn_4: 0.1194 (0.1229)  loss_giou_dn_4: 0.4804 (0.4882)  loss_vfl_dn_5: 0.4062 (0.4012)  loss_bbox_dn_5: 0.1193 (0.1227)  loss_giou_dn_5: 0.4797 (0.4885)\n",
            "Test:  [0/6]  eta: 0:00:07    time: 1.2019  data: 0.5784  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4417  data: 0.1117  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4555 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 87, 'coco_eval_bbox': 0.3416346519357726}\n",
            "Epoch: [108]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 14.2588 (14.2588)  loss_vfl: 0.5067 (0.5067)  loss_bbox: 0.1013 (0.1013)  loss_giou: 0.4710 (0.4710)  loss_vfl_aux_0: 0.4914 (0.4914)  loss_bbox_aux_0: 0.1245 (0.1245)  loss_giou_aux_0: 0.5551 (0.5551)  loss_vfl_aux_1: 0.4852 (0.4852)  loss_bbox_aux_1: 0.1019 (0.1019)  loss_giou_aux_1: 0.5292 (0.5292)  loss_vfl_aux_2: 0.4888 (0.4888)  loss_bbox_aux_2: 0.1114 (0.1114)  loss_giou_aux_2: 0.4950 (0.4950)  loss_vfl_aux_3: 0.4816 (0.4816)  loss_bbox_aux_3: 0.1093 (0.1093)  loss_giou_aux_3: 0.4852 (0.4852)  loss_vfl_aux_4: 0.5052 (0.5052)  loss_bbox_aux_4: 0.1019 (0.1019)  loss_giou_aux_4: 0.4708 (0.4708)  loss_vfl_aux_5: 0.5573 (0.5573)  loss_bbox_aux_5: 0.1220 (0.1220)  loss_giou_aux_5: 0.5923 (0.5923)  loss_vfl_dn_0: 0.4438 (0.4438)  loss_bbox_dn_0: 0.1430 (0.1430)  loss_giou_dn_0: 0.6846 (0.6846)  loss_vfl_dn_1: 0.4116 (0.4116)  loss_bbox_dn_1: 0.1079 (0.1079)  loss_giou_dn_1: 0.5292 (0.5292)  loss_vfl_dn_2: 0.4070 (0.4070)  loss_bbox_dn_2: 0.1063 (0.1063)  loss_giou_dn_2: 0.5062 (0.5062)  loss_vfl_dn_3: 0.4088 (0.4088)  loss_bbox_dn_3: 0.1057 (0.1057)  loss_giou_dn_3: 0.4982 (0.4982)  loss_vfl_dn_4: 0.4088 (0.4088)  loss_bbox_dn_4: 0.1062 (0.1062)  loss_giou_dn_4: 0.4941 (0.4941)  loss_vfl_dn_5: 0.4109 (0.4109)  loss_bbox_dn_5: 0.1059 (0.1059)  loss_giou_dn_5: 0.4935 (0.4935)  time: 1.0010  data: 0.5673  max mem: 7790\n",
            "Epoch: [108]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.5529 (14.8598)  loss_vfl: 0.5581 (0.5526)  loss_bbox: 0.0990 (0.1109)  loss_giou: 0.4389 (0.4693)  loss_vfl_aux_0: 0.5718 (0.5688)  loss_bbox_aux_0: 0.1222 (0.1267)  loss_giou_aux_0: 0.4911 (0.5173)  loss_vfl_aux_1: 0.5413 (0.5504)  loss_bbox_aux_1: 0.0994 (0.1131)  loss_giou_aux_1: 0.4507 (0.4869)  loss_vfl_aux_2: 0.5423 (0.5517)  loss_bbox_aux_2: 0.1024 (0.1127)  loss_giou_aux_2: 0.4500 (0.4772)  loss_vfl_aux_3: 0.5377 (0.5482)  loss_bbox_aux_3: 0.1050 (0.1112)  loss_giou_aux_3: 0.4504 (0.4742)  loss_vfl_aux_4: 0.5543 (0.5495)  loss_bbox_aux_4: 0.0973 (0.1118)  loss_giou_aux_4: 0.4470 (0.4717)  loss_vfl_aux_5: 0.5992 (0.6174)  loss_bbox_aux_5: 0.1507 (0.1614)  loss_giou_aux_5: 0.6305 (0.6400)  loss_vfl_dn_0: 0.4360 (0.4394)  loss_bbox_dn_0: 0.1654 (0.1880)  loss_giou_dn_0: 0.6771 (0.6930)  loss_vfl_dn_1: 0.4187 (0.4184)  loss_bbox_dn_1: 0.1142 (0.1421)  loss_giou_dn_1: 0.5182 (0.5320)  loss_vfl_dn_2: 0.4107 (0.4104)  loss_bbox_dn_2: 0.1061 (0.1330)  loss_giou_dn_2: 0.4892 (0.5016)  loss_vfl_dn_3: 0.4058 (0.4060)  loss_bbox_dn_3: 0.1011 (0.1300)  loss_giou_dn_3: 0.4811 (0.4924)  loss_vfl_dn_4: 0.4094 (0.4059)  loss_bbox_dn_4: 0.1004 (0.1293)  loss_giou_dn_4: 0.4796 (0.4903)  loss_vfl_dn_5: 0.4088 (0.4062)  loss_bbox_dn_5: 0.0996 (0.1291)  loss_giou_dn_5: 0.4802 (0.4898)  time: 0.3255  data: 0.0146  max mem: 7790\n",
            "Epoch: [108] Total time: 0:00:11 (0.3477 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.5529 (14.8598)  loss_vfl: 0.5581 (0.5526)  loss_bbox: 0.0990 (0.1109)  loss_giou: 0.4389 (0.4693)  loss_vfl_aux_0: 0.5718 (0.5688)  loss_bbox_aux_0: 0.1222 (0.1267)  loss_giou_aux_0: 0.4911 (0.5173)  loss_vfl_aux_1: 0.5413 (0.5504)  loss_bbox_aux_1: 0.0994 (0.1131)  loss_giou_aux_1: 0.4507 (0.4869)  loss_vfl_aux_2: 0.5423 (0.5517)  loss_bbox_aux_2: 0.1024 (0.1127)  loss_giou_aux_2: 0.4500 (0.4772)  loss_vfl_aux_3: 0.5377 (0.5482)  loss_bbox_aux_3: 0.1050 (0.1112)  loss_giou_aux_3: 0.4504 (0.4742)  loss_vfl_aux_4: 0.5543 (0.5495)  loss_bbox_aux_4: 0.0973 (0.1118)  loss_giou_aux_4: 0.4470 (0.4717)  loss_vfl_aux_5: 0.5992 (0.6174)  loss_bbox_aux_5: 0.1507 (0.1614)  loss_giou_aux_5: 0.6305 (0.6400)  loss_vfl_dn_0: 0.4360 (0.4394)  loss_bbox_dn_0: 0.1654 (0.1880)  loss_giou_dn_0: 0.6771 (0.6930)  loss_vfl_dn_1: 0.4187 (0.4184)  loss_bbox_dn_1: 0.1142 (0.1421)  loss_giou_dn_1: 0.5182 (0.5320)  loss_vfl_dn_2: 0.4107 (0.4104)  loss_bbox_dn_2: 0.1061 (0.1330)  loss_giou_dn_2: 0.4892 (0.5016)  loss_vfl_dn_3: 0.4058 (0.4060)  loss_bbox_dn_3: 0.1011 (0.1300)  loss_giou_dn_3: 0.4811 (0.4924)  loss_vfl_dn_4: 0.4094 (0.4059)  loss_bbox_dn_4: 0.1004 (0.1293)  loss_giou_dn_4: 0.4796 (0.4903)  loss_vfl_dn_5: 0.4088 (0.4062)  loss_bbox_dn_5: 0.0996 (0.1291)  loss_giou_dn_5: 0.4802 (0.4898)\n",
            "Test:  [0/6]  eta: 0:00:04    time: 0.8272  data: 0.5175  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4336  data: 0.1107  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4472 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [109]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 10.1548 (10.1548)  loss_vfl: 0.4532 (0.4532)  loss_bbox: 0.0648 (0.0648)  loss_giou: 0.2201 (0.2201)  loss_vfl_aux_0: 0.4495 (0.4495)  loss_bbox_aux_0: 0.0791 (0.0791)  loss_giou_aux_0: 0.2739 (0.2739)  loss_vfl_aux_1: 0.4461 (0.4461)  loss_bbox_aux_1: 0.0731 (0.0731)  loss_giou_aux_1: 0.2451 (0.2451)  loss_vfl_aux_2: 0.4346 (0.4346)  loss_bbox_aux_2: 0.0684 (0.0684)  loss_giou_aux_2: 0.2333 (0.2333)  loss_vfl_aux_3: 0.4406 (0.4406)  loss_bbox_aux_3: 0.0661 (0.0661)  loss_giou_aux_3: 0.2231 (0.2231)  loss_vfl_aux_4: 0.4488 (0.4488)  loss_bbox_aux_4: 0.0654 (0.0654)  loss_giou_aux_4: 0.2204 (0.2204)  loss_vfl_aux_5: 0.5462 (0.5462)  loss_bbox_aux_5: 0.1313 (0.1313)  loss_giou_aux_5: 0.4196 (0.4196)  loss_vfl_dn_0: 0.4529 (0.4529)  loss_bbox_dn_0: 0.1612 (0.1612)  loss_giou_dn_0: 0.5062 (0.5062)  loss_vfl_dn_1: 0.3992 (0.3992)  loss_bbox_dn_1: 0.0947 (0.0947)  loss_giou_dn_1: 0.2940 (0.2940)  loss_vfl_dn_2: 0.3697 (0.3697)  loss_bbox_dn_2: 0.0762 (0.0762)  loss_giou_dn_2: 0.2426 (0.2426)  loss_vfl_dn_3: 0.3580 (0.3580)  loss_bbox_dn_3: 0.0718 (0.0718)  loss_giou_dn_3: 0.2292 (0.2292)  loss_vfl_dn_4: 0.3553 (0.3553)  loss_bbox_dn_4: 0.0703 (0.0703)  loss_giou_dn_4: 0.2239 (0.2239)  loss_vfl_dn_5: 0.3540 (0.3540)  loss_bbox_dn_5: 0.0695 (0.0695)  loss_giou_dn_5: 0.2233 (0.2233)  time: 0.9125  data: 0.5249  max mem: 7790\n",
            "Epoch: [109]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.5670 (14.3876)  loss_vfl: 0.5376 (0.5396)  loss_bbox: 0.1045 (0.1036)  loss_giou: 0.4560 (0.4528)  loss_vfl_aux_0: 0.5325 (0.5429)  loss_bbox_aux_0: 0.1191 (0.1162)  loss_giou_aux_0: 0.4794 (0.5016)  loss_vfl_aux_1: 0.5269 (0.5366)  loss_bbox_aux_1: 0.1084 (0.1067)  loss_giou_aux_1: 0.4605 (0.4639)  loss_vfl_aux_2: 0.5317 (0.5379)  loss_bbox_aux_2: 0.1041 (0.1040)  loss_giou_aux_2: 0.4551 (0.4548)  loss_vfl_aux_3: 0.5361 (0.5413)  loss_bbox_aux_3: 0.1018 (0.1023)  loss_giou_aux_3: 0.4576 (0.4506)  loss_vfl_aux_4: 0.5322 (0.5398)  loss_bbox_aux_4: 0.1040 (0.1035)  loss_giou_aux_4: 0.4342 (0.4512)  loss_vfl_aux_5: 0.5891 (0.5888)  loss_bbox_aux_5: 0.1588 (0.1639)  loss_giou_aux_5: 0.6528 (0.6370)  loss_vfl_dn_0: 0.4377 (0.4409)  loss_bbox_dn_0: 0.1733 (0.1841)  loss_giou_dn_0: 0.6820 (0.6854)  loss_vfl_dn_1: 0.4137 (0.4141)  loss_bbox_dn_1: 0.1204 (0.1311)  loss_giou_dn_1: 0.5084 (0.5135)  loss_vfl_dn_2: 0.4014 (0.4044)  loss_bbox_dn_2: 0.1100 (0.1202)  loss_giou_dn_2: 0.4989 (0.4815)  loss_vfl_dn_3: 0.3994 (0.4010)  loss_bbox_dn_3: 0.1076 (0.1174)  loss_giou_dn_3: 0.4937 (0.4747)  loss_vfl_dn_4: 0.4010 (0.3996)  loss_bbox_dn_4: 0.1073 (0.1171)  loss_giou_dn_4: 0.4937 (0.4735)  loss_vfl_dn_5: 0.3970 (0.3992)  loss_bbox_dn_5: 0.1081 (0.1169)  loss_giou_dn_5: 0.4900 (0.4741)  time: 0.3226  data: 0.0145  max mem: 7790\n",
            "Epoch: [109] Total time: 0:00:11 (0.3452 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.5670 (14.3876)  loss_vfl: 0.5376 (0.5396)  loss_bbox: 0.1045 (0.1036)  loss_giou: 0.4560 (0.4528)  loss_vfl_aux_0: 0.5325 (0.5429)  loss_bbox_aux_0: 0.1191 (0.1162)  loss_giou_aux_0: 0.4794 (0.5016)  loss_vfl_aux_1: 0.5269 (0.5366)  loss_bbox_aux_1: 0.1084 (0.1067)  loss_giou_aux_1: 0.4605 (0.4639)  loss_vfl_aux_2: 0.5317 (0.5379)  loss_bbox_aux_2: 0.1041 (0.1040)  loss_giou_aux_2: 0.4551 (0.4548)  loss_vfl_aux_3: 0.5361 (0.5413)  loss_bbox_aux_3: 0.1018 (0.1023)  loss_giou_aux_3: 0.4576 (0.4506)  loss_vfl_aux_4: 0.5322 (0.5398)  loss_bbox_aux_4: 0.1040 (0.1035)  loss_giou_aux_4: 0.4342 (0.4512)  loss_vfl_aux_5: 0.5891 (0.5888)  loss_bbox_aux_5: 0.1588 (0.1639)  loss_giou_aux_5: 0.6528 (0.6370)  loss_vfl_dn_0: 0.4377 (0.4409)  loss_bbox_dn_0: 0.1733 (0.1841)  loss_giou_dn_0: 0.6820 (0.6854)  loss_vfl_dn_1: 0.4137 (0.4141)  loss_bbox_dn_1: 0.1204 (0.1311)  loss_giou_dn_1: 0.5084 (0.5135)  loss_vfl_dn_2: 0.4014 (0.4044)  loss_bbox_dn_2: 0.1100 (0.1202)  loss_giou_dn_2: 0.4989 (0.4815)  loss_vfl_dn_3: 0.3994 (0.4010)  loss_bbox_dn_3: 0.1076 (0.1174)  loss_giou_dn_3: 0.4937 (0.4747)  loss_vfl_dn_4: 0.4010 (0.3996)  loss_bbox_dn_4: 0.1073 (0.1171)  loss_giou_dn_4: 0.4937 (0.4735)  loss_vfl_dn_5: 0.3970 (0.3992)  loss_bbox_dn_5: 0.1081 (0.1169)  loss_giou_dn_5: 0.4900 (0.4741)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9397  data: 0.6198  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4576  data: 0.1155  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4731 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.623\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [110]  [ 0/33]  eta: 0:00:29  lr: 0.000001  loss: 14.7238 (14.7238)  loss_vfl: 0.5392 (0.5392)  loss_bbox: 0.1165 (0.1165)  loss_giou: 0.4332 (0.4332)  loss_vfl_aux_0: 0.5426 (0.5426)  loss_bbox_aux_0: 0.1509 (0.1509)  loss_giou_aux_0: 0.5642 (0.5642)  loss_vfl_aux_1: 0.5205 (0.5205)  loss_bbox_aux_1: 0.1244 (0.1244)  loss_giou_aux_1: 0.4745 (0.4745)  loss_vfl_aux_2: 0.5265 (0.5265)  loss_bbox_aux_2: 0.1170 (0.1170)  loss_giou_aux_2: 0.4460 (0.4460)  loss_vfl_aux_3: 0.5324 (0.5324)  loss_bbox_aux_3: 0.1173 (0.1173)  loss_giou_aux_3: 0.4352 (0.4352)  loss_vfl_aux_4: 0.5460 (0.5460)  loss_bbox_aux_4: 0.1163 (0.1163)  loss_giou_aux_4: 0.4330 (0.4330)  loss_vfl_aux_5: 0.6172 (0.6172)  loss_bbox_aux_5: 0.2513 (0.2513)  loss_giou_aux_5: 0.8783 (0.8783)  loss_vfl_dn_0: 0.4386 (0.4386)  loss_bbox_dn_0: 0.1734 (0.1734)  loss_giou_dn_0: 0.7320 (0.7320)  loss_vfl_dn_1: 0.4088 (0.4088)  loss_bbox_dn_1: 0.1112 (0.1112)  loss_giou_dn_1: 0.5225 (0.5225)  loss_vfl_dn_2: 0.4016 (0.4016)  loss_bbox_dn_2: 0.0993 (0.0993)  loss_giou_dn_2: 0.4808 (0.4808)  loss_vfl_dn_3: 0.3959 (0.3959)  loss_bbox_dn_3: 0.0966 (0.0966)  loss_giou_dn_3: 0.4660 (0.4660)  loss_vfl_dn_4: 0.3983 (0.3983)  loss_bbox_dn_4: 0.0960 (0.0960)  loss_giou_dn_4: 0.4647 (0.4647)  loss_vfl_dn_5: 0.3959 (0.3959)  loss_bbox_dn_5: 0.0959 (0.0959)  loss_giou_dn_5: 0.4639 (0.4639)  time: 0.9058  data: 0.4702  max mem: 7790\n",
            "Epoch: [110]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.7675 (14.8462)  loss_vfl: 0.5272 (0.5634)  loss_bbox: 0.0969 (0.1094)  loss_giou: 0.4228 (0.4555)  loss_vfl_aux_0: 0.5676 (0.5770)  loss_bbox_aux_0: 0.1249 (0.1333)  loss_giou_aux_0: 0.4801 (0.5175)  loss_vfl_aux_1: 0.5542 (0.5683)  loss_bbox_aux_1: 0.1065 (0.1172)  loss_giou_aux_1: 0.4420 (0.4730)  loss_vfl_aux_2: 0.5307 (0.5606)  loss_bbox_aux_2: 0.0976 (0.1145)  loss_giou_aux_2: 0.4309 (0.4628)  loss_vfl_aux_3: 0.5367 (0.5612)  loss_bbox_aux_3: 0.0987 (0.1130)  loss_giou_aux_3: 0.4268 (0.4597)  loss_vfl_aux_4: 0.5291 (0.5623)  loss_bbox_aux_4: 0.0972 (0.1095)  loss_giou_aux_4: 0.4241 (0.4565)  loss_vfl_aux_5: 0.6045 (0.6109)  loss_bbox_aux_5: 0.1673 (0.1916)  loss_giou_aux_5: 0.6403 (0.6885)  loss_vfl_dn_0: 0.4380 (0.4422)  loss_bbox_dn_0: 0.1526 (0.1949)  loss_giou_dn_0: 0.6447 (0.6851)  loss_vfl_dn_1: 0.4070 (0.4164)  loss_bbox_dn_1: 0.1114 (0.1438)  loss_giou_dn_1: 0.4852 (0.5195)  loss_vfl_dn_2: 0.3966 (0.4071)  loss_bbox_dn_2: 0.1002 (0.1322)  loss_giou_dn_2: 0.4449 (0.4854)  loss_vfl_dn_3: 0.3938 (0.4033)  loss_bbox_dn_3: 0.0987 (0.1294)  loss_giou_dn_3: 0.4356 (0.4763)  loss_vfl_dn_4: 0.3946 (0.4013)  loss_bbox_dn_4: 0.0978 (0.1286)  loss_giou_dn_4: 0.4304 (0.4736)  loss_vfl_dn_5: 0.3945 (0.4010)  loss_bbox_dn_5: 0.0976 (0.1280)  loss_giou_dn_5: 0.4291 (0.4728)  time: 0.3244  data: 0.0140  max mem: 7790\n",
            "Epoch: [110] Total time: 0:00:11 (0.3448 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.7675 (14.8462)  loss_vfl: 0.5272 (0.5634)  loss_bbox: 0.0969 (0.1094)  loss_giou: 0.4228 (0.4555)  loss_vfl_aux_0: 0.5676 (0.5770)  loss_bbox_aux_0: 0.1249 (0.1333)  loss_giou_aux_0: 0.4801 (0.5175)  loss_vfl_aux_1: 0.5542 (0.5683)  loss_bbox_aux_1: 0.1065 (0.1172)  loss_giou_aux_1: 0.4420 (0.4730)  loss_vfl_aux_2: 0.5307 (0.5606)  loss_bbox_aux_2: 0.0976 (0.1145)  loss_giou_aux_2: 0.4309 (0.4628)  loss_vfl_aux_3: 0.5367 (0.5612)  loss_bbox_aux_3: 0.0987 (0.1130)  loss_giou_aux_3: 0.4268 (0.4597)  loss_vfl_aux_4: 0.5291 (0.5623)  loss_bbox_aux_4: 0.0972 (0.1095)  loss_giou_aux_4: 0.4241 (0.4565)  loss_vfl_aux_5: 0.6045 (0.6109)  loss_bbox_aux_5: 0.1673 (0.1916)  loss_giou_aux_5: 0.6403 (0.6885)  loss_vfl_dn_0: 0.4380 (0.4422)  loss_bbox_dn_0: 0.1526 (0.1949)  loss_giou_dn_0: 0.6447 (0.6851)  loss_vfl_dn_1: 0.4070 (0.4164)  loss_bbox_dn_1: 0.1114 (0.1438)  loss_giou_dn_1: 0.4852 (0.5195)  loss_vfl_dn_2: 0.3966 (0.4071)  loss_bbox_dn_2: 0.1002 (0.1322)  loss_giou_dn_2: 0.4449 (0.4854)  loss_vfl_dn_3: 0.3938 (0.4033)  loss_bbox_dn_3: 0.0987 (0.1294)  loss_giou_dn_3: 0.4356 (0.4763)  loss_vfl_dn_4: 0.3946 (0.4013)  loss_bbox_dn_4: 0.0978 (0.1286)  loss_giou_dn_4: 0.4304 (0.4736)  loss_vfl_dn_5: 0.3945 (0.4010)  loss_bbox_dn_5: 0.0976 (0.1280)  loss_giou_dn_5: 0.4291 (0.4728)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8418  data: 0.5338  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3832  data: 0.1126  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3971 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [111]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 15.0220 (15.0220)  loss_vfl: 0.5834 (0.5834)  loss_bbox: 0.0891 (0.0891)  loss_giou: 0.4977 (0.4977)  loss_vfl_aux_0: 0.5524 (0.5524)  loss_bbox_aux_0: 0.1063 (0.1063)  loss_giou_aux_0: 0.5050 (0.5050)  loss_vfl_aux_1: 0.5428 (0.5428)  loss_bbox_aux_1: 0.0942 (0.0942)  loss_giou_aux_1: 0.5024 (0.5024)  loss_vfl_aux_2: 0.5848 (0.5848)  loss_bbox_aux_2: 0.0907 (0.0907)  loss_giou_aux_2: 0.4989 (0.4989)  loss_vfl_aux_3: 0.6036 (0.6036)  loss_bbox_aux_3: 0.0901 (0.0901)  loss_giou_aux_3: 0.4972 (0.4972)  loss_vfl_aux_4: 0.5854 (0.5854)  loss_bbox_aux_4: 0.0886 (0.0886)  loss_giou_aux_4: 0.4943 (0.4943)  loss_vfl_aux_5: 0.6298 (0.6298)  loss_bbox_aux_5: 0.1281 (0.1281)  loss_giou_aux_5: 0.6023 (0.6023)  loss_vfl_dn_0: 0.4403 (0.4403)  loss_bbox_dn_0: 0.1640 (0.1640)  loss_giou_dn_0: 0.7096 (0.7096)  loss_vfl_dn_1: 0.4302 (0.4302)  loss_bbox_dn_1: 0.1204 (0.1204)  loss_giou_dn_1: 0.5585 (0.5585)  loss_vfl_dn_2: 0.4252 (0.4252)  loss_bbox_dn_2: 0.1133 (0.1133)  loss_giou_dn_2: 0.5289 (0.5289)  loss_vfl_dn_3: 0.4207 (0.4207)  loss_bbox_dn_3: 0.1138 (0.1138)  loss_giou_dn_3: 0.5259 (0.5259)  loss_vfl_dn_4: 0.4185 (0.4185)  loss_bbox_dn_4: 0.1131 (0.1131)  loss_giou_dn_4: 0.5212 (0.5212)  loss_vfl_dn_5: 0.4156 (0.4156)  loss_bbox_dn_5: 0.1138 (0.1138)  loss_giou_dn_5: 0.5218 (0.5218)  time: 0.9690  data: 0.5909  max mem: 7790\n",
            "Epoch: [111]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.4940 (14.4458)  loss_vfl: 0.5018 (0.5283)  loss_bbox: 0.1020 (0.1111)  loss_giou: 0.4031 (0.4641)  loss_vfl_aux_0: 0.5153 (0.5365)  loss_bbox_aux_0: 0.1161 (0.1249)  loss_giou_aux_0: 0.4519 (0.5149)  loss_vfl_aux_1: 0.5040 (0.5265)  loss_bbox_aux_1: 0.1048 (0.1157)  loss_giou_aux_1: 0.4175 (0.4794)  loss_vfl_aux_2: 0.4904 (0.5252)  loss_bbox_aux_2: 0.1037 (0.1119)  loss_giou_aux_2: 0.4017 (0.4680)  loss_vfl_aux_3: 0.4963 (0.5273)  loss_bbox_aux_3: 0.1012 (0.1098)  loss_giou_aux_3: 0.3999 (0.4637)  loss_vfl_aux_4: 0.5055 (0.5317)  loss_bbox_aux_4: 0.1027 (0.1106)  loss_giou_aux_4: 0.3982 (0.4623)  loss_vfl_aux_5: 0.5743 (0.5891)  loss_bbox_aux_5: 0.1556 (0.1719)  loss_giou_aux_5: 0.6070 (0.6445)  loss_vfl_dn_0: 0.4410 (0.4397)  loss_bbox_dn_0: 0.1427 (0.1776)  loss_giou_dn_0: 0.6386 (0.6745)  loss_vfl_dn_1: 0.4123 (0.4109)  loss_bbox_dn_1: 0.1083 (0.1301)  loss_giou_dn_1: 0.4556 (0.5160)  loss_vfl_dn_2: 0.3948 (0.3988)  loss_bbox_dn_2: 0.1014 (0.1206)  loss_giou_dn_2: 0.4257 (0.4842)  loss_vfl_dn_3: 0.3943 (0.3966)  loss_bbox_dn_3: 0.1011 (0.1190)  loss_giou_dn_3: 0.4216 (0.4777)  loss_vfl_dn_4: 0.3948 (0.3957)  loss_bbox_dn_4: 0.1001 (0.1188)  loss_giou_dn_4: 0.4190 (0.4769)  loss_vfl_dn_5: 0.3957 (0.3949)  loss_bbox_dn_5: 0.1006 (0.1189)  loss_giou_dn_5: 0.4187 (0.4773)  time: 0.3345  data: 0.0137  max mem: 7790\n",
            "Epoch: [111] Total time: 0:00:11 (0.3532 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.4940 (14.4458)  loss_vfl: 0.5018 (0.5283)  loss_bbox: 0.1020 (0.1111)  loss_giou: 0.4031 (0.4641)  loss_vfl_aux_0: 0.5153 (0.5365)  loss_bbox_aux_0: 0.1161 (0.1249)  loss_giou_aux_0: 0.4519 (0.5149)  loss_vfl_aux_1: 0.5040 (0.5265)  loss_bbox_aux_1: 0.1048 (0.1157)  loss_giou_aux_1: 0.4175 (0.4794)  loss_vfl_aux_2: 0.4904 (0.5252)  loss_bbox_aux_2: 0.1037 (0.1119)  loss_giou_aux_2: 0.4017 (0.4680)  loss_vfl_aux_3: 0.4963 (0.5273)  loss_bbox_aux_3: 0.1012 (0.1098)  loss_giou_aux_3: 0.3999 (0.4637)  loss_vfl_aux_4: 0.5055 (0.5317)  loss_bbox_aux_4: 0.1027 (0.1106)  loss_giou_aux_4: 0.3982 (0.4623)  loss_vfl_aux_5: 0.5743 (0.5891)  loss_bbox_aux_5: 0.1556 (0.1719)  loss_giou_aux_5: 0.6070 (0.6445)  loss_vfl_dn_0: 0.4410 (0.4397)  loss_bbox_dn_0: 0.1427 (0.1776)  loss_giou_dn_0: 0.6386 (0.6745)  loss_vfl_dn_1: 0.4123 (0.4109)  loss_bbox_dn_1: 0.1083 (0.1301)  loss_giou_dn_1: 0.4556 (0.5160)  loss_vfl_dn_2: 0.3948 (0.3988)  loss_bbox_dn_2: 0.1014 (0.1206)  loss_giou_dn_2: 0.4257 (0.4842)  loss_vfl_dn_3: 0.3943 (0.3966)  loss_bbox_dn_3: 0.1011 (0.1190)  loss_giou_dn_3: 0.4216 (0.4777)  loss_vfl_dn_4: 0.3948 (0.3957)  loss_bbox_dn_4: 0.1001 (0.1188)  loss_giou_dn_4: 0.4190 (0.4769)  loss_vfl_dn_5: 0.3957 (0.3949)  loss_bbox_dn_5: 0.1006 (0.1189)  loss_giou_dn_5: 0.4187 (0.4773)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8679  data: 0.5449  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3888  data: 0.1123  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4024 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [112]  [ 0/33]  eta: 0:00:39  lr: 0.000001  loss: 17.0382 (17.0382)  loss_vfl: 0.6710 (0.6710)  loss_bbox: 0.1415 (0.1415)  loss_giou: 0.5381 (0.5381)  loss_vfl_aux_0: 0.6309 (0.6309)  loss_bbox_aux_0: 0.1531 (0.1531)  loss_giou_aux_0: 0.6137 (0.6137)  loss_vfl_aux_1: 0.6078 (0.6078)  loss_bbox_aux_1: 0.1487 (0.1487)  loss_giou_aux_1: 0.5960 (0.5960)  loss_vfl_aux_2: 0.6333 (0.6333)  loss_bbox_aux_2: 0.1446 (0.1446)  loss_giou_aux_2: 0.5705 (0.5705)  loss_vfl_aux_3: 0.6511 (0.6511)  loss_bbox_aux_3: 0.1401 (0.1401)  loss_giou_aux_3: 0.5545 (0.5545)  loss_vfl_aux_4: 0.6584 (0.6584)  loss_bbox_aux_4: 0.1386 (0.1386)  loss_giou_aux_4: 0.5413 (0.5413)  loss_vfl_aux_5: 0.6350 (0.6350)  loss_bbox_aux_5: 0.1876 (0.1876)  loss_giou_aux_5: 0.7165 (0.7165)  loss_vfl_dn_0: 0.4380 (0.4380)  loss_bbox_dn_0: 0.2311 (0.2311)  loss_giou_dn_0: 0.7759 (0.7759)  loss_vfl_dn_1: 0.4333 (0.4333)  loss_bbox_dn_1: 0.1798 (0.1798)  loss_giou_dn_1: 0.6118 (0.6118)  loss_vfl_dn_2: 0.4369 (0.4369)  loss_bbox_dn_2: 0.1682 (0.1682)  loss_giou_dn_2: 0.5853 (0.5853)  loss_vfl_dn_3: 0.4378 (0.4378)  loss_bbox_dn_3: 0.1622 (0.1622)  loss_giou_dn_3: 0.5720 (0.5720)  loss_vfl_dn_4: 0.4374 (0.4374)  loss_bbox_dn_4: 0.1617 (0.1617)  loss_giou_dn_4: 0.5677 (0.5677)  loss_vfl_dn_5: 0.4385 (0.4385)  loss_bbox_dn_5: 0.1614 (0.1614)  loss_giou_dn_5: 0.5669 (0.5669)  time: 1.1930  data: 0.7663  max mem: 7790\n",
            "Epoch: [112]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.8136 (14.2829)  loss_vfl: 0.5674 (0.5643)  loss_bbox: 0.1160 (0.1054)  loss_giou: 0.4072 (0.4232)  loss_vfl_aux_0: 0.5652 (0.5629)  loss_bbox_aux_0: 0.1247 (0.1199)  loss_giou_aux_0: 0.4628 (0.4708)  loss_vfl_aux_1: 0.5320 (0.5490)  loss_bbox_aux_1: 0.1131 (0.1103)  loss_giou_aux_1: 0.4230 (0.4415)  loss_vfl_aux_2: 0.5447 (0.5540)  loss_bbox_aux_2: 0.1107 (0.1077)  loss_giou_aux_2: 0.4046 (0.4298)  loss_vfl_aux_3: 0.5546 (0.5542)  loss_bbox_aux_3: 0.1097 (0.1059)  loss_giou_aux_3: 0.4093 (0.4256)  loss_vfl_aux_4: 0.5493 (0.5585)  loss_bbox_aux_4: 0.1167 (0.1060)  loss_giou_aux_4: 0.4055 (0.4244)  loss_vfl_aux_5: 0.6135 (0.6298)  loss_bbox_aux_5: 0.1496 (0.1637)  loss_giou_aux_5: 0.5851 (0.6059)  loss_vfl_dn_0: 0.4472 (0.4467)  loss_bbox_dn_0: 0.1867 (0.1871)  loss_giou_dn_0: 0.6613 (0.6606)  loss_vfl_dn_1: 0.4261 (0.4219)  loss_bbox_dn_1: 0.1306 (0.1369)  loss_giou_dn_1: 0.4837 (0.4936)  loss_vfl_dn_2: 0.4092 (0.4093)  loss_bbox_dn_2: 0.1177 (0.1262)  loss_giou_dn_2: 0.4482 (0.4563)  loss_vfl_dn_3: 0.4043 (0.4078)  loss_bbox_dn_3: 0.1177 (0.1239)  loss_giou_dn_3: 0.4473 (0.4481)  loss_vfl_dn_4: 0.4060 (0.4077)  loss_bbox_dn_4: 0.1172 (0.1230)  loss_giou_dn_4: 0.4462 (0.4455)  loss_vfl_dn_5: 0.4035 (0.4080)  loss_bbox_dn_5: 0.1176 (0.1229)  loss_giou_dn_5: 0.4484 (0.4450)  time: 0.3173  data: 0.0140  max mem: 7790\n",
            "Epoch: [112] Total time: 0:00:11 (0.3504 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.8136 (14.2829)  loss_vfl: 0.5674 (0.5643)  loss_bbox: 0.1160 (0.1054)  loss_giou: 0.4072 (0.4232)  loss_vfl_aux_0: 0.5652 (0.5629)  loss_bbox_aux_0: 0.1247 (0.1199)  loss_giou_aux_0: 0.4628 (0.4708)  loss_vfl_aux_1: 0.5320 (0.5490)  loss_bbox_aux_1: 0.1131 (0.1103)  loss_giou_aux_1: 0.4230 (0.4415)  loss_vfl_aux_2: 0.5447 (0.5540)  loss_bbox_aux_2: 0.1107 (0.1077)  loss_giou_aux_2: 0.4046 (0.4298)  loss_vfl_aux_3: 0.5546 (0.5542)  loss_bbox_aux_3: 0.1097 (0.1059)  loss_giou_aux_3: 0.4093 (0.4256)  loss_vfl_aux_4: 0.5493 (0.5585)  loss_bbox_aux_4: 0.1167 (0.1060)  loss_giou_aux_4: 0.4055 (0.4244)  loss_vfl_aux_5: 0.6135 (0.6298)  loss_bbox_aux_5: 0.1496 (0.1637)  loss_giou_aux_5: 0.5851 (0.6059)  loss_vfl_dn_0: 0.4472 (0.4467)  loss_bbox_dn_0: 0.1867 (0.1871)  loss_giou_dn_0: 0.6613 (0.6606)  loss_vfl_dn_1: 0.4261 (0.4219)  loss_bbox_dn_1: 0.1306 (0.1369)  loss_giou_dn_1: 0.4837 (0.4936)  loss_vfl_dn_2: 0.4092 (0.4093)  loss_bbox_dn_2: 0.1177 (0.1262)  loss_giou_dn_2: 0.4482 (0.4563)  loss_vfl_dn_3: 0.4043 (0.4078)  loss_bbox_dn_3: 0.1177 (0.1239)  loss_giou_dn_3: 0.4473 (0.4481)  loss_vfl_dn_4: 0.4060 (0.4077)  loss_bbox_dn_4: 0.1172 (0.1230)  loss_giou_dn_4: 0.4462 (0.4455)  loss_vfl_dn_5: 0.4035 (0.4080)  loss_bbox_dn_5: 0.1176 (0.1229)  loss_giou_dn_5: 0.4484 (0.4450)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8811  data: 0.5701  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3831  data: 0.1099  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3971 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [113]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 13.6638 (13.6638)  loss_vfl: 0.7169 (0.7169)  loss_bbox: 0.0977 (0.0977)  loss_giou: 0.3398 (0.3398)  loss_vfl_aux_0: 0.6501 (0.6501)  loss_bbox_aux_0: 0.1175 (0.1175)  loss_giou_aux_0: 0.3665 (0.3665)  loss_vfl_aux_1: 0.6303 (0.6303)  loss_bbox_aux_1: 0.1089 (0.1089)  loss_giou_aux_1: 0.3522 (0.3522)  loss_vfl_aux_2: 0.6507 (0.6507)  loss_bbox_aux_2: 0.0993 (0.0993)  loss_giou_aux_2: 0.3375 (0.3375)  loss_vfl_aux_3: 0.6695 (0.6695)  loss_bbox_aux_3: 0.0998 (0.0998)  loss_giou_aux_3: 0.3328 (0.3328)  loss_vfl_aux_4: 0.7014 (0.7014)  loss_bbox_aux_4: 0.0977 (0.0977)  loss_giou_aux_4: 0.3399 (0.3399)  loss_vfl_aux_5: 0.6955 (0.6955)  loss_bbox_aux_5: 0.1489 (0.1489)  loss_giou_aux_5: 0.5098 (0.5098)  loss_vfl_dn_0: 0.4349 (0.4349)  loss_bbox_dn_0: 0.1909 (0.1909)  loss_giou_dn_0: 0.5947 (0.5947)  loss_vfl_dn_1: 0.3940 (0.3940)  loss_bbox_dn_1: 0.1325 (0.1325)  loss_giou_dn_1: 0.4239 (0.4239)  loss_vfl_dn_2: 0.3741 (0.3741)  loss_bbox_dn_2: 0.1201 (0.1201)  loss_giou_dn_2: 0.3850 (0.3850)  loss_vfl_dn_3: 0.3626 (0.3626)  loss_bbox_dn_3: 0.1204 (0.1204)  loss_giou_dn_3: 0.3713 (0.3713)  loss_vfl_dn_4: 0.3633 (0.3633)  loss_bbox_dn_4: 0.1191 (0.1191)  loss_giou_dn_4: 0.3679 (0.3679)  loss_vfl_dn_5: 0.3606 (0.3606)  loss_bbox_dn_5: 0.1186 (0.1186)  loss_giou_dn_5: 0.3671 (0.3671)  time: 1.0026  data: 0.5880  max mem: 7790\n",
            "Epoch: [113]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.2934 (14.1273)  loss_vfl: 0.5489 (0.5628)  loss_bbox: 0.0991 (0.1005)  loss_giou: 0.3821 (0.4180)  loss_vfl_aux_0: 0.5565 (0.5563)  loss_bbox_aux_0: 0.1215 (0.1187)  loss_giou_aux_0: 0.4708 (0.4724)  loss_vfl_aux_1: 0.5503 (0.5541)  loss_bbox_aux_1: 0.1112 (0.1056)  loss_giou_aux_1: 0.4132 (0.4353)  loss_vfl_aux_2: 0.5455 (0.5549)  loss_bbox_aux_2: 0.1021 (0.1015)  loss_giou_aux_2: 0.4000 (0.4229)  loss_vfl_aux_3: 0.5404 (0.5520)  loss_bbox_aux_3: 0.0991 (0.1008)  loss_giou_aux_3: 0.3912 (0.4193)  loss_vfl_aux_4: 0.5410 (0.5539)  loss_bbox_aux_4: 0.1016 (0.1000)  loss_giou_aux_4: 0.3941 (0.4185)  loss_vfl_aux_5: 0.5875 (0.6107)  loss_bbox_aux_5: 0.1670 (0.1636)  loss_giou_aux_5: 0.5872 (0.6151)  loss_vfl_dn_0: 0.4399 (0.4448)  loss_bbox_dn_0: 0.1865 (0.1800)  loss_giou_dn_0: 0.6367 (0.6568)  loss_vfl_dn_1: 0.4188 (0.4156)  loss_bbox_dn_1: 0.1337 (0.1293)  loss_giou_dn_1: 0.4739 (0.4895)  loss_vfl_dn_2: 0.4113 (0.4065)  loss_bbox_dn_2: 0.1235 (0.1203)  loss_giou_dn_2: 0.4387 (0.4555)  loss_vfl_dn_3: 0.4092 (0.4031)  loss_bbox_dn_3: 0.1189 (0.1180)  loss_giou_dn_3: 0.4253 (0.4449)  loss_vfl_dn_4: 0.4091 (0.4024)  loss_bbox_dn_4: 0.1192 (0.1178)  loss_giou_dn_4: 0.4221 (0.4428)  loss_vfl_dn_5: 0.4067 (0.4031)  loss_bbox_dn_5: 0.1190 (0.1176)  loss_giou_dn_5: 0.4216 (0.4425)  time: 0.3280  data: 0.0147  max mem: 7790\n",
            "Epoch: [113] Total time: 0:00:11 (0.3501 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.2934 (14.1273)  loss_vfl: 0.5489 (0.5628)  loss_bbox: 0.0991 (0.1005)  loss_giou: 0.3821 (0.4180)  loss_vfl_aux_0: 0.5565 (0.5563)  loss_bbox_aux_0: 0.1215 (0.1187)  loss_giou_aux_0: 0.4708 (0.4724)  loss_vfl_aux_1: 0.5503 (0.5541)  loss_bbox_aux_1: 0.1112 (0.1056)  loss_giou_aux_1: 0.4132 (0.4353)  loss_vfl_aux_2: 0.5455 (0.5549)  loss_bbox_aux_2: 0.1021 (0.1015)  loss_giou_aux_2: 0.4000 (0.4229)  loss_vfl_aux_3: 0.5404 (0.5520)  loss_bbox_aux_3: 0.0991 (0.1008)  loss_giou_aux_3: 0.3912 (0.4193)  loss_vfl_aux_4: 0.5410 (0.5539)  loss_bbox_aux_4: 0.1016 (0.1000)  loss_giou_aux_4: 0.3941 (0.4185)  loss_vfl_aux_5: 0.5875 (0.6107)  loss_bbox_aux_5: 0.1670 (0.1636)  loss_giou_aux_5: 0.5872 (0.6151)  loss_vfl_dn_0: 0.4399 (0.4448)  loss_bbox_dn_0: 0.1865 (0.1800)  loss_giou_dn_0: 0.6367 (0.6568)  loss_vfl_dn_1: 0.4188 (0.4156)  loss_bbox_dn_1: 0.1337 (0.1293)  loss_giou_dn_1: 0.4739 (0.4895)  loss_vfl_dn_2: 0.4113 (0.4065)  loss_bbox_dn_2: 0.1235 (0.1203)  loss_giou_dn_2: 0.4387 (0.4555)  loss_vfl_dn_3: 0.4092 (0.4031)  loss_bbox_dn_3: 0.1189 (0.1180)  loss_giou_dn_3: 0.4253 (0.4449)  loss_vfl_dn_4: 0.4091 (0.4024)  loss_bbox_dn_4: 0.1192 (0.1178)  loss_giou_dn_4: 0.4221 (0.4428)  loss_vfl_dn_5: 0.4067 (0.4031)  loss_bbox_dn_5: 0.1190 (0.1176)  loss_giou_dn_5: 0.4216 (0.4425)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8842  data: 0.5692  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.9249  data: 0.6505  max mem: 7790\n",
            "Test: Total time: 0:00:05 (0.9401 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.383\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [114]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 12.7328 (12.7328)  loss_vfl: 0.5321 (0.5321)  loss_bbox: 0.0758 (0.0758)  loss_giou: 0.3667 (0.3667)  loss_vfl_aux_0: 0.5108 (0.5108)  loss_bbox_aux_0: 0.0848 (0.0848)  loss_giou_aux_0: 0.4133 (0.4133)  loss_vfl_aux_1: 0.5159 (0.5159)  loss_bbox_aux_1: 0.0808 (0.0808)  loss_giou_aux_1: 0.3904 (0.3904)  loss_vfl_aux_2: 0.5152 (0.5152)  loss_bbox_aux_2: 0.0779 (0.0779)  loss_giou_aux_2: 0.3744 (0.3744)  loss_vfl_aux_3: 0.5247 (0.5247)  loss_bbox_aux_3: 0.0766 (0.0766)  loss_giou_aux_3: 0.3679 (0.3679)  loss_vfl_aux_4: 0.5309 (0.5309)  loss_bbox_aux_4: 0.0758 (0.0758)  loss_giou_aux_4: 0.3664 (0.3664)  loss_vfl_aux_5: 0.5998 (0.5998)  loss_bbox_aux_5: 0.1328 (0.1328)  loss_giou_aux_5: 0.5944 (0.5944)  loss_vfl_dn_0: 0.4394 (0.4394)  loss_bbox_dn_0: 0.1068 (0.1068)  loss_giou_dn_0: 0.5789 (0.5789)  loss_vfl_dn_1: 0.3975 (0.3975)  loss_bbox_dn_1: 0.0810 (0.0810)  loss_giou_dn_1: 0.4594 (0.4594)  loss_vfl_dn_2: 0.3868 (0.3868)  loss_bbox_dn_2: 0.0741 (0.0741)  loss_giou_dn_2: 0.4145 (0.4145)  loss_vfl_dn_3: 0.3843 (0.3843)  loss_bbox_dn_3: 0.0723 (0.0723)  loss_giou_dn_3: 0.4057 (0.4057)  loss_vfl_dn_4: 0.3848 (0.3848)  loss_bbox_dn_4: 0.0726 (0.0726)  loss_giou_dn_4: 0.4053 (0.4053)  loss_vfl_dn_5: 0.3828 (0.3828)  loss_bbox_dn_5: 0.0725 (0.0725)  loss_giou_dn_5: 0.4064 (0.4064)  time: 0.9733  data: 0.5433  max mem: 7790\n",
            "Epoch: [114]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.3865 (13.9322)  loss_vfl: 0.5086 (0.5338)  loss_bbox: 0.0849 (0.0926)  loss_giou: 0.4414 (0.4276)  loss_vfl_aux_0: 0.5253 (0.5554)  loss_bbox_aux_0: 0.0921 (0.1079)  loss_giou_aux_0: 0.4685 (0.4762)  loss_vfl_aux_1: 0.5185 (0.5409)  loss_bbox_aux_1: 0.0884 (0.0957)  loss_giou_aux_1: 0.4311 (0.4407)  loss_vfl_aux_2: 0.5144 (0.5366)  loss_bbox_aux_2: 0.0830 (0.0924)  loss_giou_aux_2: 0.4227 (0.4299)  loss_vfl_aux_3: 0.5133 (0.5308)  loss_bbox_aux_3: 0.0833 (0.0920)  loss_giou_aux_3: 0.4349 (0.4292)  loss_vfl_aux_4: 0.5085 (0.5331)  loss_bbox_aux_4: 0.0824 (0.0915)  loss_giou_aux_4: 0.4394 (0.4268)  loss_vfl_aux_5: 0.5884 (0.6220)  loss_bbox_aux_5: 0.1160 (0.1510)  loss_giou_aux_5: 0.5648 (0.6127)  loss_vfl_dn_0: 0.4418 (0.4440)  loss_bbox_dn_0: 0.1392 (0.1708)  loss_giou_dn_0: 0.6353 (0.6486)  loss_vfl_dn_1: 0.4126 (0.4099)  loss_bbox_dn_1: 0.0969 (0.1231)  loss_giou_dn_1: 0.4465 (0.4885)  loss_vfl_dn_2: 0.4010 (0.3967)  loss_bbox_dn_2: 0.0939 (0.1131)  loss_giou_dn_2: 0.4304 (0.4583)  loss_vfl_dn_3: 0.3967 (0.3926)  loss_bbox_dn_3: 0.0933 (0.1108)  loss_giou_dn_3: 0.4317 (0.4515)  loss_vfl_dn_4: 0.3953 (0.3921)  loss_bbox_dn_4: 0.0940 (0.1102)  loss_giou_dn_4: 0.4371 (0.4504)  loss_vfl_dn_5: 0.3966 (0.3924)  loss_bbox_dn_5: 0.0942 (0.1101)  loss_giou_dn_5: 0.4364 (0.4504)  time: 0.3323  data: 0.0149  max mem: 7790\n",
            "Epoch: [114] Total time: 0:00:11 (0.3546 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.3865 (13.9322)  loss_vfl: 0.5086 (0.5338)  loss_bbox: 0.0849 (0.0926)  loss_giou: 0.4414 (0.4276)  loss_vfl_aux_0: 0.5253 (0.5554)  loss_bbox_aux_0: 0.0921 (0.1079)  loss_giou_aux_0: 0.4685 (0.4762)  loss_vfl_aux_1: 0.5185 (0.5409)  loss_bbox_aux_1: 0.0884 (0.0957)  loss_giou_aux_1: 0.4311 (0.4407)  loss_vfl_aux_2: 0.5144 (0.5366)  loss_bbox_aux_2: 0.0830 (0.0924)  loss_giou_aux_2: 0.4227 (0.4299)  loss_vfl_aux_3: 0.5133 (0.5308)  loss_bbox_aux_3: 0.0833 (0.0920)  loss_giou_aux_3: 0.4349 (0.4292)  loss_vfl_aux_4: 0.5085 (0.5331)  loss_bbox_aux_4: 0.0824 (0.0915)  loss_giou_aux_4: 0.4394 (0.4268)  loss_vfl_aux_5: 0.5884 (0.6220)  loss_bbox_aux_5: 0.1160 (0.1510)  loss_giou_aux_5: 0.5648 (0.6127)  loss_vfl_dn_0: 0.4418 (0.4440)  loss_bbox_dn_0: 0.1392 (0.1708)  loss_giou_dn_0: 0.6353 (0.6486)  loss_vfl_dn_1: 0.4126 (0.4099)  loss_bbox_dn_1: 0.0969 (0.1231)  loss_giou_dn_1: 0.4465 (0.4885)  loss_vfl_dn_2: 0.4010 (0.3967)  loss_bbox_dn_2: 0.0939 (0.1131)  loss_giou_dn_2: 0.4304 (0.4583)  loss_vfl_dn_3: 0.3967 (0.3926)  loss_bbox_dn_3: 0.0933 (0.1108)  loss_giou_dn_3: 0.4317 (0.4515)  loss_vfl_dn_4: 0.3953 (0.3921)  loss_bbox_dn_4: 0.0940 (0.1102)  loss_giou_dn_4: 0.4371 (0.4504)  loss_vfl_dn_5: 0.3966 (0.3924)  loss_bbox_dn_5: 0.0942 (0.1101)  loss_giou_dn_5: 0.4364 (0.4504)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8753  data: 0.5635  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4352  data: 0.1116  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4488 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.667\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [115]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 14.0209 (14.0209)  loss_vfl: 0.5861 (0.5861)  loss_bbox: 0.0847 (0.0847)  loss_giou: 0.3677 (0.3677)  loss_vfl_aux_0: 0.5667 (0.5667)  loss_bbox_aux_0: 0.1127 (0.1127)  loss_giou_aux_0: 0.4747 (0.4747)  loss_vfl_aux_1: 0.5832 (0.5832)  loss_bbox_aux_1: 0.1028 (0.1028)  loss_giou_aux_1: 0.4007 (0.4007)  loss_vfl_aux_2: 0.5956 (0.5956)  loss_bbox_aux_2: 0.0976 (0.0976)  loss_giou_aux_2: 0.3818 (0.3818)  loss_vfl_aux_3: 0.5939 (0.5939)  loss_bbox_aux_3: 0.0886 (0.0886)  loss_giou_aux_3: 0.3743 (0.3743)  loss_vfl_aux_4: 0.5907 (0.5907)  loss_bbox_aux_4: 0.0862 (0.0862)  loss_giou_aux_4: 0.3983 (0.3983)  loss_vfl_aux_5: 0.6306 (0.6306)  loss_bbox_aux_5: 0.1536 (0.1536)  loss_giou_aux_5: 0.6087 (0.6087)  loss_vfl_dn_0: 0.4338 (0.4338)  loss_bbox_dn_0: 0.1831 (0.1831)  loss_giou_dn_0: 0.6684 (0.6684)  loss_vfl_dn_1: 0.4069 (0.4069)  loss_bbox_dn_1: 0.1485 (0.1485)  loss_giou_dn_1: 0.4742 (0.4742)  loss_vfl_dn_2: 0.3926 (0.3926)  loss_bbox_dn_2: 0.1425 (0.1425)  loss_giou_dn_2: 0.4349 (0.4349)  loss_vfl_dn_3: 0.3908 (0.3908)  loss_bbox_dn_3: 0.1416 (0.1416)  loss_giou_dn_3: 0.4274 (0.4274)  loss_vfl_dn_4: 0.3902 (0.3902)  loss_bbox_dn_4: 0.1397 (0.1397)  loss_giou_dn_4: 0.4233 (0.4233)  loss_vfl_dn_5: 0.3831 (0.3831)  loss_bbox_dn_5: 0.1392 (0.1392)  loss_giou_dn_5: 0.4213 (0.4213)  time: 1.0330  data: 0.6203  max mem: 7790\n",
            "Epoch: [115]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.1058 (14.4811)  loss_vfl: 0.5420 (0.5652)  loss_bbox: 0.0915 (0.1094)  loss_giou: 0.3949 (0.4270)  loss_vfl_aux_0: 0.5532 (0.5658)  loss_bbox_aux_0: 0.1135 (0.1290)  loss_giou_aux_0: 0.4517 (0.4873)  loss_vfl_aux_1: 0.5489 (0.5602)  loss_bbox_aux_1: 0.0994 (0.1140)  loss_giou_aux_1: 0.4207 (0.4447)  loss_vfl_aux_2: 0.5615 (0.5602)  loss_bbox_aux_2: 0.0934 (0.1118)  loss_giou_aux_2: 0.4020 (0.4346)  loss_vfl_aux_3: 0.5455 (0.5636)  loss_bbox_aux_3: 0.0931 (0.1093)  loss_giou_aux_3: 0.4031 (0.4282)  loss_vfl_aux_4: 0.5495 (0.5609)  loss_bbox_aux_4: 0.0908 (0.1103)  loss_giou_aux_4: 0.4041 (0.4297)  loss_vfl_aux_5: 0.5931 (0.6203)  loss_bbox_aux_5: 0.1441 (0.1767)  loss_giou_aux_5: 0.5708 (0.6116)  loss_vfl_dn_0: 0.4393 (0.4430)  loss_bbox_dn_0: 0.1724 (0.2005)  loss_giou_dn_0: 0.6493 (0.6665)  loss_vfl_dn_1: 0.4072 (0.4137)  loss_bbox_dn_1: 0.1188 (0.1477)  loss_giou_dn_1: 0.4681 (0.5002)  loss_vfl_dn_2: 0.4024 (0.4045)  loss_bbox_dn_2: 0.1099 (0.1369)  loss_giou_dn_2: 0.4478 (0.4684)  loss_vfl_dn_3: 0.3977 (0.4009)  loss_bbox_dn_3: 0.1081 (0.1344)  loss_giou_dn_3: 0.4421 (0.4603)  loss_vfl_dn_4: 0.3990 (0.3995)  loss_bbox_dn_4: 0.1057 (0.1337)  loss_giou_dn_4: 0.4400 (0.4593)  loss_vfl_dn_5: 0.4003 (0.3994)  loss_bbox_dn_5: 0.1068 (0.1335)  loss_giou_dn_5: 0.4411 (0.4593)  time: 0.3330  data: 0.0152  max mem: 7790\n",
            "Epoch: [115] Total time: 0:00:11 (0.3546 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.1058 (14.4811)  loss_vfl: 0.5420 (0.5652)  loss_bbox: 0.0915 (0.1094)  loss_giou: 0.3949 (0.4270)  loss_vfl_aux_0: 0.5532 (0.5658)  loss_bbox_aux_0: 0.1135 (0.1290)  loss_giou_aux_0: 0.4517 (0.4873)  loss_vfl_aux_1: 0.5489 (0.5602)  loss_bbox_aux_1: 0.0994 (0.1140)  loss_giou_aux_1: 0.4207 (0.4447)  loss_vfl_aux_2: 0.5615 (0.5602)  loss_bbox_aux_2: 0.0934 (0.1118)  loss_giou_aux_2: 0.4020 (0.4346)  loss_vfl_aux_3: 0.5455 (0.5636)  loss_bbox_aux_3: 0.0931 (0.1093)  loss_giou_aux_3: 0.4031 (0.4282)  loss_vfl_aux_4: 0.5495 (0.5609)  loss_bbox_aux_4: 0.0908 (0.1103)  loss_giou_aux_4: 0.4041 (0.4297)  loss_vfl_aux_5: 0.5931 (0.6203)  loss_bbox_aux_5: 0.1441 (0.1767)  loss_giou_aux_5: 0.5708 (0.6116)  loss_vfl_dn_0: 0.4393 (0.4430)  loss_bbox_dn_0: 0.1724 (0.2005)  loss_giou_dn_0: 0.6493 (0.6665)  loss_vfl_dn_1: 0.4072 (0.4137)  loss_bbox_dn_1: 0.1188 (0.1477)  loss_giou_dn_1: 0.4681 (0.5002)  loss_vfl_dn_2: 0.4024 (0.4045)  loss_bbox_dn_2: 0.1099 (0.1369)  loss_giou_dn_2: 0.4478 (0.4684)  loss_vfl_dn_3: 0.3977 (0.4009)  loss_bbox_dn_3: 0.1081 (0.1344)  loss_giou_dn_3: 0.4421 (0.4603)  loss_vfl_dn_4: 0.3990 (0.3995)  loss_bbox_dn_4: 0.1057 (0.1337)  loss_giou_dn_4: 0.4400 (0.4593)  loss_vfl_dn_5: 0.4003 (0.3994)  loss_bbox_dn_5: 0.1068 (0.1335)  loss_giou_dn_5: 0.4411 (0.4593)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8995  data: 0.5741  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4574  data: 0.1171  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4717 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.665\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [116]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 15.2267 (15.2267)  loss_vfl: 0.5269 (0.5269)  loss_bbox: 0.0724 (0.0724)  loss_giou: 0.5193 (0.5193)  loss_vfl_aux_0: 0.5634 (0.5634)  loss_bbox_aux_0: 0.0811 (0.0811)  loss_giou_aux_0: 0.5542 (0.5542)  loss_vfl_aux_1: 0.5462 (0.5462)  loss_bbox_aux_1: 0.0732 (0.0732)  loss_giou_aux_1: 0.5368 (0.5368)  loss_vfl_aux_2: 0.5359 (0.5359)  loss_bbox_aux_2: 0.0759 (0.0759)  loss_giou_aux_2: 0.5194 (0.5194)  loss_vfl_aux_3: 0.5289 (0.5289)  loss_bbox_aux_3: 0.0750 (0.0750)  loss_giou_aux_3: 0.5192 (0.5192)  loss_vfl_aux_4: 0.5243 (0.5243)  loss_bbox_aux_4: 0.0748 (0.0748)  loss_giou_aux_4: 0.5118 (0.5118)  loss_vfl_aux_5: 0.6122 (0.6122)  loss_bbox_aux_5: 0.0908 (0.0908)  loss_giou_aux_5: 0.6040 (0.6040)  loss_vfl_dn_0: 0.4351 (0.4351)  loss_bbox_dn_0: 0.1256 (0.1256)  loss_giou_dn_0: 0.7841 (0.7841)  loss_vfl_dn_1: 0.4241 (0.4241)  loss_bbox_dn_1: 0.1042 (0.1042)  loss_giou_dn_1: 0.6583 (0.6583)  loss_vfl_dn_2: 0.4223 (0.4223)  loss_bbox_dn_2: 0.0986 (0.0986)  loss_giou_dn_2: 0.6291 (0.6291)  loss_vfl_dn_3: 0.4226 (0.4226)  loss_bbox_dn_3: 0.0969 (0.0969)  loss_giou_dn_3: 0.6168 (0.6168)  loss_vfl_dn_4: 0.4231 (0.4231)  loss_bbox_dn_4: 0.0959 (0.0959)  loss_giou_dn_4: 0.6116 (0.6116)  loss_vfl_dn_5: 0.4265 (0.4265)  loss_bbox_dn_5: 0.0957 (0.0957)  loss_giou_dn_5: 0.6104 (0.6104)  time: 0.9498  data: 0.5551  max mem: 7790\n",
            "Epoch: [116]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.8113 (14.2788)  loss_vfl: 0.5360 (0.5477)  loss_bbox: 0.0864 (0.1023)  loss_giou: 0.4313 (0.4319)  loss_vfl_aux_0: 0.5403 (0.5538)  loss_bbox_aux_0: 0.1020 (0.1232)  loss_giou_aux_0: 0.4805 (0.4836)  loss_vfl_aux_1: 0.5244 (0.5486)  loss_bbox_aux_1: 0.0881 (0.1097)  loss_giou_aux_1: 0.4488 (0.4471)  loss_vfl_aux_2: 0.5274 (0.5507)  loss_bbox_aux_2: 0.0853 (0.1035)  loss_giou_aux_2: 0.4327 (0.4353)  loss_vfl_aux_3: 0.5342 (0.5489)  loss_bbox_aux_3: 0.0857 (0.1030)  loss_giou_aux_3: 0.4338 (0.4334)  loss_vfl_aux_4: 0.5248 (0.5485)  loss_bbox_aux_4: 0.0866 (0.1028)  loss_giou_aux_4: 0.4290 (0.4317)  loss_vfl_aux_5: 0.5778 (0.6018)  loss_bbox_aux_5: 0.1292 (0.1714)  loss_giou_aux_5: 0.6229 (0.6247)  loss_vfl_dn_0: 0.4349 (0.4400)  loss_bbox_dn_0: 0.1400 (0.1819)  loss_giou_dn_0: 0.6678 (0.6621)  loss_vfl_dn_1: 0.4032 (0.4073)  loss_bbox_dn_1: 0.1023 (0.1347)  loss_giou_dn_1: 0.5002 (0.5020)  loss_vfl_dn_2: 0.3849 (0.3971)  loss_bbox_dn_2: 0.0974 (0.1270)  loss_giou_dn_2: 0.4757 (0.4725)  loss_vfl_dn_3: 0.3839 (0.3948)  loss_bbox_dn_3: 0.0972 (0.1255)  loss_giou_dn_3: 0.4687 (0.4654)  loss_vfl_dn_4: 0.3825 (0.3936)  loss_bbox_dn_4: 0.0977 (0.1258)  loss_giou_dn_4: 0.4675 (0.4633)  loss_vfl_dn_5: 0.3827 (0.3936)  loss_bbox_dn_5: 0.0972 (0.1258)  loss_giou_dn_5: 0.4691 (0.4629)  time: 0.3243  data: 0.0145  max mem: 7790\n",
            "Epoch: [116] Total time: 0:00:11 (0.3501 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.8113 (14.2788)  loss_vfl: 0.5360 (0.5477)  loss_bbox: 0.0864 (0.1023)  loss_giou: 0.4313 (0.4319)  loss_vfl_aux_0: 0.5403 (0.5538)  loss_bbox_aux_0: 0.1020 (0.1232)  loss_giou_aux_0: 0.4805 (0.4836)  loss_vfl_aux_1: 0.5244 (0.5486)  loss_bbox_aux_1: 0.0881 (0.1097)  loss_giou_aux_1: 0.4488 (0.4471)  loss_vfl_aux_2: 0.5274 (0.5507)  loss_bbox_aux_2: 0.0853 (0.1035)  loss_giou_aux_2: 0.4327 (0.4353)  loss_vfl_aux_3: 0.5342 (0.5489)  loss_bbox_aux_3: 0.0857 (0.1030)  loss_giou_aux_3: 0.4338 (0.4334)  loss_vfl_aux_4: 0.5248 (0.5485)  loss_bbox_aux_4: 0.0866 (0.1028)  loss_giou_aux_4: 0.4290 (0.4317)  loss_vfl_aux_5: 0.5778 (0.6018)  loss_bbox_aux_5: 0.1292 (0.1714)  loss_giou_aux_5: 0.6229 (0.6247)  loss_vfl_dn_0: 0.4349 (0.4400)  loss_bbox_dn_0: 0.1400 (0.1819)  loss_giou_dn_0: 0.6678 (0.6621)  loss_vfl_dn_1: 0.4032 (0.4073)  loss_bbox_dn_1: 0.1023 (0.1347)  loss_giou_dn_1: 0.5002 (0.5020)  loss_vfl_dn_2: 0.3849 (0.3971)  loss_bbox_dn_2: 0.0974 (0.1270)  loss_giou_dn_2: 0.4757 (0.4725)  loss_vfl_dn_3: 0.3839 (0.3948)  loss_bbox_dn_3: 0.0972 (0.1255)  loss_giou_dn_3: 0.4687 (0.4654)  loss_vfl_dn_4: 0.3825 (0.3936)  loss_bbox_dn_4: 0.0977 (0.1258)  loss_giou_dn_4: 0.4675 (0.4633)  loss_vfl_dn_5: 0.3827 (0.3936)  loss_bbox_dn_5: 0.0972 (0.1258)  loss_giou_dn_5: 0.4691 (0.4629)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9104  data: 0.6013  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3853  data: 0.1136  max mem: 7790\n",
            "Test: Total time: 0:00:04 (0.7159 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.662\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [117]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 14.7832 (14.7832)  loss_vfl: 0.5127 (0.5127)  loss_bbox: 0.1213 (0.1213)  loss_giou: 0.4431 (0.4431)  loss_vfl_aux_0: 0.5043 (0.5043)  loss_bbox_aux_0: 0.1541 (0.1541)  loss_giou_aux_0: 0.5332 (0.5332)  loss_vfl_aux_1: 0.5234 (0.5234)  loss_bbox_aux_1: 0.1308 (0.1308)  loss_giou_aux_1: 0.4633 (0.4633)  loss_vfl_aux_2: 0.5277 (0.5277)  loss_bbox_aux_2: 0.1252 (0.1252)  loss_giou_aux_2: 0.4383 (0.4383)  loss_vfl_aux_3: 0.5191 (0.5191)  loss_bbox_aux_3: 0.1228 (0.1228)  loss_giou_aux_3: 0.4442 (0.4442)  loss_vfl_aux_4: 0.5195 (0.5195)  loss_bbox_aux_4: 0.1218 (0.1218)  loss_giou_aux_4: 0.4397 (0.4397)  loss_vfl_aux_5: 0.5437 (0.5437)  loss_bbox_aux_5: 0.3281 (0.3281)  loss_giou_aux_5: 0.9342 (0.9342)  loss_vfl_dn_0: 0.4391 (0.4391)  loss_bbox_dn_0: 0.2039 (0.2039)  loss_giou_dn_0: 0.6954 (0.6954)  loss_vfl_dn_1: 0.4000 (0.4000)  loss_bbox_dn_1: 0.1426 (0.1426)  loss_giou_dn_1: 0.5059 (0.5059)  loss_vfl_dn_2: 0.3904 (0.3904)  loss_bbox_dn_2: 0.1301 (0.1301)  loss_giou_dn_2: 0.4695 (0.4695)  loss_vfl_dn_3: 0.3886 (0.3886)  loss_bbox_dn_3: 0.1273 (0.1273)  loss_giou_dn_3: 0.4665 (0.4665)  loss_vfl_dn_4: 0.3910 (0.3910)  loss_bbox_dn_4: 0.1270 (0.1270)  loss_giou_dn_4: 0.4665 (0.4665)  loss_vfl_dn_5: 0.3937 (0.3937)  loss_bbox_dn_5: 0.1272 (0.1272)  loss_giou_dn_5: 0.4680 (0.4680)  time: 0.9149  data: 0.5276  max mem: 7790\n",
            "Epoch: [117]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.9482 (14.1375)  loss_vfl: 0.5731 (0.5660)  loss_bbox: 0.0925 (0.0978)  loss_giou: 0.3877 (0.4225)  loss_vfl_aux_0: 0.5761 (0.5643)  loss_bbox_aux_0: 0.1083 (0.1199)  loss_giou_aux_0: 0.4479 (0.4788)  loss_vfl_aux_1: 0.5672 (0.5494)  loss_bbox_aux_1: 0.1044 (0.1044)  loss_giou_aux_1: 0.4212 (0.4408)  loss_vfl_aux_2: 0.5660 (0.5558)  loss_bbox_aux_2: 0.1010 (0.0998)  loss_giou_aux_2: 0.3948 (0.4292)  loss_vfl_aux_3: 0.5661 (0.5577)  loss_bbox_aux_3: 0.0889 (0.0978)  loss_giou_aux_3: 0.3919 (0.4243)  loss_vfl_aux_4: 0.5743 (0.5587)  loss_bbox_aux_4: 0.0891 (0.0986)  loss_giou_aux_4: 0.3894 (0.4233)  loss_vfl_aux_5: 0.6208 (0.6151)  loss_bbox_aux_5: 0.1318 (0.1637)  loss_giou_aux_5: 0.5518 (0.6162)  loss_vfl_dn_0: 0.4378 (0.4400)  loss_bbox_dn_0: 0.1564 (0.1798)  loss_giou_dn_0: 0.6456 (0.6488)  loss_vfl_dn_1: 0.4039 (0.4048)  loss_bbox_dn_1: 0.1195 (0.1318)  loss_giou_dn_1: 0.4886 (0.4876)  loss_vfl_dn_2: 0.3936 (0.3944)  loss_bbox_dn_2: 0.1098 (0.1231)  loss_giou_dn_2: 0.4736 (0.4580)  loss_vfl_dn_3: 0.3868 (0.3912)  loss_bbox_dn_3: 0.1069 (0.1208)  loss_giou_dn_3: 0.4679 (0.4502)  loss_vfl_dn_4: 0.3895 (0.3917)  loss_bbox_dn_4: 0.1059 (0.1204)  loss_giou_dn_4: 0.4647 (0.4486)  loss_vfl_dn_5: 0.3935 (0.3935)  loss_bbox_dn_5: 0.1059 (0.1203)  loss_giou_dn_5: 0.4628 (0.4486)  time: 0.3434  data: 0.0141  max mem: 7790\n",
            "Epoch: [117] Total time: 0:00:11 (0.3575 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.9482 (14.1375)  loss_vfl: 0.5731 (0.5660)  loss_bbox: 0.0925 (0.0978)  loss_giou: 0.3877 (0.4225)  loss_vfl_aux_0: 0.5761 (0.5643)  loss_bbox_aux_0: 0.1083 (0.1199)  loss_giou_aux_0: 0.4479 (0.4788)  loss_vfl_aux_1: 0.5672 (0.5494)  loss_bbox_aux_1: 0.1044 (0.1044)  loss_giou_aux_1: 0.4212 (0.4408)  loss_vfl_aux_2: 0.5660 (0.5558)  loss_bbox_aux_2: 0.1010 (0.0998)  loss_giou_aux_2: 0.3948 (0.4292)  loss_vfl_aux_3: 0.5661 (0.5577)  loss_bbox_aux_3: 0.0889 (0.0978)  loss_giou_aux_3: 0.3919 (0.4243)  loss_vfl_aux_4: 0.5743 (0.5587)  loss_bbox_aux_4: 0.0891 (0.0986)  loss_giou_aux_4: 0.3894 (0.4233)  loss_vfl_aux_5: 0.6208 (0.6151)  loss_bbox_aux_5: 0.1318 (0.1637)  loss_giou_aux_5: 0.5518 (0.6162)  loss_vfl_dn_0: 0.4378 (0.4400)  loss_bbox_dn_0: 0.1564 (0.1798)  loss_giou_dn_0: 0.6456 (0.6488)  loss_vfl_dn_1: 0.4039 (0.4048)  loss_bbox_dn_1: 0.1195 (0.1318)  loss_giou_dn_1: 0.4886 (0.4876)  loss_vfl_dn_2: 0.3936 (0.3944)  loss_bbox_dn_2: 0.1098 (0.1231)  loss_giou_dn_2: 0.4736 (0.4580)  loss_vfl_dn_3: 0.3868 (0.3912)  loss_bbox_dn_3: 0.1069 (0.1208)  loss_giou_dn_3: 0.4679 (0.4502)  loss_vfl_dn_4: 0.3895 (0.3917)  loss_bbox_dn_4: 0.1059 (0.1204)  loss_giou_dn_4: 0.4647 (0.4486)  loss_vfl_dn_5: 0.3935 (0.3935)  loss_bbox_dn_5: 0.1059 (0.1203)  loss_giou_dn_5: 0.4628 (0.4486)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9047  data: 0.5953  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3846  data: 0.1124  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3968 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [118]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 13.4811 (13.4811)  loss_vfl: 0.6649 (0.6649)  loss_bbox: 0.1089 (0.1089)  loss_giou: 0.2564 (0.2564)  loss_vfl_aux_0: 0.6488 (0.6488)  loss_bbox_aux_0: 0.1260 (0.1260)  loss_giou_aux_0: 0.3430 (0.3430)  loss_vfl_aux_1: 0.6455 (0.6455)  loss_bbox_aux_1: 0.1105 (0.1105)  loss_giou_aux_1: 0.2779 (0.2779)  loss_vfl_aux_2: 0.6485 (0.6485)  loss_bbox_aux_2: 0.1140 (0.1140)  loss_giou_aux_2: 0.2665 (0.2665)  loss_vfl_aux_3: 0.6254 (0.6254)  loss_bbox_aux_3: 0.1088 (0.1088)  loss_giou_aux_3: 0.2565 (0.2565)  loss_vfl_aux_4: 0.6237 (0.6237)  loss_bbox_aux_4: 0.1090 (0.1090)  loss_giou_aux_4: 0.2565 (0.2565)  loss_vfl_aux_5: 0.6899 (0.6899)  loss_bbox_aux_5: 0.2899 (0.2899)  loss_giou_aux_5: 0.6445 (0.6445)  loss_vfl_dn_0: 0.4527 (0.4527)  loss_bbox_dn_0: 0.2966 (0.2966)  loss_giou_dn_0: 0.5368 (0.5368)  loss_vfl_dn_1: 0.4020 (0.4020)  loss_bbox_dn_1: 0.1972 (0.1972)  loss_giou_dn_1: 0.3547 (0.3547)  loss_vfl_dn_2: 0.3868 (0.3868)  loss_bbox_dn_2: 0.1708 (0.1708)  loss_giou_dn_2: 0.3146 (0.3146)  loss_vfl_dn_3: 0.3808 (0.3808)  loss_bbox_dn_3: 0.1649 (0.1649)  loss_giou_dn_3: 0.3043 (0.3043)  loss_vfl_dn_4: 0.3776 (0.3776)  loss_bbox_dn_4: 0.1647 (0.1647)  loss_giou_dn_4: 0.3049 (0.3049)  loss_vfl_dn_5: 0.3871 (0.3871)  loss_bbox_dn_5: 0.1644 (0.1644)  loss_giou_dn_5: 0.3052 (0.3052)  time: 1.0023  data: 0.6165  max mem: 7790\n",
            "Epoch: [118]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.8307 (14.5008)  loss_vfl: 0.5658 (0.5545)  loss_bbox: 0.0981 (0.1026)  loss_giou: 0.4326 (0.4549)  loss_vfl_aux_0: 0.5510 (0.5579)  loss_bbox_aux_0: 0.1044 (0.1189)  loss_giou_aux_0: 0.5007 (0.5068)  loss_vfl_aux_1: 0.5330 (0.5503)  loss_bbox_aux_1: 0.0939 (0.1089)  loss_giou_aux_1: 0.4463 (0.4723)  loss_vfl_aux_2: 0.5507 (0.5544)  loss_bbox_aux_2: 0.0907 (0.1058)  loss_giou_aux_2: 0.4390 (0.4601)  loss_vfl_aux_3: 0.5419 (0.5540)  loss_bbox_aux_3: 0.0936 (0.1043)  loss_giou_aux_3: 0.4325 (0.4561)  loss_vfl_aux_4: 0.5556 (0.5531)  loss_bbox_aux_4: 0.0962 (0.1036)  loss_giou_aux_4: 0.4323 (0.4555)  loss_vfl_aux_5: 0.6011 (0.6150)  loss_bbox_aux_5: 0.1534 (0.1655)  loss_giou_aux_5: 0.6296 (0.6457)  loss_vfl_dn_0: 0.4408 (0.4387)  loss_bbox_dn_0: 0.1574 (0.1789)  loss_giou_dn_0: 0.6726 (0.6608)  loss_vfl_dn_1: 0.4136 (0.4087)  loss_bbox_dn_1: 0.1134 (0.1311)  loss_giou_dn_1: 0.5123 (0.5105)  loss_vfl_dn_2: 0.4089 (0.3993)  loss_bbox_dn_2: 0.1022 (0.1217)  loss_giou_dn_2: 0.4929 (0.4824)  loss_vfl_dn_3: 0.4089 (0.3974)  loss_bbox_dn_3: 0.0993 (0.1187)  loss_giou_dn_3: 0.4843 (0.4753)  loss_vfl_dn_4: 0.4066 (0.3963)  loss_bbox_dn_4: 0.1002 (0.1182)  loss_giou_dn_4: 0.4831 (0.4735)  loss_vfl_dn_5: 0.4064 (0.3976)  loss_bbox_dn_5: 0.1004 (0.1179)  loss_giou_dn_5: 0.4831 (0.4737)  time: 0.3412  data: 0.0148  max mem: 7790\n",
            "Epoch: [118] Total time: 0:00:11 (0.3584 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.8307 (14.5008)  loss_vfl: 0.5658 (0.5545)  loss_bbox: 0.0981 (0.1026)  loss_giou: 0.4326 (0.4549)  loss_vfl_aux_0: 0.5510 (0.5579)  loss_bbox_aux_0: 0.1044 (0.1189)  loss_giou_aux_0: 0.5007 (0.5068)  loss_vfl_aux_1: 0.5330 (0.5503)  loss_bbox_aux_1: 0.0939 (0.1089)  loss_giou_aux_1: 0.4463 (0.4723)  loss_vfl_aux_2: 0.5507 (0.5544)  loss_bbox_aux_2: 0.0907 (0.1058)  loss_giou_aux_2: 0.4390 (0.4601)  loss_vfl_aux_3: 0.5419 (0.5540)  loss_bbox_aux_3: 0.0936 (0.1043)  loss_giou_aux_3: 0.4325 (0.4561)  loss_vfl_aux_4: 0.5556 (0.5531)  loss_bbox_aux_4: 0.0962 (0.1036)  loss_giou_aux_4: 0.4323 (0.4555)  loss_vfl_aux_5: 0.6011 (0.6150)  loss_bbox_aux_5: 0.1534 (0.1655)  loss_giou_aux_5: 0.6296 (0.6457)  loss_vfl_dn_0: 0.4408 (0.4387)  loss_bbox_dn_0: 0.1574 (0.1789)  loss_giou_dn_0: 0.6726 (0.6608)  loss_vfl_dn_1: 0.4136 (0.4087)  loss_bbox_dn_1: 0.1134 (0.1311)  loss_giou_dn_1: 0.5123 (0.5105)  loss_vfl_dn_2: 0.4089 (0.3993)  loss_bbox_dn_2: 0.1022 (0.1217)  loss_giou_dn_2: 0.4929 (0.4824)  loss_vfl_dn_3: 0.4089 (0.3974)  loss_bbox_dn_3: 0.0993 (0.1187)  loss_giou_dn_3: 0.4843 (0.4753)  loss_vfl_dn_4: 0.4066 (0.3963)  loss_bbox_dn_4: 0.1002 (0.1182)  loss_giou_dn_4: 0.4831 (0.4735)  loss_vfl_dn_5: 0.4064 (0.3976)  loss_bbox_dn_5: 0.1004 (0.1179)  loss_giou_dn_5: 0.4831 (0.4737)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8936  data: 0.5836  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3838  data: 0.1117  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3964 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.635\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [119]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 13.0746 (13.0746)  loss_vfl: 0.6043 (0.6043)  loss_bbox: 0.1249 (0.1249)  loss_giou: 0.3423 (0.3423)  loss_vfl_aux_0: 0.5464 (0.5464)  loss_bbox_aux_0: 0.1297 (0.1297)  loss_giou_aux_0: 0.3852 (0.3852)  loss_vfl_aux_1: 0.5397 (0.5397)  loss_bbox_aux_1: 0.1237 (0.1237)  loss_giou_aux_1: 0.3555 (0.3555)  loss_vfl_aux_2: 0.5622 (0.5622)  loss_bbox_aux_2: 0.1215 (0.1215)  loss_giou_aux_2: 0.3399 (0.3399)  loss_vfl_aux_3: 0.5759 (0.5759)  loss_bbox_aux_3: 0.1223 (0.1223)  loss_giou_aux_3: 0.3358 (0.3358)  loss_vfl_aux_4: 0.5740 (0.5740)  loss_bbox_aux_4: 0.1239 (0.1239)  loss_giou_aux_4: 0.3406 (0.3406)  loss_vfl_aux_5: 0.6173 (0.6173)  loss_bbox_aux_5: 0.1682 (0.1682)  loss_giou_aux_5: 0.5224 (0.5224)  loss_vfl_dn_0: 0.4442 (0.4442)  loss_bbox_dn_0: 0.2010 (0.2010)  loss_giou_dn_0: 0.5909 (0.5909)  loss_vfl_dn_1: 0.4114 (0.4114)  loss_bbox_dn_1: 0.1253 (0.1253)  loss_giou_dn_1: 0.4019 (0.4019)  loss_vfl_dn_2: 0.3970 (0.3970)  loss_bbox_dn_2: 0.1048 (0.1048)  loss_giou_dn_2: 0.3413 (0.3413)  loss_vfl_dn_3: 0.4038 (0.4038)  loss_bbox_dn_3: 0.1037 (0.1037)  loss_giou_dn_3: 0.3297 (0.3297)  loss_vfl_dn_4: 0.4029 (0.4029)  loss_bbox_dn_4: 0.1034 (0.1034)  loss_giou_dn_4: 0.3224 (0.3224)  loss_vfl_dn_5: 0.4093 (0.4093)  loss_bbox_dn_5: 0.1040 (0.1040)  loss_giou_dn_5: 0.3219 (0.3219)  time: 0.9701  data: 0.5755  max mem: 7790\n",
            "Epoch: [119]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.8662 (14.3350)  loss_vfl: 0.5622 (0.5574)  loss_bbox: 0.0932 (0.1034)  loss_giou: 0.4592 (0.4382)  loss_vfl_aux_0: 0.5404 (0.5518)  loss_bbox_aux_0: 0.1081 (0.1206)  loss_giou_aux_0: 0.4877 (0.4937)  loss_vfl_aux_1: 0.5477 (0.5537)  loss_bbox_aux_1: 0.0978 (0.1084)  loss_giou_aux_1: 0.4670 (0.4538)  loss_vfl_aux_2: 0.5485 (0.5551)  loss_bbox_aux_2: 0.0941 (0.1051)  loss_giou_aux_2: 0.4648 (0.4433)  loss_vfl_aux_3: 0.5688 (0.5539)  loss_bbox_aux_3: 0.0969 (0.1048)  loss_giou_aux_3: 0.4698 (0.4394)  loss_vfl_aux_4: 0.5635 (0.5532)  loss_bbox_aux_4: 0.0950 (0.1056)  loss_giou_aux_4: 0.4672 (0.4402)  loss_vfl_aux_5: 0.5667 (0.5949)  loss_bbox_aux_5: 0.1549 (0.1642)  loss_giou_aux_5: 0.6528 (0.6342)  loss_vfl_dn_0: 0.4401 (0.4404)  loss_bbox_dn_0: 0.1531 (0.1808)  loss_giou_dn_0: 0.6706 (0.6606)  loss_vfl_dn_1: 0.4105 (0.4105)  loss_bbox_dn_1: 0.1109 (0.1330)  loss_giou_dn_1: 0.5274 (0.5026)  loss_vfl_dn_2: 0.4019 (0.3994)  loss_bbox_dn_2: 0.1052 (0.1234)  loss_giou_dn_2: 0.5028 (0.4728)  loss_vfl_dn_3: 0.3948 (0.3959)  loss_bbox_dn_3: 0.1051 (0.1213)  loss_giou_dn_3: 0.4974 (0.4637)  loss_vfl_dn_4: 0.3945 (0.3955)  loss_bbox_dn_4: 0.1057 (0.1210)  loss_giou_dn_4: 0.5013 (0.4618)  loss_vfl_dn_5: 0.3937 (0.3956)  loss_bbox_dn_5: 0.1061 (0.1208)  loss_giou_dn_5: 0.4992 (0.4609)  time: 0.3201  data: 0.0145  max mem: 7790\n",
            "Epoch: [119] Total time: 0:00:11 (0.3478 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.8662 (14.3350)  loss_vfl: 0.5622 (0.5574)  loss_bbox: 0.0932 (0.1034)  loss_giou: 0.4592 (0.4382)  loss_vfl_aux_0: 0.5404 (0.5518)  loss_bbox_aux_0: 0.1081 (0.1206)  loss_giou_aux_0: 0.4877 (0.4937)  loss_vfl_aux_1: 0.5477 (0.5537)  loss_bbox_aux_1: 0.0978 (0.1084)  loss_giou_aux_1: 0.4670 (0.4538)  loss_vfl_aux_2: 0.5485 (0.5551)  loss_bbox_aux_2: 0.0941 (0.1051)  loss_giou_aux_2: 0.4648 (0.4433)  loss_vfl_aux_3: 0.5688 (0.5539)  loss_bbox_aux_3: 0.0969 (0.1048)  loss_giou_aux_3: 0.4698 (0.4394)  loss_vfl_aux_4: 0.5635 (0.5532)  loss_bbox_aux_4: 0.0950 (0.1056)  loss_giou_aux_4: 0.4672 (0.4402)  loss_vfl_aux_5: 0.5667 (0.5949)  loss_bbox_aux_5: 0.1549 (0.1642)  loss_giou_aux_5: 0.6528 (0.6342)  loss_vfl_dn_0: 0.4401 (0.4404)  loss_bbox_dn_0: 0.1531 (0.1808)  loss_giou_dn_0: 0.6706 (0.6606)  loss_vfl_dn_1: 0.4105 (0.4105)  loss_bbox_dn_1: 0.1109 (0.1330)  loss_giou_dn_1: 0.5274 (0.5026)  loss_vfl_dn_2: 0.4019 (0.3994)  loss_bbox_dn_2: 0.1052 (0.1234)  loss_giou_dn_2: 0.5028 (0.4728)  loss_vfl_dn_3: 0.3948 (0.3959)  loss_bbox_dn_3: 0.1051 (0.1213)  loss_giou_dn_3: 0.4974 (0.4637)  loss_vfl_dn_4: 0.3945 (0.3955)  loss_bbox_dn_4: 0.1057 (0.1210)  loss_giou_dn_4: 0.5013 (0.4618)  loss_vfl_dn_5: 0.3937 (0.3956)  loss_bbox_dn_5: 0.1061 (0.1208)  loss_giou_dn_5: 0.4992 (0.4609)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9114  data: 0.5967  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3850  data: 0.1114  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3978 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.645\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.577\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.343\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [120]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 16.3042 (16.3042)  loss_vfl: 0.4359 (0.4359)  loss_bbox: 0.1048 (0.1048)  loss_giou: 0.7091 (0.7091)  loss_vfl_aux_0: 0.4666 (0.4666)  loss_bbox_aux_0: 0.1140 (0.1140)  loss_giou_aux_0: 0.7920 (0.7920)  loss_vfl_aux_1: 0.4553 (0.4553)  loss_bbox_aux_1: 0.1122 (0.1122)  loss_giou_aux_1: 0.7531 (0.7531)  loss_vfl_aux_2: 0.4447 (0.4447)  loss_bbox_aux_2: 0.1045 (0.1045)  loss_giou_aux_2: 0.7358 (0.7358)  loss_vfl_aux_3: 0.4448 (0.4448)  loss_bbox_aux_3: 0.1054 (0.1054)  loss_giou_aux_3: 0.7128 (0.7128)  loss_vfl_aux_4: 0.4387 (0.4387)  loss_bbox_aux_4: 0.1061 (0.1061)  loss_giou_aux_4: 0.7112 (0.7112)  loss_vfl_aux_5: 0.4570 (0.4570)  loss_bbox_aux_5: 0.1396 (0.1396)  loss_giou_aux_5: 0.9292 (0.9292)  loss_vfl_dn_0: 0.4155 (0.4155)  loss_bbox_dn_0: 0.1215 (0.1215)  loss_giou_dn_0: 0.8170 (0.8170)  loss_vfl_dn_1: 0.3865 (0.3865)  loss_bbox_dn_1: 0.0895 (0.0895)  loss_giou_dn_1: 0.6913 (0.6913)  loss_vfl_dn_2: 0.3750 (0.3750)  loss_bbox_dn_2: 0.0867 (0.0867)  loss_giou_dn_2: 0.6760 (0.6760)  loss_vfl_dn_3: 0.3715 (0.3715)  loss_bbox_dn_3: 0.0847 (0.0847)  loss_giou_dn_3: 0.6684 (0.6684)  loss_vfl_dn_4: 0.3755 (0.3755)  loss_bbox_dn_4: 0.0844 (0.0844)  loss_giou_dn_4: 0.6661 (0.6661)  loss_vfl_dn_5: 0.3719 (0.3719)  loss_bbox_dn_5: 0.0841 (0.0841)  loss_giou_dn_5: 0.6658 (0.6658)  time: 1.0855  data: 0.7021  max mem: 7790\n",
            "Epoch: [120]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.2972 (14.0216)  loss_vfl: 0.5295 (0.5305)  loss_bbox: 0.0982 (0.0978)  loss_giou: 0.4093 (0.4353)  loss_vfl_aux_0: 0.5281 (0.5430)  loss_bbox_aux_0: 0.1064 (0.1108)  loss_giou_aux_0: 0.4386 (0.4844)  loss_vfl_aux_1: 0.5252 (0.5348)  loss_bbox_aux_1: 0.0884 (0.0996)  loss_giou_aux_1: 0.4052 (0.4489)  loss_vfl_aux_2: 0.5207 (0.5325)  loss_bbox_aux_2: 0.0874 (0.0970)  loss_giou_aux_2: 0.4022 (0.4404)  loss_vfl_aux_3: 0.5182 (0.5323)  loss_bbox_aux_3: 0.0886 (0.0972)  loss_giou_aux_3: 0.4004 (0.4367)  loss_vfl_aux_4: 0.5296 (0.5321)  loss_bbox_aux_4: 0.0978 (0.0971)  loss_giou_aux_4: 0.4095 (0.4358)  loss_vfl_aux_5: 0.6003 (0.6059)  loss_bbox_aux_5: 0.1387 (0.1520)  loss_giou_aux_5: 0.5478 (0.6125)  loss_vfl_dn_0: 0.4437 (0.4418)  loss_bbox_dn_0: 0.1487 (0.1666)  loss_giou_dn_0: 0.6189 (0.6609)  loss_vfl_dn_1: 0.4052 (0.4053)  loss_bbox_dn_1: 0.1190 (0.1218)  loss_giou_dn_1: 0.4358 (0.5012)  loss_vfl_dn_2: 0.3916 (0.3956)  loss_bbox_dn_2: 0.1102 (0.1141)  loss_giou_dn_2: 0.3972 (0.4705)  loss_vfl_dn_3: 0.3882 (0.3908)  loss_bbox_dn_3: 0.1080 (0.1120)  loss_giou_dn_3: 0.3983 (0.4628)  loss_vfl_dn_4: 0.3892 (0.3893)  loss_bbox_dn_4: 0.1064 (0.1117)  loss_giou_dn_4: 0.3982 (0.4606)  loss_vfl_dn_5: 0.3874 (0.3882)  loss_bbox_dn_5: 0.1053 (0.1115)  loss_giou_dn_5: 0.3994 (0.4604)  time: 0.3281  data: 0.0147  max mem: 7790\n",
            "Epoch: [120] Total time: 0:00:11 (0.3549 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.2972 (14.0216)  loss_vfl: 0.5295 (0.5305)  loss_bbox: 0.0982 (0.0978)  loss_giou: 0.4093 (0.4353)  loss_vfl_aux_0: 0.5281 (0.5430)  loss_bbox_aux_0: 0.1064 (0.1108)  loss_giou_aux_0: 0.4386 (0.4844)  loss_vfl_aux_1: 0.5252 (0.5348)  loss_bbox_aux_1: 0.0884 (0.0996)  loss_giou_aux_1: 0.4052 (0.4489)  loss_vfl_aux_2: 0.5207 (0.5325)  loss_bbox_aux_2: 0.0874 (0.0970)  loss_giou_aux_2: 0.4022 (0.4404)  loss_vfl_aux_3: 0.5182 (0.5323)  loss_bbox_aux_3: 0.0886 (0.0972)  loss_giou_aux_3: 0.4004 (0.4367)  loss_vfl_aux_4: 0.5296 (0.5321)  loss_bbox_aux_4: 0.0978 (0.0971)  loss_giou_aux_4: 0.4095 (0.4358)  loss_vfl_aux_5: 0.6003 (0.6059)  loss_bbox_aux_5: 0.1387 (0.1520)  loss_giou_aux_5: 0.5478 (0.6125)  loss_vfl_dn_0: 0.4437 (0.4418)  loss_bbox_dn_0: 0.1487 (0.1666)  loss_giou_dn_0: 0.6189 (0.6609)  loss_vfl_dn_1: 0.4052 (0.4053)  loss_bbox_dn_1: 0.1190 (0.1218)  loss_giou_dn_1: 0.4358 (0.5012)  loss_vfl_dn_2: 0.3916 (0.3956)  loss_bbox_dn_2: 0.1102 (0.1141)  loss_giou_dn_2: 0.3972 (0.4705)  loss_vfl_dn_3: 0.3882 (0.3908)  loss_bbox_dn_3: 0.1080 (0.1120)  loss_giou_dn_3: 0.3983 (0.4628)  loss_vfl_dn_4: 0.3892 (0.3893)  loss_bbox_dn_4: 0.1064 (0.1117)  loss_giou_dn_4: 0.3982 (0.4606)  loss_vfl_dn_5: 0.3874 (0.3882)  loss_bbox_dn_5: 0.1053 (0.1115)  loss_giou_dn_5: 0.3994 (0.4604)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9074  data: 0.5988  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3846  data: 0.1118  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3970 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.679\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.223\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [121]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 16.6086 (16.6086)  loss_vfl: 0.6716 (0.6716)  loss_bbox: 0.0762 (0.0762)  loss_giou: 0.5918 (0.5918)  loss_vfl_aux_0: 0.6456 (0.6456)  loss_bbox_aux_0: 0.1004 (0.1004)  loss_giou_aux_0: 0.6438 (0.6438)  loss_vfl_aux_1: 0.6529 (0.6529)  loss_bbox_aux_1: 0.0820 (0.0820)  loss_giou_aux_1: 0.6056 (0.6056)  loss_vfl_aux_2: 0.6502 (0.6502)  loss_bbox_aux_2: 0.0790 (0.0790)  loss_giou_aux_2: 0.5836 (0.5836)  loss_vfl_aux_3: 0.6860 (0.6860)  loss_bbox_aux_3: 0.0799 (0.0799)  loss_giou_aux_3: 0.5975 (0.5975)  loss_vfl_aux_4: 0.6858 (0.6858)  loss_bbox_aux_4: 0.0790 (0.0790)  loss_giou_aux_4: 0.6002 (0.6002)  loss_vfl_aux_5: 0.6272 (0.6272)  loss_bbox_aux_5: 0.1221 (0.1221)  loss_giou_aux_5: 0.7300 (0.7300)  loss_vfl_dn_0: 0.4433 (0.4433)  loss_bbox_dn_0: 0.1282 (0.1282)  loss_giou_dn_0: 0.7328 (0.7328)  loss_vfl_dn_1: 0.4114 (0.4114)  loss_bbox_dn_1: 0.0952 (0.0952)  loss_giou_dn_1: 0.6499 (0.6499)  loss_vfl_dn_2: 0.3989 (0.3989)  loss_bbox_dn_2: 0.0897 (0.0897)  loss_giou_dn_2: 0.6409 (0.6409)  loss_vfl_dn_3: 0.4005 (0.4005)  loss_bbox_dn_3: 0.0892 (0.0892)  loss_giou_dn_3: 0.6455 (0.6455)  loss_vfl_dn_4: 0.4008 (0.4008)  loss_bbox_dn_4: 0.0893 (0.0893)  loss_giou_dn_4: 0.6557 (0.6557)  loss_vfl_dn_5: 0.4032 (0.4032)  loss_bbox_dn_5: 0.0874 (0.0874)  loss_giou_dn_5: 0.6564 (0.6564)  time: 1.0562  data: 0.6789  max mem: 7790\n",
            "Epoch: [121]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.8303 (14.1778)  loss_vfl: 0.5084 (0.5451)  loss_bbox: 0.0884 (0.1137)  loss_giou: 0.3494 (0.4231)  loss_vfl_aux_0: 0.5218 (0.5550)  loss_bbox_aux_0: 0.1098 (0.1313)  loss_giou_aux_0: 0.4068 (0.4685)  loss_vfl_aux_1: 0.5039 (0.5454)  loss_bbox_aux_1: 0.0999 (0.1201)  loss_giou_aux_1: 0.3572 (0.4354)  loss_vfl_aux_2: 0.4980 (0.5412)  loss_bbox_aux_2: 0.0974 (0.1187)  loss_giou_aux_2: 0.3489 (0.4289)  loss_vfl_aux_3: 0.5126 (0.5468)  loss_bbox_aux_3: 0.0924 (0.1155)  loss_giou_aux_3: 0.3507 (0.4242)  loss_vfl_aux_4: 0.5100 (0.5435)  loss_bbox_aux_4: 0.0951 (0.1158)  loss_giou_aux_4: 0.3488 (0.4245)  loss_vfl_aux_5: 0.5870 (0.6076)  loss_bbox_aux_5: 0.1712 (0.1960)  loss_giou_aux_5: 0.5478 (0.6328)  loss_vfl_dn_0: 0.4424 (0.4396)  loss_bbox_dn_0: 0.1724 (0.1937)  loss_giou_dn_0: 0.5712 (0.6342)  loss_vfl_dn_1: 0.4005 (0.4046)  loss_bbox_dn_1: 0.1160 (0.1422)  loss_giou_dn_1: 0.4109 (0.4795)  loss_vfl_dn_2: 0.3866 (0.3926)  loss_bbox_dn_2: 0.1074 (0.1321)  loss_giou_dn_2: 0.3798 (0.4499)  loss_vfl_dn_3: 0.3855 (0.3893)  loss_bbox_dn_3: 0.1056 (0.1298)  loss_giou_dn_3: 0.3796 (0.4427)  loss_vfl_dn_4: 0.3856 (0.3874)  loss_bbox_dn_4: 0.1053 (0.1293)  loss_giou_dn_4: 0.3779 (0.4413)  loss_vfl_dn_5: 0.3858 (0.3866)  loss_bbox_dn_5: 0.1059 (0.1290)  loss_giou_dn_5: 0.3760 (0.4411)  time: 0.3329  data: 0.0137  max mem: 7790\n",
            "Epoch: [121] Total time: 0:00:11 (0.3545 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.8303 (14.1778)  loss_vfl: 0.5084 (0.5451)  loss_bbox: 0.0884 (0.1137)  loss_giou: 0.3494 (0.4231)  loss_vfl_aux_0: 0.5218 (0.5550)  loss_bbox_aux_0: 0.1098 (0.1313)  loss_giou_aux_0: 0.4068 (0.4685)  loss_vfl_aux_1: 0.5039 (0.5454)  loss_bbox_aux_1: 0.0999 (0.1201)  loss_giou_aux_1: 0.3572 (0.4354)  loss_vfl_aux_2: 0.4980 (0.5412)  loss_bbox_aux_2: 0.0974 (0.1187)  loss_giou_aux_2: 0.3489 (0.4289)  loss_vfl_aux_3: 0.5126 (0.5468)  loss_bbox_aux_3: 0.0924 (0.1155)  loss_giou_aux_3: 0.3507 (0.4242)  loss_vfl_aux_4: 0.5100 (0.5435)  loss_bbox_aux_4: 0.0951 (0.1158)  loss_giou_aux_4: 0.3488 (0.4245)  loss_vfl_aux_5: 0.5870 (0.6076)  loss_bbox_aux_5: 0.1712 (0.1960)  loss_giou_aux_5: 0.5478 (0.6328)  loss_vfl_dn_0: 0.4424 (0.4396)  loss_bbox_dn_0: 0.1724 (0.1937)  loss_giou_dn_0: 0.5712 (0.6342)  loss_vfl_dn_1: 0.4005 (0.4046)  loss_bbox_dn_1: 0.1160 (0.1422)  loss_giou_dn_1: 0.4109 (0.4795)  loss_vfl_dn_2: 0.3866 (0.3926)  loss_bbox_dn_2: 0.1074 (0.1321)  loss_giou_dn_2: 0.3798 (0.4499)  loss_vfl_dn_3: 0.3855 (0.3893)  loss_bbox_dn_3: 0.1056 (0.1298)  loss_giou_dn_3: 0.3796 (0.4427)  loss_vfl_dn_4: 0.3856 (0.3874)  loss_bbox_dn_4: 0.1053 (0.1293)  loss_giou_dn_4: 0.3779 (0.4413)  loss_vfl_dn_5: 0.3858 (0.3866)  loss_bbox_dn_5: 0.1059 (0.1290)  loss_giou_dn_5: 0.3760 (0.4411)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9044  data: 0.5893  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4401  data: 0.1133  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4542 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.652\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.300\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.366\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [122]  [ 0/33]  eta: 0:00:36  lr: 0.000001  loss: 14.1966 (14.1966)  loss_vfl: 0.4755 (0.4755)  loss_bbox: 0.0665 (0.0665)  loss_giou: 0.5558 (0.5558)  loss_vfl_aux_0: 0.5222 (0.5222)  loss_bbox_aux_0: 0.0641 (0.0641)  loss_giou_aux_0: 0.5999 (0.5999)  loss_vfl_aux_1: 0.4955 (0.4955)  loss_bbox_aux_1: 0.0624 (0.0624)  loss_giou_aux_1: 0.5657 (0.5657)  loss_vfl_aux_2: 0.4907 (0.4907)  loss_bbox_aux_2: 0.0671 (0.0671)  loss_giou_aux_2: 0.5667 (0.5667)  loss_vfl_aux_3: 0.4999 (0.4999)  loss_bbox_aux_3: 0.0611 (0.0611)  loss_giou_aux_3: 0.5436 (0.5436)  loss_vfl_aux_4: 0.5074 (0.5074)  loss_bbox_aux_4: 0.0608 (0.0608)  loss_giou_aux_4: 0.5361 (0.5361)  loss_vfl_aux_5: 0.5480 (0.5480)  loss_bbox_aux_5: 0.0899 (0.0899)  loss_giou_aux_5: 0.6898 (0.6898)  loss_vfl_dn_0: 0.4332 (0.4332)  loss_bbox_dn_0: 0.0781 (0.0781)  loss_giou_dn_0: 0.6993 (0.6993)  loss_vfl_dn_1: 0.4091 (0.4091)  loss_bbox_dn_1: 0.0562 (0.0562)  loss_giou_dn_1: 0.5357 (0.5357)  loss_vfl_dn_2: 0.4090 (0.4090)  loss_bbox_dn_2: 0.0558 (0.0558)  loss_giou_dn_2: 0.5261 (0.5261)  loss_vfl_dn_3: 0.4017 (0.4017)  loss_bbox_dn_3: 0.0550 (0.0550)  loss_giou_dn_3: 0.5213 (0.5213)  loss_vfl_dn_4: 0.3993 (0.3993)  loss_bbox_dn_4: 0.0549 (0.0549)  loss_giou_dn_4: 0.5207 (0.5207)  loss_vfl_dn_5: 0.3980 (0.3980)  loss_bbox_dn_5: 0.0548 (0.0548)  loss_giou_dn_5: 0.5199 (0.5199)  time: 1.1143  data: 0.7028  max mem: 7790\n",
            "Epoch: [122]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.0591 (13.7257)  loss_vfl: 0.4936 (0.5255)  loss_bbox: 0.0991 (0.0997)  loss_giou: 0.3676 (0.4137)  loss_vfl_aux_0: 0.5383 (0.5430)  loss_bbox_aux_0: 0.1091 (0.1116)  loss_giou_aux_0: 0.4373 (0.4654)  loss_vfl_aux_1: 0.5040 (0.5235)  loss_bbox_aux_1: 0.1025 (0.1020)  loss_giou_aux_1: 0.3958 (0.4304)  loss_vfl_aux_2: 0.5015 (0.5218)  loss_bbox_aux_2: 0.1004 (0.0999)  loss_giou_aux_2: 0.3836 (0.4212)  loss_vfl_aux_3: 0.5018 (0.5233)  loss_bbox_aux_3: 0.1013 (0.0984)  loss_giou_aux_3: 0.3776 (0.4157)  loss_vfl_aux_4: 0.4968 (0.5238)  loss_bbox_aux_4: 0.0990 (0.0993)  loss_giou_aux_4: 0.3692 (0.4138)  loss_vfl_aux_5: 0.5947 (0.6004)  loss_bbox_aux_5: 0.1589 (0.1634)  loss_giou_aux_5: 0.5752 (0.6027)  loss_vfl_dn_0: 0.4416 (0.4416)  loss_bbox_dn_0: 0.1809 (0.1773)  loss_giou_dn_0: 0.6146 (0.6367)  loss_vfl_dn_1: 0.4027 (0.4053)  loss_bbox_dn_1: 0.1127 (0.1249)  loss_giou_dn_1: 0.4321 (0.4711)  loss_vfl_dn_2: 0.3940 (0.3947)  loss_bbox_dn_2: 0.1068 (0.1158)  loss_giou_dn_2: 0.4020 (0.4421)  loss_vfl_dn_3: 0.3881 (0.3909)  loss_bbox_dn_3: 0.1040 (0.1136)  loss_giou_dn_3: 0.3949 (0.4357)  loss_vfl_dn_4: 0.3881 (0.3908)  loss_bbox_dn_4: 0.1037 (0.1132)  loss_giou_dn_4: 0.3929 (0.4346)  loss_vfl_dn_5: 0.3862 (0.3908)  loss_bbox_dn_5: 0.1043 (0.1131)  loss_giou_dn_5: 0.3931 (0.4349)  time: 0.3313  data: 0.0155  max mem: 7790\n",
            "Epoch: [122] Total time: 0:00:11 (0.3585 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.0591 (13.7257)  loss_vfl: 0.4936 (0.5255)  loss_bbox: 0.0991 (0.0997)  loss_giou: 0.3676 (0.4137)  loss_vfl_aux_0: 0.5383 (0.5430)  loss_bbox_aux_0: 0.1091 (0.1116)  loss_giou_aux_0: 0.4373 (0.4654)  loss_vfl_aux_1: 0.5040 (0.5235)  loss_bbox_aux_1: 0.1025 (0.1020)  loss_giou_aux_1: 0.3958 (0.4304)  loss_vfl_aux_2: 0.5015 (0.5218)  loss_bbox_aux_2: 0.1004 (0.0999)  loss_giou_aux_2: 0.3836 (0.4212)  loss_vfl_aux_3: 0.5018 (0.5233)  loss_bbox_aux_3: 0.1013 (0.0984)  loss_giou_aux_3: 0.3776 (0.4157)  loss_vfl_aux_4: 0.4968 (0.5238)  loss_bbox_aux_4: 0.0990 (0.0993)  loss_giou_aux_4: 0.3692 (0.4138)  loss_vfl_aux_5: 0.5947 (0.6004)  loss_bbox_aux_5: 0.1589 (0.1634)  loss_giou_aux_5: 0.5752 (0.6027)  loss_vfl_dn_0: 0.4416 (0.4416)  loss_bbox_dn_0: 0.1809 (0.1773)  loss_giou_dn_0: 0.6146 (0.6367)  loss_vfl_dn_1: 0.4027 (0.4053)  loss_bbox_dn_1: 0.1127 (0.1249)  loss_giou_dn_1: 0.4321 (0.4711)  loss_vfl_dn_2: 0.3940 (0.3947)  loss_bbox_dn_2: 0.1068 (0.1158)  loss_giou_dn_2: 0.4020 (0.4421)  loss_vfl_dn_3: 0.3881 (0.3909)  loss_bbox_dn_3: 0.1040 (0.1136)  loss_giou_dn_3: 0.3949 (0.4357)  loss_vfl_dn_4: 0.3881 (0.3908)  loss_bbox_dn_4: 0.1037 (0.1132)  loss_giou_dn_4: 0.3929 (0.4346)  loss_vfl_dn_5: 0.3862 (0.3908)  loss_bbox_dn_5: 0.1043 (0.1131)  loss_giou_dn_5: 0.3931 (0.4349)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8783  data: 0.5637  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4387  data: 0.1127  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4515 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.668\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [123]  [ 0/33]  eta: 0:00:37  lr: 0.000001  loss: 16.1832 (16.1832)  loss_vfl: 0.8888 (0.8888)  loss_bbox: 0.0916 (0.0916)  loss_giou: 0.4267 (0.4267)  loss_vfl_aux_0: 0.7715 (0.7715)  loss_bbox_aux_0: 0.1523 (0.1523)  loss_giou_aux_0: 0.4598 (0.4598)  loss_vfl_aux_1: 0.8184 (0.8184)  loss_bbox_aux_1: 0.1162 (0.1162)  loss_giou_aux_1: 0.4397 (0.4397)  loss_vfl_aux_2: 0.7812 (0.7812)  loss_bbox_aux_2: 0.0908 (0.0908)  loss_giou_aux_2: 0.4391 (0.4391)  loss_vfl_aux_3: 0.8700 (0.8700)  loss_bbox_aux_3: 0.0886 (0.0886)  loss_giou_aux_3: 0.4235 (0.4235)  loss_vfl_aux_4: 0.8658 (0.8658)  loss_bbox_aux_4: 0.0908 (0.0908)  loss_giou_aux_4: 0.4186 (0.4186)  loss_vfl_aux_5: 0.7387 (0.7387)  loss_bbox_aux_5: 0.2620 (0.2620)  loss_giou_aux_5: 0.6536 (0.6536)  loss_vfl_dn_0: 0.4437 (0.4437)  loss_bbox_dn_0: 0.2454 (0.2454)  loss_giou_dn_0: 0.6724 (0.6724)  loss_vfl_dn_1: 0.4027 (0.4027)  loss_bbox_dn_1: 0.1509 (0.1509)  loss_giou_dn_1: 0.4961 (0.4961)  loss_vfl_dn_2: 0.3881 (0.3881)  loss_bbox_dn_2: 0.1295 (0.1295)  loss_giou_dn_2: 0.4664 (0.4664)  loss_vfl_dn_3: 0.3939 (0.3939)  loss_bbox_dn_3: 0.1202 (0.1202)  loss_giou_dn_3: 0.4565 (0.4565)  loss_vfl_dn_4: 0.3936 (0.3936)  loss_bbox_dn_4: 0.1187 (0.1187)  loss_giou_dn_4: 0.4517 (0.4517)  loss_vfl_dn_5: 0.3948 (0.3948)  loss_bbox_dn_5: 0.1176 (0.1176)  loss_giou_dn_5: 0.4532 (0.4532)  time: 1.1284  data: 0.6969  max mem: 7790\n",
            "Epoch: [123]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.6619 (13.6566)  loss_vfl: 0.5073 (0.5370)  loss_bbox: 0.0801 (0.1005)  loss_giou: 0.3742 (0.3988)  loss_vfl_aux_0: 0.5142 (0.5357)  loss_bbox_aux_0: 0.0888 (0.1178)  loss_giou_aux_0: 0.4369 (0.4509)  loss_vfl_aux_1: 0.4944 (0.5295)  loss_bbox_aux_1: 0.0851 (0.1065)  loss_giou_aux_1: 0.3968 (0.4165)  loss_vfl_aux_2: 0.5289 (0.5351)  loss_bbox_aux_2: 0.0787 (0.1023)  loss_giou_aux_2: 0.3867 (0.4046)  loss_vfl_aux_3: 0.5109 (0.5374)  loss_bbox_aux_3: 0.0799 (0.1013)  loss_giou_aux_3: 0.3853 (0.4017)  loss_vfl_aux_4: 0.4930 (0.5311)  loss_bbox_aux_4: 0.0843 (0.1020)  loss_giou_aux_4: 0.3890 (0.4009)  loss_vfl_aux_5: 0.5962 (0.6117)  loss_bbox_aux_5: 0.1461 (0.1607)  loss_giou_aux_5: 0.5521 (0.5711)  loss_vfl_dn_0: 0.4415 (0.4464)  loss_bbox_dn_0: 0.1543 (0.1810)  loss_giou_dn_0: 0.5963 (0.6149)  loss_vfl_dn_1: 0.3996 (0.4098)  loss_bbox_dn_1: 0.1044 (0.1298)  loss_giou_dn_1: 0.4110 (0.4613)  loss_vfl_dn_2: 0.3867 (0.3985)  loss_bbox_dn_2: 0.0933 (0.1205)  loss_giou_dn_2: 0.3805 (0.4332)  loss_vfl_dn_3: 0.3839 (0.3947)  loss_bbox_dn_3: 0.0930 (0.1181)  loss_giou_dn_3: 0.3742 (0.4255)  loss_vfl_dn_4: 0.3826 (0.3935)  loss_bbox_dn_4: 0.0935 (0.1179)  loss_giou_dn_4: 0.3722 (0.4237)  loss_vfl_dn_5: 0.3834 (0.3939)  loss_bbox_dn_5: 0.0938 (0.1177)  loss_giou_dn_5: 0.3707 (0.4232)  time: 0.3275  data: 0.0140  max mem: 7790\n",
            "Epoch: [123] Total time: 0:00:11 (0.3525 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.6619 (13.6566)  loss_vfl: 0.5073 (0.5370)  loss_bbox: 0.0801 (0.1005)  loss_giou: 0.3742 (0.3988)  loss_vfl_aux_0: 0.5142 (0.5357)  loss_bbox_aux_0: 0.0888 (0.1178)  loss_giou_aux_0: 0.4369 (0.4509)  loss_vfl_aux_1: 0.4944 (0.5295)  loss_bbox_aux_1: 0.0851 (0.1065)  loss_giou_aux_1: 0.3968 (0.4165)  loss_vfl_aux_2: 0.5289 (0.5351)  loss_bbox_aux_2: 0.0787 (0.1023)  loss_giou_aux_2: 0.3867 (0.4046)  loss_vfl_aux_3: 0.5109 (0.5374)  loss_bbox_aux_3: 0.0799 (0.1013)  loss_giou_aux_3: 0.3853 (0.4017)  loss_vfl_aux_4: 0.4930 (0.5311)  loss_bbox_aux_4: 0.0843 (0.1020)  loss_giou_aux_4: 0.3890 (0.4009)  loss_vfl_aux_5: 0.5962 (0.6117)  loss_bbox_aux_5: 0.1461 (0.1607)  loss_giou_aux_5: 0.5521 (0.5711)  loss_vfl_dn_0: 0.4415 (0.4464)  loss_bbox_dn_0: 0.1543 (0.1810)  loss_giou_dn_0: 0.5963 (0.6149)  loss_vfl_dn_1: 0.3996 (0.4098)  loss_bbox_dn_1: 0.1044 (0.1298)  loss_giou_dn_1: 0.4110 (0.4613)  loss_vfl_dn_2: 0.3867 (0.3985)  loss_bbox_dn_2: 0.0933 (0.1205)  loss_giou_dn_2: 0.3805 (0.4332)  loss_vfl_dn_3: 0.3839 (0.3947)  loss_bbox_dn_3: 0.0930 (0.1181)  loss_giou_dn_3: 0.3742 (0.4255)  loss_vfl_dn_4: 0.3826 (0.3935)  loss_bbox_dn_4: 0.0935 (0.1179)  loss_giou_dn_4: 0.3722 (0.4237)  loss_vfl_dn_5: 0.3834 (0.3939)  loss_bbox_dn_5: 0.0938 (0.1177)  loss_giou_dn_5: 0.3707 (0.4232)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9283  data: 0.6167  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3886  data: 0.1157  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4009 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.653\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.545\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [124]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 14.3143 (14.3143)  loss_vfl: 0.5697 (0.5697)  loss_bbox: 0.1086 (0.1086)  loss_giou: 0.4371 (0.4371)  loss_vfl_aux_0: 0.5823 (0.5823)  loss_bbox_aux_0: 0.1123 (0.1123)  loss_giou_aux_0: 0.4462 (0.4462)  loss_vfl_aux_1: 0.5414 (0.5414)  loss_bbox_aux_1: 0.1139 (0.1139)  loss_giou_aux_1: 0.4512 (0.4512)  loss_vfl_aux_2: 0.5320 (0.5320)  loss_bbox_aux_2: 0.1102 (0.1102)  loss_giou_aux_2: 0.4411 (0.4411)  loss_vfl_aux_3: 0.5529 (0.5529)  loss_bbox_aux_3: 0.1056 (0.1056)  loss_giou_aux_3: 0.4370 (0.4370)  loss_vfl_aux_4: 0.5604 (0.5604)  loss_bbox_aux_4: 0.1099 (0.1099)  loss_giou_aux_4: 0.4400 (0.4400)  loss_vfl_aux_5: 0.6661 (0.6661)  loss_bbox_aux_5: 0.1483 (0.1483)  loss_giou_aux_5: 0.5627 (0.5627)  loss_vfl_dn_0: 0.4696 (0.4696)  loss_bbox_dn_0: 0.1668 (0.1668)  loss_giou_dn_0: 0.5948 (0.5948)  loss_vfl_dn_1: 0.4266 (0.4266)  loss_bbox_dn_1: 0.1320 (0.1320)  loss_giou_dn_1: 0.4840 (0.4840)  loss_vfl_dn_2: 0.4090 (0.4090)  loss_bbox_dn_2: 0.1309 (0.1309)  loss_giou_dn_2: 0.4627 (0.4627)  loss_vfl_dn_3: 0.4034 (0.4034)  loss_bbox_dn_3: 0.1312 (0.1312)  loss_giou_dn_3: 0.4653 (0.4653)  loss_vfl_dn_4: 0.4085 (0.4085)  loss_bbox_dn_4: 0.1328 (0.1328)  loss_giou_dn_4: 0.4653 (0.4653)  loss_vfl_dn_5: 0.4041 (0.4041)  loss_bbox_dn_5: 0.1327 (0.1327)  loss_giou_dn_5: 0.4656 (0.4656)  time: 1.0177  data: 0.6011  max mem: 7790\n",
            "Epoch: [124]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.5483 (13.8471)  loss_vfl: 0.5228 (0.5482)  loss_bbox: 0.1003 (0.1061)  loss_giou: 0.3991 (0.4143)  loss_vfl_aux_0: 0.5341 (0.5495)  loss_bbox_aux_0: 0.1129 (0.1230)  loss_giou_aux_0: 0.4605 (0.4678)  loss_vfl_aux_1: 0.5229 (0.5357)  loss_bbox_aux_1: 0.1065 (0.1122)  loss_giou_aux_1: 0.4138 (0.4321)  loss_vfl_aux_2: 0.5159 (0.5378)  loss_bbox_aux_2: 0.1025 (0.1090)  loss_giou_aux_2: 0.4038 (0.4194)  loss_vfl_aux_3: 0.5141 (0.5356)  loss_bbox_aux_3: 0.1013 (0.1069)  loss_giou_aux_3: 0.4085 (0.4178)  loss_vfl_aux_4: 0.5231 (0.5430)  loss_bbox_aux_4: 0.1015 (0.1051)  loss_giou_aux_4: 0.3968 (0.4153)  loss_vfl_aux_5: 0.5896 (0.6114)  loss_bbox_aux_5: 0.1463 (0.1703)  loss_giou_aux_5: 0.5807 (0.5971)  loss_vfl_dn_0: 0.4398 (0.4407)  loss_bbox_dn_0: 0.1502 (0.1848)  loss_giou_dn_0: 0.6106 (0.6232)  loss_vfl_dn_1: 0.4072 (0.4038)  loss_bbox_dn_1: 0.1175 (0.1322)  loss_giou_dn_1: 0.4406 (0.4621)  loss_vfl_dn_2: 0.3993 (0.3931)  loss_bbox_dn_2: 0.1050 (0.1222)  loss_giou_dn_2: 0.4074 (0.4321)  loss_vfl_dn_3: 0.3931 (0.3891)  loss_bbox_dn_3: 0.1047 (0.1196)  loss_giou_dn_3: 0.3943 (0.4251)  loss_vfl_dn_4: 0.3924 (0.3886)  loss_bbox_dn_4: 0.1038 (0.1190)  loss_giou_dn_4: 0.3919 (0.4232)  loss_vfl_dn_5: 0.3942 (0.3888)  loss_bbox_dn_5: 0.1042 (0.1189)  loss_giou_dn_5: 0.3901 (0.4229)  time: 0.3380  data: 0.0142  max mem: 7790\n",
            "Epoch: [124] Total time: 0:00:11 (0.3590 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.5483 (13.8471)  loss_vfl: 0.5228 (0.5482)  loss_bbox: 0.1003 (0.1061)  loss_giou: 0.3991 (0.4143)  loss_vfl_aux_0: 0.5341 (0.5495)  loss_bbox_aux_0: 0.1129 (0.1230)  loss_giou_aux_0: 0.4605 (0.4678)  loss_vfl_aux_1: 0.5229 (0.5357)  loss_bbox_aux_1: 0.1065 (0.1122)  loss_giou_aux_1: 0.4138 (0.4321)  loss_vfl_aux_2: 0.5159 (0.5378)  loss_bbox_aux_2: 0.1025 (0.1090)  loss_giou_aux_2: 0.4038 (0.4194)  loss_vfl_aux_3: 0.5141 (0.5356)  loss_bbox_aux_3: 0.1013 (0.1069)  loss_giou_aux_3: 0.4085 (0.4178)  loss_vfl_aux_4: 0.5231 (0.5430)  loss_bbox_aux_4: 0.1015 (0.1051)  loss_giou_aux_4: 0.3968 (0.4153)  loss_vfl_aux_5: 0.5896 (0.6114)  loss_bbox_aux_5: 0.1463 (0.1703)  loss_giou_aux_5: 0.5807 (0.5971)  loss_vfl_dn_0: 0.4398 (0.4407)  loss_bbox_dn_0: 0.1502 (0.1848)  loss_giou_dn_0: 0.6106 (0.6232)  loss_vfl_dn_1: 0.4072 (0.4038)  loss_bbox_dn_1: 0.1175 (0.1322)  loss_giou_dn_1: 0.4406 (0.4621)  loss_vfl_dn_2: 0.3993 (0.3931)  loss_bbox_dn_2: 0.1050 (0.1222)  loss_giou_dn_2: 0.4074 (0.4321)  loss_vfl_dn_3: 0.3931 (0.3891)  loss_bbox_dn_3: 0.1047 (0.1196)  loss_giou_dn_3: 0.3943 (0.4251)  loss_vfl_dn_4: 0.3924 (0.3886)  loss_bbox_dn_4: 0.1038 (0.1190)  loss_giou_dn_4: 0.3919 (0.4232)  loss_vfl_dn_5: 0.3942 (0.3888)  loss_bbox_dn_5: 0.1042 (0.1189)  loss_giou_dn_5: 0.3901 (0.4229)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8986  data: 0.5543  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4159  data: 0.1212  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4298 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [125]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 15.7478 (15.7478)  loss_vfl: 0.4956 (0.4956)  loss_bbox: 0.0935 (0.0935)  loss_giou: 0.6037 (0.6037)  loss_vfl_aux_0: 0.4801 (0.4801)  loss_bbox_aux_0: 0.1026 (0.1026)  loss_giou_aux_0: 0.6205 (0.6205)  loss_vfl_aux_1: 0.5034 (0.5034)  loss_bbox_aux_1: 0.0969 (0.0969)  loss_giou_aux_1: 0.5956 (0.5956)  loss_vfl_aux_2: 0.4946 (0.4946)  loss_bbox_aux_2: 0.0946 (0.0946)  loss_giou_aux_2: 0.6033 (0.6033)  loss_vfl_aux_3: 0.4972 (0.4972)  loss_bbox_aux_3: 0.0939 (0.0939)  loss_giou_aux_3: 0.6039 (0.6039)  loss_vfl_aux_4: 0.4887 (0.4887)  loss_bbox_aux_4: 0.0945 (0.0945)  loss_giou_aux_4: 0.6055 (0.6055)  loss_vfl_aux_5: 0.5328 (0.5328)  loss_bbox_aux_5: 0.1706 (0.1706)  loss_giou_aux_5: 0.7230 (0.7230)  loss_vfl_dn_0: 0.4349 (0.4349)  loss_bbox_dn_0: 0.1530 (0.1530)  loss_giou_dn_0: 0.7739 (0.7739)  loss_vfl_dn_1: 0.4147 (0.4147)  loss_bbox_dn_1: 0.1138 (0.1138)  loss_giou_dn_1: 0.6488 (0.6488)  loss_vfl_dn_2: 0.4066 (0.4066)  loss_bbox_dn_2: 0.1112 (0.1112)  loss_giou_dn_2: 0.6397 (0.6397)  loss_vfl_dn_3: 0.4039 (0.4039)  loss_bbox_dn_3: 0.1115 (0.1115)  loss_giou_dn_3: 0.6366 (0.6366)  loss_vfl_dn_4: 0.4047 (0.4047)  loss_bbox_dn_4: 0.1111 (0.1111)  loss_giou_dn_4: 0.6354 (0.6354)  loss_vfl_dn_5: 0.4035 (0.4035)  loss_bbox_dn_5: 0.1110 (0.1110)  loss_giou_dn_5: 0.6387 (0.6387)  time: 0.9388  data: 0.5524  max mem: 7790\n",
            "Epoch: [125]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.2431 (13.9646)  loss_vfl: 0.5171 (0.5360)  loss_bbox: 0.1014 (0.1041)  loss_giou: 0.3795 (0.4169)  loss_vfl_aux_0: 0.5301 (0.5418)  loss_bbox_aux_0: 0.1158 (0.1234)  loss_giou_aux_0: 0.4262 (0.4695)  loss_vfl_aux_1: 0.5312 (0.5384)  loss_bbox_aux_1: 0.1052 (0.1096)  loss_giou_aux_1: 0.3921 (0.4304)  loss_vfl_aux_2: 0.5167 (0.5315)  loss_bbox_aux_2: 0.1001 (0.1056)  loss_giou_aux_2: 0.3937 (0.4222)  loss_vfl_aux_3: 0.5222 (0.5337)  loss_bbox_aux_3: 0.0949 (0.1031)  loss_giou_aux_3: 0.3819 (0.4161)  loss_vfl_aux_4: 0.5207 (0.5374)  loss_bbox_aux_4: 0.0970 (0.1035)  loss_giou_aux_4: 0.3736 (0.4158)  loss_vfl_aux_5: 0.5869 (0.5943)  loss_bbox_aux_5: 0.1611 (0.1735)  loss_giou_aux_5: 0.5783 (0.6086)  loss_vfl_dn_0: 0.4401 (0.4396)  loss_bbox_dn_0: 0.1843 (0.1866)  loss_giou_dn_0: 0.6301 (0.6387)  loss_vfl_dn_1: 0.4052 (0.4092)  loss_bbox_dn_1: 0.1314 (0.1365)  loss_giou_dn_1: 0.4572 (0.4790)  loss_vfl_dn_2: 0.3959 (0.3986)  loss_bbox_dn_2: 0.1164 (0.1274)  loss_giou_dn_2: 0.4287 (0.4512)  loss_vfl_dn_3: 0.3901 (0.3945)  loss_bbox_dn_3: 0.1104 (0.1249)  loss_giou_dn_3: 0.4211 (0.4430)  loss_vfl_dn_4: 0.3976 (0.3930)  loss_bbox_dn_4: 0.1090 (0.1247)  loss_giou_dn_4: 0.4153 (0.4421)  loss_vfl_dn_5: 0.3937 (0.3933)  loss_bbox_dn_5: 0.1092 (0.1246)  loss_giou_dn_5: 0.4136 (0.4425)  time: 0.3251  data: 0.0139  max mem: 7790\n",
            "Epoch: [125] Total time: 0:00:11 (0.3463 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.2431 (13.9646)  loss_vfl: 0.5171 (0.5360)  loss_bbox: 0.1014 (0.1041)  loss_giou: 0.3795 (0.4169)  loss_vfl_aux_0: 0.5301 (0.5418)  loss_bbox_aux_0: 0.1158 (0.1234)  loss_giou_aux_0: 0.4262 (0.4695)  loss_vfl_aux_1: 0.5312 (0.5384)  loss_bbox_aux_1: 0.1052 (0.1096)  loss_giou_aux_1: 0.3921 (0.4304)  loss_vfl_aux_2: 0.5167 (0.5315)  loss_bbox_aux_2: 0.1001 (0.1056)  loss_giou_aux_2: 0.3937 (0.4222)  loss_vfl_aux_3: 0.5222 (0.5337)  loss_bbox_aux_3: 0.0949 (0.1031)  loss_giou_aux_3: 0.3819 (0.4161)  loss_vfl_aux_4: 0.5207 (0.5374)  loss_bbox_aux_4: 0.0970 (0.1035)  loss_giou_aux_4: 0.3736 (0.4158)  loss_vfl_aux_5: 0.5869 (0.5943)  loss_bbox_aux_5: 0.1611 (0.1735)  loss_giou_aux_5: 0.5783 (0.6086)  loss_vfl_dn_0: 0.4401 (0.4396)  loss_bbox_dn_0: 0.1843 (0.1866)  loss_giou_dn_0: 0.6301 (0.6387)  loss_vfl_dn_1: 0.4052 (0.4092)  loss_bbox_dn_1: 0.1314 (0.1365)  loss_giou_dn_1: 0.4572 (0.4790)  loss_vfl_dn_2: 0.3959 (0.3986)  loss_bbox_dn_2: 0.1164 (0.1274)  loss_giou_dn_2: 0.4287 (0.4512)  loss_vfl_dn_3: 0.3901 (0.3945)  loss_bbox_dn_3: 0.1104 (0.1249)  loss_giou_dn_3: 0.4211 (0.4430)  loss_vfl_dn_4: 0.3976 (0.3930)  loss_bbox_dn_4: 0.1090 (0.1247)  loss_giou_dn_4: 0.4153 (0.4421)  loss_vfl_dn_5: 0.3937 (0.3933)  loss_bbox_dn_5: 0.1092 (0.1246)  loss_giou_dn_5: 0.4136 (0.4425)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9048  data: 0.5920  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3860  data: 0.1118  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3987 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.655\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [126]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 15.5192 (15.5192)  loss_vfl: 0.9136 (0.9136)  loss_bbox: 0.1288 (0.1288)  loss_giou: 0.3993 (0.3993)  loss_vfl_aux_0: 0.7588 (0.7588)  loss_bbox_aux_0: 0.1325 (0.1325)  loss_giou_aux_0: 0.4659 (0.4659)  loss_vfl_aux_1: 0.7772 (0.7772)  loss_bbox_aux_1: 0.1275 (0.1275)  loss_giou_aux_1: 0.4346 (0.4346)  loss_vfl_aux_2: 0.7869 (0.7869)  loss_bbox_aux_2: 0.1300 (0.1300)  loss_giou_aux_2: 0.4208 (0.4208)  loss_vfl_aux_3: 0.8641 (0.8641)  loss_bbox_aux_3: 0.1278 (0.1278)  loss_giou_aux_3: 0.4046 (0.4046)  loss_vfl_aux_4: 0.8571 (0.8571)  loss_bbox_aux_4: 0.1284 (0.1284)  loss_giou_aux_4: 0.3986 (0.3986)  loss_vfl_aux_5: 0.7706 (0.7706)  loss_bbox_aux_5: 0.1893 (0.1893)  loss_giou_aux_5: 0.5349 (0.5349)  loss_vfl_dn_0: 0.4557 (0.4557)  loss_bbox_dn_0: 0.1895 (0.1895)  loss_giou_dn_0: 0.5685 (0.5685)  loss_vfl_dn_1: 0.4043 (0.4043)  loss_bbox_dn_1: 0.1281 (0.1281)  loss_giou_dn_1: 0.4108 (0.4108)  loss_vfl_dn_2: 0.3969 (0.3969)  loss_bbox_dn_2: 0.1250 (0.1250)  loss_giou_dn_2: 0.3839 (0.3839)  loss_vfl_dn_3: 0.3999 (0.3999)  loss_bbox_dn_3: 0.1243 (0.1243)  loss_giou_dn_3: 0.3767 (0.3767)  loss_vfl_dn_4: 0.3985 (0.3985)  loss_bbox_dn_4: 0.1243 (0.1243)  loss_giou_dn_4: 0.3758 (0.3758)  loss_vfl_dn_5: 0.4038 (0.4038)  loss_bbox_dn_5: 0.1250 (0.1250)  loss_giou_dn_5: 0.3769 (0.3769)  time: 1.0174  data: 0.6060  max mem: 7790\n",
            "Epoch: [126]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.5165 (13.6235)  loss_vfl: 0.5229 (0.5259)  loss_bbox: 0.0918 (0.1001)  loss_giou: 0.4019 (0.4133)  loss_vfl_aux_0: 0.5303 (0.5398)  loss_bbox_aux_0: 0.1055 (0.1164)  loss_giou_aux_0: 0.4621 (0.4678)  loss_vfl_aux_1: 0.4987 (0.5188)  loss_bbox_aux_1: 0.0966 (0.1068)  loss_giou_aux_1: 0.4126 (0.4316)  loss_vfl_aux_2: 0.4968 (0.5157)  loss_bbox_aux_2: 0.0937 (0.1022)  loss_giou_aux_2: 0.4013 (0.4202)  loss_vfl_aux_3: 0.5105 (0.5208)  loss_bbox_aux_3: 0.0931 (0.1011)  loss_giou_aux_3: 0.4082 (0.4159)  loss_vfl_aux_4: 0.5196 (0.5223)  loss_bbox_aux_4: 0.0922 (0.1003)  loss_giou_aux_4: 0.3972 (0.4144)  loss_vfl_aux_5: 0.5713 (0.5887)  loss_bbox_aux_5: 0.1495 (0.1709)  loss_giou_aux_5: 0.6058 (0.6173)  loss_vfl_dn_0: 0.4445 (0.4438)  loss_bbox_dn_0: 0.1500 (0.1726)  loss_giou_dn_0: 0.6010 (0.6156)  loss_vfl_dn_1: 0.4095 (0.4050)  loss_bbox_dn_1: 0.1014 (0.1219)  loss_giou_dn_1: 0.4525 (0.4552)  loss_vfl_dn_2: 0.3958 (0.3936)  loss_bbox_dn_2: 0.0918 (0.1142)  loss_giou_dn_2: 0.4121 (0.4286)  loss_vfl_dn_3: 0.3917 (0.3898)  loss_bbox_dn_3: 0.0929 (0.1123)  loss_giou_dn_3: 0.4028 (0.4211)  loss_vfl_dn_4: 0.3899 (0.3889)  loss_bbox_dn_4: 0.0930 (0.1120)  loss_giou_dn_4: 0.4007 (0.4194)  loss_vfl_dn_5: 0.3881 (0.3880)  loss_bbox_dn_5: 0.0930 (0.1119)  loss_giou_dn_5: 0.3997 (0.4190)  time: 0.3251  data: 0.0145  max mem: 7790\n",
            "Epoch: [126] Total time: 0:00:11 (0.3488 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.5165 (13.6235)  loss_vfl: 0.5229 (0.5259)  loss_bbox: 0.0918 (0.1001)  loss_giou: 0.4019 (0.4133)  loss_vfl_aux_0: 0.5303 (0.5398)  loss_bbox_aux_0: 0.1055 (0.1164)  loss_giou_aux_0: 0.4621 (0.4678)  loss_vfl_aux_1: 0.4987 (0.5188)  loss_bbox_aux_1: 0.0966 (0.1068)  loss_giou_aux_1: 0.4126 (0.4316)  loss_vfl_aux_2: 0.4968 (0.5157)  loss_bbox_aux_2: 0.0937 (0.1022)  loss_giou_aux_2: 0.4013 (0.4202)  loss_vfl_aux_3: 0.5105 (0.5208)  loss_bbox_aux_3: 0.0931 (0.1011)  loss_giou_aux_3: 0.4082 (0.4159)  loss_vfl_aux_4: 0.5196 (0.5223)  loss_bbox_aux_4: 0.0922 (0.1003)  loss_giou_aux_4: 0.3972 (0.4144)  loss_vfl_aux_5: 0.5713 (0.5887)  loss_bbox_aux_5: 0.1495 (0.1709)  loss_giou_aux_5: 0.6058 (0.6173)  loss_vfl_dn_0: 0.4445 (0.4438)  loss_bbox_dn_0: 0.1500 (0.1726)  loss_giou_dn_0: 0.6010 (0.6156)  loss_vfl_dn_1: 0.4095 (0.4050)  loss_bbox_dn_1: 0.1014 (0.1219)  loss_giou_dn_1: 0.4525 (0.4552)  loss_vfl_dn_2: 0.3958 (0.3936)  loss_bbox_dn_2: 0.0918 (0.1142)  loss_giou_dn_2: 0.4121 (0.4286)  loss_vfl_dn_3: 0.3917 (0.3898)  loss_bbox_dn_3: 0.0929 (0.1123)  loss_giou_dn_3: 0.4028 (0.4211)  loss_vfl_dn_4: 0.3899 (0.3889)  loss_bbox_dn_4: 0.0930 (0.1120)  loss_giou_dn_4: 0.4007 (0.4194)  loss_vfl_dn_5: 0.3881 (0.3880)  loss_bbox_dn_5: 0.0930 (0.1119)  loss_giou_dn_5: 0.3997 (0.4190)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8977  data: 0.5849  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3855  data: 0.1129  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3998 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.625\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [127]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 16.2964 (16.2964)  loss_vfl: 0.5881 (0.5881)  loss_bbox: 0.0846 (0.0846)  loss_giou: 0.6210 (0.6210)  loss_vfl_aux_0: 0.5386 (0.5386)  loss_bbox_aux_0: 0.0876 (0.0876)  loss_giou_aux_0: 0.6713 (0.6713)  loss_vfl_aux_1: 0.5534 (0.5534)  loss_bbox_aux_1: 0.0812 (0.0812)  loss_giou_aux_1: 0.6051 (0.6051)  loss_vfl_aux_2: 0.5866 (0.5866)  loss_bbox_aux_2: 0.0842 (0.0842)  loss_giou_aux_2: 0.6021 (0.6021)  loss_vfl_aux_3: 0.5600 (0.5600)  loss_bbox_aux_3: 0.0855 (0.0855)  loss_giou_aux_3: 0.6214 (0.6214)  loss_vfl_aux_4: 0.5781 (0.5781)  loss_bbox_aux_4: 0.0833 (0.0833)  loss_giou_aux_4: 0.6214 (0.6214)  loss_vfl_aux_5: 0.5454 (0.5454)  loss_bbox_aux_5: 0.1163 (0.1163)  loss_giou_aux_5: 0.7727 (0.7727)  loss_vfl_dn_0: 0.4459 (0.4459)  loss_bbox_dn_0: 0.1320 (0.1320)  loss_giou_dn_0: 0.7904 (0.7904)  loss_vfl_dn_1: 0.4334 (0.4334)  loss_bbox_dn_1: 0.1005 (0.1005)  loss_giou_dn_1: 0.6477 (0.6477)  loss_vfl_dn_2: 0.4283 (0.4283)  loss_bbox_dn_2: 0.0984 (0.0984)  loss_giou_dn_2: 0.6346 (0.6346)  loss_vfl_dn_3: 0.4282 (0.4282)  loss_bbox_dn_3: 0.0978 (0.0978)  loss_giou_dn_3: 0.6397 (0.6397)  loss_vfl_dn_4: 0.4270 (0.4270)  loss_bbox_dn_4: 0.0987 (0.0987)  loss_giou_dn_4: 0.6397 (0.6397)  loss_vfl_dn_5: 0.4234 (0.4234)  loss_bbox_dn_5: 0.0993 (0.0993)  loss_giou_dn_5: 0.6435 (0.6435)  time: 1.0455  data: 0.6581  max mem: 7790\n",
            "Epoch: [127]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.3082 (13.7650)  loss_vfl: 0.4859 (0.5104)  loss_bbox: 0.0799 (0.0960)  loss_giou: 0.4176 (0.4363)  loss_vfl_aux_0: 0.5121 (0.5183)  loss_bbox_aux_0: 0.0934 (0.1103)  loss_giou_aux_0: 0.4830 (0.4836)  loss_vfl_aux_1: 0.4969 (0.5101)  loss_bbox_aux_1: 0.0821 (0.0989)  loss_giou_aux_1: 0.4356 (0.4465)  loss_vfl_aux_2: 0.4907 (0.5077)  loss_bbox_aux_2: 0.0815 (0.0974)  loss_giou_aux_2: 0.4276 (0.4399)  loss_vfl_aux_3: 0.4888 (0.5071)  loss_bbox_aux_3: 0.0802 (0.0966)  loss_giou_aux_3: 0.4221 (0.4376)  loss_vfl_aux_4: 0.4850 (0.5062)  loss_bbox_aux_4: 0.0805 (0.0961)  loss_giou_aux_4: 0.4167 (0.4370)  loss_vfl_aux_5: 0.5778 (0.5816)  loss_bbox_aux_5: 0.1332 (0.1588)  loss_giou_aux_5: 0.5809 (0.6342)  loss_vfl_dn_0: 0.4391 (0.4389)  loss_bbox_dn_0: 0.1442 (0.1639)  loss_giou_dn_0: 0.6217 (0.6476)  loss_vfl_dn_1: 0.4099 (0.4060)  loss_bbox_dn_1: 0.0965 (0.1157)  loss_giou_dn_1: 0.4727 (0.4862)  loss_vfl_dn_2: 0.3984 (0.3949)  loss_bbox_dn_2: 0.0881 (0.1064)  loss_giou_dn_2: 0.4531 (0.4562)  loss_vfl_dn_3: 0.3936 (0.3914)  loss_bbox_dn_3: 0.0884 (0.1047)  loss_giou_dn_3: 0.4554 (0.4510)  loss_vfl_dn_4: 0.3940 (0.3915)  loss_bbox_dn_4: 0.0879 (0.1045)  loss_giou_dn_4: 0.4549 (0.4497)  loss_vfl_dn_5: 0.3948 (0.3916)  loss_bbox_dn_5: 0.0878 (0.1042)  loss_giou_dn_5: 0.4530 (0.4499)  time: 0.3180  data: 0.0139  max mem: 7790\n",
            "Epoch: [127] Total time: 0:00:11 (0.3448 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.3082 (13.7650)  loss_vfl: 0.4859 (0.5104)  loss_bbox: 0.0799 (0.0960)  loss_giou: 0.4176 (0.4363)  loss_vfl_aux_0: 0.5121 (0.5183)  loss_bbox_aux_0: 0.0934 (0.1103)  loss_giou_aux_0: 0.4830 (0.4836)  loss_vfl_aux_1: 0.4969 (0.5101)  loss_bbox_aux_1: 0.0821 (0.0989)  loss_giou_aux_1: 0.4356 (0.4465)  loss_vfl_aux_2: 0.4907 (0.5077)  loss_bbox_aux_2: 0.0815 (0.0974)  loss_giou_aux_2: 0.4276 (0.4399)  loss_vfl_aux_3: 0.4888 (0.5071)  loss_bbox_aux_3: 0.0802 (0.0966)  loss_giou_aux_3: 0.4221 (0.4376)  loss_vfl_aux_4: 0.4850 (0.5062)  loss_bbox_aux_4: 0.0805 (0.0961)  loss_giou_aux_4: 0.4167 (0.4370)  loss_vfl_aux_5: 0.5778 (0.5816)  loss_bbox_aux_5: 0.1332 (0.1588)  loss_giou_aux_5: 0.5809 (0.6342)  loss_vfl_dn_0: 0.4391 (0.4389)  loss_bbox_dn_0: 0.1442 (0.1639)  loss_giou_dn_0: 0.6217 (0.6476)  loss_vfl_dn_1: 0.4099 (0.4060)  loss_bbox_dn_1: 0.0965 (0.1157)  loss_giou_dn_1: 0.4727 (0.4862)  loss_vfl_dn_2: 0.3984 (0.3949)  loss_bbox_dn_2: 0.0881 (0.1064)  loss_giou_dn_2: 0.4531 (0.4562)  loss_vfl_dn_3: 0.3936 (0.3914)  loss_bbox_dn_3: 0.0884 (0.1047)  loss_giou_dn_3: 0.4554 (0.4510)  loss_vfl_dn_4: 0.3940 (0.3915)  loss_bbox_dn_4: 0.0879 (0.1045)  loss_giou_dn_4: 0.4549 (0.4497)  loss_vfl_dn_5: 0.3948 (0.3916)  loss_bbox_dn_5: 0.0878 (0.1042)  loss_giou_dn_5: 0.4530 (0.4499)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8615  data: 0.5535  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.9961  data: 0.6697  max mem: 7790\n",
            "Test: Total time: 0:00:06 (1.0092 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.662\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.317\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [128]  [ 0/33]  eta: 0:00:29  lr: 0.000001  loss: 14.0792 (14.0792)  loss_vfl: 0.5370 (0.5370)  loss_bbox: 0.1088 (0.1088)  loss_giou: 0.3988 (0.3988)  loss_vfl_aux_0: 0.5233 (0.5233)  loss_bbox_aux_0: 0.1261 (0.1261)  loss_giou_aux_0: 0.4734 (0.4734)  loss_vfl_aux_1: 0.5053 (0.5053)  loss_bbox_aux_1: 0.1242 (0.1242)  loss_giou_aux_1: 0.4434 (0.4434)  loss_vfl_aux_2: 0.5170 (0.5170)  loss_bbox_aux_2: 0.1201 (0.1201)  loss_giou_aux_2: 0.4404 (0.4404)  loss_vfl_aux_3: 0.5247 (0.5247)  loss_bbox_aux_3: 0.1135 (0.1135)  loss_giou_aux_3: 0.4114 (0.4114)  loss_vfl_aux_4: 0.5130 (0.5130)  loss_bbox_aux_4: 0.1169 (0.1169)  loss_giou_aux_4: 0.4449 (0.4449)  loss_vfl_aux_5: 0.5862 (0.5862)  loss_bbox_aux_5: 0.1503 (0.1503)  loss_giou_aux_5: 0.5451 (0.5451)  loss_vfl_dn_0: 0.4327 (0.4327)  loss_bbox_dn_0: 0.2121 (0.2121)  loss_giou_dn_0: 0.6451 (0.6451)  loss_vfl_dn_1: 0.4031 (0.4031)  loss_bbox_dn_1: 0.1682 (0.1682)  loss_giou_dn_1: 0.4762 (0.4762)  loss_vfl_dn_2: 0.3921 (0.3921)  loss_bbox_dn_2: 0.1673 (0.1673)  loss_giou_dn_2: 0.4545 (0.4545)  loss_vfl_dn_3: 0.3892 (0.3892)  loss_bbox_dn_3: 0.1663 (0.1663)  loss_giou_dn_3: 0.4459 (0.4459)  loss_vfl_dn_4: 0.3881 (0.3881)  loss_bbox_dn_4: 0.1672 (0.1672)  loss_giou_dn_4: 0.4454 (0.4454)  loss_vfl_dn_5: 0.3870 (0.3870)  loss_bbox_dn_5: 0.1682 (0.1682)  loss_giou_dn_5: 0.4469 (0.4469)  time: 0.9025  data: 0.5229  max mem: 7790\n",
            "Epoch: [128]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.7323 (14.0353)  loss_vfl: 0.5121 (0.5233)  loss_bbox: 0.0901 (0.1001)  loss_giou: 0.3929 (0.4454)  loss_vfl_aux_0: 0.5369 (0.5276)  loss_bbox_aux_0: 0.1042 (0.1153)  loss_giou_aux_0: 0.4657 (0.4980)  loss_vfl_aux_1: 0.5136 (0.5196)  loss_bbox_aux_1: 0.0940 (0.1051)  loss_giou_aux_1: 0.4183 (0.4614)  loss_vfl_aux_2: 0.5107 (0.5179)  loss_bbox_aux_2: 0.0912 (0.1019)  loss_giou_aux_2: 0.3947 (0.4527)  loss_vfl_aux_3: 0.4985 (0.5166)  loss_bbox_aux_3: 0.0897 (0.1002)  loss_giou_aux_3: 0.3956 (0.4474)  loss_vfl_aux_4: 0.5009 (0.5176)  loss_bbox_aux_4: 0.0897 (0.1008)  loss_giou_aux_4: 0.3962 (0.4460)  loss_vfl_aux_5: 0.5906 (0.5900)  loss_bbox_aux_5: 0.1519 (0.1601)  loss_giou_aux_5: 0.6211 (0.6332)  loss_vfl_dn_0: 0.4471 (0.4445)  loss_bbox_dn_0: 0.1582 (0.1675)  loss_giou_dn_0: 0.6309 (0.6466)  loss_vfl_dn_1: 0.4205 (0.4132)  loss_bbox_dn_1: 0.1107 (0.1216)  loss_giou_dn_1: 0.4493 (0.4889)  loss_vfl_dn_2: 0.4099 (0.4020)  loss_bbox_dn_2: 0.1057 (0.1136)  loss_giou_dn_2: 0.4125 (0.4616)  loss_vfl_dn_3: 0.4068 (0.3987)  loss_bbox_dn_3: 0.1064 (0.1122)  loss_giou_dn_3: 0.4099 (0.4551)  loss_vfl_dn_4: 0.4074 (0.3979)  loss_bbox_dn_4: 0.1071 (0.1120)  loss_giou_dn_4: 0.4109 (0.4543)  loss_vfl_dn_5: 0.4061 (0.3985)  loss_bbox_dn_5: 0.1073 (0.1120)  loss_giou_dn_5: 0.4107 (0.4547)  time: 0.3262  data: 0.0173  max mem: 7790\n",
            "Epoch: [128] Total time: 0:00:11 (0.3459 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.7323 (14.0353)  loss_vfl: 0.5121 (0.5233)  loss_bbox: 0.0901 (0.1001)  loss_giou: 0.3929 (0.4454)  loss_vfl_aux_0: 0.5369 (0.5276)  loss_bbox_aux_0: 0.1042 (0.1153)  loss_giou_aux_0: 0.4657 (0.4980)  loss_vfl_aux_1: 0.5136 (0.5196)  loss_bbox_aux_1: 0.0940 (0.1051)  loss_giou_aux_1: 0.4183 (0.4614)  loss_vfl_aux_2: 0.5107 (0.5179)  loss_bbox_aux_2: 0.0912 (0.1019)  loss_giou_aux_2: 0.3947 (0.4527)  loss_vfl_aux_3: 0.4985 (0.5166)  loss_bbox_aux_3: 0.0897 (0.1002)  loss_giou_aux_3: 0.3956 (0.4474)  loss_vfl_aux_4: 0.5009 (0.5176)  loss_bbox_aux_4: 0.0897 (0.1008)  loss_giou_aux_4: 0.3962 (0.4460)  loss_vfl_aux_5: 0.5906 (0.5900)  loss_bbox_aux_5: 0.1519 (0.1601)  loss_giou_aux_5: 0.6211 (0.6332)  loss_vfl_dn_0: 0.4471 (0.4445)  loss_bbox_dn_0: 0.1582 (0.1675)  loss_giou_dn_0: 0.6309 (0.6466)  loss_vfl_dn_1: 0.4205 (0.4132)  loss_bbox_dn_1: 0.1107 (0.1216)  loss_giou_dn_1: 0.4493 (0.4889)  loss_vfl_dn_2: 0.4099 (0.4020)  loss_bbox_dn_2: 0.1057 (0.1136)  loss_giou_dn_2: 0.4125 (0.4616)  loss_vfl_dn_3: 0.4068 (0.3987)  loss_bbox_dn_3: 0.1064 (0.1122)  loss_giou_dn_3: 0.4099 (0.4551)  loss_vfl_dn_4: 0.4074 (0.3979)  loss_bbox_dn_4: 0.1071 (0.1120)  loss_giou_dn_4: 0.4109 (0.4543)  loss_vfl_dn_5: 0.4061 (0.3985)  loss_bbox_dn_5: 0.1073 (0.1120)  loss_giou_dn_5: 0.4107 (0.4547)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8531  data: 0.5439  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4384  data: 0.1126  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4518 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.651\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [129]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 15.3623 (15.3623)  loss_vfl: 0.5265 (0.5265)  loss_bbox: 0.0664 (0.0664)  loss_giou: 0.5524 (0.5524)  loss_vfl_aux_0: 0.5503 (0.5503)  loss_bbox_aux_0: 0.0797 (0.0797)  loss_giou_aux_0: 0.6244 (0.6244)  loss_vfl_aux_1: 0.5166 (0.5166)  loss_bbox_aux_1: 0.0701 (0.0701)  loss_giou_aux_1: 0.5851 (0.5851)  loss_vfl_aux_2: 0.5247 (0.5247)  loss_bbox_aux_2: 0.0670 (0.0670)  loss_giou_aux_2: 0.5622 (0.5622)  loss_vfl_aux_3: 0.5353 (0.5353)  loss_bbox_aux_3: 0.0667 (0.0667)  loss_giou_aux_3: 0.5549 (0.5549)  loss_vfl_aux_4: 0.5310 (0.5310)  loss_bbox_aux_4: 0.0663 (0.0663)  loss_giou_aux_4: 0.5516 (0.5516)  loss_vfl_aux_5: 0.5502 (0.5502)  loss_bbox_aux_5: 0.1123 (0.1123)  loss_giou_aux_5: 0.7305 (0.7305)  loss_vfl_dn_0: 0.4365 (0.4365)  loss_bbox_dn_0: 0.0993 (0.0993)  loss_giou_dn_0: 0.8078 (0.8078)  loss_vfl_dn_1: 0.4173 (0.4173)  loss_bbox_dn_1: 0.0791 (0.0791)  loss_giou_dn_1: 0.6585 (0.6585)  loss_vfl_dn_2: 0.4116 (0.4116)  loss_bbox_dn_2: 0.0749 (0.0749)  loss_giou_dn_2: 0.6328 (0.6328)  loss_vfl_dn_3: 0.4099 (0.4099)  loss_bbox_dn_3: 0.0747 (0.0747)  loss_giou_dn_3: 0.6259 (0.6259)  loss_vfl_dn_4: 0.4079 (0.4079)  loss_bbox_dn_4: 0.0744 (0.0744)  loss_giou_dn_4: 0.6224 (0.6224)  loss_vfl_dn_5: 0.4087 (0.4087)  loss_bbox_dn_5: 0.0747 (0.0747)  loss_giou_dn_5: 0.6216 (0.6216)  time: 1.0557  data: 0.6677  max mem: 7790\n",
            "Epoch: [129]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.4391 (13.5349)  loss_vfl: 0.5217 (0.5298)  loss_bbox: 0.0819 (0.0941)  loss_giou: 0.3832 (0.3985)  loss_vfl_aux_0: 0.5293 (0.5404)  loss_bbox_aux_0: 0.1014 (0.1118)  loss_giou_aux_0: 0.4184 (0.4495)  loss_vfl_aux_1: 0.5341 (0.5358)  loss_bbox_aux_1: 0.0864 (0.0978)  loss_giou_aux_1: 0.3977 (0.4127)  loss_vfl_aux_2: 0.5152 (0.5331)  loss_bbox_aux_2: 0.0852 (0.0958)  loss_giou_aux_2: 0.3879 (0.4045)  loss_vfl_aux_3: 0.5152 (0.5287)  loss_bbox_aux_3: 0.0828 (0.0940)  loss_giou_aux_3: 0.3871 (0.4019)  loss_vfl_aux_4: 0.5197 (0.5262)  loss_bbox_aux_4: 0.0820 (0.0940)  loss_giou_aux_4: 0.3880 (0.4000)  loss_vfl_aux_5: 0.5999 (0.6083)  loss_bbox_aux_5: 0.1324 (0.1558)  loss_giou_aux_5: 0.5685 (0.5787)  loss_vfl_dn_0: 0.4379 (0.4400)  loss_bbox_dn_0: 0.1469 (0.1706)  loss_giou_dn_0: 0.5907 (0.6225)  loss_vfl_dn_1: 0.4008 (0.4025)  loss_bbox_dn_1: 0.0989 (0.1223)  loss_giou_dn_1: 0.4347 (0.4664)  loss_vfl_dn_2: 0.3855 (0.3914)  loss_bbox_dn_2: 0.0916 (0.1126)  loss_giou_dn_2: 0.4097 (0.4357)  loss_vfl_dn_3: 0.3838 (0.3883)  loss_bbox_dn_3: 0.0910 (0.1109)  loss_giou_dn_3: 0.4012 (0.4288)  loss_vfl_dn_4: 0.3803 (0.3869)  loss_bbox_dn_4: 0.0904 (0.1107)  loss_giou_dn_4: 0.4006 (0.4277)  loss_vfl_dn_5: 0.3834 (0.3875)  loss_bbox_dn_5: 0.0905 (0.1107)  loss_giou_dn_5: 0.4016 (0.4280)  time: 0.3282  data: 0.0137  max mem: 7790\n",
            "Epoch: [129] Total time: 0:00:11 (0.3493 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.4391 (13.5349)  loss_vfl: 0.5217 (0.5298)  loss_bbox: 0.0819 (0.0941)  loss_giou: 0.3832 (0.3985)  loss_vfl_aux_0: 0.5293 (0.5404)  loss_bbox_aux_0: 0.1014 (0.1118)  loss_giou_aux_0: 0.4184 (0.4495)  loss_vfl_aux_1: 0.5341 (0.5358)  loss_bbox_aux_1: 0.0864 (0.0978)  loss_giou_aux_1: 0.3977 (0.4127)  loss_vfl_aux_2: 0.5152 (0.5331)  loss_bbox_aux_2: 0.0852 (0.0958)  loss_giou_aux_2: 0.3879 (0.4045)  loss_vfl_aux_3: 0.5152 (0.5287)  loss_bbox_aux_3: 0.0828 (0.0940)  loss_giou_aux_3: 0.3871 (0.4019)  loss_vfl_aux_4: 0.5197 (0.5262)  loss_bbox_aux_4: 0.0820 (0.0940)  loss_giou_aux_4: 0.3880 (0.4000)  loss_vfl_aux_5: 0.5999 (0.6083)  loss_bbox_aux_5: 0.1324 (0.1558)  loss_giou_aux_5: 0.5685 (0.5787)  loss_vfl_dn_0: 0.4379 (0.4400)  loss_bbox_dn_0: 0.1469 (0.1706)  loss_giou_dn_0: 0.5907 (0.6225)  loss_vfl_dn_1: 0.4008 (0.4025)  loss_bbox_dn_1: 0.0989 (0.1223)  loss_giou_dn_1: 0.4347 (0.4664)  loss_vfl_dn_2: 0.3855 (0.3914)  loss_bbox_dn_2: 0.0916 (0.1126)  loss_giou_dn_2: 0.4097 (0.4357)  loss_vfl_dn_3: 0.3838 (0.3883)  loss_bbox_dn_3: 0.0910 (0.1109)  loss_giou_dn_3: 0.4012 (0.4288)  loss_vfl_dn_4: 0.3803 (0.3869)  loss_bbox_dn_4: 0.0904 (0.1107)  loss_giou_dn_4: 0.4006 (0.4277)  loss_vfl_dn_5: 0.3834 (0.3875)  loss_bbox_dn_5: 0.0905 (0.1107)  loss_giou_dn_5: 0.4016 (0.4280)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9179  data: 0.6090  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3867  data: 0.1143  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4018 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.549\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [130]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 18.6296 (18.6296)  loss_vfl: 0.5098 (0.5098)  loss_bbox: 0.0837 (0.0837)  loss_giou: 0.8556 (0.8556)  loss_vfl_aux_0: 0.4727 (0.4727)  loss_bbox_aux_0: 0.1065 (0.1065)  loss_giou_aux_0: 0.9495 (0.9495)  loss_vfl_aux_1: 0.5341 (0.5341)  loss_bbox_aux_1: 0.0850 (0.0850)  loss_giou_aux_1: 0.8682 (0.8682)  loss_vfl_aux_2: 0.5605 (0.5605)  loss_bbox_aux_2: 0.0838 (0.0838)  loss_giou_aux_2: 0.8579 (0.8579)  loss_vfl_aux_3: 0.5285 (0.5285)  loss_bbox_aux_3: 0.0844 (0.0844)  loss_giou_aux_3: 0.8519 (0.8519)  loss_vfl_aux_4: 0.5358 (0.5358)  loss_bbox_aux_4: 0.0837 (0.0837)  loss_giou_aux_4: 0.8509 (0.8509)  loss_vfl_aux_5: 0.5269 (0.5269)  loss_bbox_aux_5: 0.1532 (0.1532)  loss_giou_aux_5: 1.0060 (1.0060)  loss_vfl_dn_0: 0.4131 (0.4131)  loss_bbox_dn_0: 0.1634 (0.1634)  loss_giou_dn_0: 0.9283 (0.9283)  loss_vfl_dn_1: 0.3940 (0.3940)  loss_bbox_dn_1: 0.1077 (0.1077)  loss_giou_dn_1: 0.8463 (0.8463)  loss_vfl_dn_2: 0.3788 (0.3788)  loss_bbox_dn_2: 0.0945 (0.0945)  loss_giou_dn_2: 0.8404 (0.8404)  loss_vfl_dn_3: 0.3678 (0.3678)  loss_bbox_dn_3: 0.0894 (0.0894)  loss_giou_dn_3: 0.8388 (0.8388)  loss_vfl_dn_4: 0.3628 (0.3628)  loss_bbox_dn_4: 0.0874 (0.0874)  loss_giou_dn_4: 0.8407 (0.8407)  loss_vfl_dn_5: 0.3602 (0.3602)  loss_bbox_dn_5: 0.0866 (0.0866)  loss_giou_dn_5: 0.8408 (0.8408)  time: 1.0552  data: 0.6731  max mem: 7790\n",
            "Epoch: [130]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.8018 (13.9960)  loss_vfl: 0.5054 (0.5308)  loss_bbox: 0.0964 (0.1008)  loss_giou: 0.3596 (0.4275)  loss_vfl_aux_0: 0.5280 (0.5483)  loss_bbox_aux_0: 0.1066 (0.1188)  loss_giou_aux_0: 0.4203 (0.4797)  loss_vfl_aux_1: 0.5107 (0.5349)  loss_bbox_aux_1: 0.0981 (0.1039)  loss_giou_aux_1: 0.3858 (0.4419)  loss_vfl_aux_2: 0.5016 (0.5353)  loss_bbox_aux_2: 0.0954 (0.1016)  loss_giou_aux_2: 0.3808 (0.4319)  loss_vfl_aux_3: 0.4940 (0.5312)  loss_bbox_aux_3: 0.0946 (0.1007)  loss_giou_aux_3: 0.3737 (0.4280)  loss_vfl_aux_4: 0.5042 (0.5336)  loss_bbox_aux_4: 0.0954 (0.1001)  loss_giou_aux_4: 0.3583 (0.4252)  loss_vfl_aux_5: 0.5939 (0.6078)  loss_bbox_aux_5: 0.1424 (0.1643)  loss_giou_aux_5: 0.5511 (0.6127)  loss_vfl_dn_0: 0.4333 (0.4376)  loss_bbox_dn_0: 0.1629 (0.1820)  loss_giou_dn_0: 0.5753 (0.6372)  loss_vfl_dn_1: 0.3973 (0.4019)  loss_bbox_dn_1: 0.1213 (0.1350)  loss_giou_dn_1: 0.4247 (0.4843)  loss_vfl_dn_2: 0.3858 (0.3919)  loss_bbox_dn_2: 0.1171 (0.1263)  loss_giou_dn_2: 0.3917 (0.4575)  loss_vfl_dn_3: 0.3804 (0.3873)  loss_bbox_dn_3: 0.1165 (0.1245)  loss_giou_dn_3: 0.3895 (0.4516)  loss_vfl_dn_4: 0.3823 (0.3855)  loss_bbox_dn_4: 0.1169 (0.1241)  loss_giou_dn_4: 0.3879 (0.4503)  loss_vfl_dn_5: 0.3832 (0.3855)  loss_bbox_dn_5: 0.1171 (0.1240)  loss_giou_dn_5: 0.3883 (0.4504)  time: 0.3411  data: 0.0144  max mem: 7790\n",
            "Epoch: [130] Total time: 0:00:11 (0.3611 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.8018 (13.9960)  loss_vfl: 0.5054 (0.5308)  loss_bbox: 0.0964 (0.1008)  loss_giou: 0.3596 (0.4275)  loss_vfl_aux_0: 0.5280 (0.5483)  loss_bbox_aux_0: 0.1066 (0.1188)  loss_giou_aux_0: 0.4203 (0.4797)  loss_vfl_aux_1: 0.5107 (0.5349)  loss_bbox_aux_1: 0.0981 (0.1039)  loss_giou_aux_1: 0.3858 (0.4419)  loss_vfl_aux_2: 0.5016 (0.5353)  loss_bbox_aux_2: 0.0954 (0.1016)  loss_giou_aux_2: 0.3808 (0.4319)  loss_vfl_aux_3: 0.4940 (0.5312)  loss_bbox_aux_3: 0.0946 (0.1007)  loss_giou_aux_3: 0.3737 (0.4280)  loss_vfl_aux_4: 0.5042 (0.5336)  loss_bbox_aux_4: 0.0954 (0.1001)  loss_giou_aux_4: 0.3583 (0.4252)  loss_vfl_aux_5: 0.5939 (0.6078)  loss_bbox_aux_5: 0.1424 (0.1643)  loss_giou_aux_5: 0.5511 (0.6127)  loss_vfl_dn_0: 0.4333 (0.4376)  loss_bbox_dn_0: 0.1629 (0.1820)  loss_giou_dn_0: 0.5753 (0.6372)  loss_vfl_dn_1: 0.3973 (0.4019)  loss_bbox_dn_1: 0.1213 (0.1350)  loss_giou_dn_1: 0.4247 (0.4843)  loss_vfl_dn_2: 0.3858 (0.3919)  loss_bbox_dn_2: 0.1171 (0.1263)  loss_giou_dn_2: 0.3917 (0.4575)  loss_vfl_dn_3: 0.3804 (0.3873)  loss_bbox_dn_3: 0.1165 (0.1245)  loss_giou_dn_3: 0.3895 (0.4516)  loss_vfl_dn_4: 0.3823 (0.3855)  loss_bbox_dn_4: 0.1169 (0.1241)  loss_giou_dn_4: 0.3879 (0.4503)  loss_vfl_dn_5: 0.3832 (0.3855)  loss_bbox_dn_5: 0.1171 (0.1240)  loss_giou_dn_5: 0.3883 (0.4504)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8496  data: 0.5400  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.8382  data: 0.5642  max mem: 7790\n",
            "Test: Total time: 0:00:05 (0.8524 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.662\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.305\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.226\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [131]  [ 0/33]  eta: 0:00:36  lr: 0.000001  loss: 12.7688 (12.7688)  loss_vfl: 0.5095 (0.5095)  loss_bbox: 0.1238 (0.1238)  loss_giou: 0.3473 (0.3473)  loss_vfl_aux_0: 0.4951 (0.4951)  loss_bbox_aux_0: 0.1408 (0.1408)  loss_giou_aux_0: 0.3904 (0.3904)  loss_vfl_aux_1: 0.4910 (0.4910)  loss_bbox_aux_1: 0.1325 (0.1325)  loss_giou_aux_1: 0.3563 (0.3563)  loss_vfl_aux_2: 0.5103 (0.5103)  loss_bbox_aux_2: 0.1281 (0.1281)  loss_giou_aux_2: 0.3471 (0.3471)  loss_vfl_aux_3: 0.5066 (0.5066)  loss_bbox_aux_3: 0.1257 (0.1257)  loss_giou_aux_3: 0.3505 (0.3505)  loss_vfl_aux_4: 0.5140 (0.5140)  loss_bbox_aux_4: 0.1244 (0.1244)  loss_giou_aux_4: 0.3485 (0.3485)  loss_vfl_aux_5: 0.5754 (0.5754)  loss_bbox_aux_5: 0.1716 (0.1716)  loss_giou_aux_5: 0.4959 (0.4959)  loss_vfl_dn_0: 0.4227 (0.4227)  loss_bbox_dn_0: 0.1768 (0.1768)  loss_giou_dn_0: 0.5030 (0.5030)  loss_vfl_dn_1: 0.3896 (0.3896)  loss_bbox_dn_1: 0.1476 (0.1476)  loss_giou_dn_1: 0.3926 (0.3926)  loss_vfl_dn_2: 0.3808 (0.3808)  loss_bbox_dn_2: 0.1396 (0.1396)  loss_giou_dn_2: 0.3711 (0.3711)  loss_vfl_dn_3: 0.3792 (0.3792)  loss_bbox_dn_3: 0.1390 (0.1390)  loss_giou_dn_3: 0.3751 (0.3751)  loss_vfl_dn_4: 0.3739 (0.3739)  loss_bbox_dn_4: 0.1371 (0.1371)  loss_giou_dn_4: 0.3718 (0.3718)  loss_vfl_dn_5: 0.3767 (0.3767)  loss_bbox_dn_5: 0.1364 (0.1364)  loss_giou_dn_5: 0.3711 (0.3711)  time: 1.1207  data: 0.7402  max mem: 7790\n",
            "Epoch: [131]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.4928 (13.8770)  loss_vfl: 0.5096 (0.5397)  loss_bbox: 0.0831 (0.0969)  loss_giou: 0.3883 (0.4123)  loss_vfl_aux_0: 0.5511 (0.5607)  loss_bbox_aux_0: 0.0915 (0.1166)  loss_giou_aux_0: 0.4450 (0.4631)  loss_vfl_aux_1: 0.5039 (0.5470)  loss_bbox_aux_1: 0.0836 (0.1034)  loss_giou_aux_1: 0.3975 (0.4257)  loss_vfl_aux_2: 0.5086 (0.5417)  loss_bbox_aux_2: 0.0811 (0.0995)  loss_giou_aux_2: 0.3832 (0.4178)  loss_vfl_aux_3: 0.5047 (0.5411)  loss_bbox_aux_3: 0.0825 (0.0979)  loss_giou_aux_3: 0.3855 (0.4130)  loss_vfl_aux_4: 0.5089 (0.5400)  loss_bbox_aux_4: 0.0817 (0.0969)  loss_giou_aux_4: 0.3882 (0.4116)  loss_vfl_aux_5: 0.6015 (0.6301)  loss_bbox_aux_5: 0.1472 (0.1548)  loss_giou_aux_5: 0.6066 (0.5856)  loss_vfl_dn_0: 0.4369 (0.4382)  loss_bbox_dn_0: 0.1553 (0.1883)  loss_giou_dn_0: 0.6241 (0.6215)  loss_vfl_dn_1: 0.3989 (0.3982)  loss_bbox_dn_1: 0.1153 (0.1399)  loss_giou_dn_1: 0.4591 (0.4763)  loss_vfl_dn_2: 0.3905 (0.3879)  loss_bbox_dn_2: 0.1057 (0.1302)  loss_giou_dn_2: 0.4377 (0.4489)  loss_vfl_dn_3: 0.3877 (0.3843)  loss_bbox_dn_3: 0.1018 (0.1278)  loss_giou_dn_3: 0.4234 (0.4416)  loss_vfl_dn_4: 0.3843 (0.3827)  loss_bbox_dn_4: 0.1010 (0.1270)  loss_giou_dn_4: 0.4238 (0.4393)  loss_vfl_dn_5: 0.3861 (0.3836)  loss_bbox_dn_5: 0.1012 (0.1268)  loss_giou_dn_5: 0.4248 (0.4390)  time: 0.3386  data: 0.0157  max mem: 7790\n",
            "Epoch: [131] Total time: 0:00:11 (0.3618 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.4928 (13.8770)  loss_vfl: 0.5096 (0.5397)  loss_bbox: 0.0831 (0.0969)  loss_giou: 0.3883 (0.4123)  loss_vfl_aux_0: 0.5511 (0.5607)  loss_bbox_aux_0: 0.0915 (0.1166)  loss_giou_aux_0: 0.4450 (0.4631)  loss_vfl_aux_1: 0.5039 (0.5470)  loss_bbox_aux_1: 0.0836 (0.1034)  loss_giou_aux_1: 0.3975 (0.4257)  loss_vfl_aux_2: 0.5086 (0.5417)  loss_bbox_aux_2: 0.0811 (0.0995)  loss_giou_aux_2: 0.3832 (0.4178)  loss_vfl_aux_3: 0.5047 (0.5411)  loss_bbox_aux_3: 0.0825 (0.0979)  loss_giou_aux_3: 0.3855 (0.4130)  loss_vfl_aux_4: 0.5089 (0.5400)  loss_bbox_aux_4: 0.0817 (0.0969)  loss_giou_aux_4: 0.3882 (0.4116)  loss_vfl_aux_5: 0.6015 (0.6301)  loss_bbox_aux_5: 0.1472 (0.1548)  loss_giou_aux_5: 0.6066 (0.5856)  loss_vfl_dn_0: 0.4369 (0.4382)  loss_bbox_dn_0: 0.1553 (0.1883)  loss_giou_dn_0: 0.6241 (0.6215)  loss_vfl_dn_1: 0.3989 (0.3982)  loss_bbox_dn_1: 0.1153 (0.1399)  loss_giou_dn_1: 0.4591 (0.4763)  loss_vfl_dn_2: 0.3905 (0.3879)  loss_bbox_dn_2: 0.1057 (0.1302)  loss_giou_dn_2: 0.4377 (0.4489)  loss_vfl_dn_3: 0.3877 (0.3843)  loss_bbox_dn_3: 0.1018 (0.1278)  loss_giou_dn_3: 0.4234 (0.4416)  loss_vfl_dn_4: 0.3843 (0.3827)  loss_bbox_dn_4: 0.1010 (0.1270)  loss_giou_dn_4: 0.4238 (0.4393)  loss_vfl_dn_5: 0.3861 (0.3836)  loss_bbox_dn_5: 0.1012 (0.1268)  loss_giou_dn_5: 0.4248 (0.4390)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8911  data: 0.5787  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3882  data: 0.1148  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4018 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [132]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 10.0065 (10.0065)  loss_vfl: 0.3685 (0.3685)  loss_bbox: 0.0610 (0.0610)  loss_giou: 0.2808 (0.2808)  loss_vfl_aux_0: 0.4260 (0.4260)  loss_bbox_aux_0: 0.0699 (0.0699)  loss_giou_aux_0: 0.3144 (0.3144)  loss_vfl_aux_1: 0.3875 (0.3875)  loss_bbox_aux_1: 0.0646 (0.0646)  loss_giou_aux_1: 0.2933 (0.2933)  loss_vfl_aux_2: 0.3783 (0.3783)  loss_bbox_aux_2: 0.0635 (0.0635)  loss_giou_aux_2: 0.2912 (0.2912)  loss_vfl_aux_3: 0.3717 (0.3717)  loss_bbox_aux_3: 0.0621 (0.0621)  loss_giou_aux_3: 0.2870 (0.2870)  loss_vfl_aux_4: 0.3691 (0.3691)  loss_bbox_aux_4: 0.0614 (0.0614)  loss_giou_aux_4: 0.2832 (0.2832)  loss_vfl_aux_5: 0.4887 (0.4887)  loss_bbox_aux_5: 0.0994 (0.0994)  loss_giou_aux_5: 0.4405 (0.4405)  loss_vfl_dn_0: 0.4297 (0.4297)  loss_bbox_dn_0: 0.1115 (0.1115)  loss_giou_dn_0: 0.4704 (0.4704)  loss_vfl_dn_1: 0.3712 (0.3712)  loss_bbox_dn_1: 0.0690 (0.0690)  loss_giou_dn_1: 0.3073 (0.3073)  loss_vfl_dn_2: 0.3588 (0.3588)  loss_bbox_dn_2: 0.0652 (0.0652)  loss_giou_dn_2: 0.2860 (0.2860)  loss_vfl_dn_3: 0.3540 (0.3540)  loss_bbox_dn_3: 0.0632 (0.0632)  loss_giou_dn_3: 0.2791 (0.2791)  loss_vfl_dn_4: 0.3519 (0.3519)  loss_bbox_dn_4: 0.0625 (0.0625)  loss_giou_dn_4: 0.2771 (0.2771)  loss_vfl_dn_5: 0.3505 (0.3505)  loss_bbox_dn_5: 0.0619 (0.0619)  loss_giou_dn_5: 0.2750 (0.2750)  time: 0.9297  data: 0.5114  max mem: 7790\n",
            "Epoch: [132]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.2522 (13.2387)  loss_vfl: 0.5256 (0.5094)  loss_bbox: 0.0792 (0.0868)  loss_giou: 0.3869 (0.3998)  loss_vfl_aux_0: 0.5478 (0.5333)  loss_bbox_aux_0: 0.0894 (0.1030)  loss_giou_aux_0: 0.4471 (0.4534)  loss_vfl_aux_1: 0.5376 (0.5159)  loss_bbox_aux_1: 0.0839 (0.0917)  loss_giou_aux_1: 0.4080 (0.4163)  loss_vfl_aux_2: 0.5307 (0.5135)  loss_bbox_aux_2: 0.0809 (0.0878)  loss_giou_aux_2: 0.3921 (0.4050)  loss_vfl_aux_3: 0.5286 (0.5130)  loss_bbox_aux_3: 0.0794 (0.0863)  loss_giou_aux_3: 0.3870 (0.4015)  loss_vfl_aux_4: 0.5276 (0.5118)  loss_bbox_aux_4: 0.0766 (0.0861)  loss_giou_aux_4: 0.3836 (0.3987)  loss_vfl_aux_5: 0.5806 (0.5851)  loss_bbox_aux_5: 0.1226 (0.1494)  loss_giou_aux_5: 0.5444 (0.5946)  loss_vfl_dn_0: 0.4401 (0.4406)  loss_bbox_dn_0: 0.1336 (0.1572)  loss_giou_dn_0: 0.5989 (0.6098)  loss_vfl_dn_1: 0.3998 (0.4044)  loss_bbox_dn_1: 0.1041 (0.1095)  loss_giou_dn_1: 0.4140 (0.4522)  loss_vfl_dn_2: 0.3879 (0.3918)  loss_bbox_dn_2: 0.0998 (0.1013)  loss_giou_dn_2: 0.3815 (0.4238)  loss_vfl_dn_3: 0.3853 (0.3864)  loss_bbox_dn_3: 0.0972 (0.0995)  loss_giou_dn_3: 0.3724 (0.4176)  loss_vfl_dn_4: 0.3791 (0.3856)  loss_bbox_dn_4: 0.0948 (0.0991)  loss_giou_dn_4: 0.3694 (0.4163)  loss_vfl_dn_5: 0.3789 (0.3859)  loss_bbox_dn_5: 0.0946 (0.0990)  loss_giou_dn_5: 0.3688 (0.4163)  time: 0.3274  data: 0.0137  max mem: 7790\n",
            "Epoch: [132] Total time: 0:00:11 (0.3492 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.2522 (13.2387)  loss_vfl: 0.5256 (0.5094)  loss_bbox: 0.0792 (0.0868)  loss_giou: 0.3869 (0.3998)  loss_vfl_aux_0: 0.5478 (0.5333)  loss_bbox_aux_0: 0.0894 (0.1030)  loss_giou_aux_0: 0.4471 (0.4534)  loss_vfl_aux_1: 0.5376 (0.5159)  loss_bbox_aux_1: 0.0839 (0.0917)  loss_giou_aux_1: 0.4080 (0.4163)  loss_vfl_aux_2: 0.5307 (0.5135)  loss_bbox_aux_2: 0.0809 (0.0878)  loss_giou_aux_2: 0.3921 (0.4050)  loss_vfl_aux_3: 0.5286 (0.5130)  loss_bbox_aux_3: 0.0794 (0.0863)  loss_giou_aux_3: 0.3870 (0.4015)  loss_vfl_aux_4: 0.5276 (0.5118)  loss_bbox_aux_4: 0.0766 (0.0861)  loss_giou_aux_4: 0.3836 (0.3987)  loss_vfl_aux_5: 0.5806 (0.5851)  loss_bbox_aux_5: 0.1226 (0.1494)  loss_giou_aux_5: 0.5444 (0.5946)  loss_vfl_dn_0: 0.4401 (0.4406)  loss_bbox_dn_0: 0.1336 (0.1572)  loss_giou_dn_0: 0.5989 (0.6098)  loss_vfl_dn_1: 0.3998 (0.4044)  loss_bbox_dn_1: 0.1041 (0.1095)  loss_giou_dn_1: 0.4140 (0.4522)  loss_vfl_dn_2: 0.3879 (0.3918)  loss_bbox_dn_2: 0.0998 (0.1013)  loss_giou_dn_2: 0.3815 (0.4238)  loss_vfl_dn_3: 0.3853 (0.3864)  loss_bbox_dn_3: 0.0972 (0.0995)  loss_giou_dn_3: 0.3724 (0.4176)  loss_vfl_dn_4: 0.3791 (0.3856)  loss_bbox_dn_4: 0.0948 (0.0991)  loss_giou_dn_4: 0.3694 (0.4163)  loss_vfl_dn_5: 0.3789 (0.3859)  loss_bbox_dn_5: 0.0946 (0.0990)  loss_giou_dn_5: 0.3688 (0.4163)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8862  data: 0.5679  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3896  data: 0.1099  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4022 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [133]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 11.5006 (11.5006)  loss_vfl: 0.4748 (0.4748)  loss_bbox: 0.0704 (0.0704)  loss_giou: 0.2972 (0.2972)  loss_vfl_aux_0: 0.5119 (0.5119)  loss_bbox_aux_0: 0.0867 (0.0867)  loss_giou_aux_0: 0.3526 (0.3526)  loss_vfl_aux_1: 0.4590 (0.4590)  loss_bbox_aux_1: 0.0774 (0.0774)  loss_giou_aux_1: 0.3174 (0.3174)  loss_vfl_aux_2: 0.4612 (0.4612)  loss_bbox_aux_2: 0.0737 (0.0737)  loss_giou_aux_2: 0.3077 (0.3077)  loss_vfl_aux_3: 0.4659 (0.4659)  loss_bbox_aux_3: 0.0718 (0.0718)  loss_giou_aux_3: 0.3021 (0.3021)  loss_vfl_aux_4: 0.4684 (0.4684)  loss_bbox_aux_4: 0.0709 (0.0709)  loss_giou_aux_4: 0.2996 (0.2996)  loss_vfl_aux_5: 0.5642 (0.5642)  loss_bbox_aux_5: 0.1253 (0.1253)  loss_giou_aux_5: 0.5085 (0.5085)  loss_vfl_dn_0: 0.4380 (0.4380)  loss_bbox_dn_0: 0.1680 (0.1680)  loss_giou_dn_0: 0.5808 (0.5808)  loss_vfl_dn_1: 0.3873 (0.3873)  loss_bbox_dn_1: 0.1003 (0.1003)  loss_giou_dn_1: 0.3786 (0.3786)  loss_vfl_dn_2: 0.3641 (0.3641)  loss_bbox_dn_2: 0.0917 (0.0917)  loss_giou_dn_2: 0.3396 (0.3396)  loss_vfl_dn_3: 0.3550 (0.3550)  loss_bbox_dn_3: 0.0879 (0.0879)  loss_giou_dn_3: 0.3243 (0.3243)  loss_vfl_dn_4: 0.3525 (0.3525)  loss_bbox_dn_4: 0.0872 (0.0872)  loss_giou_dn_4: 0.3203 (0.3203)  loss_vfl_dn_5: 0.3514 (0.3514)  loss_bbox_dn_5: 0.0872 (0.0872)  loss_giou_dn_5: 0.3199 (0.3199)  time: 1.0452  data: 0.6344  max mem: 7790\n",
            "Epoch: [133]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.5614 (14.1664)  loss_vfl: 0.5125 (0.5318)  loss_bbox: 0.0979 (0.1059)  loss_giou: 0.3822 (0.4420)  loss_vfl_aux_0: 0.5357 (0.5465)  loss_bbox_aux_0: 0.1109 (0.1224)  loss_giou_aux_0: 0.4326 (0.4879)  loss_vfl_aux_1: 0.5241 (0.5342)  loss_bbox_aux_1: 0.1000 (0.1119)  loss_giou_aux_1: 0.3988 (0.4555)  loss_vfl_aux_2: 0.5131 (0.5300)  loss_bbox_aux_2: 0.1103 (0.1093)  loss_giou_aux_2: 0.4014 (0.4486)  loss_vfl_aux_3: 0.5133 (0.5303)  loss_bbox_aux_3: 0.1074 (0.1078)  loss_giou_aux_3: 0.4027 (0.4451)  loss_vfl_aux_4: 0.5180 (0.5239)  loss_bbox_aux_4: 0.0995 (0.1065)  loss_giou_aux_4: 0.3815 (0.4425)  loss_vfl_aux_5: 0.5985 (0.6001)  loss_bbox_aux_5: 0.1427 (0.1734)  loss_giou_aux_5: 0.5838 (0.6366)  loss_vfl_dn_0: 0.4369 (0.4365)  loss_bbox_dn_0: 0.1693 (0.1846)  loss_giou_dn_0: 0.6178 (0.6487)  loss_vfl_dn_1: 0.4068 (0.4011)  loss_bbox_dn_1: 0.1103 (0.1314)  loss_giou_dn_1: 0.4643 (0.4952)  loss_vfl_dn_2: 0.3886 (0.3903)  loss_bbox_dn_2: 0.1077 (0.1219)  loss_giou_dn_2: 0.4273 (0.4680)  loss_vfl_dn_3: 0.3837 (0.3871)  loss_bbox_dn_3: 0.1061 (0.1192)  loss_giou_dn_3: 0.4179 (0.4610)  loss_vfl_dn_4: 0.3809 (0.3859)  loss_bbox_dn_4: 0.1048 (0.1188)  loss_giou_dn_4: 0.4184 (0.4593)  loss_vfl_dn_5: 0.3836 (0.3868)  loss_bbox_dn_5: 0.1054 (0.1187)  loss_giou_dn_5: 0.4154 (0.4595)  time: 0.3196  data: 0.0154  max mem: 7790\n",
            "Epoch: [133] Total time: 0:00:11 (0.3489 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.5614 (14.1664)  loss_vfl: 0.5125 (0.5318)  loss_bbox: 0.0979 (0.1059)  loss_giou: 0.3822 (0.4420)  loss_vfl_aux_0: 0.5357 (0.5465)  loss_bbox_aux_0: 0.1109 (0.1224)  loss_giou_aux_0: 0.4326 (0.4879)  loss_vfl_aux_1: 0.5241 (0.5342)  loss_bbox_aux_1: 0.1000 (0.1119)  loss_giou_aux_1: 0.3988 (0.4555)  loss_vfl_aux_2: 0.5131 (0.5300)  loss_bbox_aux_2: 0.1103 (0.1093)  loss_giou_aux_2: 0.4014 (0.4486)  loss_vfl_aux_3: 0.5133 (0.5303)  loss_bbox_aux_3: 0.1074 (0.1078)  loss_giou_aux_3: 0.4027 (0.4451)  loss_vfl_aux_4: 0.5180 (0.5239)  loss_bbox_aux_4: 0.0995 (0.1065)  loss_giou_aux_4: 0.3815 (0.4425)  loss_vfl_aux_5: 0.5985 (0.6001)  loss_bbox_aux_5: 0.1427 (0.1734)  loss_giou_aux_5: 0.5838 (0.6366)  loss_vfl_dn_0: 0.4369 (0.4365)  loss_bbox_dn_0: 0.1693 (0.1846)  loss_giou_dn_0: 0.6178 (0.6487)  loss_vfl_dn_1: 0.4068 (0.4011)  loss_bbox_dn_1: 0.1103 (0.1314)  loss_giou_dn_1: 0.4643 (0.4952)  loss_vfl_dn_2: 0.3886 (0.3903)  loss_bbox_dn_2: 0.1077 (0.1219)  loss_giou_dn_2: 0.4273 (0.4680)  loss_vfl_dn_3: 0.3837 (0.3871)  loss_bbox_dn_3: 0.1061 (0.1192)  loss_giou_dn_3: 0.4179 (0.4610)  loss_vfl_dn_4: 0.3809 (0.3859)  loss_bbox_dn_4: 0.1048 (0.1188)  loss_giou_dn_4: 0.4184 (0.4593)  loss_vfl_dn_5: 0.3836 (0.3868)  loss_bbox_dn_5: 0.1054 (0.1187)  loss_giou_dn_5: 0.4154 (0.4595)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8992  data: 0.5772  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4548  data: 0.1149  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4693 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.582\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.352\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [134]  [ 0/33]  eta: 0:00:38  lr: 0.000001  loss: 14.2770 (14.2770)  loss_vfl: 0.5989 (0.5989)  loss_bbox: 0.0537 (0.0537)  loss_giou: 0.4720 (0.4720)  loss_vfl_aux_0: 0.6287 (0.6287)  loss_bbox_aux_0: 0.0699 (0.0699)  loss_giou_aux_0: 0.5573 (0.5573)  loss_vfl_aux_1: 0.6110 (0.6110)  loss_bbox_aux_1: 0.0681 (0.0681)  loss_giou_aux_1: 0.5320 (0.5320)  loss_vfl_aux_2: 0.5904 (0.5904)  loss_bbox_aux_2: 0.0677 (0.0677)  loss_giou_aux_2: 0.5153 (0.5153)  loss_vfl_aux_3: 0.6001 (0.6001)  loss_bbox_aux_3: 0.0538 (0.0538)  loss_giou_aux_3: 0.4715 (0.4715)  loss_vfl_aux_4: 0.6004 (0.6004)  loss_bbox_aux_4: 0.0539 (0.0539)  loss_giou_aux_4: 0.4735 (0.4735)  loss_vfl_aux_5: 0.6073 (0.6073)  loss_bbox_aux_5: 0.0878 (0.0878)  loss_giou_aux_5: 0.6711 (0.6711)  loss_vfl_dn_0: 0.4374 (0.4374)  loss_bbox_dn_0: 0.0944 (0.0944)  loss_giou_dn_0: 0.6528 (0.6528)  loss_vfl_dn_1: 0.4018 (0.4018)  loss_bbox_dn_1: 0.0637 (0.0637)  loss_giou_dn_1: 0.5103 (0.5103)  loss_vfl_dn_2: 0.3965 (0.3965)  loss_bbox_dn_2: 0.0591 (0.0591)  loss_giou_dn_2: 0.4856 (0.4856)  loss_vfl_dn_3: 0.3970 (0.3970)  loss_bbox_dn_3: 0.0580 (0.0580)  loss_giou_dn_3: 0.4788 (0.4788)  loss_vfl_dn_4: 0.3960 (0.3960)  loss_bbox_dn_4: 0.0579 (0.0579)  loss_giou_dn_4: 0.4755 (0.4755)  loss_vfl_dn_5: 0.3977 (0.3977)  loss_bbox_dn_5: 0.0573 (0.0573)  loss_giou_dn_5: 0.4729 (0.4729)  time: 1.1800  data: 0.7925  max mem: 7790\n",
            "Epoch: [134]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.8480 (13.8675)  loss_vfl: 0.5277 (0.5497)  loss_bbox: 0.0868 (0.0947)  loss_giou: 0.4321 (0.4079)  loss_vfl_aux_0: 0.5406 (0.5619)  loss_bbox_aux_0: 0.0943 (0.1128)  loss_giou_aux_0: 0.4954 (0.4675)  loss_vfl_aux_1: 0.5332 (0.5473)  loss_bbox_aux_1: 0.0905 (0.0996)  loss_giou_aux_1: 0.4552 (0.4293)  loss_vfl_aux_2: 0.5261 (0.5472)  loss_bbox_aux_2: 0.0847 (0.0950)  loss_giou_aux_2: 0.4414 (0.4150)  loss_vfl_aux_3: 0.5241 (0.5423)  loss_bbox_aux_3: 0.0872 (0.0948)  loss_giou_aux_3: 0.4359 (0.4099)  loss_vfl_aux_4: 0.5227 (0.5435)  loss_bbox_aux_4: 0.0869 (0.0950)  loss_giou_aux_4: 0.4399 (0.4106)  loss_vfl_aux_5: 0.5733 (0.6066)  loss_bbox_aux_5: 0.1297 (0.1540)  loss_giou_aux_5: 0.6001 (0.5914)  loss_vfl_dn_0: 0.4464 (0.4441)  loss_bbox_dn_0: 0.1534 (0.1812)  loss_giou_dn_0: 0.6689 (0.6275)  loss_vfl_dn_1: 0.4217 (0.4086)  loss_bbox_dn_1: 0.1108 (0.1322)  loss_giou_dn_1: 0.4991 (0.4716)  loss_vfl_dn_2: 0.4108 (0.3992)  loss_bbox_dn_2: 0.0981 (0.1231)  loss_giou_dn_2: 0.4677 (0.4449)  loss_vfl_dn_3: 0.4077 (0.3963)  loss_bbox_dn_3: 0.0972 (0.1209)  loss_giou_dn_3: 0.4611 (0.4380)  loss_vfl_dn_4: 0.4058 (0.3948)  loss_bbox_dn_4: 0.0984 (0.1205)  loss_giou_dn_4: 0.4590 (0.4369)  loss_vfl_dn_5: 0.4047 (0.3948)  loss_bbox_dn_5: 0.0987 (0.1203)  loss_giou_dn_5: 0.4584 (0.4368)  time: 0.3290  data: 0.0142  max mem: 7790\n",
            "Epoch: [134] Total time: 0:00:11 (0.3544 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.8480 (13.8675)  loss_vfl: 0.5277 (0.5497)  loss_bbox: 0.0868 (0.0947)  loss_giou: 0.4321 (0.4079)  loss_vfl_aux_0: 0.5406 (0.5619)  loss_bbox_aux_0: 0.0943 (0.1128)  loss_giou_aux_0: 0.4954 (0.4675)  loss_vfl_aux_1: 0.5332 (0.5473)  loss_bbox_aux_1: 0.0905 (0.0996)  loss_giou_aux_1: 0.4552 (0.4293)  loss_vfl_aux_2: 0.5261 (0.5472)  loss_bbox_aux_2: 0.0847 (0.0950)  loss_giou_aux_2: 0.4414 (0.4150)  loss_vfl_aux_3: 0.5241 (0.5423)  loss_bbox_aux_3: 0.0872 (0.0948)  loss_giou_aux_3: 0.4359 (0.4099)  loss_vfl_aux_4: 0.5227 (0.5435)  loss_bbox_aux_4: 0.0869 (0.0950)  loss_giou_aux_4: 0.4399 (0.4106)  loss_vfl_aux_5: 0.5733 (0.6066)  loss_bbox_aux_5: 0.1297 (0.1540)  loss_giou_aux_5: 0.6001 (0.5914)  loss_vfl_dn_0: 0.4464 (0.4441)  loss_bbox_dn_0: 0.1534 (0.1812)  loss_giou_dn_0: 0.6689 (0.6275)  loss_vfl_dn_1: 0.4217 (0.4086)  loss_bbox_dn_1: 0.1108 (0.1322)  loss_giou_dn_1: 0.4991 (0.4716)  loss_vfl_dn_2: 0.4108 (0.3992)  loss_bbox_dn_2: 0.0981 (0.1231)  loss_giou_dn_2: 0.4677 (0.4449)  loss_vfl_dn_3: 0.4077 (0.3963)  loss_bbox_dn_3: 0.0972 (0.1209)  loss_giou_dn_3: 0.4611 (0.4380)  loss_vfl_dn_4: 0.4058 (0.3948)  loss_bbox_dn_4: 0.0984 (0.1205)  loss_giou_dn_4: 0.4590 (0.4369)  loss_vfl_dn_5: 0.4047 (0.3948)  loss_bbox_dn_5: 0.0987 (0.1203)  loss_giou_dn_5: 0.4584 (0.4368)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9113  data: 0.5943  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4421  data: 0.1139  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4572 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.651\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [135]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 13.3929 (13.3929)  loss_vfl: 0.5161 (0.5161)  loss_bbox: 0.0827 (0.0827)  loss_giou: 0.4398 (0.4398)  loss_vfl_aux_0: 0.5604 (0.5604)  loss_bbox_aux_0: 0.0897 (0.0897)  loss_giou_aux_0: 0.4547 (0.4547)  loss_vfl_aux_1: 0.5111 (0.5111)  loss_bbox_aux_1: 0.0803 (0.0803)  loss_giou_aux_1: 0.4367 (0.4367)  loss_vfl_aux_2: 0.5235 (0.5235)  loss_bbox_aux_2: 0.0811 (0.0811)  loss_giou_aux_2: 0.4276 (0.4276)  loss_vfl_aux_3: 0.5324 (0.5324)  loss_bbox_aux_3: 0.0789 (0.0789)  loss_giou_aux_3: 0.4163 (0.4163)  loss_vfl_aux_4: 0.5304 (0.5304)  loss_bbox_aux_4: 0.0796 (0.0796)  loss_giou_aux_4: 0.4230 (0.4230)  loss_vfl_aux_5: 0.5643 (0.5643)  loss_bbox_aux_5: 0.1041 (0.1041)  loss_giou_aux_5: 0.5170 (0.5170)  loss_vfl_dn_0: 0.4541 (0.4541)  loss_bbox_dn_0: 0.1390 (0.1390)  loss_giou_dn_0: 0.6214 (0.6214)  loss_vfl_dn_1: 0.4330 (0.4330)  loss_bbox_dn_1: 0.0954 (0.0954)  loss_giou_dn_1: 0.4638 (0.4638)  loss_vfl_dn_2: 0.4182 (0.4182)  loss_bbox_dn_2: 0.0890 (0.0890)  loss_giou_dn_2: 0.4375 (0.4375)  loss_vfl_dn_3: 0.4145 (0.4145)  loss_bbox_dn_3: 0.0856 (0.0856)  loss_giou_dn_3: 0.4311 (0.4311)  loss_vfl_dn_4: 0.4135 (0.4135)  loss_bbox_dn_4: 0.0854 (0.0854)  loss_giou_dn_4: 0.4292 (0.4292)  loss_vfl_dn_5: 0.4166 (0.4166)  loss_bbox_dn_5: 0.0856 (0.0856)  loss_giou_dn_5: 0.4300 (0.4300)  time: 0.9722  data: 0.6013  max mem: 7790\n",
            "Epoch: [135]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.2214 (13.3163)  loss_vfl: 0.5136 (0.5199)  loss_bbox: 0.1004 (0.1022)  loss_giou: 0.3371 (0.3796)  loss_vfl_aux_0: 0.5368 (0.5421)  loss_bbox_aux_0: 0.1096 (0.1196)  loss_giou_aux_0: 0.3911 (0.4329)  loss_vfl_aux_1: 0.5087 (0.5140)  loss_bbox_aux_1: 0.1063 (0.1097)  loss_giou_aux_1: 0.3643 (0.3965)  loss_vfl_aux_2: 0.5041 (0.5140)  loss_bbox_aux_2: 0.1029 (0.1058)  loss_giou_aux_2: 0.3446 (0.3854)  loss_vfl_aux_3: 0.5124 (0.5201)  loss_bbox_aux_3: 0.0989 (0.1033)  loss_giou_aux_3: 0.3378 (0.3798)  loss_vfl_aux_4: 0.5167 (0.5198)  loss_bbox_aux_4: 0.1002 (0.1015)  loss_giou_aux_4: 0.3376 (0.3794)  loss_vfl_aux_5: 0.6053 (0.6031)  loss_bbox_aux_5: 0.1676 (0.1685)  loss_giou_aux_5: 0.5517 (0.5737)  loss_vfl_dn_0: 0.4451 (0.4426)  loss_bbox_dn_0: 0.1798 (0.1843)  loss_giou_dn_0: 0.5896 (0.5950)  loss_vfl_dn_1: 0.4043 (0.4012)  loss_bbox_dn_1: 0.1216 (0.1342)  loss_giou_dn_1: 0.4173 (0.4392)  loss_vfl_dn_2: 0.3906 (0.3885)  loss_bbox_dn_2: 0.1124 (0.1244)  loss_giou_dn_2: 0.3872 (0.4107)  loss_vfl_dn_3: 0.3878 (0.3847)  loss_bbox_dn_3: 0.1057 (0.1220)  loss_giou_dn_3: 0.3767 (0.4042)  loss_vfl_dn_4: 0.3901 (0.3836)  loss_bbox_dn_4: 0.1067 (0.1215)  loss_giou_dn_4: 0.3735 (0.4024)  loss_vfl_dn_5: 0.3896 (0.3833)  loss_bbox_dn_5: 0.1073 (0.1213)  loss_giou_dn_5: 0.3724 (0.4023)  time: 0.3245  data: 0.0142  max mem: 7790\n",
            "Epoch: [135] Total time: 0:00:11 (0.3473 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.2214 (13.3163)  loss_vfl: 0.5136 (0.5199)  loss_bbox: 0.1004 (0.1022)  loss_giou: 0.3371 (0.3796)  loss_vfl_aux_0: 0.5368 (0.5421)  loss_bbox_aux_0: 0.1096 (0.1196)  loss_giou_aux_0: 0.3911 (0.4329)  loss_vfl_aux_1: 0.5087 (0.5140)  loss_bbox_aux_1: 0.1063 (0.1097)  loss_giou_aux_1: 0.3643 (0.3965)  loss_vfl_aux_2: 0.5041 (0.5140)  loss_bbox_aux_2: 0.1029 (0.1058)  loss_giou_aux_2: 0.3446 (0.3854)  loss_vfl_aux_3: 0.5124 (0.5201)  loss_bbox_aux_3: 0.0989 (0.1033)  loss_giou_aux_3: 0.3378 (0.3798)  loss_vfl_aux_4: 0.5167 (0.5198)  loss_bbox_aux_4: 0.1002 (0.1015)  loss_giou_aux_4: 0.3376 (0.3794)  loss_vfl_aux_5: 0.6053 (0.6031)  loss_bbox_aux_5: 0.1676 (0.1685)  loss_giou_aux_5: 0.5517 (0.5737)  loss_vfl_dn_0: 0.4451 (0.4426)  loss_bbox_dn_0: 0.1798 (0.1843)  loss_giou_dn_0: 0.5896 (0.5950)  loss_vfl_dn_1: 0.4043 (0.4012)  loss_bbox_dn_1: 0.1216 (0.1342)  loss_giou_dn_1: 0.4173 (0.4392)  loss_vfl_dn_2: 0.3906 (0.3885)  loss_bbox_dn_2: 0.1124 (0.1244)  loss_giou_dn_2: 0.3872 (0.4107)  loss_vfl_dn_3: 0.3878 (0.3847)  loss_bbox_dn_3: 0.1057 (0.1220)  loss_giou_dn_3: 0.3767 (0.4042)  loss_vfl_dn_4: 0.3901 (0.3836)  loss_bbox_dn_4: 0.1067 (0.1215)  loss_giou_dn_4: 0.3735 (0.4024)  loss_vfl_dn_5: 0.3896 (0.3833)  loss_bbox_dn_5: 0.1073 (0.1213)  loss_giou_dn_5: 0.3724 (0.4023)\n",
            "Test:  [0/6]  eta: 0:00:04    time: 0.8276  data: 0.5209  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3794  data: 0.1091  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3930 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.659\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            "best_stat:  {'epoch': 108, 'coco_eval_bbox': 0.34567483690279815}\n",
            "Epoch: [136]  [ 0/33]  eta: 0:00:29  lr: 0.000001  loss: 16.4987 (16.4987)  loss_vfl: 0.6292 (0.6292)  loss_bbox: 0.1651 (0.1651)  loss_giou: 0.4797 (0.4797)  loss_vfl_aux_0: 0.6935 (0.6935)  loss_bbox_aux_0: 0.1976 (0.1976)  loss_giou_aux_0: 0.5266 (0.5266)  loss_vfl_aux_1: 0.6063 (0.6063)  loss_bbox_aux_1: 0.1842 (0.1842)  loss_giou_aux_1: 0.5036 (0.5036)  loss_vfl_aux_2: 0.6118 (0.6118)  loss_bbox_aux_2: 0.1631 (0.1631)  loss_giou_aux_2: 0.4779 (0.4779)  loss_vfl_aux_3: 0.6371 (0.6371)  loss_bbox_aux_3: 0.1634 (0.1634)  loss_giou_aux_3: 0.4796 (0.4796)  loss_vfl_aux_4: 0.6337 (0.6337)  loss_bbox_aux_4: 0.1636 (0.1636)  loss_giou_aux_4: 0.4773 (0.4773)  loss_vfl_aux_5: 0.6497 (0.6497)  loss_bbox_aux_5: 0.2467 (0.2467)  loss_giou_aux_5: 0.6772 (0.6772)  loss_vfl_dn_0: 0.4475 (0.4475)  loss_bbox_dn_0: 0.2615 (0.2615)  loss_giou_dn_0: 0.6877 (0.6877)  loss_vfl_dn_1: 0.4183 (0.4183)  loss_bbox_dn_1: 0.2024 (0.2024)  loss_giou_dn_1: 0.5555 (0.5555)  loss_vfl_dn_2: 0.4174 (0.4174)  loss_bbox_dn_2: 0.1925 (0.1925)  loss_giou_dn_2: 0.5350 (0.5350)  loss_vfl_dn_3: 0.4155 (0.4155)  loss_bbox_dn_3: 0.1912 (0.1912)  loss_giou_dn_3: 0.5307 (0.5307)  loss_vfl_dn_4: 0.4140 (0.4140)  loss_bbox_dn_4: 0.1918 (0.1918)  loss_giou_dn_4: 0.5309 (0.5309)  loss_vfl_dn_5: 0.4152 (0.4152)  loss_bbox_dn_5: 0.1929 (0.1929)  loss_giou_dn_5: 0.5317 (0.5317)  time: 0.8857  data: 0.5043  max mem: 7790\n",
            "Epoch: [136]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.3595 (13.5738)  loss_vfl: 0.4928 (0.5158)  loss_bbox: 0.0964 (0.1017)  loss_giou: 0.4013 (0.4052)  loss_vfl_aux_0: 0.5177 (0.5328)  loss_bbox_aux_0: 0.1046 (0.1118)  loss_giou_aux_0: 0.4363 (0.4526)  loss_vfl_aux_1: 0.5006 (0.5201)  loss_bbox_aux_1: 0.0981 (0.1001)  loss_giou_aux_1: 0.4148 (0.4200)  loss_vfl_aux_2: 0.5029 (0.5205)  loss_bbox_aux_2: 0.0948 (0.0970)  loss_giou_aux_2: 0.4026 (0.4094)  loss_vfl_aux_3: 0.5107 (0.5222)  loss_bbox_aux_3: 0.0951 (0.0970)  loss_giou_aux_3: 0.3930 (0.4065)  loss_vfl_aux_4: 0.4896 (0.5170)  loss_bbox_aux_4: 0.0925 (0.0994)  loss_giou_aux_4: 0.3879 (0.4042)  loss_vfl_aux_5: 0.5887 (0.5904)  loss_bbox_aux_5: 0.1498 (0.1674)  loss_giou_aux_5: 0.5995 (0.6075)  loss_vfl_dn_0: 0.4356 (0.4415)  loss_bbox_dn_0: 0.1550 (0.1748)  loss_giou_dn_0: 0.5907 (0.6145)  loss_vfl_dn_1: 0.4023 (0.4022)  loss_bbox_dn_1: 0.1168 (0.1284)  loss_giou_dn_1: 0.4469 (0.4620)  loss_vfl_dn_2: 0.3919 (0.3914)  loss_bbox_dn_2: 0.1080 (0.1203)  loss_giou_dn_2: 0.4196 (0.4358)  loss_vfl_dn_3: 0.3858 (0.3882)  loss_bbox_dn_3: 0.1079 (0.1186)  loss_giou_dn_3: 0.4161 (0.4305)  loss_vfl_dn_4: 0.3834 (0.3865)  loss_bbox_dn_4: 0.1066 (0.1183)  loss_giou_dn_4: 0.4165 (0.4287)  loss_vfl_dn_5: 0.3813 (0.3870)  loss_bbox_dn_5: 0.1067 (0.1182)  loss_giou_dn_5: 0.4151 (0.4285)  time: 0.3406  data: 0.0143  max mem: 7790\n",
            "Epoch: [136] Total time: 0:00:11 (0.3581 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.3595 (13.5738)  loss_vfl: 0.4928 (0.5158)  loss_bbox: 0.0964 (0.1017)  loss_giou: 0.4013 (0.4052)  loss_vfl_aux_0: 0.5177 (0.5328)  loss_bbox_aux_0: 0.1046 (0.1118)  loss_giou_aux_0: 0.4363 (0.4526)  loss_vfl_aux_1: 0.5006 (0.5201)  loss_bbox_aux_1: 0.0981 (0.1001)  loss_giou_aux_1: 0.4148 (0.4200)  loss_vfl_aux_2: 0.5029 (0.5205)  loss_bbox_aux_2: 0.0948 (0.0970)  loss_giou_aux_2: 0.4026 (0.4094)  loss_vfl_aux_3: 0.5107 (0.5222)  loss_bbox_aux_3: 0.0951 (0.0970)  loss_giou_aux_3: 0.3930 (0.4065)  loss_vfl_aux_4: 0.4896 (0.5170)  loss_bbox_aux_4: 0.0925 (0.0994)  loss_giou_aux_4: 0.3879 (0.4042)  loss_vfl_aux_5: 0.5887 (0.5904)  loss_bbox_aux_5: 0.1498 (0.1674)  loss_giou_aux_5: 0.5995 (0.6075)  loss_vfl_dn_0: 0.4356 (0.4415)  loss_bbox_dn_0: 0.1550 (0.1748)  loss_giou_dn_0: 0.5907 (0.6145)  loss_vfl_dn_1: 0.4023 (0.4022)  loss_bbox_dn_1: 0.1168 (0.1284)  loss_giou_dn_1: 0.4469 (0.4620)  loss_vfl_dn_2: 0.3919 (0.3914)  loss_bbox_dn_2: 0.1080 (0.1203)  loss_giou_dn_2: 0.4196 (0.4358)  loss_vfl_dn_3: 0.3858 (0.3882)  loss_bbox_dn_3: 0.1079 (0.1186)  loss_giou_dn_3: 0.4161 (0.4305)  loss_vfl_dn_4: 0.3834 (0.3865)  loss_bbox_dn_4: 0.1066 (0.1183)  loss_giou_dn_4: 0.4165 (0.4287)  loss_vfl_dn_5: 0.3813 (0.3870)  loss_bbox_dn_5: 0.1067 (0.1182)  loss_giou_dn_5: 0.4151 (0.4285)\n",
            "Test:  [0/6]  eta: 0:00:27    time: 4.5009  data: 4.1863  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.9926  data: 0.7186  max mem: 7790\n",
            "Test: Total time: 0:00:06 (1.0072 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.677\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.316\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "best_stat:  {'epoch': 136, 'coco_eval_bbox': 0.35008414337928806}\n",
            "Epoch: [137]  [ 0/33]  eta: 0:00:29  lr: 0.000001  loss: 16.8178 (16.8178)  loss_vfl: 0.5482 (0.5482)  loss_bbox: 0.1353 (0.1353)  loss_giou: 0.5861 (0.5861)  loss_vfl_aux_0: 0.5378 (0.5378)  loss_bbox_aux_0: 0.1704 (0.1704)  loss_giou_aux_0: 0.6667 (0.6667)  loss_vfl_aux_1: 0.5585 (0.5585)  loss_bbox_aux_1: 0.1537 (0.1537)  loss_giou_aux_1: 0.6073 (0.6073)  loss_vfl_aux_2: 0.5839 (0.5839)  loss_bbox_aux_2: 0.1402 (0.1402)  loss_giou_aux_2: 0.5877 (0.5877)  loss_vfl_aux_3: 0.5709 (0.5709)  loss_bbox_aux_3: 0.1371 (0.1371)  loss_giou_aux_3: 0.5921 (0.5921)  loss_vfl_aux_4: 0.5482 (0.5482)  loss_bbox_aux_4: 0.1357 (0.1357)  loss_giou_aux_4: 0.5907 (0.5907)  loss_vfl_aux_5: 0.6449 (0.6449)  loss_bbox_aux_5: 0.1922 (0.1922)  loss_giou_aux_5: 0.7627 (0.7627)  loss_vfl_dn_0: 0.4424 (0.4424)  loss_bbox_dn_0: 0.2295 (0.2295)  loss_giou_dn_0: 0.7512 (0.7512)  loss_vfl_dn_1: 0.4287 (0.4287)  loss_bbox_dn_1: 0.1896 (0.1896)  loss_giou_dn_1: 0.6046 (0.6046)  loss_vfl_dn_2: 0.4150 (0.4150)  loss_bbox_dn_2: 0.1816 (0.1816)  loss_giou_dn_2: 0.5895 (0.5895)  loss_vfl_dn_3: 0.4134 (0.4134)  loss_bbox_dn_3: 0.1814 (0.1814)  loss_giou_dn_3: 0.5866 (0.5866)  loss_vfl_dn_4: 0.4069 (0.4069)  loss_bbox_dn_4: 0.1831 (0.1831)  loss_giou_dn_4: 0.5861 (0.5861)  loss_vfl_dn_5: 0.4084 (0.4084)  loss_bbox_dn_5: 0.1837 (0.1837)  loss_giou_dn_5: 0.5858 (0.5858)  time: 0.8831  data: 0.5173  max mem: 7790\n",
            "Epoch: [137]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.7217 (14.3503)  loss_vfl: 0.5045 (0.5398)  loss_bbox: 0.0971 (0.1056)  loss_giou: 0.4210 (0.4463)  loss_vfl_aux_0: 0.5318 (0.5511)  loss_bbox_aux_0: 0.1041 (0.1213)  loss_giou_aux_0: 0.4519 (0.4969)  loss_vfl_aux_1: 0.5227 (0.5427)  loss_bbox_aux_1: 0.0978 (0.1103)  loss_giou_aux_1: 0.4374 (0.4638)  loss_vfl_aux_2: 0.5208 (0.5395)  loss_bbox_aux_2: 0.0946 (0.1068)  loss_giou_aux_2: 0.4257 (0.4514)  loss_vfl_aux_3: 0.5165 (0.5379)  loss_bbox_aux_3: 0.0962 (0.1059)  loss_giou_aux_3: 0.4244 (0.4464)  loss_vfl_aux_4: 0.5173 (0.5376)  loss_bbox_aux_4: 0.0975 (0.1057)  loss_giou_aux_4: 0.4213 (0.4463)  loss_vfl_aux_5: 0.5904 (0.6077)  loss_bbox_aux_5: 0.1460 (0.1751)  loss_giou_aux_5: 0.6194 (0.6397)  loss_vfl_dn_0: 0.4360 (0.4375)  loss_bbox_dn_0: 0.1563 (0.1788)  loss_giou_dn_0: 0.6376 (0.6584)  loss_vfl_dn_1: 0.4097 (0.4086)  loss_bbox_dn_1: 0.1076 (0.1324)  loss_giou_dn_1: 0.4718 (0.5070)  loss_vfl_dn_2: 0.3961 (0.3983)  loss_bbox_dn_2: 0.0980 (0.1238)  loss_giou_dn_2: 0.4393 (0.4776)  loss_vfl_dn_3: 0.3919 (0.3939)  loss_bbox_dn_3: 0.1004 (0.1221)  loss_giou_dn_3: 0.4301 (0.4699)  loss_vfl_dn_4: 0.3908 (0.3926)  loss_bbox_dn_4: 0.1004 (0.1219)  loss_giou_dn_4: 0.4286 (0.4683)  loss_vfl_dn_5: 0.3877 (0.3923)  loss_bbox_dn_5: 0.1001 (0.1216)  loss_giou_dn_5: 0.4299 (0.4678)  time: 0.3207  data: 0.0139  max mem: 7790\n",
            "Epoch: [137] Total time: 0:00:11 (0.3405 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.7217 (14.3503)  loss_vfl: 0.5045 (0.5398)  loss_bbox: 0.0971 (0.1056)  loss_giou: 0.4210 (0.4463)  loss_vfl_aux_0: 0.5318 (0.5511)  loss_bbox_aux_0: 0.1041 (0.1213)  loss_giou_aux_0: 0.4519 (0.4969)  loss_vfl_aux_1: 0.5227 (0.5427)  loss_bbox_aux_1: 0.0978 (0.1103)  loss_giou_aux_1: 0.4374 (0.4638)  loss_vfl_aux_2: 0.5208 (0.5395)  loss_bbox_aux_2: 0.0946 (0.1068)  loss_giou_aux_2: 0.4257 (0.4514)  loss_vfl_aux_3: 0.5165 (0.5379)  loss_bbox_aux_3: 0.0962 (0.1059)  loss_giou_aux_3: 0.4244 (0.4464)  loss_vfl_aux_4: 0.5173 (0.5376)  loss_bbox_aux_4: 0.0975 (0.1057)  loss_giou_aux_4: 0.4213 (0.4463)  loss_vfl_aux_5: 0.5904 (0.6077)  loss_bbox_aux_5: 0.1460 (0.1751)  loss_giou_aux_5: 0.6194 (0.6397)  loss_vfl_dn_0: 0.4360 (0.4375)  loss_bbox_dn_0: 0.1563 (0.1788)  loss_giou_dn_0: 0.6376 (0.6584)  loss_vfl_dn_1: 0.4097 (0.4086)  loss_bbox_dn_1: 0.1076 (0.1324)  loss_giou_dn_1: 0.4718 (0.5070)  loss_vfl_dn_2: 0.3961 (0.3983)  loss_bbox_dn_2: 0.0980 (0.1238)  loss_giou_dn_2: 0.4393 (0.4776)  loss_vfl_dn_3: 0.3919 (0.3939)  loss_bbox_dn_3: 0.1004 (0.1221)  loss_giou_dn_3: 0.4301 (0.4699)  loss_vfl_dn_4: 0.3908 (0.3926)  loss_bbox_dn_4: 0.1004 (0.1219)  loss_giou_dn_4: 0.4286 (0.4683)  loss_vfl_dn_5: 0.3877 (0.3923)  loss_bbox_dn_5: 0.1001 (0.1216)  loss_giou_dn_5: 0.4299 (0.4678)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8712  data: 0.5500  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3840  data: 0.1109  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3972 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678\n",
            "best_stat:  {'epoch': 136, 'coco_eval_bbox': 0.35008414337928806}\n",
            "Epoch: [138]  [ 0/33]  eta: 0:00:37  lr: 0.000001  loss: 12.1672 (12.1672)  loss_vfl: 0.4748 (0.4748)  loss_bbox: 0.0471 (0.0471)  loss_giou: 0.3776 (0.3776)  loss_vfl_aux_0: 0.5580 (0.5580)  loss_bbox_aux_0: 0.0551 (0.0551)  loss_giou_aux_0: 0.3959 (0.3959)  loss_vfl_aux_1: 0.5034 (0.5034)  loss_bbox_aux_1: 0.0500 (0.0500)  loss_giou_aux_1: 0.3802 (0.3802)  loss_vfl_aux_2: 0.4792 (0.4792)  loss_bbox_aux_2: 0.0484 (0.0484)  loss_giou_aux_2: 0.3735 (0.3735)  loss_vfl_aux_3: 0.4733 (0.4733)  loss_bbox_aux_3: 0.0487 (0.0487)  loss_giou_aux_3: 0.3781 (0.3781)  loss_vfl_aux_4: 0.4746 (0.4746)  loss_bbox_aux_4: 0.0475 (0.0475)  loss_giou_aux_4: 0.3757 (0.3757)  loss_vfl_aux_5: 0.6325 (0.6325)  loss_bbox_aux_5: 0.0960 (0.0960)  loss_giou_aux_5: 0.4855 (0.4855)  loss_vfl_dn_0: 0.4381 (0.4381)  loss_bbox_dn_0: 0.1004 (0.1004)  loss_giou_dn_0: 0.5903 (0.5903)  loss_vfl_dn_1: 0.4005 (0.4005)  loss_bbox_dn_1: 0.0642 (0.0642)  loss_giou_dn_1: 0.4379 (0.4379)  loss_vfl_dn_2: 0.3890 (0.3890)  loss_bbox_dn_2: 0.0561 (0.0561)  loss_giou_dn_2: 0.4100 (0.4100)  loss_vfl_dn_3: 0.3879 (0.3879)  loss_bbox_dn_3: 0.0543 (0.0543)  loss_giou_dn_3: 0.4077 (0.4077)  loss_vfl_dn_4: 0.3780 (0.3780)  loss_bbox_dn_4: 0.0536 (0.0536)  loss_giou_dn_4: 0.4071 (0.4071)  loss_vfl_dn_5: 0.3772 (0.3772)  loss_bbox_dn_5: 0.0534 (0.0534)  loss_giou_dn_5: 0.4064 (0.4064)  time: 1.1354  data: 0.7251  max mem: 7790\n",
            "Epoch: [138]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.3062 (13.5031)  loss_vfl: 0.4994 (0.5039)  loss_bbox: 0.0821 (0.0929)  loss_giou: 0.3842 (0.4117)  loss_vfl_aux_0: 0.5083 (0.5332)  loss_bbox_aux_0: 0.0956 (0.1093)  loss_giou_aux_0: 0.4277 (0.4629)  loss_vfl_aux_1: 0.4819 (0.5108)  loss_bbox_aux_1: 0.0810 (0.0970)  loss_giou_aux_1: 0.3915 (0.4267)  loss_vfl_aux_2: 0.4866 (0.5099)  loss_bbox_aux_2: 0.0789 (0.0935)  loss_giou_aux_2: 0.3935 (0.4159)  loss_vfl_aux_3: 0.4928 (0.5093)  loss_bbox_aux_3: 0.0832 (0.0934)  loss_giou_aux_3: 0.3889 (0.4123)  loss_vfl_aux_4: 0.4936 (0.5019)  loss_bbox_aux_4: 0.0838 (0.0934)  loss_giou_aux_4: 0.3844 (0.4126)  loss_vfl_aux_5: 0.5841 (0.5960)  loss_bbox_aux_5: 0.1343 (0.1544)  loss_giou_aux_5: 0.5604 (0.5800)  loss_vfl_dn_0: 0.4395 (0.4390)  loss_bbox_dn_0: 0.1500 (0.1762)  loss_giou_dn_0: 0.6132 (0.6321)  loss_vfl_dn_1: 0.3975 (0.4019)  loss_bbox_dn_1: 0.1044 (0.1232)  loss_giou_dn_1: 0.4435 (0.4697)  loss_vfl_dn_2: 0.3842 (0.3913)  loss_bbox_dn_2: 0.0979 (0.1139)  loss_giou_dn_2: 0.4125 (0.4409)  loss_vfl_dn_3: 0.3848 (0.3875)  loss_bbox_dn_3: 0.0968 (0.1121)  loss_giou_dn_3: 0.4036 (0.4346)  loss_vfl_dn_4: 0.3810 (0.3862)  loss_bbox_dn_4: 0.0970 (0.1116)  loss_giou_dn_4: 0.4038 (0.4329)  loss_vfl_dn_5: 0.3805 (0.3850)  loss_bbox_dn_5: 0.0964 (0.1113)  loss_giou_dn_5: 0.4036 (0.4327)  time: 0.3347  data: 0.0166  max mem: 7790\n",
            "Epoch: [138] Total time: 0:00:11 (0.3565 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.3062 (13.5031)  loss_vfl: 0.4994 (0.5039)  loss_bbox: 0.0821 (0.0929)  loss_giou: 0.3842 (0.4117)  loss_vfl_aux_0: 0.5083 (0.5332)  loss_bbox_aux_0: 0.0956 (0.1093)  loss_giou_aux_0: 0.4277 (0.4629)  loss_vfl_aux_1: 0.4819 (0.5108)  loss_bbox_aux_1: 0.0810 (0.0970)  loss_giou_aux_1: 0.3915 (0.4267)  loss_vfl_aux_2: 0.4866 (0.5099)  loss_bbox_aux_2: 0.0789 (0.0935)  loss_giou_aux_2: 0.3935 (0.4159)  loss_vfl_aux_3: 0.4928 (0.5093)  loss_bbox_aux_3: 0.0832 (0.0934)  loss_giou_aux_3: 0.3889 (0.4123)  loss_vfl_aux_4: 0.4936 (0.5019)  loss_bbox_aux_4: 0.0838 (0.0934)  loss_giou_aux_4: 0.3844 (0.4126)  loss_vfl_aux_5: 0.5841 (0.5960)  loss_bbox_aux_5: 0.1343 (0.1544)  loss_giou_aux_5: 0.5604 (0.5800)  loss_vfl_dn_0: 0.4395 (0.4390)  loss_bbox_dn_0: 0.1500 (0.1762)  loss_giou_dn_0: 0.6132 (0.6321)  loss_vfl_dn_1: 0.3975 (0.4019)  loss_bbox_dn_1: 0.1044 (0.1232)  loss_giou_dn_1: 0.4435 (0.4697)  loss_vfl_dn_2: 0.3842 (0.3913)  loss_bbox_dn_2: 0.0979 (0.1139)  loss_giou_dn_2: 0.4125 (0.4409)  loss_vfl_dn_3: 0.3848 (0.3875)  loss_bbox_dn_3: 0.0968 (0.1121)  loss_giou_dn_3: 0.4036 (0.4346)  loss_vfl_dn_4: 0.3810 (0.3862)  loss_bbox_dn_4: 0.0970 (0.1116)  loss_giou_dn_4: 0.4038 (0.4329)  loss_vfl_dn_5: 0.3805 (0.3850)  loss_bbox_dn_5: 0.0964 (0.1113)  loss_giou_dn_5: 0.4036 (0.4327)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9780  data: 0.6570  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4064  data: 0.1231  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4217 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.630\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "best_stat:  {'epoch': 136, 'coco_eval_bbox': 0.35008414337928806}\n",
            "Epoch: [139]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 14.0991 (14.0991)  loss_vfl: 0.5818 (0.5818)  loss_bbox: 0.1032 (0.1032)  loss_giou: 0.3981 (0.3981)  loss_vfl_aux_0: 0.5792 (0.5792)  loss_bbox_aux_0: 0.1168 (0.1168)  loss_giou_aux_0: 0.4198 (0.4198)  loss_vfl_aux_1: 0.5776 (0.5776)  loss_bbox_aux_1: 0.1103 (0.1103)  loss_giou_aux_1: 0.4105 (0.4105)  loss_vfl_aux_2: 0.5854 (0.5854)  loss_bbox_aux_2: 0.1053 (0.1053)  loss_giou_aux_2: 0.3990 (0.3990)  loss_vfl_aux_3: 0.5758 (0.5758)  loss_bbox_aux_3: 0.1042 (0.1042)  loss_giou_aux_3: 0.4024 (0.4024)  loss_vfl_aux_4: 0.5843 (0.5843)  loss_bbox_aux_4: 0.1034 (0.1034)  loss_giou_aux_4: 0.3991 (0.3991)  loss_vfl_aux_5: 0.6099 (0.6099)  loss_bbox_aux_5: 0.1437 (0.1437)  loss_giou_aux_5: 0.5368 (0.5368)  loss_vfl_dn_0: 0.4559 (0.4559)  loss_bbox_dn_0: 0.1696 (0.1696)  loss_giou_dn_0: 0.6012 (0.6012)  loss_vfl_dn_1: 0.4417 (0.4417)  loss_bbox_dn_1: 0.1331 (0.1331)  loss_giou_dn_1: 0.4840 (0.4840)  loss_vfl_dn_2: 0.4346 (0.4346)  loss_bbox_dn_2: 0.1237 (0.1237)  loss_giou_dn_2: 0.4471 (0.4471)  loss_vfl_dn_3: 0.4299 (0.4299)  loss_bbox_dn_3: 0.1204 (0.1204)  loss_giou_dn_3: 0.4404 (0.4404)  loss_vfl_dn_4: 0.4303 (0.4303)  loss_bbox_dn_4: 0.1185 (0.1185)  loss_giou_dn_4: 0.4385 (0.4385)  loss_vfl_dn_5: 0.4287 (0.4287)  loss_bbox_dn_5: 0.1178 (0.1178)  loss_giou_dn_5: 0.4370 (0.4370)  time: 1.0321  data: 0.6277  max mem: 7790\n",
            "Epoch: [139]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.6904 (14.0233)  loss_vfl: 0.5279 (0.5188)  loss_bbox: 0.0850 (0.0954)  loss_giou: 0.4453 (0.4402)  loss_vfl_aux_0: 0.5516 (0.5395)  loss_bbox_aux_0: 0.1004 (0.1113)  loss_giou_aux_0: 0.5025 (0.4901)  loss_vfl_aux_1: 0.5348 (0.5307)  loss_bbox_aux_1: 0.0896 (0.0999)  loss_giou_aux_1: 0.4655 (0.4540)  loss_vfl_aux_2: 0.5180 (0.5227)  loss_bbox_aux_2: 0.0904 (0.0985)  loss_giou_aux_2: 0.4599 (0.4463)  loss_vfl_aux_3: 0.5139 (0.5193)  loss_bbox_aux_3: 0.0866 (0.0981)  loss_giou_aux_3: 0.4515 (0.4434)  loss_vfl_aux_4: 0.5187 (0.5141)  loss_bbox_aux_4: 0.0870 (0.0971)  loss_giou_aux_4: 0.4478 (0.4422)  loss_vfl_aux_5: 0.5812 (0.5947)  loss_bbox_aux_5: 0.1567 (0.1552)  loss_giou_aux_5: 0.5968 (0.6096)  loss_vfl_dn_0: 0.4392 (0.4383)  loss_bbox_dn_0: 0.1635 (0.1785)  loss_giou_dn_0: 0.6762 (0.6425)  loss_vfl_dn_1: 0.4074 (0.4051)  loss_bbox_dn_1: 0.1116 (0.1309)  loss_giou_dn_1: 0.5187 (0.4961)  loss_vfl_dn_2: 0.4002 (0.3966)  loss_bbox_dn_2: 0.1022 (0.1219)  loss_giou_dn_2: 0.4848 (0.4706)  loss_vfl_dn_3: 0.3953 (0.3922)  loss_bbox_dn_3: 0.0996 (0.1197)  loss_giou_dn_3: 0.4732 (0.4642)  loss_vfl_dn_4: 0.3942 (0.3920)  loss_bbox_dn_4: 0.0988 (0.1191)  loss_giou_dn_4: 0.4667 (0.4619)  loss_vfl_dn_5: 0.3927 (0.3924)  loss_bbox_dn_5: 0.0985 (0.1188)  loss_giou_dn_5: 0.4648 (0.4614)  time: 0.3231  data: 0.0148  max mem: 7790\n",
            "Epoch: [139] Total time: 0:00:11 (0.3468 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.6904 (14.0233)  loss_vfl: 0.5279 (0.5188)  loss_bbox: 0.0850 (0.0954)  loss_giou: 0.4453 (0.4402)  loss_vfl_aux_0: 0.5516 (0.5395)  loss_bbox_aux_0: 0.1004 (0.1113)  loss_giou_aux_0: 0.5025 (0.4901)  loss_vfl_aux_1: 0.5348 (0.5307)  loss_bbox_aux_1: 0.0896 (0.0999)  loss_giou_aux_1: 0.4655 (0.4540)  loss_vfl_aux_2: 0.5180 (0.5227)  loss_bbox_aux_2: 0.0904 (0.0985)  loss_giou_aux_2: 0.4599 (0.4463)  loss_vfl_aux_3: 0.5139 (0.5193)  loss_bbox_aux_3: 0.0866 (0.0981)  loss_giou_aux_3: 0.4515 (0.4434)  loss_vfl_aux_4: 0.5187 (0.5141)  loss_bbox_aux_4: 0.0870 (0.0971)  loss_giou_aux_4: 0.4478 (0.4422)  loss_vfl_aux_5: 0.5812 (0.5947)  loss_bbox_aux_5: 0.1567 (0.1552)  loss_giou_aux_5: 0.5968 (0.6096)  loss_vfl_dn_0: 0.4392 (0.4383)  loss_bbox_dn_0: 0.1635 (0.1785)  loss_giou_dn_0: 0.6762 (0.6425)  loss_vfl_dn_1: 0.4074 (0.4051)  loss_bbox_dn_1: 0.1116 (0.1309)  loss_giou_dn_1: 0.5187 (0.4961)  loss_vfl_dn_2: 0.4002 (0.3966)  loss_bbox_dn_2: 0.1022 (0.1219)  loss_giou_dn_2: 0.4848 (0.4706)  loss_vfl_dn_3: 0.3953 (0.3922)  loss_bbox_dn_3: 0.0996 (0.1197)  loss_giou_dn_3: 0.4732 (0.4642)  loss_vfl_dn_4: 0.3942 (0.3920)  loss_bbox_dn_4: 0.0988 (0.1191)  loss_giou_dn_4: 0.4667 (0.4619)  loss_vfl_dn_5: 0.3927 (0.3924)  loss_bbox_dn_5: 0.0985 (0.1188)  loss_giou_dn_5: 0.4648 (0.4614)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9268  data: 0.6164  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4402  data: 0.1147  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4544 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            "best_stat:  {'epoch': 136, 'coco_eval_bbox': 0.35008414337928806}\n",
            "Epoch: [140]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 15.3727 (15.3727)  loss_vfl: 0.5126 (0.5126)  loss_bbox: 0.0942 (0.0942)  loss_giou: 0.5502 (0.5502)  loss_vfl_aux_0: 0.5431 (0.5431)  loss_bbox_aux_0: 0.1192 (0.1192)  loss_giou_aux_0: 0.5702 (0.5702)  loss_vfl_aux_1: 0.5533 (0.5533)  loss_bbox_aux_1: 0.1012 (0.1012)  loss_giou_aux_1: 0.5659 (0.5659)  loss_vfl_aux_2: 0.5479 (0.5479)  loss_bbox_aux_2: 0.0954 (0.0954)  loss_giou_aux_2: 0.5597 (0.5597)  loss_vfl_aux_3: 0.5270 (0.5270)  loss_bbox_aux_3: 0.0932 (0.0932)  loss_giou_aux_3: 0.5453 (0.5453)  loss_vfl_aux_4: 0.5080 (0.5080)  loss_bbox_aux_4: 0.0939 (0.0939)  loss_giou_aux_4: 0.5521 (0.5521)  loss_vfl_aux_5: 0.6132 (0.6132)  loss_bbox_aux_5: 0.1673 (0.1673)  loss_giou_aux_5: 0.6412 (0.6412)  loss_vfl_dn_0: 0.4280 (0.4280)  loss_bbox_dn_0: 0.1762 (0.1762)  loss_giou_dn_0: 0.7208 (0.7208)  loss_vfl_dn_1: 0.4106 (0.4106)  loss_bbox_dn_1: 0.1262 (0.1262)  loss_giou_dn_1: 0.6088 (0.6088)  loss_vfl_dn_2: 0.3955 (0.3955)  loss_bbox_dn_2: 0.1169 (0.1169)  loss_giou_dn_2: 0.5862 (0.5862)  loss_vfl_dn_3: 0.3927 (0.3927)  loss_bbox_dn_3: 0.1117 (0.1117)  loss_giou_dn_3: 0.5790 (0.5790)  loss_vfl_dn_4: 0.3878 (0.3878)  loss_bbox_dn_4: 0.1102 (0.1102)  loss_giou_dn_4: 0.5850 (0.5850)  loss_vfl_dn_5: 0.3895 (0.3895)  loss_bbox_dn_5: 0.1098 (0.1098)  loss_giou_dn_5: 0.5840 (0.5840)  time: 1.0470  data: 0.6766  max mem: 7790\n",
            "Epoch: [140]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.9020 (13.3078)  loss_vfl: 0.5077 (0.5077)  loss_bbox: 0.0914 (0.1063)  loss_giou: 0.3796 (0.3848)  loss_vfl_aux_0: 0.5491 (0.5324)  loss_bbox_aux_0: 0.1043 (0.1211)  loss_giou_aux_0: 0.4138 (0.4304)  loss_vfl_aux_1: 0.5343 (0.5182)  loss_bbox_aux_1: 0.0963 (0.1079)  loss_giou_aux_1: 0.3863 (0.3954)  loss_vfl_aux_2: 0.5314 (0.5130)  loss_bbox_aux_2: 0.0950 (0.1067)  loss_giou_aux_2: 0.3824 (0.3876)  loss_vfl_aux_3: 0.5195 (0.5146)  loss_bbox_aux_3: 0.0917 (0.1046)  loss_giou_aux_3: 0.3794 (0.3828)  loss_vfl_aux_4: 0.5226 (0.5092)  loss_bbox_aux_4: 0.1009 (0.1064)  loss_giou_aux_4: 0.3788 (0.3827)  loss_vfl_aux_5: 0.5899 (0.5844)  loss_bbox_aux_5: 0.1588 (0.1796)  loss_giou_aux_5: 0.5533 (0.5885)  loss_vfl_dn_0: 0.4436 (0.4422)  loss_bbox_dn_0: 0.1706 (0.1861)  loss_giou_dn_0: 0.5794 (0.5873)  loss_vfl_dn_1: 0.3977 (0.4017)  loss_bbox_dn_1: 0.1235 (0.1352)  loss_giou_dn_1: 0.4297 (0.4380)  loss_vfl_dn_2: 0.3821 (0.3895)  loss_bbox_dn_2: 0.1165 (0.1254)  loss_giou_dn_2: 0.4005 (0.4094)  loss_vfl_dn_3: 0.3816 (0.3859)  loss_bbox_dn_3: 0.1158 (0.1234)  loss_giou_dn_3: 0.3939 (0.4028)  loss_vfl_dn_4: 0.3828 (0.3842)  loss_bbox_dn_4: 0.1155 (0.1229)  loss_giou_dn_4: 0.3906 (0.4014)  loss_vfl_dn_5: 0.3809 (0.3839)  loss_bbox_dn_5: 0.1153 (0.1226)  loss_giou_dn_5: 0.3911 (0.4017)  time: 0.3294  data: 0.0145  max mem: 7790\n",
            "Epoch: [140] Total time: 0:00:11 (0.3528 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.9020 (13.3078)  loss_vfl: 0.5077 (0.5077)  loss_bbox: 0.0914 (0.1063)  loss_giou: 0.3796 (0.3848)  loss_vfl_aux_0: 0.5491 (0.5324)  loss_bbox_aux_0: 0.1043 (0.1211)  loss_giou_aux_0: 0.4138 (0.4304)  loss_vfl_aux_1: 0.5343 (0.5182)  loss_bbox_aux_1: 0.0963 (0.1079)  loss_giou_aux_1: 0.3863 (0.3954)  loss_vfl_aux_2: 0.5314 (0.5130)  loss_bbox_aux_2: 0.0950 (0.1067)  loss_giou_aux_2: 0.3824 (0.3876)  loss_vfl_aux_3: 0.5195 (0.5146)  loss_bbox_aux_3: 0.0917 (0.1046)  loss_giou_aux_3: 0.3794 (0.3828)  loss_vfl_aux_4: 0.5226 (0.5092)  loss_bbox_aux_4: 0.1009 (0.1064)  loss_giou_aux_4: 0.3788 (0.3827)  loss_vfl_aux_5: 0.5899 (0.5844)  loss_bbox_aux_5: 0.1588 (0.1796)  loss_giou_aux_5: 0.5533 (0.5885)  loss_vfl_dn_0: 0.4436 (0.4422)  loss_bbox_dn_0: 0.1706 (0.1861)  loss_giou_dn_0: 0.5794 (0.5873)  loss_vfl_dn_1: 0.3977 (0.4017)  loss_bbox_dn_1: 0.1235 (0.1352)  loss_giou_dn_1: 0.4297 (0.4380)  loss_vfl_dn_2: 0.3821 (0.3895)  loss_bbox_dn_2: 0.1165 (0.1254)  loss_giou_dn_2: 0.4005 (0.4094)  loss_vfl_dn_3: 0.3816 (0.3859)  loss_bbox_dn_3: 0.1158 (0.1234)  loss_giou_dn_3: 0.3939 (0.4028)  loss_vfl_dn_4: 0.3828 (0.3842)  loss_bbox_dn_4: 0.1155 (0.1229)  loss_giou_dn_4: 0.3906 (0.4014)  loss_vfl_dn_5: 0.3809 (0.3839)  loss_bbox_dn_5: 0.1153 (0.1226)  loss_giou_dn_5: 0.3911 (0.4017)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8952  data: 0.5824  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4409  data: 0.1121  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4555 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.653\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 136, 'coco_eval_bbox': 0.35008414337928806}\n",
            "Epoch: [141]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 14.7629 (14.7629)  loss_vfl: 0.4740 (0.4740)  loss_bbox: 0.1967 (0.1967)  loss_giou: 0.4408 (0.4408)  loss_vfl_aux_0: 0.5952 (0.5952)  loss_bbox_aux_0: 0.1941 (0.1941)  loss_giou_aux_0: 0.4354 (0.4354)  loss_vfl_aux_1: 0.5778 (0.5778)  loss_bbox_aux_1: 0.1772 (0.1772)  loss_giou_aux_1: 0.4114 (0.4114)  loss_vfl_aux_2: 0.5183 (0.5183)  loss_bbox_aux_2: 0.1982 (0.1982)  loss_giou_aux_2: 0.4447 (0.4447)  loss_vfl_aux_3: 0.4933 (0.4933)  loss_bbox_aux_3: 0.1953 (0.1953)  loss_giou_aux_3: 0.4359 (0.4359)  loss_vfl_aux_4: 0.4771 (0.4771)  loss_bbox_aux_4: 0.1967 (0.1967)  loss_giou_aux_4: 0.4398 (0.4398)  loss_vfl_aux_5: 0.6585 (0.6585)  loss_bbox_aux_5: 0.2569 (0.2569)  loss_giou_aux_5: 0.6343 (0.6343)  loss_vfl_dn_0: 0.4307 (0.4307)  loss_bbox_dn_0: 0.2790 (0.2790)  loss_giou_dn_0: 0.6344 (0.6344)  loss_vfl_dn_1: 0.3989 (0.3989)  loss_bbox_dn_1: 0.2025 (0.2025)  loss_giou_dn_1: 0.4628 (0.4628)  loss_vfl_dn_2: 0.3820 (0.3820)  loss_bbox_dn_2: 0.1882 (0.1882)  loss_giou_dn_2: 0.4330 (0.4330)  loss_vfl_dn_3: 0.3738 (0.3738)  loss_bbox_dn_3: 0.1795 (0.1795)  loss_giou_dn_3: 0.4194 (0.4194)  loss_vfl_dn_4: 0.3677 (0.3677)  loss_bbox_dn_4: 0.1791 (0.1791)  loss_giou_dn_4: 0.4159 (0.4159)  loss_vfl_dn_5: 0.3701 (0.3701)  loss_bbox_dn_5: 0.1783 (0.1783)  loss_giou_dn_5: 0.4161 (0.4161)  time: 0.9363  data: 0.5184  max mem: 7790\n",
            "Epoch: [141]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.8042 (12.8097)  loss_vfl: 0.4662 (0.4984)  loss_bbox: 0.0882 (0.0941)  loss_giou: 0.3369 (0.3657)  loss_vfl_aux_0: 0.4971 (0.5161)  loss_bbox_aux_0: 0.1005 (0.1125)  loss_giou_aux_0: 0.3939 (0.4167)  loss_vfl_aux_1: 0.4856 (0.5099)  loss_bbox_aux_1: 0.0929 (0.0996)  loss_giou_aux_1: 0.3509 (0.3792)  loss_vfl_aux_2: 0.4825 (0.5045)  loss_bbox_aux_2: 0.0923 (0.0954)  loss_giou_aux_2: 0.3420 (0.3694)  loss_vfl_aux_3: 0.4705 (0.5006)  loss_bbox_aux_3: 0.0909 (0.0944)  loss_giou_aux_3: 0.3448 (0.3672)  loss_vfl_aux_4: 0.4650 (0.4983)  loss_bbox_aux_4: 0.0886 (0.0939)  loss_giou_aux_4: 0.3514 (0.3662)  loss_vfl_aux_5: 0.5711 (0.5893)  loss_bbox_aux_5: 0.1244 (0.1681)  loss_giou_aux_5: 0.5395 (0.5709)  loss_vfl_dn_0: 0.4340 (0.4363)  loss_bbox_dn_0: 0.1340 (0.1714)  loss_giou_dn_0: 0.5558 (0.5819)  loss_vfl_dn_1: 0.3844 (0.3930)  loss_bbox_dn_1: 0.0951 (0.1188)  loss_giou_dn_1: 0.3840 (0.4228)  loss_vfl_dn_2: 0.3730 (0.3795)  loss_bbox_dn_2: 0.0895 (0.1080)  loss_giou_dn_2: 0.3536 (0.3934)  loss_vfl_dn_3: 0.3715 (0.3756)  loss_bbox_dn_3: 0.0884 (0.1051)  loss_giou_dn_3: 0.3384 (0.3863)  loss_vfl_dn_4: 0.3706 (0.3746)  loss_bbox_dn_4: 0.0911 (0.1045)  loss_giou_dn_4: 0.3380 (0.3847)  loss_vfl_dn_5: 0.3685 (0.3748)  loss_bbox_dn_5: 0.0914 (0.1043)  loss_giou_dn_5: 0.3365 (0.3843)  time: 0.3308  data: 0.0153  max mem: 7790\n",
            "Epoch: [141] Total time: 0:00:11 (0.3496 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.8042 (12.8097)  loss_vfl: 0.4662 (0.4984)  loss_bbox: 0.0882 (0.0941)  loss_giou: 0.3369 (0.3657)  loss_vfl_aux_0: 0.4971 (0.5161)  loss_bbox_aux_0: 0.1005 (0.1125)  loss_giou_aux_0: 0.3939 (0.4167)  loss_vfl_aux_1: 0.4856 (0.5099)  loss_bbox_aux_1: 0.0929 (0.0996)  loss_giou_aux_1: 0.3509 (0.3792)  loss_vfl_aux_2: 0.4825 (0.5045)  loss_bbox_aux_2: 0.0923 (0.0954)  loss_giou_aux_2: 0.3420 (0.3694)  loss_vfl_aux_3: 0.4705 (0.5006)  loss_bbox_aux_3: 0.0909 (0.0944)  loss_giou_aux_3: 0.3448 (0.3672)  loss_vfl_aux_4: 0.4650 (0.4983)  loss_bbox_aux_4: 0.0886 (0.0939)  loss_giou_aux_4: 0.3514 (0.3662)  loss_vfl_aux_5: 0.5711 (0.5893)  loss_bbox_aux_5: 0.1244 (0.1681)  loss_giou_aux_5: 0.5395 (0.5709)  loss_vfl_dn_0: 0.4340 (0.4363)  loss_bbox_dn_0: 0.1340 (0.1714)  loss_giou_dn_0: 0.5558 (0.5819)  loss_vfl_dn_1: 0.3844 (0.3930)  loss_bbox_dn_1: 0.0951 (0.1188)  loss_giou_dn_1: 0.3840 (0.4228)  loss_vfl_dn_2: 0.3730 (0.3795)  loss_bbox_dn_2: 0.0895 (0.1080)  loss_giou_dn_2: 0.3536 (0.3934)  loss_vfl_dn_3: 0.3715 (0.3756)  loss_bbox_dn_3: 0.0884 (0.1051)  loss_giou_dn_3: 0.3384 (0.3863)  loss_vfl_dn_4: 0.3706 (0.3746)  loss_bbox_dn_4: 0.0911 (0.1045)  loss_giou_dn_4: 0.3380 (0.3847)  loss_vfl_dn_5: 0.3685 (0.3748)  loss_bbox_dn_5: 0.0914 (0.1043)  loss_giou_dn_5: 0.3365 (0.3843)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8911  data: 0.5705  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.8352  data: 0.5555  max mem: 7790\n",
            "Test: Total time: 0:00:05 (0.8478 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.298\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "best_stat:  {'epoch': 136, 'coco_eval_bbox': 0.35008414337928806}\n",
            "Epoch: [142]  [ 0/33]  eta: 0:00:36  lr: 0.000001  loss: 13.5056 (13.5056)  loss_vfl: 0.4591 (0.4591)  loss_bbox: 0.0963 (0.0963)  loss_giou: 0.4769 (0.4769)  loss_vfl_aux_0: 0.5152 (0.5152)  loss_bbox_aux_0: 0.1017 (0.1017)  loss_giou_aux_0: 0.5034 (0.5034)  loss_vfl_aux_1: 0.4711 (0.4711)  loss_bbox_aux_1: 0.1014 (0.1014)  loss_giou_aux_1: 0.5041 (0.5041)  loss_vfl_aux_2: 0.4617 (0.4617)  loss_bbox_aux_2: 0.0992 (0.0992)  loss_giou_aux_2: 0.4905 (0.4905)  loss_vfl_aux_3: 0.4499 (0.4499)  loss_bbox_aux_3: 0.0974 (0.0974)  loss_giou_aux_3: 0.4914 (0.4914)  loss_vfl_aux_4: 0.4525 (0.4525)  loss_bbox_aux_4: 0.0966 (0.0966)  loss_giou_aux_4: 0.4799 (0.4799)  loss_vfl_aux_5: 0.5176 (0.5176)  loss_bbox_aux_5: 0.1267 (0.1267)  loss_giou_aux_5: 0.6110 (0.6110)  loss_vfl_dn_0: 0.4363 (0.4363)  loss_bbox_dn_0: 0.1140 (0.1140)  loss_giou_dn_0: 0.6098 (0.6098)  loss_vfl_dn_1: 0.4039 (0.4039)  loss_bbox_dn_1: 0.0857 (0.0857)  loss_giou_dn_1: 0.4742 (0.4742)  loss_vfl_dn_2: 0.3965 (0.3965)  loss_bbox_dn_2: 0.0859 (0.0859)  loss_giou_dn_2: 0.4696 (0.4696)  loss_vfl_dn_3: 0.3930 (0.3930)  loss_bbox_dn_3: 0.0856 (0.0856)  loss_giou_dn_3: 0.4639 (0.4639)  loss_vfl_dn_4: 0.3918 (0.3918)  loss_bbox_dn_4: 0.0856 (0.0856)  loss_giou_dn_4: 0.4654 (0.4654)  loss_vfl_dn_5: 0.3925 (0.3925)  loss_bbox_dn_5: 0.0854 (0.0854)  loss_giou_dn_5: 0.4631 (0.4631)  time: 1.1093  data: 0.7354  max mem: 7790\n",
            "Epoch: [142]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 14.1442 (13.8930)  loss_vfl: 0.5293 (0.5196)  loss_bbox: 0.0961 (0.1002)  loss_giou: 0.4437 (0.4217)  loss_vfl_aux_0: 0.5314 (0.5457)  loss_bbox_aux_0: 0.1123 (0.1172)  loss_giou_aux_0: 0.5083 (0.4642)  loss_vfl_aux_1: 0.5349 (0.5330)  loss_bbox_aux_1: 0.1014 (0.1049)  loss_giou_aux_1: 0.4504 (0.4346)  loss_vfl_aux_2: 0.5328 (0.5281)  loss_bbox_aux_2: 0.0973 (0.1022)  loss_giou_aux_2: 0.4422 (0.4251)  loss_vfl_aux_3: 0.5330 (0.5240)  loss_bbox_aux_3: 0.0960 (0.0997)  loss_giou_aux_3: 0.4432 (0.4230)  loss_vfl_aux_4: 0.5352 (0.5172)  loss_bbox_aux_4: 0.0967 (0.1015)  loss_giou_aux_4: 0.4415 (0.4237)  loss_vfl_aux_5: 0.6066 (0.6072)  loss_bbox_aux_5: 0.1593 (0.1643)  loss_giou_aux_5: 0.6229 (0.6016)  loss_vfl_dn_0: 0.4412 (0.4417)  loss_bbox_dn_0: 0.1856 (0.1872)  loss_giou_dn_0: 0.6241 (0.6223)  loss_vfl_dn_1: 0.4062 (0.4046)  loss_bbox_dn_1: 0.1383 (0.1402)  loss_giou_dn_1: 0.4774 (0.4769)  loss_vfl_dn_2: 0.3951 (0.3946)  loss_bbox_dn_2: 0.1110 (0.1313)  loss_giou_dn_2: 0.4622 (0.4508)  loss_vfl_dn_3: 0.3981 (0.3916)  loss_bbox_dn_3: 0.1020 (0.1288)  loss_giou_dn_3: 0.4506 (0.4438)  loss_vfl_dn_4: 0.3952 (0.3899)  loss_bbox_dn_4: 0.1013 (0.1284)  loss_giou_dn_4: 0.4492 (0.4419)  loss_vfl_dn_5: 0.3944 (0.3898)  loss_bbox_dn_5: 0.1010 (0.1283)  loss_giou_dn_5: 0.4501 (0.4419)  time: 0.3268  data: 0.0151  max mem: 7790\n",
            "Epoch: [142] Total time: 0:00:12 (0.3671 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 14.1442 (13.8930)  loss_vfl: 0.5293 (0.5196)  loss_bbox: 0.0961 (0.1002)  loss_giou: 0.4437 (0.4217)  loss_vfl_aux_0: 0.5314 (0.5457)  loss_bbox_aux_0: 0.1123 (0.1172)  loss_giou_aux_0: 0.5083 (0.4642)  loss_vfl_aux_1: 0.5349 (0.5330)  loss_bbox_aux_1: 0.1014 (0.1049)  loss_giou_aux_1: 0.4504 (0.4346)  loss_vfl_aux_2: 0.5328 (0.5281)  loss_bbox_aux_2: 0.0973 (0.1022)  loss_giou_aux_2: 0.4422 (0.4251)  loss_vfl_aux_3: 0.5330 (0.5240)  loss_bbox_aux_3: 0.0960 (0.0997)  loss_giou_aux_3: 0.4432 (0.4230)  loss_vfl_aux_4: 0.5352 (0.5172)  loss_bbox_aux_4: 0.0967 (0.1015)  loss_giou_aux_4: 0.4415 (0.4237)  loss_vfl_aux_5: 0.6066 (0.6072)  loss_bbox_aux_5: 0.1593 (0.1643)  loss_giou_aux_5: 0.6229 (0.6016)  loss_vfl_dn_0: 0.4412 (0.4417)  loss_bbox_dn_0: 0.1856 (0.1872)  loss_giou_dn_0: 0.6241 (0.6223)  loss_vfl_dn_1: 0.4062 (0.4046)  loss_bbox_dn_1: 0.1383 (0.1402)  loss_giou_dn_1: 0.4774 (0.4769)  loss_vfl_dn_2: 0.3951 (0.3946)  loss_bbox_dn_2: 0.1110 (0.1313)  loss_giou_dn_2: 0.4622 (0.4508)  loss_vfl_dn_3: 0.3981 (0.3916)  loss_bbox_dn_3: 0.1020 (0.1288)  loss_giou_dn_3: 0.4506 (0.4438)  loss_vfl_dn_4: 0.3952 (0.3899)  loss_bbox_dn_4: 0.1013 (0.1284)  loss_giou_dn_4: 0.4492 (0.4419)  loss_vfl_dn_5: 0.3944 (0.3898)  loss_bbox_dn_5: 0.1010 (0.1283)  loss_giou_dn_5: 0.4501 (0.4419)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8951  data: 0.5835  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3825  data: 0.1118  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3956 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "best_stat:  {'epoch': 136, 'coco_eval_bbox': 0.35008414337928806}\n",
            "Epoch: [143]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 11.7072 (11.7072)  loss_vfl: 0.4586 (0.4586)  loss_bbox: 0.0832 (0.0832)  loss_giou: 0.2652 (0.2652)  loss_vfl_aux_0: 0.4691 (0.4691)  loss_bbox_aux_0: 0.1416 (0.1416)  loss_giou_aux_0: 0.3898 (0.3898)  loss_vfl_aux_1: 0.4773 (0.4773)  loss_bbox_aux_1: 0.0971 (0.0971)  loss_giou_aux_1: 0.3016 (0.3016)  loss_vfl_aux_2: 0.4642 (0.4642)  loss_bbox_aux_2: 0.0894 (0.0894)  loss_giou_aux_2: 0.2787 (0.2787)  loss_vfl_aux_3: 0.4794 (0.4794)  loss_bbox_aux_3: 0.0837 (0.0837)  loss_giou_aux_3: 0.2661 (0.2661)  loss_vfl_aux_4: 0.4680 (0.4680)  loss_bbox_aux_4: 0.0831 (0.0831)  loss_giou_aux_4: 0.2654 (0.2654)  loss_vfl_aux_5: 0.5720 (0.5720)  loss_bbox_aux_5: 0.1905 (0.1905)  loss_giou_aux_5: 0.5399 (0.5399)  loss_vfl_dn_0: 0.4408 (0.4408)  loss_bbox_dn_0: 0.1857 (0.1857)  loss_giou_dn_0: 0.5839 (0.5839)  loss_vfl_dn_1: 0.3888 (0.3888)  loss_bbox_dn_1: 0.1183 (0.1183)  loss_giou_dn_1: 0.3672 (0.3672)  loss_vfl_dn_2: 0.3733 (0.3733)  loss_bbox_dn_2: 0.1037 (0.1037)  loss_giou_dn_2: 0.3275 (0.3275)  loss_vfl_dn_3: 0.3699 (0.3699)  loss_bbox_dn_3: 0.0993 (0.0993)  loss_giou_dn_3: 0.3193 (0.3193)  loss_vfl_dn_4: 0.3691 (0.3691)  loss_bbox_dn_4: 0.0991 (0.0991)  loss_giou_dn_4: 0.3159 (0.3159)  loss_vfl_dn_5: 0.3691 (0.3691)  loss_bbox_dn_5: 0.0982 (0.0982)  loss_giou_dn_5: 0.3143 (0.3143)  time: 0.9774  data: 0.5350  max mem: 7790\n",
            "Epoch: [143]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.3774 (13.2990)  loss_vfl: 0.4763 (0.5022)  loss_bbox: 0.0757 (0.0905)  loss_giou: 0.3704 (0.4115)  loss_vfl_aux_0: 0.5008 (0.5243)  loss_bbox_aux_0: 0.0849 (0.1069)  loss_giou_aux_0: 0.4171 (0.4529)  loss_vfl_aux_1: 0.4927 (0.5133)  loss_bbox_aux_1: 0.0804 (0.0938)  loss_giou_aux_1: 0.3775 (0.4204)  loss_vfl_aux_2: 0.4864 (0.5100)  loss_bbox_aux_2: 0.0753 (0.0917)  loss_giou_aux_2: 0.3750 (0.4134)  loss_vfl_aux_3: 0.4760 (0.5048)  loss_bbox_aux_3: 0.0762 (0.0900)  loss_giou_aux_3: 0.3720 (0.4120)  loss_vfl_aux_4: 0.4840 (0.5017)  loss_bbox_aux_4: 0.0754 (0.0899)  loss_giou_aux_4: 0.3704 (0.4102)  loss_vfl_aux_5: 0.5764 (0.6092)  loss_bbox_aux_5: 0.1283 (0.1504)  loss_giou_aux_5: 0.5765 (0.5878)  loss_vfl_dn_0: 0.4311 (0.4332)  loss_bbox_dn_0: 0.1341 (0.1637)  loss_giou_dn_0: 0.5617 (0.6055)  loss_vfl_dn_1: 0.3880 (0.3947)  loss_bbox_dn_1: 0.0931 (0.1150)  loss_giou_dn_1: 0.3935 (0.4555)  loss_vfl_dn_2: 0.3733 (0.3835)  loss_bbox_dn_2: 0.0833 (0.1072)  loss_giou_dn_2: 0.3670 (0.4308)  loss_vfl_dn_3: 0.3715 (0.3803)  loss_bbox_dn_3: 0.0828 (0.1046)  loss_giou_dn_3: 0.3639 (0.4243)  loss_vfl_dn_4: 0.3734 (0.3788)  loss_bbox_dn_4: 0.0830 (0.1044)  loss_giou_dn_4: 0.3622 (0.4237)  loss_vfl_dn_5: 0.3716 (0.3791)  loss_bbox_dn_5: 0.0831 (0.1041)  loss_giou_dn_5: 0.3629 (0.4237)  time: 0.3405  data: 0.0144  max mem: 7790\n",
            "Epoch: [143] Total time: 0:00:11 (0.3570 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.3774 (13.2990)  loss_vfl: 0.4763 (0.5022)  loss_bbox: 0.0757 (0.0905)  loss_giou: 0.3704 (0.4115)  loss_vfl_aux_0: 0.5008 (0.5243)  loss_bbox_aux_0: 0.0849 (0.1069)  loss_giou_aux_0: 0.4171 (0.4529)  loss_vfl_aux_1: 0.4927 (0.5133)  loss_bbox_aux_1: 0.0804 (0.0938)  loss_giou_aux_1: 0.3775 (0.4204)  loss_vfl_aux_2: 0.4864 (0.5100)  loss_bbox_aux_2: 0.0753 (0.0917)  loss_giou_aux_2: 0.3750 (0.4134)  loss_vfl_aux_3: 0.4760 (0.5048)  loss_bbox_aux_3: 0.0762 (0.0900)  loss_giou_aux_3: 0.3720 (0.4120)  loss_vfl_aux_4: 0.4840 (0.5017)  loss_bbox_aux_4: 0.0754 (0.0899)  loss_giou_aux_4: 0.3704 (0.4102)  loss_vfl_aux_5: 0.5764 (0.6092)  loss_bbox_aux_5: 0.1283 (0.1504)  loss_giou_aux_5: 0.5765 (0.5878)  loss_vfl_dn_0: 0.4311 (0.4332)  loss_bbox_dn_0: 0.1341 (0.1637)  loss_giou_dn_0: 0.5617 (0.6055)  loss_vfl_dn_1: 0.3880 (0.3947)  loss_bbox_dn_1: 0.0931 (0.1150)  loss_giou_dn_1: 0.3935 (0.4555)  loss_vfl_dn_2: 0.3733 (0.3835)  loss_bbox_dn_2: 0.0833 (0.1072)  loss_giou_dn_2: 0.3670 (0.4308)  loss_vfl_dn_3: 0.3715 (0.3803)  loss_bbox_dn_3: 0.0828 (0.1046)  loss_giou_dn_3: 0.3639 (0.4243)  loss_vfl_dn_4: 0.3734 (0.3788)  loss_bbox_dn_4: 0.0830 (0.1044)  loss_giou_dn_4: 0.3622 (0.4237)  loss_vfl_dn_5: 0.3716 (0.3791)  loss_bbox_dn_5: 0.0831 (0.1041)  loss_giou_dn_5: 0.3629 (0.4237)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9244  data: 0.6154  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3864  data: 0.1145  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3998 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.657\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n",
            "best_stat:  {'epoch': 136, 'coco_eval_bbox': 0.35008414337928806}\n",
            "Epoch: [144]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 12.6568 (12.6568)  loss_vfl: 0.4589 (0.4589)  loss_bbox: 0.0669 (0.0669)  loss_giou: 0.4068 (0.4068)  loss_vfl_aux_0: 0.4800 (0.4800)  loss_bbox_aux_0: 0.0716 (0.0716)  loss_giou_aux_0: 0.4199 (0.4199)  loss_vfl_aux_1: 0.4528 (0.4528)  loss_bbox_aux_1: 0.0674 (0.0674)  loss_giou_aux_1: 0.4040 (0.4040)  loss_vfl_aux_2: 0.4463 (0.4463)  loss_bbox_aux_2: 0.0689 (0.0689)  loss_giou_aux_2: 0.4061 (0.4061)  loss_vfl_aux_3: 0.4505 (0.4505)  loss_bbox_aux_3: 0.0692 (0.0692)  loss_giou_aux_3: 0.4029 (0.4029)  loss_vfl_aux_4: 0.4529 (0.4529)  loss_bbox_aux_4: 0.0691 (0.0691)  loss_giou_aux_4: 0.4014 (0.4014)  loss_vfl_aux_5: 0.5639 (0.5639)  loss_bbox_aux_5: 0.1097 (0.1097)  loss_giou_aux_5: 0.5788 (0.5788)  loss_vfl_dn_0: 0.4348 (0.4348)  loss_bbox_dn_0: 0.1137 (0.1137)  loss_giou_dn_0: 0.6128 (0.6128)  loss_vfl_dn_1: 0.4018 (0.4018)  loss_bbox_dn_1: 0.0818 (0.0818)  loss_giou_dn_1: 0.4777 (0.4777)  loss_vfl_dn_2: 0.3929 (0.3929)  loss_bbox_dn_2: 0.0788 (0.0788)  loss_giou_dn_2: 0.4552 (0.4552)  loss_vfl_dn_3: 0.3891 (0.3891)  loss_bbox_dn_3: 0.0787 (0.0787)  loss_giou_dn_3: 0.4554 (0.4554)  loss_vfl_dn_4: 0.3875 (0.3875)  loss_bbox_dn_4: 0.0792 (0.0792)  loss_giou_dn_4: 0.4525 (0.4525)  loss_vfl_dn_5: 0.3862 (0.3862)  loss_bbox_dn_5: 0.0789 (0.0789)  loss_giou_dn_5: 0.4520 (0.4520)  time: 0.9637  data: 0.5583  max mem: 7790\n",
            "Epoch: [144]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.9043 (12.9411)  loss_vfl: 0.4860 (0.4954)  loss_bbox: 0.0820 (0.0846)  loss_giou: 0.3684 (0.3938)  loss_vfl_aux_0: 0.5180 (0.5116)  loss_bbox_aux_0: 0.1015 (0.0984)  loss_giou_aux_0: 0.4102 (0.4381)  loss_vfl_aux_1: 0.5084 (0.5071)  loss_bbox_aux_1: 0.0906 (0.0884)  loss_giou_aux_1: 0.3797 (0.4048)  loss_vfl_aux_2: 0.5079 (0.5066)  loss_bbox_aux_2: 0.0857 (0.0863)  loss_giou_aux_2: 0.3749 (0.3960)  loss_vfl_aux_3: 0.5035 (0.5036)  loss_bbox_aux_3: 0.0834 (0.0846)  loss_giou_aux_3: 0.3656 (0.3927)  loss_vfl_aux_4: 0.4845 (0.4939)  loss_bbox_aux_4: 0.0824 (0.0853)  loss_giou_aux_4: 0.3644 (0.3947)  loss_vfl_aux_5: 0.5850 (0.5909)  loss_bbox_aux_5: 0.1363 (0.1337)  loss_giou_aux_5: 0.5494 (0.5582)  loss_vfl_dn_0: 0.4349 (0.4338)  loss_bbox_dn_0: 0.1515 (0.1544)  loss_giou_dn_0: 0.5712 (0.5925)  loss_vfl_dn_1: 0.3875 (0.3904)  loss_bbox_dn_1: 0.1024 (0.1096)  loss_giou_dn_1: 0.4215 (0.4442)  loss_vfl_dn_2: 0.3770 (0.3797)  loss_bbox_dn_2: 0.0894 (0.1021)  loss_giou_dn_2: 0.4031 (0.4197)  loss_vfl_dn_3: 0.3718 (0.3758)  loss_bbox_dn_3: 0.0874 (0.1002)  loss_giou_dn_3: 0.3999 (0.4146)  loss_vfl_dn_4: 0.3700 (0.3747)  loss_bbox_dn_4: 0.0865 (0.0999)  loss_giou_dn_4: 0.4006 (0.4136)  loss_vfl_dn_5: 0.3706 (0.3737)  loss_bbox_dn_5: 0.0869 (0.0998)  loss_giou_dn_5: 0.3984 (0.4140)  time: 0.3195  data: 0.0139  max mem: 7790\n",
            "Epoch: [144] Total time: 0:00:11 (0.3460 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.9043 (12.9411)  loss_vfl: 0.4860 (0.4954)  loss_bbox: 0.0820 (0.0846)  loss_giou: 0.3684 (0.3938)  loss_vfl_aux_0: 0.5180 (0.5116)  loss_bbox_aux_0: 0.1015 (0.0984)  loss_giou_aux_0: 0.4102 (0.4381)  loss_vfl_aux_1: 0.5084 (0.5071)  loss_bbox_aux_1: 0.0906 (0.0884)  loss_giou_aux_1: 0.3797 (0.4048)  loss_vfl_aux_2: 0.5079 (0.5066)  loss_bbox_aux_2: 0.0857 (0.0863)  loss_giou_aux_2: 0.3749 (0.3960)  loss_vfl_aux_3: 0.5035 (0.5036)  loss_bbox_aux_3: 0.0834 (0.0846)  loss_giou_aux_3: 0.3656 (0.3927)  loss_vfl_aux_4: 0.4845 (0.4939)  loss_bbox_aux_4: 0.0824 (0.0853)  loss_giou_aux_4: 0.3644 (0.3947)  loss_vfl_aux_5: 0.5850 (0.5909)  loss_bbox_aux_5: 0.1363 (0.1337)  loss_giou_aux_5: 0.5494 (0.5582)  loss_vfl_dn_0: 0.4349 (0.4338)  loss_bbox_dn_0: 0.1515 (0.1544)  loss_giou_dn_0: 0.5712 (0.5925)  loss_vfl_dn_1: 0.3875 (0.3904)  loss_bbox_dn_1: 0.1024 (0.1096)  loss_giou_dn_1: 0.4215 (0.4442)  loss_vfl_dn_2: 0.3770 (0.3797)  loss_bbox_dn_2: 0.0894 (0.1021)  loss_giou_dn_2: 0.4031 (0.4197)  loss_vfl_dn_3: 0.3718 (0.3758)  loss_bbox_dn_3: 0.0874 (0.1002)  loss_giou_dn_3: 0.3999 (0.4146)  loss_vfl_dn_4: 0.3700 (0.3747)  loss_bbox_dn_4: 0.0865 (0.0999)  loss_giou_dn_4: 0.4006 (0.4136)  loss_vfl_dn_5: 0.3706 (0.3737)  loss_bbox_dn_5: 0.0869 (0.0998)  loss_giou_dn_5: 0.3984 (0.4140)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8666  data: 0.5587  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3875  data: 0.1113  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3992 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.668\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.557\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684\n",
            "best_stat:  {'epoch': 136, 'coco_eval_bbox': 0.35008414337928806}\n",
            "Epoch: [145]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 9.6272 (9.6272)  loss_vfl: 0.3881 (0.3881)  loss_bbox: 0.0480 (0.0480)  loss_giou: 0.2326 (0.2326)  loss_vfl_aux_0: 0.4123 (0.4123)  loss_bbox_aux_0: 0.0604 (0.0604)  loss_giou_aux_0: 0.2742 (0.2742)  loss_vfl_aux_1: 0.3937 (0.3937)  loss_bbox_aux_1: 0.0531 (0.0531)  loss_giou_aux_1: 0.2528 (0.2528)  loss_vfl_aux_2: 0.3837 (0.3837)  loss_bbox_aux_2: 0.0505 (0.0505)  loss_giou_aux_2: 0.2415 (0.2415)  loss_vfl_aux_3: 0.3837 (0.3837)  loss_bbox_aux_3: 0.0484 (0.0484)  loss_giou_aux_3: 0.2338 (0.2338)  loss_vfl_aux_4: 0.3779 (0.3779)  loss_bbox_aux_4: 0.0483 (0.0483)  loss_giou_aux_4: 0.2333 (0.2333)  loss_vfl_aux_5: 0.5320 (0.5320)  loss_bbox_aux_5: 0.1490 (0.1490)  loss_giou_aux_5: 0.5303 (0.5303)  loss_vfl_dn_0: 0.4547 (0.4547)  loss_bbox_dn_0: 0.0993 (0.0993)  loss_giou_dn_0: 0.4595 (0.4595)  loss_vfl_dn_1: 0.3756 (0.3756)  loss_bbox_dn_1: 0.0586 (0.0586)  loss_giou_dn_1: 0.2797 (0.2797)  loss_vfl_dn_2: 0.3581 (0.3581)  loss_bbox_dn_2: 0.0520 (0.0520)  loss_giou_dn_2: 0.2529 (0.2529)  loss_vfl_dn_3: 0.3463 (0.3463)  loss_bbox_dn_3: 0.0505 (0.0505)  loss_giou_dn_3: 0.2436 (0.2436)  loss_vfl_dn_4: 0.3420 (0.3420)  loss_bbox_dn_4: 0.0508 (0.0508)  loss_giou_dn_4: 0.2426 (0.2426)  loss_vfl_dn_5: 0.3409 (0.3409)  loss_bbox_dn_5: 0.0505 (0.0505)  loss_giou_dn_5: 0.2417 (0.2417)  time: 1.0199  data: 0.6036  max mem: 7790\n",
            "Epoch: [145]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.4981 (13.0969)  loss_vfl: 0.4819 (0.4701)  loss_bbox: 0.0907 (0.0866)  loss_giou: 0.3896 (0.4152)  loss_vfl_aux_0: 0.5245 (0.5048)  loss_bbox_aux_0: 0.1044 (0.1016)  loss_giou_aux_0: 0.4480 (0.4556)  loss_vfl_aux_1: 0.4772 (0.4854)  loss_bbox_aux_1: 0.0929 (0.0905)  loss_giou_aux_1: 0.4165 (0.4239)  loss_vfl_aux_2: 0.4741 (0.4780)  loss_bbox_aux_2: 0.0923 (0.0891)  loss_giou_aux_2: 0.4034 (0.4192)  loss_vfl_aux_3: 0.4653 (0.4747)  loss_bbox_aux_3: 0.0911 (0.0882)  loss_giou_aux_3: 0.4090 (0.4161)  loss_vfl_aux_4: 0.4643 (0.4667)  loss_bbox_aux_4: 0.0895 (0.0879)  loss_giou_aux_4: 0.4092 (0.4167)  loss_vfl_aux_5: 0.5770 (0.5732)  loss_bbox_aux_5: 0.1402 (0.1522)  loss_giou_aux_5: 0.6078 (0.6074)  loss_vfl_dn_0: 0.4357 (0.4383)  loss_bbox_dn_0: 0.1501 (0.1548)  loss_giou_dn_0: 0.6173 (0.6067)  loss_vfl_dn_1: 0.4037 (0.4006)  loss_bbox_dn_1: 0.1160 (0.1075)  loss_giou_dn_1: 0.4559 (0.4532)  loss_vfl_dn_2: 0.3986 (0.3898)  loss_bbox_dn_2: 0.1079 (0.1004)  loss_giou_dn_2: 0.4177 (0.4285)  loss_vfl_dn_3: 0.3928 (0.3863)  loss_bbox_dn_3: 0.1032 (0.0987)  loss_giou_dn_3: 0.4021 (0.4224)  loss_vfl_dn_4: 0.3919 (0.3846)  loss_bbox_dn_4: 0.1032 (0.0982)  loss_giou_dn_4: 0.4052 (0.4209)  loss_vfl_dn_5: 0.3929 (0.3841)  loss_bbox_dn_5: 0.1031 (0.0980)  loss_giou_dn_5: 0.4052 (0.4209)  time: 0.3264  data: 0.0146  max mem: 7790\n",
            "Epoch: [145] Total time: 0:00:11 (0.3507 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.4981 (13.0969)  loss_vfl: 0.4819 (0.4701)  loss_bbox: 0.0907 (0.0866)  loss_giou: 0.3896 (0.4152)  loss_vfl_aux_0: 0.5245 (0.5048)  loss_bbox_aux_0: 0.1044 (0.1016)  loss_giou_aux_0: 0.4480 (0.4556)  loss_vfl_aux_1: 0.4772 (0.4854)  loss_bbox_aux_1: 0.0929 (0.0905)  loss_giou_aux_1: 0.4165 (0.4239)  loss_vfl_aux_2: 0.4741 (0.4780)  loss_bbox_aux_2: 0.0923 (0.0891)  loss_giou_aux_2: 0.4034 (0.4192)  loss_vfl_aux_3: 0.4653 (0.4747)  loss_bbox_aux_3: 0.0911 (0.0882)  loss_giou_aux_3: 0.4090 (0.4161)  loss_vfl_aux_4: 0.4643 (0.4667)  loss_bbox_aux_4: 0.0895 (0.0879)  loss_giou_aux_4: 0.4092 (0.4167)  loss_vfl_aux_5: 0.5770 (0.5732)  loss_bbox_aux_5: 0.1402 (0.1522)  loss_giou_aux_5: 0.6078 (0.6074)  loss_vfl_dn_0: 0.4357 (0.4383)  loss_bbox_dn_0: 0.1501 (0.1548)  loss_giou_dn_0: 0.6173 (0.6067)  loss_vfl_dn_1: 0.4037 (0.4006)  loss_bbox_dn_1: 0.1160 (0.1075)  loss_giou_dn_1: 0.4559 (0.4532)  loss_vfl_dn_2: 0.3986 (0.3898)  loss_bbox_dn_2: 0.1079 (0.1004)  loss_giou_dn_2: 0.4177 (0.4285)  loss_vfl_dn_3: 0.3928 (0.3863)  loss_bbox_dn_3: 0.1032 (0.0987)  loss_giou_dn_3: 0.4021 (0.4224)  loss_vfl_dn_4: 0.3919 (0.3846)  loss_bbox_dn_4: 0.1032 (0.0982)  loss_giou_dn_4: 0.4052 (0.4209)  loss_vfl_dn_5: 0.3929 (0.3841)  loss_bbox_dn_5: 0.1031 (0.0980)  loss_giou_dn_5: 0.4052 (0.4209)\n",
            "Test:  [0/6]  eta: 0:00:07    time: 1.1742  data: 0.5613  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4351  data: 0.1124  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4490 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.675\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [146]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 11.1302 (11.1302)  loss_vfl: 0.5080 (0.5080)  loss_bbox: 0.0564 (0.0564)  loss_giou: 0.2569 (0.2569)  loss_vfl_aux_0: 0.5056 (0.5056)  loss_bbox_aux_0: 0.0869 (0.0869)  loss_giou_aux_0: 0.3637 (0.3637)  loss_vfl_aux_1: 0.4936 (0.4936)  loss_bbox_aux_1: 0.0660 (0.0660)  loss_giou_aux_1: 0.2985 (0.2985)  loss_vfl_aux_2: 0.5061 (0.5061)  loss_bbox_aux_2: 0.0606 (0.0606)  loss_giou_aux_2: 0.2735 (0.2735)  loss_vfl_aux_3: 0.5155 (0.5155)  loss_bbox_aux_3: 0.0587 (0.0587)  loss_giou_aux_3: 0.2625 (0.2625)  loss_vfl_aux_4: 0.5027 (0.5027)  loss_bbox_aux_4: 0.0570 (0.0570)  loss_giou_aux_4: 0.2582 (0.2582)  loss_vfl_aux_5: 0.5995 (0.5995)  loss_bbox_aux_5: 0.1581 (0.1581)  loss_giou_aux_5: 0.5858 (0.5858)  loss_vfl_dn_0: 0.4110 (0.4110)  loss_bbox_dn_0: 0.1375 (0.1375)  loss_giou_dn_0: 0.5158 (0.5158)  loss_vfl_dn_1: 0.3666 (0.3666)  loss_bbox_dn_1: 0.0771 (0.0771)  loss_giou_dn_1: 0.3429 (0.3429)  loss_vfl_dn_2: 0.3477 (0.3477)  loss_bbox_dn_2: 0.0663 (0.0663)  loss_giou_dn_2: 0.3068 (0.3068)  loss_vfl_dn_3: 0.3416 (0.3416)  loss_bbox_dn_3: 0.0624 (0.0624)  loss_giou_dn_3: 0.2951 (0.2951)  loss_vfl_dn_4: 0.3411 (0.3411)  loss_bbox_dn_4: 0.0610 (0.0610)  loss_giou_dn_4: 0.2917 (0.2917)  loss_vfl_dn_5: 0.3400 (0.3400)  loss_bbox_dn_5: 0.0607 (0.0607)  loss_giou_dn_5: 0.2913 (0.2913)  time: 0.9240  data: 0.5471  max mem: 7790\n",
            "Epoch: [146]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.2450 (13.2076)  loss_vfl: 0.4986 (0.4968)  loss_bbox: 0.0890 (0.0942)  loss_giou: 0.3636 (0.3801)  loss_vfl_aux_0: 0.5086 (0.5249)  loss_bbox_aux_0: 0.1112 (0.1142)  loss_giou_aux_0: 0.4423 (0.4327)  loss_vfl_aux_1: 0.5063 (0.5113)  loss_bbox_aux_1: 0.0958 (0.1017)  loss_giou_aux_1: 0.3899 (0.3945)  loss_vfl_aux_2: 0.5065 (0.5110)  loss_bbox_aux_2: 0.0913 (0.0974)  loss_giou_aux_2: 0.3783 (0.3857)  loss_vfl_aux_3: 0.5130 (0.5063)  loss_bbox_aux_3: 0.0893 (0.0960)  loss_giou_aux_3: 0.3765 (0.3817)  loss_vfl_aux_4: 0.5087 (0.4966)  loss_bbox_aux_4: 0.0889 (0.0955)  loss_giou_aux_4: 0.3725 (0.3814)  loss_vfl_aux_5: 0.6097 (0.6095)  loss_bbox_aux_5: 0.1708 (0.1628)  loss_giou_aux_5: 0.5707 (0.5738)  loss_vfl_dn_0: 0.4411 (0.4375)  loss_bbox_dn_0: 0.1806 (0.1774)  loss_giou_dn_0: 0.6198 (0.6123)  loss_vfl_dn_1: 0.4026 (0.4012)  loss_bbox_dn_1: 0.1277 (0.1285)  loss_giou_dn_1: 0.4640 (0.4467)  loss_vfl_dn_2: 0.3989 (0.3912)  loss_bbox_dn_2: 0.1172 (0.1183)  loss_giou_dn_2: 0.4347 (0.4164)  loss_vfl_dn_3: 0.3917 (0.3883)  loss_bbox_dn_3: 0.1135 (0.1159)  loss_giou_dn_3: 0.4221 (0.4090)  loss_vfl_dn_4: 0.3842 (0.3854)  loss_bbox_dn_4: 0.1121 (0.1156)  loss_giou_dn_4: 0.4227 (0.4076)  loss_vfl_dn_5: 0.3830 (0.3854)  loss_bbox_dn_5: 0.1115 (0.1154)  loss_giou_dn_5: 0.4228 (0.4074)  time: 0.3337  data: 0.0143  max mem: 7790\n",
            "Epoch: [146] Total time: 0:00:11 (0.3585 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.2450 (13.2076)  loss_vfl: 0.4986 (0.4968)  loss_bbox: 0.0890 (0.0942)  loss_giou: 0.3636 (0.3801)  loss_vfl_aux_0: 0.5086 (0.5249)  loss_bbox_aux_0: 0.1112 (0.1142)  loss_giou_aux_0: 0.4423 (0.4327)  loss_vfl_aux_1: 0.5063 (0.5113)  loss_bbox_aux_1: 0.0958 (0.1017)  loss_giou_aux_1: 0.3899 (0.3945)  loss_vfl_aux_2: 0.5065 (0.5110)  loss_bbox_aux_2: 0.0913 (0.0974)  loss_giou_aux_2: 0.3783 (0.3857)  loss_vfl_aux_3: 0.5130 (0.5063)  loss_bbox_aux_3: 0.0893 (0.0960)  loss_giou_aux_3: 0.3765 (0.3817)  loss_vfl_aux_4: 0.5087 (0.4966)  loss_bbox_aux_4: 0.0889 (0.0955)  loss_giou_aux_4: 0.3725 (0.3814)  loss_vfl_aux_5: 0.6097 (0.6095)  loss_bbox_aux_5: 0.1708 (0.1628)  loss_giou_aux_5: 0.5707 (0.5738)  loss_vfl_dn_0: 0.4411 (0.4375)  loss_bbox_dn_0: 0.1806 (0.1774)  loss_giou_dn_0: 0.6198 (0.6123)  loss_vfl_dn_1: 0.4026 (0.4012)  loss_bbox_dn_1: 0.1277 (0.1285)  loss_giou_dn_1: 0.4640 (0.4467)  loss_vfl_dn_2: 0.3989 (0.3912)  loss_bbox_dn_2: 0.1172 (0.1183)  loss_giou_dn_2: 0.4347 (0.4164)  loss_vfl_dn_3: 0.3917 (0.3883)  loss_bbox_dn_3: 0.1135 (0.1159)  loss_giou_dn_3: 0.4221 (0.4090)  loss_vfl_dn_4: 0.3842 (0.3854)  loss_bbox_dn_4: 0.1121 (0.1156)  loss_giou_dn_4: 0.4227 (0.4076)  loss_vfl_dn_5: 0.3830 (0.3854)  loss_bbox_dn_5: 0.1115 (0.1154)  loss_giou_dn_5: 0.4228 (0.4074)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8444  data: 0.5260  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4463  data: 0.1111  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4597 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.658\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.317\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.337\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [147]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 13.8919 (13.8919)  loss_vfl: 0.4657 (0.4657)  loss_bbox: 0.0830 (0.0830)  loss_giou: 0.5138 (0.5138)  loss_vfl_aux_0: 0.4706 (0.4706)  loss_bbox_aux_0: 0.0963 (0.0963)  loss_giou_aux_0: 0.5636 (0.5636)  loss_vfl_aux_1: 0.4828 (0.4828)  loss_bbox_aux_1: 0.0844 (0.0844)  loss_giou_aux_1: 0.5172 (0.5172)  loss_vfl_aux_2: 0.4611 (0.4611)  loss_bbox_aux_2: 0.0843 (0.0843)  loss_giou_aux_2: 0.5084 (0.5084)  loss_vfl_aux_3: 0.4548 (0.4548)  loss_bbox_aux_3: 0.0838 (0.0838)  loss_giou_aux_3: 0.5124 (0.5124)  loss_vfl_aux_4: 0.4521 (0.4521)  loss_bbox_aux_4: 0.0832 (0.0832)  loss_giou_aux_4: 0.5144 (0.5144)  loss_vfl_aux_5: 0.5356 (0.5356)  loss_bbox_aux_5: 0.1074 (0.1074)  loss_giou_aux_5: 0.6174 (0.6174)  loss_vfl_dn_0: 0.4548 (0.4548)  loss_bbox_dn_0: 0.1329 (0.1329)  loss_giou_dn_0: 0.6719 (0.6719)  loss_vfl_dn_1: 0.4155 (0.4155)  loss_bbox_dn_1: 0.0901 (0.0901)  loss_giou_dn_1: 0.5070 (0.5070)  loss_vfl_dn_2: 0.4027 (0.4027)  loss_bbox_dn_2: 0.0859 (0.0859)  loss_giou_dn_2: 0.4887 (0.4887)  loss_vfl_dn_3: 0.4048 (0.4048)  loss_bbox_dn_3: 0.0853 (0.0853)  loss_giou_dn_3: 0.4919 (0.4919)  loss_vfl_dn_4: 0.4040 (0.4040)  loss_bbox_dn_4: 0.0862 (0.0862)  loss_giou_dn_4: 0.4945 (0.4945)  loss_vfl_dn_5: 0.4025 (0.4025)  loss_bbox_dn_5: 0.0861 (0.0861)  loss_giou_dn_5: 0.4949 (0.4949)  time: 0.9977  data: 0.5807  max mem: 7790\n",
            "Epoch: [147]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.6165 (13.5692)  loss_vfl: 0.4883 (0.5002)  loss_bbox: 0.0873 (0.0980)  loss_giou: 0.4028 (0.4165)  loss_vfl_aux_0: 0.5137 (0.5202)  loss_bbox_aux_0: 0.0948 (0.1143)  loss_giou_aux_0: 0.4557 (0.4684)  loss_vfl_aux_1: 0.5007 (0.5103)  loss_bbox_aux_1: 0.0863 (0.1028)  loss_giou_aux_1: 0.4332 (0.4310)  loss_vfl_aux_2: 0.4890 (0.5099)  loss_bbox_aux_2: 0.0821 (0.0994)  loss_giou_aux_2: 0.4097 (0.4204)  loss_vfl_aux_3: 0.4887 (0.5078)  loss_bbox_aux_3: 0.0865 (0.0982)  loss_giou_aux_3: 0.4068 (0.4160)  loss_vfl_aux_4: 0.4863 (0.4985)  loss_bbox_aux_4: 0.0871 (0.0982)  loss_giou_aux_4: 0.4047 (0.4177)  loss_vfl_aux_5: 0.5737 (0.5843)  loss_bbox_aux_5: 0.1307 (0.1548)  loss_giou_aux_5: 0.5765 (0.5811)  loss_vfl_dn_0: 0.4385 (0.4376)  loss_bbox_dn_0: 0.1508 (0.1722)  loss_giou_dn_0: 0.5948 (0.6215)  loss_vfl_dn_1: 0.4074 (0.4035)  loss_bbox_dn_1: 0.1049 (0.1259)  loss_giou_dn_1: 0.4609 (0.4730)  loss_vfl_dn_2: 0.3940 (0.3921)  loss_bbox_dn_2: 0.0958 (0.1173)  loss_giou_dn_2: 0.4386 (0.4469)  loss_vfl_dn_3: 0.3899 (0.3890)  loss_bbox_dn_3: 0.0954 (0.1155)  loss_giou_dn_3: 0.4325 (0.4412)  loss_vfl_dn_4: 0.3879 (0.3882)  loss_bbox_dn_4: 0.0957 (0.1151)  loss_giou_dn_4: 0.4306 (0.4396)  loss_vfl_dn_5: 0.3878 (0.3882)  loss_bbox_dn_5: 0.0961 (0.1149)  loss_giou_dn_5: 0.4300 (0.4395)  time: 0.3226  data: 0.0151  max mem: 7790\n",
            "Epoch: [147] Total time: 0:00:11 (0.3510 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.6165 (13.5692)  loss_vfl: 0.4883 (0.5002)  loss_bbox: 0.0873 (0.0980)  loss_giou: 0.4028 (0.4165)  loss_vfl_aux_0: 0.5137 (0.5202)  loss_bbox_aux_0: 0.0948 (0.1143)  loss_giou_aux_0: 0.4557 (0.4684)  loss_vfl_aux_1: 0.5007 (0.5103)  loss_bbox_aux_1: 0.0863 (0.1028)  loss_giou_aux_1: 0.4332 (0.4310)  loss_vfl_aux_2: 0.4890 (0.5099)  loss_bbox_aux_2: 0.0821 (0.0994)  loss_giou_aux_2: 0.4097 (0.4204)  loss_vfl_aux_3: 0.4887 (0.5078)  loss_bbox_aux_3: 0.0865 (0.0982)  loss_giou_aux_3: 0.4068 (0.4160)  loss_vfl_aux_4: 0.4863 (0.4985)  loss_bbox_aux_4: 0.0871 (0.0982)  loss_giou_aux_4: 0.4047 (0.4177)  loss_vfl_aux_5: 0.5737 (0.5843)  loss_bbox_aux_5: 0.1307 (0.1548)  loss_giou_aux_5: 0.5765 (0.5811)  loss_vfl_dn_0: 0.4385 (0.4376)  loss_bbox_dn_0: 0.1508 (0.1722)  loss_giou_dn_0: 0.5948 (0.6215)  loss_vfl_dn_1: 0.4074 (0.4035)  loss_bbox_dn_1: 0.1049 (0.1259)  loss_giou_dn_1: 0.4609 (0.4730)  loss_vfl_dn_2: 0.3940 (0.3921)  loss_bbox_dn_2: 0.0958 (0.1173)  loss_giou_dn_2: 0.4386 (0.4469)  loss_vfl_dn_3: 0.3899 (0.3890)  loss_bbox_dn_3: 0.0954 (0.1155)  loss_giou_dn_3: 0.4325 (0.4412)  loss_vfl_dn_4: 0.3879 (0.3882)  loss_bbox_dn_4: 0.0957 (0.1151)  loss_giou_dn_4: 0.4306 (0.4396)  loss_vfl_dn_5: 0.3878 (0.3882)  loss_bbox_dn_5: 0.0961 (0.1149)  loss_giou_dn_5: 0.4300 (0.4395)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8524  data: 0.5405  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3819  data: 0.1110  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4185 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.659\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [148]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 13.3898 (13.3898)  loss_vfl: 0.5426 (0.5426)  loss_bbox: 0.1242 (0.1242)  loss_giou: 0.3538 (0.3538)  loss_vfl_aux_0: 0.5939 (0.5939)  loss_bbox_aux_0: 0.1339 (0.1339)  loss_giou_aux_0: 0.3877 (0.3877)  loss_vfl_aux_1: 0.5704 (0.5704)  loss_bbox_aux_1: 0.1266 (0.1266)  loss_giou_aux_1: 0.3756 (0.3756)  loss_vfl_aux_2: 0.5689 (0.5689)  loss_bbox_aux_2: 0.1245 (0.1245)  loss_giou_aux_2: 0.3604 (0.3604)  loss_vfl_aux_3: 0.5612 (0.5612)  loss_bbox_aux_3: 0.1248 (0.1248)  loss_giou_aux_3: 0.3605 (0.3605)  loss_vfl_aux_4: 0.5261 (0.5261)  loss_bbox_aux_4: 0.1240 (0.1240)  loss_giou_aux_4: 0.3545 (0.3545)  loss_vfl_aux_5: 0.6606 (0.6606)  loss_bbox_aux_5: 0.1435 (0.1435)  loss_giou_aux_5: 0.4567 (0.4567)  loss_vfl_dn_0: 0.4542 (0.4542)  loss_bbox_dn_0: 0.2037 (0.2037)  loss_giou_dn_0: 0.5644 (0.5644)  loss_vfl_dn_1: 0.4205 (0.4205)  loss_bbox_dn_1: 0.1409 (0.1409)  loss_giou_dn_1: 0.4196 (0.4196)  loss_vfl_dn_2: 0.3996 (0.3996)  loss_bbox_dn_2: 0.1310 (0.1310)  loss_giou_dn_2: 0.3807 (0.3807)  loss_vfl_dn_3: 0.4014 (0.4014)  loss_bbox_dn_3: 0.1293 (0.1293)  loss_giou_dn_3: 0.3729 (0.3729)  loss_vfl_dn_4: 0.4029 (0.4029)  loss_bbox_dn_4: 0.1283 (0.1283)  loss_giou_dn_4: 0.3668 (0.3668)  loss_vfl_dn_5: 0.4030 (0.4030)  loss_bbox_dn_5: 0.1285 (0.1285)  loss_giou_dn_5: 0.3677 (0.3677)  time: 1.0893  data: 0.6909  max mem: 7790\n",
            "Epoch: [148]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.3701 (13.2198)  loss_vfl: 0.4501 (0.5043)  loss_bbox: 0.0848 (0.0957)  loss_giou: 0.3803 (0.3877)  loss_vfl_aux_0: 0.4897 (0.5225)  loss_bbox_aux_0: 0.0910 (0.1129)  loss_giou_aux_0: 0.4150 (0.4360)  loss_vfl_aux_1: 0.4642 (0.5051)  loss_bbox_aux_1: 0.0745 (0.1005)  loss_giou_aux_1: 0.3906 (0.4009)  loss_vfl_aux_2: 0.4579 (0.5069)  loss_bbox_aux_2: 0.0895 (0.0982)  loss_giou_aux_2: 0.3833 (0.3936)  loss_vfl_aux_3: 0.4536 (0.5071)  loss_bbox_aux_3: 0.0837 (0.0958)  loss_giou_aux_3: 0.3812 (0.3882)  loss_vfl_aux_4: 0.4502 (0.5008)  loss_bbox_aux_4: 0.0848 (0.0969)  loss_giou_aux_4: 0.3807 (0.3893)  loss_vfl_aux_5: 0.5564 (0.5945)  loss_bbox_aux_5: 0.1316 (0.1636)  loss_giou_aux_5: 0.5605 (0.5764)  loss_vfl_dn_0: 0.4401 (0.4403)  loss_bbox_dn_0: 0.1389 (0.1787)  loss_giou_dn_0: 0.5741 (0.5914)  loss_vfl_dn_1: 0.3997 (0.4005)  loss_bbox_dn_1: 0.0971 (0.1319)  loss_giou_dn_1: 0.4216 (0.4393)  loss_vfl_dn_2: 0.3860 (0.3883)  loss_bbox_dn_2: 0.0869 (0.1232)  loss_giou_dn_2: 0.3914 (0.4128)  loss_vfl_dn_3: 0.3822 (0.3849)  loss_bbox_dn_3: 0.0864 (0.1210)  loss_giou_dn_3: 0.3839 (0.4073)  loss_vfl_dn_4: 0.3837 (0.3843)  loss_bbox_dn_4: 0.0862 (0.1207)  loss_giou_dn_4: 0.3803 (0.4065)  loss_vfl_dn_5: 0.3818 (0.3842)  loss_bbox_dn_5: 0.0867 (0.1206)  loss_giou_dn_5: 0.3800 (0.4069)  time: 0.3225  data: 0.0144  max mem: 7790\n",
            "Epoch: [148] Total time: 0:00:11 (0.3619 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.3701 (13.2198)  loss_vfl: 0.4501 (0.5043)  loss_bbox: 0.0848 (0.0957)  loss_giou: 0.3803 (0.3877)  loss_vfl_aux_0: 0.4897 (0.5225)  loss_bbox_aux_0: 0.0910 (0.1129)  loss_giou_aux_0: 0.4150 (0.4360)  loss_vfl_aux_1: 0.4642 (0.5051)  loss_bbox_aux_1: 0.0745 (0.1005)  loss_giou_aux_1: 0.3906 (0.4009)  loss_vfl_aux_2: 0.4579 (0.5069)  loss_bbox_aux_2: 0.0895 (0.0982)  loss_giou_aux_2: 0.3833 (0.3936)  loss_vfl_aux_3: 0.4536 (0.5071)  loss_bbox_aux_3: 0.0837 (0.0958)  loss_giou_aux_3: 0.3812 (0.3882)  loss_vfl_aux_4: 0.4502 (0.5008)  loss_bbox_aux_4: 0.0848 (0.0969)  loss_giou_aux_4: 0.3807 (0.3893)  loss_vfl_aux_5: 0.5564 (0.5945)  loss_bbox_aux_5: 0.1316 (0.1636)  loss_giou_aux_5: 0.5605 (0.5764)  loss_vfl_dn_0: 0.4401 (0.4403)  loss_bbox_dn_0: 0.1389 (0.1787)  loss_giou_dn_0: 0.5741 (0.5914)  loss_vfl_dn_1: 0.3997 (0.4005)  loss_bbox_dn_1: 0.0971 (0.1319)  loss_giou_dn_1: 0.4216 (0.4393)  loss_vfl_dn_2: 0.3860 (0.3883)  loss_bbox_dn_2: 0.0869 (0.1232)  loss_giou_dn_2: 0.3914 (0.4128)  loss_vfl_dn_3: 0.3822 (0.3849)  loss_bbox_dn_3: 0.0864 (0.1210)  loss_giou_dn_3: 0.3839 (0.4073)  loss_vfl_dn_4: 0.3837 (0.3843)  loss_bbox_dn_4: 0.0862 (0.1207)  loss_giou_dn_4: 0.3803 (0.4065)  loss_vfl_dn_5: 0.3818 (0.3842)  loss_bbox_dn_5: 0.0867 (0.1206)  loss_giou_dn_5: 0.3800 (0.4069)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9007  data: 0.5827  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3860  data: 0.1091  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3994 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.667\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [149]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 13.0684 (13.0684)  loss_vfl: 0.4895 (0.4895)  loss_bbox: 0.1139 (0.1139)  loss_giou: 0.3226 (0.3226)  loss_vfl_aux_0: 0.5108 (0.5108)  loss_bbox_aux_0: 0.1193 (0.1193)  loss_giou_aux_0: 0.3792 (0.3792)  loss_vfl_aux_1: 0.4951 (0.4951)  loss_bbox_aux_1: 0.1022 (0.1022)  loss_giou_aux_1: 0.3432 (0.3432)  loss_vfl_aux_2: 0.4775 (0.4775)  loss_bbox_aux_2: 0.1067 (0.1067)  loss_giou_aux_2: 0.3249 (0.3249)  loss_vfl_aux_3: 0.4944 (0.4944)  loss_bbox_aux_3: 0.1120 (0.1120)  loss_giou_aux_3: 0.3192 (0.3192)  loss_vfl_aux_4: 0.4990 (0.4990)  loss_bbox_aux_4: 0.1282 (0.1282)  loss_giou_aux_4: 0.3155 (0.3155)  loss_vfl_aux_5: 0.5908 (0.5908)  loss_bbox_aux_5: 0.1570 (0.1570)  loss_giou_aux_5: 0.4984 (0.4984)  loss_vfl_dn_0: 0.4090 (0.4090)  loss_bbox_dn_0: 0.2491 (0.2491)  loss_giou_dn_0: 0.6020 (0.6020)  loss_vfl_dn_1: 0.3738 (0.3738)  loss_bbox_dn_1: 0.2043 (0.2043)  loss_giou_dn_1: 0.4455 (0.4455)  loss_vfl_dn_2: 0.3654 (0.3654)  loss_bbox_dn_2: 0.1991 (0.1991)  loss_giou_dn_2: 0.4084 (0.4084)  loss_vfl_dn_3: 0.3649 (0.3649)  loss_bbox_dn_3: 0.2016 (0.2016)  loss_giou_dn_3: 0.3994 (0.3994)  loss_vfl_dn_4: 0.3655 (0.3655)  loss_bbox_dn_4: 0.2048 (0.2048)  loss_giou_dn_4: 0.4015 (0.4015)  loss_vfl_dn_5: 0.3661 (0.3661)  loss_bbox_dn_5: 0.2044 (0.2044)  loss_giou_dn_5: 0.4045 (0.4045)  time: 1.0101  data: 0.6260  max mem: 7790\n",
            "Epoch: [149]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.9749 (13.2855)  loss_vfl: 0.4779 (0.4805)  loss_bbox: 0.0858 (0.0925)  loss_giou: 0.3964 (0.4183)  loss_vfl_aux_0: 0.4977 (0.5087)  loss_bbox_aux_0: 0.0999 (0.1048)  loss_giou_aux_0: 0.4535 (0.4682)  loss_vfl_aux_1: 0.4829 (0.4898)  loss_bbox_aux_1: 0.0935 (0.0967)  loss_giou_aux_1: 0.4143 (0.4295)  loss_vfl_aux_2: 0.4679 (0.4869)  loss_bbox_aux_2: 0.0874 (0.0938)  loss_giou_aux_2: 0.4040 (0.4203)  loss_vfl_aux_3: 0.4723 (0.4876)  loss_bbox_aux_3: 0.0864 (0.0924)  loss_giou_aux_3: 0.4026 (0.4195)  loss_vfl_aux_4: 0.4789 (0.4793)  loss_bbox_aux_4: 0.0851 (0.0934)  loss_giou_aux_4: 0.3955 (0.4188)  loss_vfl_aux_5: 0.5827 (0.5878)  loss_bbox_aux_5: 0.1348 (0.1471)  loss_giou_aux_5: 0.5721 (0.6038)  loss_vfl_dn_0: 0.4389 (0.4357)  loss_bbox_dn_0: 0.1567 (0.1558)  loss_giou_dn_0: 0.6104 (0.6160)  loss_vfl_dn_1: 0.3991 (0.3949)  loss_bbox_dn_1: 0.1089 (0.1134)  loss_giou_dn_1: 0.4465 (0.4645)  loss_vfl_dn_2: 0.3903 (0.3850)  loss_bbox_dn_2: 0.0996 (0.1062)  loss_giou_dn_2: 0.4231 (0.4380)  loss_vfl_dn_3: 0.3912 (0.3824)  loss_bbox_dn_3: 0.1008 (0.1050)  loss_giou_dn_3: 0.4127 (0.4326)  loss_vfl_dn_4: 0.3884 (0.3823)  loss_bbox_dn_4: 0.1004 (0.1046)  loss_giou_dn_4: 0.4091 (0.4314)  loss_vfl_dn_5: 0.3904 (0.3823)  loss_bbox_dn_5: 0.0998 (0.1044)  loss_giou_dn_5: 0.4079 (0.4314)  time: 0.3427  data: 0.0159  max mem: 7790\n",
            "Epoch: [149] Total time: 0:00:11 (0.3589 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.9749 (13.2855)  loss_vfl: 0.4779 (0.4805)  loss_bbox: 0.0858 (0.0925)  loss_giou: 0.3964 (0.4183)  loss_vfl_aux_0: 0.4977 (0.5087)  loss_bbox_aux_0: 0.0999 (0.1048)  loss_giou_aux_0: 0.4535 (0.4682)  loss_vfl_aux_1: 0.4829 (0.4898)  loss_bbox_aux_1: 0.0935 (0.0967)  loss_giou_aux_1: 0.4143 (0.4295)  loss_vfl_aux_2: 0.4679 (0.4869)  loss_bbox_aux_2: 0.0874 (0.0938)  loss_giou_aux_2: 0.4040 (0.4203)  loss_vfl_aux_3: 0.4723 (0.4876)  loss_bbox_aux_3: 0.0864 (0.0924)  loss_giou_aux_3: 0.4026 (0.4195)  loss_vfl_aux_4: 0.4789 (0.4793)  loss_bbox_aux_4: 0.0851 (0.0934)  loss_giou_aux_4: 0.3955 (0.4188)  loss_vfl_aux_5: 0.5827 (0.5878)  loss_bbox_aux_5: 0.1348 (0.1471)  loss_giou_aux_5: 0.5721 (0.6038)  loss_vfl_dn_0: 0.4389 (0.4357)  loss_bbox_dn_0: 0.1567 (0.1558)  loss_giou_dn_0: 0.6104 (0.6160)  loss_vfl_dn_1: 0.3991 (0.3949)  loss_bbox_dn_1: 0.1089 (0.1134)  loss_giou_dn_1: 0.4465 (0.4645)  loss_vfl_dn_2: 0.3903 (0.3850)  loss_bbox_dn_2: 0.0996 (0.1062)  loss_giou_dn_2: 0.4231 (0.4380)  loss_vfl_dn_3: 0.3912 (0.3824)  loss_bbox_dn_3: 0.1008 (0.1050)  loss_giou_dn_3: 0.4127 (0.4326)  loss_vfl_dn_4: 0.3884 (0.3823)  loss_bbox_dn_4: 0.1004 (0.1046)  loss_giou_dn_4: 0.4091 (0.4314)  loss_vfl_dn_5: 0.3904 (0.3823)  loss_bbox_dn_5: 0.0998 (0.1044)  loss_giou_dn_5: 0.4079 (0.4314)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9020  data: 0.5830  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3936  data: 0.1127  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4080 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.546\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [150]  [ 0/33]  eta: 0:00:40  lr: 0.000001  loss: 13.4479 (13.4479)  loss_vfl: 0.5120 (0.5120)  loss_bbox: 0.0917 (0.0917)  loss_giou: 0.4343 (0.4343)  loss_vfl_aux_0: 0.4821 (0.4821)  loss_bbox_aux_0: 0.0987 (0.0987)  loss_giou_aux_0: 0.5123 (0.5123)  loss_vfl_aux_1: 0.4956 (0.4956)  loss_bbox_aux_1: 0.1029 (0.1029)  loss_giou_aux_1: 0.4830 (0.4830)  loss_vfl_aux_2: 0.5159 (0.5159)  loss_bbox_aux_2: 0.1070 (0.1070)  loss_giou_aux_2: 0.4806 (0.4806)  loss_vfl_aux_3: 0.5300 (0.5300)  loss_bbox_aux_3: 0.0901 (0.0901)  loss_giou_aux_3: 0.4297 (0.4297)  loss_vfl_aux_4: 0.5099 (0.5099)  loss_bbox_aux_4: 0.0925 (0.0925)  loss_giou_aux_4: 0.4382 (0.4382)  loss_vfl_aux_5: 0.5957 (0.5957)  loss_bbox_aux_5: 0.1657 (0.1657)  loss_giou_aux_5: 0.7394 (0.7394)  loss_vfl_dn_0: 0.4335 (0.4335)  loss_bbox_dn_0: 0.1255 (0.1255)  loss_giou_dn_0: 0.5782 (0.5782)  loss_vfl_dn_1: 0.4005 (0.4005)  loss_bbox_dn_1: 0.0972 (0.0972)  loss_giou_dn_1: 0.4367 (0.4367)  loss_vfl_dn_2: 0.3875 (0.3875)  loss_bbox_dn_2: 0.0896 (0.0896)  loss_giou_dn_2: 0.4040 (0.4040)  loss_vfl_dn_3: 0.3834 (0.3834)  loss_bbox_dn_3: 0.0875 (0.0875)  loss_giou_dn_3: 0.3962 (0.3962)  loss_vfl_dn_4: 0.3833 (0.3833)  loss_bbox_dn_4: 0.0867 (0.0867)  loss_giou_dn_4: 0.3923 (0.3923)  loss_vfl_dn_5: 0.3812 (0.3812)  loss_bbox_dn_5: 0.0866 (0.0866)  loss_giou_dn_5: 0.3907 (0.3907)  time: 1.2296  data: 0.8267  max mem: 7790\n",
            "Epoch: [150]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.6340 (12.8175)  loss_vfl: 0.4849 (0.4971)  loss_bbox: 0.0812 (0.0853)  loss_giou: 0.3671 (0.3678)  loss_vfl_aux_0: 0.5084 (0.5131)  loss_bbox_aux_0: 0.0978 (0.1057)  loss_giou_aux_0: 0.4213 (0.4264)  loss_vfl_aux_1: 0.4871 (0.4966)  loss_bbox_aux_1: 0.0876 (0.0928)  loss_giou_aux_1: 0.3807 (0.3858)  loss_vfl_aux_2: 0.4904 (0.4982)  loss_bbox_aux_2: 0.0845 (0.0900)  loss_giou_aux_2: 0.3706 (0.3763)  loss_vfl_aux_3: 0.4943 (0.4992)  loss_bbox_aux_3: 0.0827 (0.0870)  loss_giou_aux_3: 0.3620 (0.3690)  loss_vfl_aux_4: 0.4902 (0.4973)  loss_bbox_aux_4: 0.0817 (0.0859)  loss_giou_aux_4: 0.3629 (0.3676)  loss_vfl_aux_5: 0.5934 (0.6051)  loss_bbox_aux_5: 0.1409 (0.1514)  loss_giou_aux_5: 0.5345 (0.5636)  loss_vfl_dn_0: 0.4316 (0.4366)  loss_bbox_dn_0: 0.1501 (0.1653)  loss_giou_dn_0: 0.5806 (0.5883)  loss_vfl_dn_1: 0.3932 (0.3950)  loss_bbox_dn_1: 0.1000 (0.1168)  loss_giou_dn_1: 0.4123 (0.4300)  loss_vfl_dn_2: 0.3842 (0.3843)  loss_bbox_dn_2: 0.0904 (0.1086)  loss_giou_dn_2: 0.3924 (0.4002)  loss_vfl_dn_3: 0.3773 (0.3800)  loss_bbox_dn_3: 0.0912 (0.1062)  loss_giou_dn_3: 0.3833 (0.3926)  loss_vfl_dn_4: 0.3788 (0.3795)  loss_bbox_dn_4: 0.0909 (0.1059)  loss_giou_dn_4: 0.3826 (0.3913)  loss_vfl_dn_5: 0.3769 (0.3786)  loss_bbox_dn_5: 0.0907 (0.1057)  loss_giou_dn_5: 0.3826 (0.3912)  time: 0.3200  data: 0.0138  max mem: 7790\n",
            "Epoch: [150] Total time: 0:00:11 (0.3558 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.6340 (12.8175)  loss_vfl: 0.4849 (0.4971)  loss_bbox: 0.0812 (0.0853)  loss_giou: 0.3671 (0.3678)  loss_vfl_aux_0: 0.5084 (0.5131)  loss_bbox_aux_0: 0.0978 (0.1057)  loss_giou_aux_0: 0.4213 (0.4264)  loss_vfl_aux_1: 0.4871 (0.4966)  loss_bbox_aux_1: 0.0876 (0.0928)  loss_giou_aux_1: 0.3807 (0.3858)  loss_vfl_aux_2: 0.4904 (0.4982)  loss_bbox_aux_2: 0.0845 (0.0900)  loss_giou_aux_2: 0.3706 (0.3763)  loss_vfl_aux_3: 0.4943 (0.4992)  loss_bbox_aux_3: 0.0827 (0.0870)  loss_giou_aux_3: 0.3620 (0.3690)  loss_vfl_aux_4: 0.4902 (0.4973)  loss_bbox_aux_4: 0.0817 (0.0859)  loss_giou_aux_4: 0.3629 (0.3676)  loss_vfl_aux_5: 0.5934 (0.6051)  loss_bbox_aux_5: 0.1409 (0.1514)  loss_giou_aux_5: 0.5345 (0.5636)  loss_vfl_dn_0: 0.4316 (0.4366)  loss_bbox_dn_0: 0.1501 (0.1653)  loss_giou_dn_0: 0.5806 (0.5883)  loss_vfl_dn_1: 0.3932 (0.3950)  loss_bbox_dn_1: 0.1000 (0.1168)  loss_giou_dn_1: 0.4123 (0.4300)  loss_vfl_dn_2: 0.3842 (0.3843)  loss_bbox_dn_2: 0.0904 (0.1086)  loss_giou_dn_2: 0.3924 (0.4002)  loss_vfl_dn_3: 0.3773 (0.3800)  loss_bbox_dn_3: 0.0912 (0.1062)  loss_giou_dn_3: 0.3833 (0.3926)  loss_vfl_dn_4: 0.3788 (0.3795)  loss_bbox_dn_4: 0.0909 (0.1059)  loss_giou_dn_4: 0.3826 (0.3913)  loss_vfl_dn_5: 0.3769 (0.3786)  loss_bbox_dn_5: 0.0907 (0.1057)  loss_giou_dn_5: 0.3826 (0.3912)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9323  data: 0.6216  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3907  data: 0.1164  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4055 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.656\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [151]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 10.3054 (10.3054)  loss_vfl: 0.4563 (0.4563)  loss_bbox: 0.0710 (0.0710)  loss_giou: 0.2320 (0.2320)  loss_vfl_aux_0: 0.4848 (0.4848)  loss_bbox_aux_0: 0.0813 (0.0813)  loss_giou_aux_0: 0.2620 (0.2620)  loss_vfl_aux_1: 0.4611 (0.4611)  loss_bbox_aux_1: 0.0714 (0.0714)  loss_giou_aux_1: 0.2324 (0.2324)  loss_vfl_aux_2: 0.4628 (0.4628)  loss_bbox_aux_2: 0.0728 (0.0728)  loss_giou_aux_2: 0.2340 (0.2340)  loss_vfl_aux_3: 0.4560 (0.4560)  loss_bbox_aux_3: 0.0751 (0.0751)  loss_giou_aux_3: 0.2460 (0.2460)  loss_vfl_aux_4: 0.4414 (0.4414)  loss_bbox_aux_4: 0.0765 (0.0765)  loss_giou_aux_4: 0.2477 (0.2477)  loss_vfl_aux_5: 0.5404 (0.5404)  loss_bbox_aux_5: 0.1352 (0.1352)  loss_giou_aux_5: 0.4208 (0.4208)  loss_vfl_dn_0: 0.4315 (0.4315)  loss_bbox_dn_0: 0.1889 (0.1889)  loss_giou_dn_0: 0.4711 (0.4711)  loss_vfl_dn_1: 0.3756 (0.3756)  loss_bbox_dn_1: 0.1020 (0.1020)  loss_giou_dn_1: 0.2848 (0.2848)  loss_vfl_dn_2: 0.3541 (0.3541)  loss_bbox_dn_2: 0.0825 (0.0825)  loss_giou_dn_2: 0.2479 (0.2479)  loss_vfl_dn_3: 0.3454 (0.3454)  loss_bbox_dn_3: 0.0788 (0.0788)  loss_giou_dn_3: 0.2442 (0.2442)  loss_vfl_dn_4: 0.3434 (0.3434)  loss_bbox_dn_4: 0.0798 (0.0798)  loss_giou_dn_4: 0.2451 (0.2451)  loss_vfl_dn_5: 0.3442 (0.3442)  loss_bbox_dn_5: 0.0794 (0.0794)  loss_giou_dn_5: 0.2459 (0.2459)  time: 0.9506  data: 0.5278  max mem: 7790\n",
            "Epoch: [151]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.3276 (13.2086)  loss_vfl: 0.4691 (0.5022)  loss_bbox: 0.0876 (0.0956)  loss_giou: 0.3802 (0.3922)  loss_vfl_aux_0: 0.5002 (0.5351)  loss_bbox_aux_0: 0.0896 (0.1092)  loss_giou_aux_0: 0.4291 (0.4294)  loss_vfl_aux_1: 0.4731 (0.5196)  loss_bbox_aux_1: 0.0873 (0.0993)  loss_giou_aux_1: 0.3844 (0.4000)  loss_vfl_aux_2: 0.4886 (0.5187)  loss_bbox_aux_2: 0.0880 (0.0960)  loss_giou_aux_2: 0.3865 (0.3938)  loss_vfl_aux_3: 0.4724 (0.5078)  loss_bbox_aux_3: 0.0870 (0.0942)  loss_giou_aux_3: 0.3840 (0.3930)  loss_vfl_aux_4: 0.4699 (0.5038)  loss_bbox_aux_4: 0.0867 (0.0959)  loss_giou_aux_4: 0.3810 (0.3940)  loss_vfl_aux_5: 0.6016 (0.6018)  loss_bbox_aux_5: 0.1418 (0.1575)  loss_giou_aux_5: 0.5526 (0.5621)  loss_vfl_dn_0: 0.4399 (0.4406)  loss_bbox_dn_0: 0.1508 (0.1771)  loss_giou_dn_0: 0.5624 (0.5814)  loss_vfl_dn_1: 0.3977 (0.3993)  loss_bbox_dn_1: 0.1069 (0.1282)  loss_giou_dn_1: 0.4325 (0.4372)  loss_vfl_dn_2: 0.3821 (0.3876)  loss_bbox_dn_2: 0.1014 (0.1195)  loss_giou_dn_2: 0.4014 (0.4126)  loss_vfl_dn_3: 0.3772 (0.3840)  loss_bbox_dn_3: 0.1012 (0.1178)  loss_giou_dn_3: 0.3907 (0.4083)  loss_vfl_dn_4: 0.3743 (0.3831)  loss_bbox_dn_4: 0.1011 (0.1172)  loss_giou_dn_4: 0.3878 (0.4069)  loss_vfl_dn_5: 0.3751 (0.3828)  loss_bbox_dn_5: 0.1006 (0.1170)  loss_giou_dn_5: 0.3888 (0.4067)  time: 0.3262  data: 0.0149  max mem: 7790\n",
            "Epoch: [151] Total time: 0:00:11 (0.3480 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.3276 (13.2086)  loss_vfl: 0.4691 (0.5022)  loss_bbox: 0.0876 (0.0956)  loss_giou: 0.3802 (0.3922)  loss_vfl_aux_0: 0.5002 (0.5351)  loss_bbox_aux_0: 0.0896 (0.1092)  loss_giou_aux_0: 0.4291 (0.4294)  loss_vfl_aux_1: 0.4731 (0.5196)  loss_bbox_aux_1: 0.0873 (0.0993)  loss_giou_aux_1: 0.3844 (0.4000)  loss_vfl_aux_2: 0.4886 (0.5187)  loss_bbox_aux_2: 0.0880 (0.0960)  loss_giou_aux_2: 0.3865 (0.3938)  loss_vfl_aux_3: 0.4724 (0.5078)  loss_bbox_aux_3: 0.0870 (0.0942)  loss_giou_aux_3: 0.3840 (0.3930)  loss_vfl_aux_4: 0.4699 (0.5038)  loss_bbox_aux_4: 0.0867 (0.0959)  loss_giou_aux_4: 0.3810 (0.3940)  loss_vfl_aux_5: 0.6016 (0.6018)  loss_bbox_aux_5: 0.1418 (0.1575)  loss_giou_aux_5: 0.5526 (0.5621)  loss_vfl_dn_0: 0.4399 (0.4406)  loss_bbox_dn_0: 0.1508 (0.1771)  loss_giou_dn_0: 0.5624 (0.5814)  loss_vfl_dn_1: 0.3977 (0.3993)  loss_bbox_dn_1: 0.1069 (0.1282)  loss_giou_dn_1: 0.4325 (0.4372)  loss_vfl_dn_2: 0.3821 (0.3876)  loss_bbox_dn_2: 0.1014 (0.1195)  loss_giou_dn_2: 0.4014 (0.4126)  loss_vfl_dn_3: 0.3772 (0.3840)  loss_bbox_dn_3: 0.1012 (0.1178)  loss_giou_dn_3: 0.3907 (0.4083)  loss_vfl_dn_4: 0.3743 (0.3831)  loss_bbox_dn_4: 0.1011 (0.1172)  loss_giou_dn_4: 0.3878 (0.4069)  loss_vfl_dn_5: 0.3751 (0.3828)  loss_bbox_dn_5: 0.1006 (0.1170)  loss_giou_dn_5: 0.3888 (0.4067)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8675  data: 0.5592  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3861  data: 0.1131  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4018 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [152]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 10.6685 (10.6685)  loss_vfl: 0.4527 (0.4527)  loss_bbox: 0.0649 (0.0649)  loss_giou: 0.2507 (0.2507)  loss_vfl_aux_0: 0.5293 (0.5293)  loss_bbox_aux_0: 0.0742 (0.0742)  loss_giou_aux_0: 0.2900 (0.2900)  loss_vfl_aux_1: 0.5241 (0.5241)  loss_bbox_aux_1: 0.0661 (0.0661)  loss_giou_aux_1: 0.2465 (0.2465)  loss_vfl_aux_2: 0.4974 (0.4974)  loss_bbox_aux_2: 0.0664 (0.0664)  loss_giou_aux_2: 0.2498 (0.2498)  loss_vfl_aux_3: 0.4717 (0.4717)  loss_bbox_aux_3: 0.0665 (0.0665)  loss_giou_aux_3: 0.2498 (0.2498)  loss_vfl_aux_4: 0.4770 (0.4770)  loss_bbox_aux_4: 0.0656 (0.0656)  loss_giou_aux_4: 0.2510 (0.2510)  loss_vfl_aux_5: 0.5059 (0.5059)  loss_bbox_aux_5: 0.1400 (0.1400)  loss_giou_aux_5: 0.4541 (0.4541)  loss_vfl_dn_0: 0.4494 (0.4494)  loss_bbox_dn_0: 0.1469 (0.1469)  loss_giou_dn_0: 0.4944 (0.4944)  loss_vfl_dn_1: 0.3894 (0.3894)  loss_bbox_dn_1: 0.0855 (0.0855)  loss_giou_dn_1: 0.2902 (0.2902)  loss_vfl_dn_2: 0.3757 (0.3757)  loss_bbox_dn_2: 0.0739 (0.0739)  loss_giou_dn_2: 0.2638 (0.2638)  loss_vfl_dn_3: 0.3716 (0.3716)  loss_bbox_dn_3: 0.0729 (0.0729)  loss_giou_dn_3: 0.2577 (0.2577)  loss_vfl_dn_4: 0.3731 (0.3731)  loss_bbox_dn_4: 0.0721 (0.0721)  loss_giou_dn_4: 0.2576 (0.2576)  loss_vfl_dn_5: 0.3714 (0.3714)  loss_bbox_dn_5: 0.0716 (0.0716)  loss_giou_dn_5: 0.2574 (0.2574)  time: 0.9771  data: 0.4816  max mem: 7790\n",
            "Epoch: [152]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.8928 (13.1805)  loss_vfl: 0.4890 (0.4834)  loss_bbox: 0.0870 (0.0935)  loss_giou: 0.4089 (0.4054)  loss_vfl_aux_0: 0.5074 (0.5143)  loss_bbox_aux_0: 0.0981 (0.1084)  loss_giou_aux_0: 0.4391 (0.4513)  loss_vfl_aux_1: 0.5035 (0.4954)  loss_bbox_aux_1: 0.0950 (0.0984)  loss_giou_aux_1: 0.4334 (0.4179)  loss_vfl_aux_2: 0.5103 (0.4921)  loss_bbox_aux_2: 0.0937 (0.0954)  loss_giou_aux_2: 0.4111 (0.4092)  loss_vfl_aux_3: 0.5027 (0.4840)  loss_bbox_aux_3: 0.0925 (0.0956)  loss_giou_aux_3: 0.4061 (0.4088)  loss_vfl_aux_4: 0.5023 (0.4796)  loss_bbox_aux_4: 0.0915 (0.0954)  loss_giou_aux_4: 0.4101 (0.4080)  loss_vfl_aux_5: 0.5867 (0.5853)  loss_bbox_aux_5: 0.1405 (0.1526)  loss_giou_aux_5: 0.6055 (0.5773)  loss_vfl_dn_0: 0.4315 (0.4371)  loss_bbox_dn_0: 0.1433 (0.1680)  loss_giou_dn_0: 0.5853 (0.6045)  loss_vfl_dn_1: 0.4057 (0.3982)  loss_bbox_dn_1: 0.0989 (0.1179)  loss_giou_dn_1: 0.4330 (0.4508)  loss_vfl_dn_2: 0.3926 (0.3880)  loss_bbox_dn_2: 0.0960 (0.1088)  loss_giou_dn_2: 0.4124 (0.4261)  loss_vfl_dn_3: 0.3906 (0.3834)  loss_bbox_dn_3: 0.0936 (0.1071)  loss_giou_dn_3: 0.4082 (0.4212)  loss_vfl_dn_4: 0.3889 (0.3821)  loss_bbox_dn_4: 0.0929 (0.1067)  loss_giou_dn_4: 0.4083 (0.4208)  loss_vfl_dn_5: 0.3885 (0.3814)  loss_bbox_dn_5: 0.0939 (0.1065)  loss_giou_dn_5: 0.4079 (0.4208)  time: 0.3196  data: 0.0142  max mem: 7790\n",
            "Epoch: [152] Total time: 0:00:11 (0.3494 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.8928 (13.1805)  loss_vfl: 0.4890 (0.4834)  loss_bbox: 0.0870 (0.0935)  loss_giou: 0.4089 (0.4054)  loss_vfl_aux_0: 0.5074 (0.5143)  loss_bbox_aux_0: 0.0981 (0.1084)  loss_giou_aux_0: 0.4391 (0.4513)  loss_vfl_aux_1: 0.5035 (0.4954)  loss_bbox_aux_1: 0.0950 (0.0984)  loss_giou_aux_1: 0.4334 (0.4179)  loss_vfl_aux_2: 0.5103 (0.4921)  loss_bbox_aux_2: 0.0937 (0.0954)  loss_giou_aux_2: 0.4111 (0.4092)  loss_vfl_aux_3: 0.5027 (0.4840)  loss_bbox_aux_3: 0.0925 (0.0956)  loss_giou_aux_3: 0.4061 (0.4088)  loss_vfl_aux_4: 0.5023 (0.4796)  loss_bbox_aux_4: 0.0915 (0.0954)  loss_giou_aux_4: 0.4101 (0.4080)  loss_vfl_aux_5: 0.5867 (0.5853)  loss_bbox_aux_5: 0.1405 (0.1526)  loss_giou_aux_5: 0.6055 (0.5773)  loss_vfl_dn_0: 0.4315 (0.4371)  loss_bbox_dn_0: 0.1433 (0.1680)  loss_giou_dn_0: 0.5853 (0.6045)  loss_vfl_dn_1: 0.4057 (0.3982)  loss_bbox_dn_1: 0.0989 (0.1179)  loss_giou_dn_1: 0.4330 (0.4508)  loss_vfl_dn_2: 0.3926 (0.3880)  loss_bbox_dn_2: 0.0960 (0.1088)  loss_giou_dn_2: 0.4124 (0.4261)  loss_vfl_dn_3: 0.3906 (0.3834)  loss_bbox_dn_3: 0.0936 (0.1071)  loss_giou_dn_3: 0.4082 (0.4212)  loss_vfl_dn_4: 0.3889 (0.3821)  loss_bbox_dn_4: 0.0929 (0.1067)  loss_giou_dn_4: 0.4083 (0.4208)  loss_vfl_dn_5: 0.3885 (0.3814)  loss_bbox_dn_5: 0.0939 (0.1065)  loss_giou_dn_5: 0.4079 (0.4208)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9226  data: 0.6097  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4465  data: 0.1173  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4612 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.662\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.578\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [153]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 11.9308 (11.9308)  loss_vfl: 0.4619 (0.4619)  loss_bbox: 0.0692 (0.0692)  loss_giou: 0.3318 (0.3318)  loss_vfl_aux_0: 0.5240 (0.5240)  loss_bbox_aux_0: 0.0759 (0.0759)  loss_giou_aux_0: 0.3755 (0.3755)  loss_vfl_aux_1: 0.4870 (0.4870)  loss_bbox_aux_1: 0.0689 (0.0689)  loss_giou_aux_1: 0.3534 (0.3534)  loss_vfl_aux_2: 0.4790 (0.4790)  loss_bbox_aux_2: 0.0705 (0.0705)  loss_giou_aux_2: 0.3378 (0.3378)  loss_vfl_aux_3: 0.4718 (0.4718)  loss_bbox_aux_3: 0.0696 (0.0696)  loss_giou_aux_3: 0.3359 (0.3359)  loss_vfl_aux_4: 0.4656 (0.4656)  loss_bbox_aux_4: 0.0697 (0.0697)  loss_giou_aux_4: 0.3327 (0.3327)  loss_vfl_aux_5: 0.5280 (0.5280)  loss_bbox_aux_5: 0.1062 (0.1062)  loss_giou_aux_5: 0.5265 (0.5265)  loss_vfl_dn_0: 0.4599 (0.4599)  loss_bbox_dn_0: 0.1039 (0.1039)  loss_giou_dn_0: 0.5280 (0.5280)  loss_vfl_dn_1: 0.4150 (0.4150)  loss_bbox_dn_1: 0.0795 (0.0795)  loss_giou_dn_1: 0.4070 (0.4070)  loss_vfl_dn_2: 0.4016 (0.4016)  loss_bbox_dn_2: 0.0766 (0.0766)  loss_giou_dn_2: 0.3813 (0.3813)  loss_vfl_dn_3: 0.3939 (0.3939)  loss_bbox_dn_3: 0.0761 (0.0761)  loss_giou_dn_3: 0.3777 (0.3777)  loss_vfl_dn_4: 0.3928 (0.3928)  loss_bbox_dn_4: 0.0762 (0.0762)  loss_giou_dn_4: 0.3755 (0.3755)  loss_vfl_dn_5: 0.3930 (0.3930)  loss_bbox_dn_5: 0.0763 (0.0763)  loss_giou_dn_5: 0.3758 (0.3758)  time: 1.0297  data: 0.6424  max mem: 7790\n",
            "Epoch: [153]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.6995 (13.6486)  loss_vfl: 0.5034 (0.4959)  loss_bbox: 0.1036 (0.0909)  loss_giou: 0.4305 (0.4408)  loss_vfl_aux_0: 0.5196 (0.5199)  loss_bbox_aux_0: 0.1126 (0.1035)  loss_giou_aux_0: 0.4819 (0.4857)  loss_vfl_aux_1: 0.5097 (0.5090)  loss_bbox_aux_1: 0.0970 (0.0925)  loss_giou_aux_1: 0.4538 (0.4508)  loss_vfl_aux_2: 0.5059 (0.5063)  loss_bbox_aux_2: 0.0999 (0.0915)  loss_giou_aux_2: 0.4509 (0.4434)  loss_vfl_aux_3: 0.5051 (0.5040)  loss_bbox_aux_3: 0.0990 (0.0897)  loss_giou_aux_3: 0.4428 (0.4413)  loss_vfl_aux_4: 0.4915 (0.4966)  loss_bbox_aux_4: 0.1038 (0.0912)  loss_giou_aux_4: 0.4315 (0.4409)  loss_vfl_aux_5: 0.5923 (0.5810)  loss_bbox_aux_5: 0.1520 (0.1362)  loss_giou_aux_5: 0.5876 (0.5967)  loss_vfl_dn_0: 0.4393 (0.4393)  loss_bbox_dn_0: 0.1604 (0.1554)  loss_giou_dn_0: 0.6192 (0.6259)  loss_vfl_dn_1: 0.4008 (0.4034)  loss_bbox_dn_1: 0.1151 (0.1115)  loss_giou_dn_1: 0.4617 (0.4875)  loss_vfl_dn_2: 0.3966 (0.3939)  loss_bbox_dn_2: 0.1044 (0.1050)  loss_giou_dn_2: 0.4345 (0.4648)  loss_vfl_dn_3: 0.3927 (0.3903)  loss_bbox_dn_3: 0.1031 (0.1036)  loss_giou_dn_3: 0.4280 (0.4595)  loss_vfl_dn_4: 0.3852 (0.3895)  loss_bbox_dn_4: 0.1028 (0.1030)  loss_giou_dn_4: 0.4263 (0.4577)  loss_vfl_dn_5: 0.3820 (0.3893)  loss_bbox_dn_5: 0.1028 (0.1029)  loss_giou_dn_5: 0.4267 (0.4582)  time: 0.3262  data: 0.0149  max mem: 7790\n",
            "Epoch: [153] Total time: 0:00:11 (0.3533 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.6995 (13.6486)  loss_vfl: 0.5034 (0.4959)  loss_bbox: 0.1036 (0.0909)  loss_giou: 0.4305 (0.4408)  loss_vfl_aux_0: 0.5196 (0.5199)  loss_bbox_aux_0: 0.1126 (0.1035)  loss_giou_aux_0: 0.4819 (0.4857)  loss_vfl_aux_1: 0.5097 (0.5090)  loss_bbox_aux_1: 0.0970 (0.0925)  loss_giou_aux_1: 0.4538 (0.4508)  loss_vfl_aux_2: 0.5059 (0.5063)  loss_bbox_aux_2: 0.0999 (0.0915)  loss_giou_aux_2: 0.4509 (0.4434)  loss_vfl_aux_3: 0.5051 (0.5040)  loss_bbox_aux_3: 0.0990 (0.0897)  loss_giou_aux_3: 0.4428 (0.4413)  loss_vfl_aux_4: 0.4915 (0.4966)  loss_bbox_aux_4: 0.1038 (0.0912)  loss_giou_aux_4: 0.4315 (0.4409)  loss_vfl_aux_5: 0.5923 (0.5810)  loss_bbox_aux_5: 0.1520 (0.1362)  loss_giou_aux_5: 0.5876 (0.5967)  loss_vfl_dn_0: 0.4393 (0.4393)  loss_bbox_dn_0: 0.1604 (0.1554)  loss_giou_dn_0: 0.6192 (0.6259)  loss_vfl_dn_1: 0.4008 (0.4034)  loss_bbox_dn_1: 0.1151 (0.1115)  loss_giou_dn_1: 0.4617 (0.4875)  loss_vfl_dn_2: 0.3966 (0.3939)  loss_bbox_dn_2: 0.1044 (0.1050)  loss_giou_dn_2: 0.4345 (0.4648)  loss_vfl_dn_3: 0.3927 (0.3903)  loss_bbox_dn_3: 0.1031 (0.1036)  loss_giou_dn_3: 0.4280 (0.4595)  loss_vfl_dn_4: 0.3852 (0.3895)  loss_bbox_dn_4: 0.1028 (0.1030)  loss_giou_dn_4: 0.4263 (0.4577)  loss_vfl_dn_5: 0.3820 (0.3893)  loss_bbox_dn_5: 0.1028 (0.1029)  loss_giou_dn_5: 0.4267 (0.4582)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9319  data: 0.6123  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4484  data: 0.1141  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4643 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.677\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.579\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [154]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 14.9615 (14.9615)  loss_vfl: 0.5924 (0.5924)  loss_bbox: 0.0962 (0.0962)  loss_giou: 0.4654 (0.4654)  loss_vfl_aux_0: 0.5747 (0.5747)  loss_bbox_aux_0: 0.1065 (0.1065)  loss_giou_aux_0: 0.4784 (0.4784)  loss_vfl_aux_1: 0.6136 (0.6136)  loss_bbox_aux_1: 0.0998 (0.0998)  loss_giou_aux_1: 0.4771 (0.4771)  loss_vfl_aux_2: 0.6411 (0.6411)  loss_bbox_aux_2: 0.0924 (0.0924)  loss_giou_aux_2: 0.4566 (0.4566)  loss_vfl_aux_3: 0.6140 (0.6140)  loss_bbox_aux_3: 0.0947 (0.0947)  loss_giou_aux_3: 0.4594 (0.4594)  loss_vfl_aux_4: 0.5908 (0.5908)  loss_bbox_aux_4: 0.0966 (0.0966)  loss_giou_aux_4: 0.4661 (0.4661)  loss_vfl_aux_5: 0.6256 (0.6256)  loss_bbox_aux_5: 0.1545 (0.1545)  loss_giou_aux_5: 0.5564 (0.5564)  loss_vfl_dn_0: 0.4584 (0.4584)  loss_bbox_dn_0: 0.1754 (0.1754)  loss_giou_dn_0: 0.6725 (0.6725)  loss_vfl_dn_1: 0.4291 (0.4291)  loss_bbox_dn_1: 0.1240 (0.1240)  loss_giou_dn_1: 0.5344 (0.5344)  loss_vfl_dn_2: 0.4250 (0.4250)  loss_bbox_dn_2: 0.1147 (0.1147)  loss_giou_dn_2: 0.5139 (0.5139)  loss_vfl_dn_3: 0.4242 (0.4242)  loss_bbox_dn_3: 0.1151 (0.1151)  loss_giou_dn_3: 0.5157 (0.5157)  loss_vfl_dn_4: 0.4204 (0.4204)  loss_bbox_dn_4: 0.1149 (0.1149)  loss_giou_dn_4: 0.5170 (0.5170)  loss_vfl_dn_5: 0.4217 (0.4217)  loss_bbox_dn_5: 0.1148 (0.1148)  loss_giou_dn_5: 0.5178 (0.5178)  time: 0.9806  data: 0.5268  max mem: 7790\n",
            "Epoch: [154]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.0381 (13.1053)  loss_vfl: 0.4789 (0.4963)  loss_bbox: 0.0817 (0.0950)  loss_giou: 0.4011 (0.3786)  loss_vfl_aux_0: 0.5259 (0.5270)  loss_bbox_aux_0: 0.1010 (0.1124)  loss_giou_aux_0: 0.4465 (0.4302)  loss_vfl_aux_1: 0.5054 (0.5098)  loss_bbox_aux_1: 0.0887 (0.1008)  loss_giou_aux_1: 0.4081 (0.3928)  loss_vfl_aux_2: 0.4956 (0.5024)  loss_bbox_aux_2: 0.0812 (0.0964)  loss_giou_aux_2: 0.3910 (0.3848)  loss_vfl_aux_3: 0.4819 (0.4994)  loss_bbox_aux_3: 0.0825 (0.0951)  loss_giou_aux_3: 0.3905 (0.3804)  loss_vfl_aux_4: 0.4802 (0.4951)  loss_bbox_aux_4: 0.0839 (0.0957)  loss_giou_aux_4: 0.3974 (0.3795)  loss_vfl_aux_5: 0.5671 (0.5917)  loss_bbox_aux_5: 0.1319 (0.1630)  loss_giou_aux_5: 0.5947 (0.5732)  loss_vfl_dn_0: 0.4368 (0.4404)  loss_bbox_dn_0: 0.1392 (0.1768)  loss_giou_dn_0: 0.5782 (0.5948)  loss_vfl_dn_1: 0.4048 (0.4028)  loss_bbox_dn_1: 0.0998 (0.1249)  loss_giou_dn_1: 0.4530 (0.4389)  loss_vfl_dn_2: 0.3892 (0.3894)  loss_bbox_dn_2: 0.0931 (0.1154)  loss_giou_dn_2: 0.4295 (0.4117)  loss_vfl_dn_3: 0.3850 (0.3856)  loss_bbox_dn_3: 0.0915 (0.1135)  loss_giou_dn_3: 0.4210 (0.4063)  loss_vfl_dn_4: 0.3812 (0.3848)  loss_bbox_dn_4: 0.0910 (0.1133)  loss_giou_dn_4: 0.4183 (0.4052)  loss_vfl_dn_5: 0.3801 (0.3844)  loss_bbox_dn_5: 0.0918 (0.1132)  loss_giou_dn_5: 0.4166 (0.4044)  time: 0.3257  data: 0.0141  max mem: 7790\n",
            "Epoch: [154] Total time: 0:00:11 (0.3543 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.0381 (13.1053)  loss_vfl: 0.4789 (0.4963)  loss_bbox: 0.0817 (0.0950)  loss_giou: 0.4011 (0.3786)  loss_vfl_aux_0: 0.5259 (0.5270)  loss_bbox_aux_0: 0.1010 (0.1124)  loss_giou_aux_0: 0.4465 (0.4302)  loss_vfl_aux_1: 0.5054 (0.5098)  loss_bbox_aux_1: 0.0887 (0.1008)  loss_giou_aux_1: 0.4081 (0.3928)  loss_vfl_aux_2: 0.4956 (0.5024)  loss_bbox_aux_2: 0.0812 (0.0964)  loss_giou_aux_2: 0.3910 (0.3848)  loss_vfl_aux_3: 0.4819 (0.4994)  loss_bbox_aux_3: 0.0825 (0.0951)  loss_giou_aux_3: 0.3905 (0.3804)  loss_vfl_aux_4: 0.4802 (0.4951)  loss_bbox_aux_4: 0.0839 (0.0957)  loss_giou_aux_4: 0.3974 (0.3795)  loss_vfl_aux_5: 0.5671 (0.5917)  loss_bbox_aux_5: 0.1319 (0.1630)  loss_giou_aux_5: 0.5947 (0.5732)  loss_vfl_dn_0: 0.4368 (0.4404)  loss_bbox_dn_0: 0.1392 (0.1768)  loss_giou_dn_0: 0.5782 (0.5948)  loss_vfl_dn_1: 0.4048 (0.4028)  loss_bbox_dn_1: 0.0998 (0.1249)  loss_giou_dn_1: 0.4530 (0.4389)  loss_vfl_dn_2: 0.3892 (0.3894)  loss_bbox_dn_2: 0.0931 (0.1154)  loss_giou_dn_2: 0.4295 (0.4117)  loss_vfl_dn_3: 0.3850 (0.3856)  loss_bbox_dn_3: 0.0915 (0.1135)  loss_giou_dn_3: 0.4210 (0.4063)  loss_vfl_dn_4: 0.3812 (0.3848)  loss_bbox_dn_4: 0.0910 (0.1133)  loss_giou_dn_4: 0.4183 (0.4052)  loss_vfl_dn_5: 0.3801 (0.3844)  loss_bbox_dn_5: 0.0918 (0.1132)  loss_giou_dn_5: 0.4166 (0.4044)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9042  data: 0.5948  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3874  data: 0.1144  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4004 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.658\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [155]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 14.7748 (14.7748)  loss_vfl: 0.4683 (0.4683)  loss_bbox: 0.0804 (0.0804)  loss_giou: 0.5539 (0.5539)  loss_vfl_aux_0: 0.4908 (0.4908)  loss_bbox_aux_0: 0.0991 (0.0991)  loss_giou_aux_0: 0.5977 (0.5977)  loss_vfl_aux_1: 0.4701 (0.4701)  loss_bbox_aux_1: 0.0886 (0.0886)  loss_giou_aux_1: 0.5713 (0.5713)  loss_vfl_aux_2: 0.4649 (0.4649)  loss_bbox_aux_2: 0.0898 (0.0898)  loss_giou_aux_2: 0.5760 (0.5760)  loss_vfl_aux_3: 0.4653 (0.4653)  loss_bbox_aux_3: 0.0891 (0.0891)  loss_giou_aux_3: 0.5724 (0.5724)  loss_vfl_aux_4: 0.4573 (0.4573)  loss_bbox_aux_4: 0.0821 (0.0821)  loss_giou_aux_4: 0.5621 (0.5621)  loss_vfl_aux_5: 0.5123 (0.5123)  loss_bbox_aux_5: 0.1543 (0.1543)  loss_giou_aux_5: 0.7276 (0.7276)  loss_vfl_dn_0: 0.4473 (0.4473)  loss_bbox_dn_0: 0.1329 (0.1329)  loss_giou_dn_0: 0.7126 (0.7126)  loss_vfl_dn_1: 0.4204 (0.4204)  loss_bbox_dn_1: 0.0955 (0.0955)  loss_giou_dn_1: 0.5857 (0.5857)  loss_vfl_dn_2: 0.4115 (0.4115)  loss_bbox_dn_2: 0.0866 (0.0866)  loss_giou_dn_2: 0.5594 (0.5594)  loss_vfl_dn_3: 0.4181 (0.4181)  loss_bbox_dn_3: 0.0847 (0.0847)  loss_giou_dn_3: 0.5510 (0.5510)  loss_vfl_dn_4: 0.4146 (0.4146)  loss_bbox_dn_4: 0.0847 (0.0847)  loss_giou_dn_4: 0.5483 (0.5483)  loss_vfl_dn_5: 0.4153 (0.4153)  loss_bbox_dn_5: 0.0847 (0.0847)  loss_giou_dn_5: 0.5480 (0.5480)  time: 1.0274  data: 0.6616  max mem: 7790\n",
            "Epoch: [155]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.6898 (13.2812)  loss_vfl: 0.4589 (0.4873)  loss_bbox: 0.0905 (0.0954)  loss_giou: 0.3642 (0.4034)  loss_vfl_aux_0: 0.4986 (0.5203)  loss_bbox_aux_0: 0.1046 (0.1135)  loss_giou_aux_0: 0.4374 (0.4552)  loss_vfl_aux_1: 0.4856 (0.5124)  loss_bbox_aux_1: 0.0945 (0.0964)  loss_giou_aux_1: 0.3850 (0.4165)  loss_vfl_aux_2: 0.4709 (0.5056)  loss_bbox_aux_2: 0.0905 (0.0933)  loss_giou_aux_2: 0.3670 (0.4064)  loss_vfl_aux_3: 0.4648 (0.4976)  loss_bbox_aux_3: 0.0899 (0.0929)  loss_giou_aux_3: 0.3653 (0.4029)  loss_vfl_aux_4: 0.4695 (0.4945)  loss_bbox_aux_4: 0.0909 (0.0931)  loss_giou_aux_4: 0.3656 (0.4006)  loss_vfl_aux_5: 0.5811 (0.5857)  loss_bbox_aux_5: 0.1367 (0.1549)  loss_giou_aux_5: 0.5633 (0.5799)  loss_vfl_dn_0: 0.4401 (0.4367)  loss_bbox_dn_0: 0.1637 (0.1684)  loss_giou_dn_0: 0.5927 (0.6103)  loss_vfl_dn_1: 0.3961 (0.3991)  loss_bbox_dn_1: 0.1112 (0.1197)  loss_giou_dn_1: 0.4162 (0.4595)  loss_vfl_dn_2: 0.3874 (0.3871)  loss_bbox_dn_2: 0.1027 (0.1110)  loss_giou_dn_2: 0.3835 (0.4320)  loss_vfl_dn_3: 0.3823 (0.3842)  loss_bbox_dn_3: 0.1009 (0.1091)  loss_giou_dn_3: 0.3794 (0.4258)  loss_vfl_dn_4: 0.3791 (0.3819)  loss_bbox_dn_4: 0.1009 (0.1087)  loss_giou_dn_4: 0.3791 (0.4246)  loss_vfl_dn_5: 0.3767 (0.3819)  loss_bbox_dn_5: 0.1016 (0.1086)  loss_giou_dn_5: 0.3806 (0.4248)  time: 0.3444  data: 0.0141  max mem: 7790\n",
            "Epoch: [155] Total time: 0:00:11 (0.3624 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.6898 (13.2812)  loss_vfl: 0.4589 (0.4873)  loss_bbox: 0.0905 (0.0954)  loss_giou: 0.3642 (0.4034)  loss_vfl_aux_0: 0.4986 (0.5203)  loss_bbox_aux_0: 0.1046 (0.1135)  loss_giou_aux_0: 0.4374 (0.4552)  loss_vfl_aux_1: 0.4856 (0.5124)  loss_bbox_aux_1: 0.0945 (0.0964)  loss_giou_aux_1: 0.3850 (0.4165)  loss_vfl_aux_2: 0.4709 (0.5056)  loss_bbox_aux_2: 0.0905 (0.0933)  loss_giou_aux_2: 0.3670 (0.4064)  loss_vfl_aux_3: 0.4648 (0.4976)  loss_bbox_aux_3: 0.0899 (0.0929)  loss_giou_aux_3: 0.3653 (0.4029)  loss_vfl_aux_4: 0.4695 (0.4945)  loss_bbox_aux_4: 0.0909 (0.0931)  loss_giou_aux_4: 0.3656 (0.4006)  loss_vfl_aux_5: 0.5811 (0.5857)  loss_bbox_aux_5: 0.1367 (0.1549)  loss_giou_aux_5: 0.5633 (0.5799)  loss_vfl_dn_0: 0.4401 (0.4367)  loss_bbox_dn_0: 0.1637 (0.1684)  loss_giou_dn_0: 0.5927 (0.6103)  loss_vfl_dn_1: 0.3961 (0.3991)  loss_bbox_dn_1: 0.1112 (0.1197)  loss_giou_dn_1: 0.4162 (0.4595)  loss_vfl_dn_2: 0.3874 (0.3871)  loss_bbox_dn_2: 0.1027 (0.1110)  loss_giou_dn_2: 0.3835 (0.4320)  loss_vfl_dn_3: 0.3823 (0.3842)  loss_bbox_dn_3: 0.1009 (0.1091)  loss_giou_dn_3: 0.3794 (0.4258)  loss_vfl_dn_4: 0.3791 (0.3819)  loss_bbox_dn_4: 0.1009 (0.1087)  loss_giou_dn_4: 0.3791 (0.4246)  loss_vfl_dn_5: 0.3767 (0.3819)  loss_bbox_dn_5: 0.1016 (0.1086)  loss_giou_dn_5: 0.3806 (0.4248)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9109  data: 0.6020  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3882  data: 0.1124  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4011 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.574\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [156]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 15.3615 (15.3615)  loss_vfl: 0.5861 (0.5861)  loss_bbox: 0.2100 (0.2100)  loss_giou: 0.2954 (0.2954)  loss_vfl_aux_0: 0.7283 (0.7283)  loss_bbox_aux_0: 0.2645 (0.2645)  loss_giou_aux_0: 0.3607 (0.3607)  loss_vfl_aux_1: 0.6370 (0.6370)  loss_bbox_aux_1: 0.2257 (0.2257)  loss_giou_aux_1: 0.3070 (0.3070)  loss_vfl_aux_2: 0.6032 (0.6032)  loss_bbox_aux_2: 0.2238 (0.2238)  loss_giou_aux_2: 0.3065 (0.3065)  loss_vfl_aux_3: 0.5726 (0.5726)  loss_bbox_aux_3: 0.2163 (0.2163)  loss_giou_aux_3: 0.3035 (0.3035)  loss_vfl_aux_4: 0.5950 (0.5950)  loss_bbox_aux_4: 0.2101 (0.2101)  loss_giou_aux_4: 0.2952 (0.2952)  loss_vfl_aux_5: 0.7853 (0.7853)  loss_bbox_aux_5: 0.5198 (0.5198)  loss_giou_aux_5: 0.6620 (0.6620)  loss_vfl_dn_0: 0.4334 (0.4334)  loss_bbox_dn_0: 0.4155 (0.4155)  loss_giou_dn_0: 0.5268 (0.5268)  loss_vfl_dn_1: 0.3794 (0.3794)  loss_bbox_dn_1: 0.3015 (0.3015)  loss_giou_dn_1: 0.3735 (0.3735)  loss_vfl_dn_2: 0.3749 (0.3749)  loss_bbox_dn_2: 0.3000 (0.3000)  loss_giou_dn_2: 0.3664 (0.3664)  loss_vfl_dn_3: 0.3598 (0.3598)  loss_bbox_dn_3: 0.2918 (0.2918)  loss_giou_dn_3: 0.3489 (0.3489)  loss_vfl_dn_4: 0.3571 (0.3571)  loss_bbox_dn_4: 0.2890 (0.2890)  loss_giou_dn_4: 0.3431 (0.3431)  loss_vfl_dn_5: 0.3576 (0.3576)  loss_bbox_dn_5: 0.2900 (0.2900)  loss_giou_dn_5: 0.3451 (0.3451)  time: 1.0883  data: 0.7180  max mem: 7790\n",
            "Epoch: [156]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.4735 (13.2855)  loss_vfl: 0.4596 (0.4819)  loss_bbox: 0.0886 (0.1010)  loss_giou: 0.3700 (0.4031)  loss_vfl_aux_0: 0.4980 (0.5209)  loss_bbox_aux_0: 0.0978 (0.1155)  loss_giou_aux_0: 0.4205 (0.4493)  loss_vfl_aux_1: 0.4754 (0.5067)  loss_bbox_aux_1: 0.0902 (0.1030)  loss_giou_aux_1: 0.3604 (0.4132)  loss_vfl_aux_2: 0.4774 (0.4989)  loss_bbox_aux_2: 0.0876 (0.1018)  loss_giou_aux_2: 0.3595 (0.4044)  loss_vfl_aux_3: 0.4648 (0.4923)  loss_bbox_aux_3: 0.0880 (0.1013)  loss_giou_aux_3: 0.3641 (0.4021)  loss_vfl_aux_4: 0.4563 (0.4837)  loss_bbox_aux_4: 0.0917 (0.1016)  loss_giou_aux_4: 0.3650 (0.4033)  loss_vfl_aux_5: 0.5518 (0.5827)  loss_bbox_aux_5: 0.1330 (0.1588)  loss_giou_aux_5: 0.5480 (0.5783)  loss_vfl_dn_0: 0.4348 (0.4364)  loss_bbox_dn_0: 0.1478 (0.1760)  loss_giou_dn_0: 0.5885 (0.6077)  loss_vfl_dn_1: 0.3908 (0.3959)  loss_bbox_dn_1: 0.1081 (0.1256)  loss_giou_dn_1: 0.4244 (0.4574)  loss_vfl_dn_2: 0.3782 (0.3848)  loss_bbox_dn_2: 0.1011 (0.1164)  loss_giou_dn_2: 0.4042 (0.4302)  loss_vfl_dn_3: 0.3751 (0.3804)  loss_bbox_dn_3: 0.0971 (0.1146)  loss_giou_dn_3: 0.4021 (0.4245)  loss_vfl_dn_4: 0.3733 (0.3787)  loss_bbox_dn_4: 0.0956 (0.1144)  loss_giou_dn_4: 0.3996 (0.4229)  loss_vfl_dn_5: 0.3734 (0.3780)  loss_bbox_dn_5: 0.0959 (0.1144)  loss_giou_dn_5: 0.4007 (0.4229)  time: 0.3277  data: 0.0153  max mem: 7790\n",
            "Epoch: [156] Total time: 0:00:11 (0.3577 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.4735 (13.2855)  loss_vfl: 0.4596 (0.4819)  loss_bbox: 0.0886 (0.1010)  loss_giou: 0.3700 (0.4031)  loss_vfl_aux_0: 0.4980 (0.5209)  loss_bbox_aux_0: 0.0978 (0.1155)  loss_giou_aux_0: 0.4205 (0.4493)  loss_vfl_aux_1: 0.4754 (0.5067)  loss_bbox_aux_1: 0.0902 (0.1030)  loss_giou_aux_1: 0.3604 (0.4132)  loss_vfl_aux_2: 0.4774 (0.4989)  loss_bbox_aux_2: 0.0876 (0.1018)  loss_giou_aux_2: 0.3595 (0.4044)  loss_vfl_aux_3: 0.4648 (0.4923)  loss_bbox_aux_3: 0.0880 (0.1013)  loss_giou_aux_3: 0.3641 (0.4021)  loss_vfl_aux_4: 0.4563 (0.4837)  loss_bbox_aux_4: 0.0917 (0.1016)  loss_giou_aux_4: 0.3650 (0.4033)  loss_vfl_aux_5: 0.5518 (0.5827)  loss_bbox_aux_5: 0.1330 (0.1588)  loss_giou_aux_5: 0.5480 (0.5783)  loss_vfl_dn_0: 0.4348 (0.4364)  loss_bbox_dn_0: 0.1478 (0.1760)  loss_giou_dn_0: 0.5885 (0.6077)  loss_vfl_dn_1: 0.3908 (0.3959)  loss_bbox_dn_1: 0.1081 (0.1256)  loss_giou_dn_1: 0.4244 (0.4574)  loss_vfl_dn_2: 0.3782 (0.3848)  loss_bbox_dn_2: 0.1011 (0.1164)  loss_giou_dn_2: 0.4042 (0.4302)  loss_vfl_dn_3: 0.3751 (0.3804)  loss_bbox_dn_3: 0.0971 (0.1146)  loss_giou_dn_3: 0.4021 (0.4245)  loss_vfl_dn_4: 0.3733 (0.3787)  loss_bbox_dn_4: 0.0956 (0.1144)  loss_giou_dn_4: 0.3996 (0.4229)  loss_vfl_dn_5: 0.3734 (0.3780)  loss_bbox_dn_5: 0.0959 (0.1144)  loss_giou_dn_5: 0.4007 (0.4229)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8658  data: 0.5533  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3956  data: 0.1159  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4102 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.673\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.404\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [157]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 13.1789 (13.1789)  loss_vfl: 0.4800 (0.4800)  loss_bbox: 0.0885 (0.0885)  loss_giou: 0.4414 (0.4414)  loss_vfl_aux_0: 0.4898 (0.4898)  loss_bbox_aux_0: 0.0967 (0.0967)  loss_giou_aux_0: 0.4393 (0.4393)  loss_vfl_aux_1: 0.4715 (0.4715)  loss_bbox_aux_1: 0.0962 (0.0962)  loss_giou_aux_1: 0.4457 (0.4457)  loss_vfl_aux_2: 0.4830 (0.4830)  loss_bbox_aux_2: 0.0906 (0.0906)  loss_giou_aux_2: 0.4449 (0.4449)  loss_vfl_aux_3: 0.4766 (0.4766)  loss_bbox_aux_3: 0.0919 (0.0919)  loss_giou_aux_3: 0.4445 (0.4445)  loss_vfl_aux_4: 0.4770 (0.4770)  loss_bbox_aux_4: 0.0904 (0.0904)  loss_giou_aux_4: 0.4390 (0.4390)  loss_vfl_aux_5: 0.5450 (0.5450)  loss_bbox_aux_5: 0.1630 (0.1630)  loss_giou_aux_5: 0.6167 (0.6167)  loss_vfl_dn_0: 0.4227 (0.4227)  loss_bbox_dn_0: 0.1357 (0.1357)  loss_giou_dn_0: 0.5994 (0.5994)  loss_vfl_dn_1: 0.3855 (0.3855)  loss_bbox_dn_1: 0.0986 (0.0986)  loss_giou_dn_1: 0.4572 (0.4572)  loss_vfl_dn_2: 0.3789 (0.3789)  loss_bbox_dn_2: 0.0940 (0.0940)  loss_giou_dn_2: 0.4420 (0.4420)  loss_vfl_dn_3: 0.3803 (0.3803)  loss_bbox_dn_3: 0.0942 (0.0942)  loss_giou_dn_3: 0.4437 (0.4437)  loss_vfl_dn_4: 0.3803 (0.3803)  loss_bbox_dn_4: 0.0934 (0.0934)  loss_giou_dn_4: 0.4429 (0.4429)  loss_vfl_dn_5: 0.3825 (0.3825)  loss_bbox_dn_5: 0.0929 (0.0929)  loss_giou_dn_5: 0.4431 (0.4431)  time: 1.0215  data: 0.6117  max mem: 7790\n",
            "Epoch: [157]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.6204 (12.9474)  loss_vfl: 0.4750 (0.4818)  loss_bbox: 0.0828 (0.0914)  loss_giou: 0.3794 (0.3907)  loss_vfl_aux_0: 0.4931 (0.5011)  loss_bbox_aux_0: 0.0990 (0.1050)  loss_giou_aux_0: 0.4307 (0.4311)  loss_vfl_aux_1: 0.4812 (0.4976)  loss_bbox_aux_1: 0.0901 (0.0957)  loss_giou_aux_1: 0.3809 (0.4022)  loss_vfl_aux_2: 0.4662 (0.4942)  loss_bbox_aux_2: 0.0901 (0.0933)  loss_giou_aux_2: 0.3803 (0.3949)  loss_vfl_aux_3: 0.4759 (0.4918)  loss_bbox_aux_3: 0.0883 (0.0916)  loss_giou_aux_3: 0.3784 (0.3914)  loss_vfl_aux_4: 0.4644 (0.4812)  loss_bbox_aux_4: 0.0847 (0.0912)  loss_giou_aux_4: 0.3805 (0.3916)  loss_vfl_aux_5: 0.5830 (0.5869)  loss_bbox_aux_5: 0.1396 (0.1508)  loss_giou_aux_5: 0.5244 (0.5632)  loss_vfl_dn_0: 0.4313 (0.4357)  loss_bbox_dn_0: 0.1444 (0.1613)  loss_giou_dn_0: 0.5719 (0.5940)  loss_vfl_dn_1: 0.3882 (0.3957)  loss_bbox_dn_1: 0.0930 (0.1138)  loss_giou_dn_1: 0.4353 (0.4443)  loss_vfl_dn_2: 0.3772 (0.3845)  loss_bbox_dn_2: 0.0853 (0.1048)  loss_giou_dn_2: 0.4139 (0.4180)  loss_vfl_dn_3: 0.3781 (0.3809)  loss_bbox_dn_3: 0.0836 (0.1027)  loss_giou_dn_3: 0.4074 (0.4108)  loss_vfl_dn_4: 0.3759 (0.3797)  loss_bbox_dn_4: 0.0832 (0.1020)  loss_giou_dn_4: 0.4064 (0.4097)  loss_vfl_dn_5: 0.3777 (0.3799)  loss_bbox_dn_5: 0.0832 (0.1017)  loss_giou_dn_5: 0.4067 (0.4092)  time: 0.3204  data: 0.0144  max mem: 7790\n",
            "Epoch: [157] Total time: 0:00:11 (0.3456 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.6204 (12.9474)  loss_vfl: 0.4750 (0.4818)  loss_bbox: 0.0828 (0.0914)  loss_giou: 0.3794 (0.3907)  loss_vfl_aux_0: 0.4931 (0.5011)  loss_bbox_aux_0: 0.0990 (0.1050)  loss_giou_aux_0: 0.4307 (0.4311)  loss_vfl_aux_1: 0.4812 (0.4976)  loss_bbox_aux_1: 0.0901 (0.0957)  loss_giou_aux_1: 0.3809 (0.4022)  loss_vfl_aux_2: 0.4662 (0.4942)  loss_bbox_aux_2: 0.0901 (0.0933)  loss_giou_aux_2: 0.3803 (0.3949)  loss_vfl_aux_3: 0.4759 (0.4918)  loss_bbox_aux_3: 0.0883 (0.0916)  loss_giou_aux_3: 0.3784 (0.3914)  loss_vfl_aux_4: 0.4644 (0.4812)  loss_bbox_aux_4: 0.0847 (0.0912)  loss_giou_aux_4: 0.3805 (0.3916)  loss_vfl_aux_5: 0.5830 (0.5869)  loss_bbox_aux_5: 0.1396 (0.1508)  loss_giou_aux_5: 0.5244 (0.5632)  loss_vfl_dn_0: 0.4313 (0.4357)  loss_bbox_dn_0: 0.1444 (0.1613)  loss_giou_dn_0: 0.5719 (0.5940)  loss_vfl_dn_1: 0.3882 (0.3957)  loss_bbox_dn_1: 0.0930 (0.1138)  loss_giou_dn_1: 0.4353 (0.4443)  loss_vfl_dn_2: 0.3772 (0.3845)  loss_bbox_dn_2: 0.0853 (0.1048)  loss_giou_dn_2: 0.4139 (0.4180)  loss_vfl_dn_3: 0.3781 (0.3809)  loss_bbox_dn_3: 0.0836 (0.1027)  loss_giou_dn_3: 0.4074 (0.4108)  loss_vfl_dn_4: 0.3759 (0.3797)  loss_bbox_dn_4: 0.0832 (0.1020)  loss_giou_dn_4: 0.4064 (0.4097)  loss_vfl_dn_5: 0.3777 (0.3799)  loss_bbox_dn_5: 0.0832 (0.1017)  loss_giou_dn_5: 0.4067 (0.4092)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9156  data: 0.5957  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3923  data: 0.1160  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4048 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.404\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            "best_stat:  {'epoch': 145, 'coco_eval_bbox': 0.35552773047010094}\n",
            "Epoch: [158]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 13.0991 (13.0991)  loss_vfl: 0.5476 (0.5476)  loss_bbox: 0.0593 (0.0593)  loss_giou: 0.4281 (0.4281)  loss_vfl_aux_0: 0.5432 (0.5432)  loss_bbox_aux_0: 0.0646 (0.0646)  loss_giou_aux_0: 0.4690 (0.4690)  loss_vfl_aux_1: 0.5485 (0.5485)  loss_bbox_aux_1: 0.0645 (0.0645)  loss_giou_aux_1: 0.4526 (0.4526)  loss_vfl_aux_2: 0.5387 (0.5387)  loss_bbox_aux_2: 0.0567 (0.0567)  loss_giou_aux_2: 0.4233 (0.4233)  loss_vfl_aux_3: 0.5294 (0.5294)  loss_bbox_aux_3: 0.0591 (0.0591)  loss_giou_aux_3: 0.4269 (0.4269)  loss_vfl_aux_4: 0.5339 (0.5339)  loss_bbox_aux_4: 0.0591 (0.0591)  loss_giou_aux_4: 0.4256 (0.4256)  loss_vfl_aux_5: 0.5914 (0.5914)  loss_bbox_aux_5: 0.0884 (0.0884)  loss_giou_aux_5: 0.5404 (0.5404)  loss_vfl_dn_0: 0.4299 (0.4299)  loss_bbox_dn_0: 0.1212 (0.1212)  loss_giou_dn_0: 0.6436 (0.6436)  loss_vfl_dn_1: 0.4024 (0.4024)  loss_bbox_dn_1: 0.0764 (0.0764)  loss_giou_dn_1: 0.4911 (0.4911)  loss_vfl_dn_2: 0.3858 (0.3858)  loss_bbox_dn_2: 0.0615 (0.0615)  loss_giou_dn_2: 0.4317 (0.4317)  loss_vfl_dn_3: 0.3864 (0.3864)  loss_bbox_dn_3: 0.0595 (0.0595)  loss_giou_dn_3: 0.4251 (0.4251)  loss_vfl_dn_4: 0.3831 (0.3831)  loss_bbox_dn_4: 0.0580 (0.0580)  loss_giou_dn_4: 0.4226 (0.4226)  loss_vfl_dn_5: 0.3871 (0.3871)  loss_bbox_dn_5: 0.0583 (0.0583)  loss_giou_dn_5: 0.4249 (0.4249)  time: 0.9940  data: 0.5598  max mem: 7790\n",
            "Epoch: [158]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.4560 (13.9204)  loss_vfl: 0.5082 (0.5151)  loss_bbox: 0.0792 (0.0982)  loss_giou: 0.4031 (0.4384)  loss_vfl_aux_0: 0.5220 (0.5309)  loss_bbox_aux_0: 0.0926 (0.1147)  loss_giou_aux_0: 0.4480 (0.4842)  loss_vfl_aux_1: 0.5216 (0.5277)  loss_bbox_aux_1: 0.0812 (0.1025)  loss_giou_aux_1: 0.4112 (0.4503)  loss_vfl_aux_2: 0.5201 (0.5246)  loss_bbox_aux_2: 0.0819 (0.1004)  loss_giou_aux_2: 0.4013 (0.4416)  loss_vfl_aux_3: 0.5157 (0.5238)  loss_bbox_aux_3: 0.0808 (0.0994)  loss_giou_aux_3: 0.3981 (0.4393)  loss_vfl_aux_4: 0.5158 (0.5167)  loss_bbox_aux_4: 0.0793 (0.0987)  loss_giou_aux_4: 0.4035 (0.4395)  loss_vfl_aux_5: 0.5977 (0.5938)  loss_bbox_aux_5: 0.1342 (0.1511)  loss_giou_aux_5: 0.5737 (0.6145)  loss_vfl_dn_0: 0.4303 (0.4384)  loss_bbox_dn_0: 0.1520 (0.1687)  loss_giou_dn_0: 0.6295 (0.6392)  loss_vfl_dn_1: 0.4102 (0.4071)  loss_bbox_dn_1: 0.1008 (0.1227)  loss_giou_dn_1: 0.4510 (0.4889)  loss_vfl_dn_2: 0.4001 (0.3969)  loss_bbox_dn_2: 0.0892 (0.1136)  loss_giou_dn_2: 0.4248 (0.4615)  loss_vfl_dn_3: 0.3947 (0.3947)  loss_bbox_dn_3: 0.0860 (0.1112)  loss_giou_dn_3: 0.4210 (0.4555)  loss_vfl_dn_4: 0.3943 (0.3935)  loss_bbox_dn_4: 0.0856 (0.1107)  loss_giou_dn_4: 0.4194 (0.4542)  loss_vfl_dn_5: 0.3940 (0.3933)  loss_bbox_dn_5: 0.0856 (0.1106)  loss_giou_dn_5: 0.4188 (0.4543)  time: 0.3237  data: 0.0149  max mem: 7790\n",
            "Epoch: [158] Total time: 0:00:11 (0.3511 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.4560 (13.9204)  loss_vfl: 0.5082 (0.5151)  loss_bbox: 0.0792 (0.0982)  loss_giou: 0.4031 (0.4384)  loss_vfl_aux_0: 0.5220 (0.5309)  loss_bbox_aux_0: 0.0926 (0.1147)  loss_giou_aux_0: 0.4480 (0.4842)  loss_vfl_aux_1: 0.5216 (0.5277)  loss_bbox_aux_1: 0.0812 (0.1025)  loss_giou_aux_1: 0.4112 (0.4503)  loss_vfl_aux_2: 0.5201 (0.5246)  loss_bbox_aux_2: 0.0819 (0.1004)  loss_giou_aux_2: 0.4013 (0.4416)  loss_vfl_aux_3: 0.5157 (0.5238)  loss_bbox_aux_3: 0.0808 (0.0994)  loss_giou_aux_3: 0.3981 (0.4393)  loss_vfl_aux_4: 0.5158 (0.5167)  loss_bbox_aux_4: 0.0793 (0.0987)  loss_giou_aux_4: 0.4035 (0.4395)  loss_vfl_aux_5: 0.5977 (0.5938)  loss_bbox_aux_5: 0.1342 (0.1511)  loss_giou_aux_5: 0.5737 (0.6145)  loss_vfl_dn_0: 0.4303 (0.4384)  loss_bbox_dn_0: 0.1520 (0.1687)  loss_giou_dn_0: 0.6295 (0.6392)  loss_vfl_dn_1: 0.4102 (0.4071)  loss_bbox_dn_1: 0.1008 (0.1227)  loss_giou_dn_1: 0.4510 (0.4889)  loss_vfl_dn_2: 0.4001 (0.3969)  loss_bbox_dn_2: 0.0892 (0.1136)  loss_giou_dn_2: 0.4248 (0.4615)  loss_vfl_dn_3: 0.3947 (0.3947)  loss_bbox_dn_3: 0.0860 (0.1112)  loss_giou_dn_3: 0.4210 (0.4555)  loss_vfl_dn_4: 0.3943 (0.3935)  loss_bbox_dn_4: 0.0856 (0.1107)  loss_giou_dn_4: 0.4194 (0.4542)  loss_vfl_dn_5: 0.3940 (0.3933)  loss_bbox_dn_5: 0.0856 (0.1106)  loss_giou_dn_5: 0.4188 (0.4543)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8692  data: 0.5602  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4364  data: 0.1113  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4503 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.674\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [159]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 13.7939 (13.7939)  loss_vfl: 0.5652 (0.5652)  loss_bbox: 0.1677 (0.1677)  loss_giou: 0.2883 (0.2883)  loss_vfl_aux_0: 0.5873 (0.5873)  loss_bbox_aux_0: 0.2117 (0.2117)  loss_giou_aux_0: 0.3617 (0.3617)  loss_vfl_aux_1: 0.6040 (0.6040)  loss_bbox_aux_1: 0.1688 (0.1688)  loss_giou_aux_1: 0.2938 (0.2938)  loss_vfl_aux_2: 0.5861 (0.5861)  loss_bbox_aux_2: 0.1694 (0.1694)  loss_giou_aux_2: 0.2906 (0.2906)  loss_vfl_aux_3: 0.5568 (0.5568)  loss_bbox_aux_3: 0.1652 (0.1652)  loss_giou_aux_3: 0.2878 (0.2878)  loss_vfl_aux_4: 0.5343 (0.5343)  loss_bbox_aux_4: 0.1672 (0.1672)  loss_giou_aux_4: 0.2875 (0.2875)  loss_vfl_aux_5: 0.6548 (0.6548)  loss_bbox_aux_5: 0.3277 (0.3277)  loss_giou_aux_5: 0.6584 (0.6584)  loss_vfl_dn_0: 0.4602 (0.4602)  loss_bbox_dn_0: 0.2995 (0.2995)  loss_giou_dn_0: 0.5343 (0.5343)  loss_vfl_dn_1: 0.4245 (0.4245)  loss_bbox_dn_1: 0.2180 (0.2180)  loss_giou_dn_1: 0.3403 (0.3403)  loss_vfl_dn_2: 0.4099 (0.4099)  loss_bbox_dn_2: 0.2031 (0.2031)  loss_giou_dn_2: 0.3032 (0.3032)  loss_vfl_dn_3: 0.4041 (0.4041)  loss_bbox_dn_3: 0.1973 (0.1973)  loss_giou_dn_3: 0.2908 (0.2908)  loss_vfl_dn_4: 0.3955 (0.3955)  loss_bbox_dn_4: 0.1974 (0.1974)  loss_giou_dn_4: 0.2908 (0.2908)  loss_vfl_dn_5: 0.4016 (0.4016)  loss_bbox_dn_5: 0.1975 (0.1975)  loss_giou_dn_5: 0.2916 (0.2916)  time: 1.0738  data: 0.7085  max mem: 7790\n",
            "Epoch: [159]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.2141 (13.8829)  loss_vfl: 0.4828 (0.5313)  loss_bbox: 0.0936 (0.1008)  loss_giou: 0.3722 (0.4238)  loss_vfl_aux_0: 0.5186 (0.5408)  loss_bbox_aux_0: 0.1154 (0.1184)  loss_giou_aux_0: 0.4232 (0.4715)  loss_vfl_aux_1: 0.5016 (0.5347)  loss_bbox_aux_1: 0.1056 (0.1064)  loss_giou_aux_1: 0.3986 (0.4383)  loss_vfl_aux_2: 0.4979 (0.5341)  loss_bbox_aux_2: 0.1002 (0.1031)  loss_giou_aux_2: 0.3816 (0.4299)  loss_vfl_aux_3: 0.4828 (0.5273)  loss_bbox_aux_3: 0.0967 (0.1039)  loss_giou_aux_3: 0.3747 (0.4261)  loss_vfl_aux_4: 0.4774 (0.5273)  loss_bbox_aux_4: 0.0977 (0.1014)  loss_giou_aux_4: 0.3720 (0.4247)  loss_vfl_aux_5: 0.5962 (0.6020)  loss_bbox_aux_5: 0.1519 (0.1629)  loss_giou_aux_5: 0.5425 (0.5943)  loss_vfl_dn_0: 0.4309 (0.4369)  loss_bbox_dn_0: 0.1363 (0.1754)  loss_giou_dn_0: 0.6173 (0.6305)  loss_vfl_dn_1: 0.4001 (0.4030)  loss_bbox_dn_1: 0.1084 (0.1282)  loss_giou_dn_1: 0.4286 (0.4798)  loss_vfl_dn_2: 0.3911 (0.3916)  loss_bbox_dn_2: 0.1018 (0.1206)  loss_giou_dn_2: 0.3961 (0.4543)  loss_vfl_dn_3: 0.3843 (0.3888)  loss_bbox_dn_3: 0.1013 (0.1188)  loss_giou_dn_3: 0.3944 (0.4476)  loss_vfl_dn_4: 0.3842 (0.3867)  loss_bbox_dn_4: 0.1002 (0.1185)  loss_giou_dn_4: 0.3954 (0.4468)  loss_vfl_dn_5: 0.3824 (0.3866)  loss_bbox_dn_5: 0.0997 (0.1185)  loss_giou_dn_5: 0.4033 (0.4473)  time: 0.3232  data: 0.0140  max mem: 7790\n",
            "Epoch: [159] Total time: 0:00:11 (0.3510 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.2141 (13.8829)  loss_vfl: 0.4828 (0.5313)  loss_bbox: 0.0936 (0.1008)  loss_giou: 0.3722 (0.4238)  loss_vfl_aux_0: 0.5186 (0.5408)  loss_bbox_aux_0: 0.1154 (0.1184)  loss_giou_aux_0: 0.4232 (0.4715)  loss_vfl_aux_1: 0.5016 (0.5347)  loss_bbox_aux_1: 0.1056 (0.1064)  loss_giou_aux_1: 0.3986 (0.4383)  loss_vfl_aux_2: 0.4979 (0.5341)  loss_bbox_aux_2: 0.1002 (0.1031)  loss_giou_aux_2: 0.3816 (0.4299)  loss_vfl_aux_3: 0.4828 (0.5273)  loss_bbox_aux_3: 0.0967 (0.1039)  loss_giou_aux_3: 0.3747 (0.4261)  loss_vfl_aux_4: 0.4774 (0.5273)  loss_bbox_aux_4: 0.0977 (0.1014)  loss_giou_aux_4: 0.3720 (0.4247)  loss_vfl_aux_5: 0.5962 (0.6020)  loss_bbox_aux_5: 0.1519 (0.1629)  loss_giou_aux_5: 0.5425 (0.5943)  loss_vfl_dn_0: 0.4309 (0.4369)  loss_bbox_dn_0: 0.1363 (0.1754)  loss_giou_dn_0: 0.6173 (0.6305)  loss_vfl_dn_1: 0.4001 (0.4030)  loss_bbox_dn_1: 0.1084 (0.1282)  loss_giou_dn_1: 0.4286 (0.4798)  loss_vfl_dn_2: 0.3911 (0.3916)  loss_bbox_dn_2: 0.1018 (0.1206)  loss_giou_dn_2: 0.3961 (0.4543)  loss_vfl_dn_3: 0.3843 (0.3888)  loss_bbox_dn_3: 0.1013 (0.1188)  loss_giou_dn_3: 0.3944 (0.4476)  loss_vfl_dn_4: 0.3842 (0.3867)  loss_bbox_dn_4: 0.1002 (0.1185)  loss_giou_dn_4: 0.3954 (0.4468)  loss_vfl_dn_5: 0.3824 (0.3866)  loss_bbox_dn_5: 0.0997 (0.1185)  loss_giou_dn_5: 0.4033 (0.4473)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8542  data: 0.5353  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4360  data: 0.1085  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4494 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.366\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [160]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 11.1863 (11.1863)  loss_vfl: 0.4089 (0.4089)  loss_bbox: 0.0957 (0.0957)  loss_giou: 0.3353 (0.3353)  loss_vfl_aux_0: 0.4348 (0.4348)  loss_bbox_aux_0: 0.1284 (0.1284)  loss_giou_aux_0: 0.4080 (0.4080)  loss_vfl_aux_1: 0.4340 (0.4340)  loss_bbox_aux_1: 0.1075 (0.1075)  loss_giou_aux_1: 0.3470 (0.3470)  loss_vfl_aux_2: 0.4207 (0.4207)  loss_bbox_aux_2: 0.0962 (0.0962)  loss_giou_aux_2: 0.3347 (0.3347)  loss_vfl_aux_3: 0.4198 (0.4198)  loss_bbox_aux_3: 0.0965 (0.0965)  loss_giou_aux_3: 0.3387 (0.3387)  loss_vfl_aux_4: 0.4124 (0.4124)  loss_bbox_aux_4: 0.0960 (0.0960)  loss_giou_aux_4: 0.3363 (0.3363)  loss_vfl_aux_5: 0.5557 (0.5557)  loss_bbox_aux_5: 0.1744 (0.1744)  loss_giou_aux_5: 0.5823 (0.5823)  loss_vfl_dn_0: 0.4410 (0.4410)  loss_bbox_dn_0: 0.1238 (0.1238)  loss_giou_dn_0: 0.4687 (0.4687)  loss_vfl_dn_1: 0.3827 (0.3827)  loss_bbox_dn_1: 0.0798 (0.0798)  loss_giou_dn_1: 0.3044 (0.3044)  loss_vfl_dn_2: 0.3610 (0.3610)  loss_bbox_dn_2: 0.0708 (0.0708)  loss_giou_dn_2: 0.2794 (0.2794)  loss_vfl_dn_3: 0.3567 (0.3567)  loss_bbox_dn_3: 0.0724 (0.0724)  loss_giou_dn_3: 0.2791 (0.2791)  loss_vfl_dn_4: 0.3546 (0.3546)  loss_bbox_dn_4: 0.0716 (0.0716)  loss_giou_dn_4: 0.2773 (0.2773)  loss_vfl_dn_5: 0.3530 (0.3530)  loss_bbox_dn_5: 0.0711 (0.0711)  loss_giou_dn_5: 0.2760 (0.2760)  time: 0.9500  data: 0.5746  max mem: 7790\n",
            "Epoch: [160]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.1084 (12.7180)  loss_vfl: 0.4601 (0.4807)  loss_bbox: 0.0772 (0.0903)  loss_giou: 0.3276 (0.3647)  loss_vfl_aux_0: 0.5052 (0.5103)  loss_bbox_aux_0: 0.1081 (0.1094)  loss_giou_aux_0: 0.3712 (0.4141)  loss_vfl_aux_1: 0.4732 (0.4979)  loss_bbox_aux_1: 0.0876 (0.0951)  loss_giou_aux_1: 0.3459 (0.3777)  loss_vfl_aux_2: 0.4756 (0.4923)  loss_bbox_aux_2: 0.0818 (0.0917)  loss_giou_aux_2: 0.3360 (0.3698)  loss_vfl_aux_3: 0.4710 (0.4857)  loss_bbox_aux_3: 0.0773 (0.0911)  loss_giou_aux_3: 0.3287 (0.3677)  loss_vfl_aux_4: 0.4627 (0.4847)  loss_bbox_aux_4: 0.0775 (0.0903)  loss_giou_aux_4: 0.3294 (0.3644)  loss_vfl_aux_5: 0.5860 (0.5943)  loss_bbox_aux_5: 0.1455 (0.1531)  loss_giou_aux_5: 0.5326 (0.5447)  loss_vfl_dn_0: 0.4312 (0.4359)  loss_bbox_dn_0: 0.1470 (0.1700)  loss_giou_dn_0: 0.5651 (0.5755)  loss_vfl_dn_1: 0.3985 (0.3950)  loss_bbox_dn_1: 0.1012 (0.1214)  loss_giou_dn_1: 0.4000 (0.4240)  loss_vfl_dn_2: 0.3840 (0.3826)  loss_bbox_dn_2: 0.0893 (0.1120)  loss_giou_dn_2: 0.3666 (0.3960)  loss_vfl_dn_3: 0.3805 (0.3799)  loss_bbox_dn_3: 0.0886 (0.1106)  loss_giou_dn_3: 0.3574 (0.3899)  loss_vfl_dn_4: 0.3794 (0.3811)  loss_bbox_dn_4: 0.0893 (0.1103)  loss_giou_dn_4: 0.3552 (0.3881)  loss_vfl_dn_5: 0.3794 (0.3774)  loss_bbox_dn_5: 0.0891 (0.1101)  loss_giou_dn_5: 0.3535 (0.3879)  time: 0.3238  data: 0.0146  max mem: 7790\n",
            "Epoch: [160] Total time: 0:00:11 (0.3456 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.1084 (12.7180)  loss_vfl: 0.4601 (0.4807)  loss_bbox: 0.0772 (0.0903)  loss_giou: 0.3276 (0.3647)  loss_vfl_aux_0: 0.5052 (0.5103)  loss_bbox_aux_0: 0.1081 (0.1094)  loss_giou_aux_0: 0.3712 (0.4141)  loss_vfl_aux_1: 0.4732 (0.4979)  loss_bbox_aux_1: 0.0876 (0.0951)  loss_giou_aux_1: 0.3459 (0.3777)  loss_vfl_aux_2: 0.4756 (0.4923)  loss_bbox_aux_2: 0.0818 (0.0917)  loss_giou_aux_2: 0.3360 (0.3698)  loss_vfl_aux_3: 0.4710 (0.4857)  loss_bbox_aux_3: 0.0773 (0.0911)  loss_giou_aux_3: 0.3287 (0.3677)  loss_vfl_aux_4: 0.4627 (0.4847)  loss_bbox_aux_4: 0.0775 (0.0903)  loss_giou_aux_4: 0.3294 (0.3644)  loss_vfl_aux_5: 0.5860 (0.5943)  loss_bbox_aux_5: 0.1455 (0.1531)  loss_giou_aux_5: 0.5326 (0.5447)  loss_vfl_dn_0: 0.4312 (0.4359)  loss_bbox_dn_0: 0.1470 (0.1700)  loss_giou_dn_0: 0.5651 (0.5755)  loss_vfl_dn_1: 0.3985 (0.3950)  loss_bbox_dn_1: 0.1012 (0.1214)  loss_giou_dn_1: 0.4000 (0.4240)  loss_vfl_dn_2: 0.3840 (0.3826)  loss_bbox_dn_2: 0.0893 (0.1120)  loss_giou_dn_2: 0.3666 (0.3960)  loss_vfl_dn_3: 0.3805 (0.3799)  loss_bbox_dn_3: 0.0886 (0.1106)  loss_giou_dn_3: 0.3574 (0.3899)  loss_vfl_dn_4: 0.3794 (0.3811)  loss_bbox_dn_4: 0.0893 (0.1103)  loss_giou_dn_4: 0.3552 (0.3881)  loss_vfl_dn_5: 0.3794 (0.3774)  loss_bbox_dn_5: 0.0891 (0.1101)  loss_giou_dn_5: 0.3535 (0.3879)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8756  data: 0.5679  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3863  data: 0.1130  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3999 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.680\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [161]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 17.1765 (17.1765)  loss_vfl: 0.4790 (0.4790)  loss_bbox: 0.0987 (0.0987)  loss_giou: 0.7577 (0.7577)  loss_vfl_aux_0: 0.5064 (0.5064)  loss_bbox_aux_0: 0.0988 (0.0988)  loss_giou_aux_0: 0.7870 (0.7870)  loss_vfl_aux_1: 0.5046 (0.5046)  loss_bbox_aux_1: 0.0986 (0.0986)  loss_giou_aux_1: 0.7617 (0.7617)  loss_vfl_aux_2: 0.4820 (0.4820)  loss_bbox_aux_2: 0.0997 (0.0997)  loss_giou_aux_2: 0.7649 (0.7649)  loss_vfl_aux_3: 0.4668 (0.4668)  loss_bbox_aux_3: 0.0999 (0.0999)  loss_giou_aux_3: 0.7606 (0.7606)  loss_vfl_aux_4: 0.4595 (0.4595)  loss_bbox_aux_4: 0.0988 (0.0988)  loss_giou_aux_4: 0.7591 (0.7591)  loss_vfl_aux_5: 0.4975 (0.4975)  loss_bbox_aux_5: 0.0960 (0.0960)  loss_giou_aux_5: 0.7987 (0.7987)  loss_vfl_dn_0: 0.4472 (0.4472)  loss_bbox_dn_0: 0.1052 (0.1052)  loss_giou_dn_0: 0.8371 (0.8371)  loss_vfl_dn_1: 0.4285 (0.4285)  loss_bbox_dn_1: 0.0930 (0.0930)  loss_giou_dn_1: 0.7532 (0.7532)  loss_vfl_dn_2: 0.4205 (0.4205)  loss_bbox_dn_2: 0.0928 (0.0928)  loss_giou_dn_2: 0.7433 (0.7433)  loss_vfl_dn_3: 0.4157 (0.4157)  loss_bbox_dn_3: 0.0946 (0.0946)  loss_giou_dn_3: 0.7490 (0.7490)  loss_vfl_dn_4: 0.4127 (0.4127)  loss_bbox_dn_4: 0.0947 (0.0947)  loss_giou_dn_4: 0.7502 (0.7502)  loss_vfl_dn_5: 0.4179 (0.4179)  loss_bbox_dn_5: 0.0946 (0.0946)  loss_giou_dn_5: 0.7503 (0.7503)  time: 1.0397  data: 0.6792  max mem: 7790\n",
            "Epoch: [161]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.6144 (13.0391)  loss_vfl: 0.5017 (0.5122)  loss_bbox: 0.0793 (0.0871)  loss_giou: 0.3261 (0.3843)  loss_vfl_aux_0: 0.5375 (0.5278)  loss_bbox_aux_0: 0.0932 (0.1022)  loss_giou_aux_0: 0.3889 (0.4324)  loss_vfl_aux_1: 0.5214 (0.5202)  loss_bbox_aux_1: 0.0853 (0.0925)  loss_giou_aux_1: 0.3356 (0.4024)  loss_vfl_aux_2: 0.5303 (0.5163)  loss_bbox_aux_2: 0.0810 (0.0899)  loss_giou_aux_2: 0.3223 (0.3947)  loss_vfl_aux_3: 0.5277 (0.5177)  loss_bbox_aux_3: 0.0792 (0.0879)  loss_giou_aux_3: 0.3269 (0.3882)  loss_vfl_aux_4: 0.5157 (0.5111)  loss_bbox_aux_4: 0.0796 (0.0876)  loss_giou_aux_4: 0.3241 (0.3851)  loss_vfl_aux_5: 0.5728 (0.5820)  loss_bbox_aux_5: 0.1306 (0.1523)  loss_giou_aux_5: 0.5164 (0.5753)  loss_vfl_dn_0: 0.4329 (0.4343)  loss_bbox_dn_0: 0.1510 (0.1610)  loss_giou_dn_0: 0.5490 (0.5876)  loss_vfl_dn_1: 0.3904 (0.3919)  loss_bbox_dn_1: 0.1030 (0.1130)  loss_giou_dn_1: 0.3996 (0.4419)  loss_vfl_dn_2: 0.3812 (0.3802)  loss_bbox_dn_2: 0.0969 (0.1044)  loss_giou_dn_2: 0.3766 (0.4156)  loss_vfl_dn_3: 0.3771 (0.3765)  loss_bbox_dn_3: 0.0970 (0.1026)  loss_giou_dn_3: 0.3673 (0.4100)  loss_vfl_dn_4: 0.3733 (0.3753)  loss_bbox_dn_4: 0.0966 (0.1019)  loss_giou_dn_4: 0.3642 (0.4089)  loss_vfl_dn_5: 0.3782 (0.3746)  loss_bbox_dn_5: 0.0960 (0.1016)  loss_giou_dn_5: 0.3641 (0.4086)  time: 0.3411  data: 0.0155  max mem: 7790\n",
            "Epoch: [161] Total time: 0:00:11 (0.3596 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.6144 (13.0391)  loss_vfl: 0.5017 (0.5122)  loss_bbox: 0.0793 (0.0871)  loss_giou: 0.3261 (0.3843)  loss_vfl_aux_0: 0.5375 (0.5278)  loss_bbox_aux_0: 0.0932 (0.1022)  loss_giou_aux_0: 0.3889 (0.4324)  loss_vfl_aux_1: 0.5214 (0.5202)  loss_bbox_aux_1: 0.0853 (0.0925)  loss_giou_aux_1: 0.3356 (0.4024)  loss_vfl_aux_2: 0.5303 (0.5163)  loss_bbox_aux_2: 0.0810 (0.0899)  loss_giou_aux_2: 0.3223 (0.3947)  loss_vfl_aux_3: 0.5277 (0.5177)  loss_bbox_aux_3: 0.0792 (0.0879)  loss_giou_aux_3: 0.3269 (0.3882)  loss_vfl_aux_4: 0.5157 (0.5111)  loss_bbox_aux_4: 0.0796 (0.0876)  loss_giou_aux_4: 0.3241 (0.3851)  loss_vfl_aux_5: 0.5728 (0.5820)  loss_bbox_aux_5: 0.1306 (0.1523)  loss_giou_aux_5: 0.5164 (0.5753)  loss_vfl_dn_0: 0.4329 (0.4343)  loss_bbox_dn_0: 0.1510 (0.1610)  loss_giou_dn_0: 0.5490 (0.5876)  loss_vfl_dn_1: 0.3904 (0.3919)  loss_bbox_dn_1: 0.1030 (0.1130)  loss_giou_dn_1: 0.3996 (0.4419)  loss_vfl_dn_2: 0.3812 (0.3802)  loss_bbox_dn_2: 0.0969 (0.1044)  loss_giou_dn_2: 0.3766 (0.4156)  loss_vfl_dn_3: 0.3771 (0.3765)  loss_bbox_dn_3: 0.0970 (0.1026)  loss_giou_dn_3: 0.3673 (0.4100)  loss_vfl_dn_4: 0.3733 (0.3753)  loss_bbox_dn_4: 0.0966 (0.1019)  loss_giou_dn_4: 0.3642 (0.4089)  loss_vfl_dn_5: 0.3782 (0.3746)  loss_bbox_dn_5: 0.0960 (0.1016)  loss_giou_dn_5: 0.3641 (0.4086)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8714  data: 0.5465  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3876  data: 0.1125  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4022 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.658\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.361\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [162]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 11.9268 (11.9268)  loss_vfl: 0.6067 (0.6067)  loss_bbox: 0.0628 (0.0628)  loss_giou: 0.2593 (0.2593)  loss_vfl_aux_0: 0.6333 (0.6333)  loss_bbox_aux_0: 0.0703 (0.0703)  loss_giou_aux_0: 0.3157 (0.3157)  loss_vfl_aux_1: 0.6921 (0.6921)  loss_bbox_aux_1: 0.0717 (0.0717)  loss_giou_aux_1: 0.2618 (0.2618)  loss_vfl_aux_2: 0.6775 (0.6775)  loss_bbox_aux_2: 0.0721 (0.0721)  loss_giou_aux_2: 0.2546 (0.2546)  loss_vfl_aux_3: 0.6602 (0.6602)  loss_bbox_aux_3: 0.0650 (0.0650)  loss_giou_aux_3: 0.2569 (0.2569)  loss_vfl_aux_4: 0.6369 (0.6369)  loss_bbox_aux_4: 0.0643 (0.0643)  loss_giou_aux_4: 0.2521 (0.2521)  loss_vfl_aux_5: 0.6223 (0.6223)  loss_bbox_aux_5: 0.1238 (0.1238)  loss_giou_aux_5: 0.4530 (0.4530)  loss_vfl_dn_0: 0.4277 (0.4277)  loss_bbox_dn_0: 0.1700 (0.1700)  loss_giou_dn_0: 0.4838 (0.4838)  loss_vfl_dn_1: 0.3564 (0.3564)  loss_bbox_dn_1: 0.1091 (0.1091)  loss_giou_dn_1: 0.3318 (0.3318)  loss_vfl_dn_2: 0.3413 (0.3413)  loss_bbox_dn_2: 0.0957 (0.0957)  loss_giou_dn_2: 0.3071 (0.3071)  loss_vfl_dn_3: 0.3322 (0.3322)  loss_bbox_dn_3: 0.0940 (0.0940)  loss_giou_dn_3: 0.3031 (0.3031)  loss_vfl_dn_4: 0.3309 (0.3309)  loss_bbox_dn_4: 0.0931 (0.0931)  loss_giou_dn_4: 0.3036 (0.3036)  loss_vfl_dn_5: 0.3336 (0.3336)  loss_bbox_dn_5: 0.0931 (0.0931)  loss_giou_dn_5: 0.3085 (0.3085)  time: 1.0114  data: 0.5866  max mem: 7790\n",
            "Epoch: [162]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.7917 (13.4754)  loss_vfl: 0.4610 (0.4998)  loss_bbox: 0.0948 (0.0953)  loss_giou: 0.4183 (0.4100)  loss_vfl_aux_0: 0.5156 (0.5271)  loss_bbox_aux_0: 0.0948 (0.1079)  loss_giou_aux_0: 0.4881 (0.4617)  loss_vfl_aux_1: 0.5008 (0.5188)  loss_bbox_aux_1: 0.0861 (0.0987)  loss_giou_aux_1: 0.4499 (0.4235)  loss_vfl_aux_2: 0.4983 (0.5168)  loss_bbox_aux_2: 0.0947 (0.0979)  loss_giou_aux_2: 0.4280 (0.4142)  loss_vfl_aux_3: 0.4751 (0.5113)  loss_bbox_aux_3: 0.0944 (0.0959)  loss_giou_aux_3: 0.4216 (0.4103)  loss_vfl_aux_4: 0.4746 (0.4985)  loss_bbox_aux_4: 0.0953 (0.0962)  loss_giou_aux_4: 0.4175 (0.4113)  loss_vfl_aux_5: 0.5660 (0.5919)  loss_bbox_aux_5: 0.1226 (0.1513)  loss_giou_aux_5: 0.5994 (0.5832)  loss_vfl_dn_0: 0.4300 (0.4321)  loss_bbox_dn_0: 0.1514 (0.1701)  loss_giou_dn_0: 0.6093 (0.6155)  loss_vfl_dn_1: 0.4027 (0.3943)  loss_bbox_dn_1: 0.1041 (0.1262)  loss_giou_dn_1: 0.4662 (0.4706)  loss_vfl_dn_2: 0.3838 (0.3823)  loss_bbox_dn_2: 0.1047 (0.1177)  loss_giou_dn_2: 0.4319 (0.4458)  loss_vfl_dn_3: 0.3798 (0.3783)  loss_bbox_dn_3: 0.1062 (0.1163)  loss_giou_dn_3: 0.4281 (0.4398)  loss_vfl_dn_4: 0.3781 (0.3763)  loss_bbox_dn_4: 0.1073 (0.1165)  loss_giou_dn_4: 0.4289 (0.4393)  loss_vfl_dn_5: 0.3800 (0.3768)  loss_bbox_dn_5: 0.1077 (0.1164)  loss_giou_dn_5: 0.4291 (0.4396)  time: 0.3252  data: 0.0140  max mem: 7790\n",
            "Epoch: [162] Total time: 0:00:11 (0.3526 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.7917 (13.4754)  loss_vfl: 0.4610 (0.4998)  loss_bbox: 0.0948 (0.0953)  loss_giou: 0.4183 (0.4100)  loss_vfl_aux_0: 0.5156 (0.5271)  loss_bbox_aux_0: 0.0948 (0.1079)  loss_giou_aux_0: 0.4881 (0.4617)  loss_vfl_aux_1: 0.5008 (0.5188)  loss_bbox_aux_1: 0.0861 (0.0987)  loss_giou_aux_1: 0.4499 (0.4235)  loss_vfl_aux_2: 0.4983 (0.5168)  loss_bbox_aux_2: 0.0947 (0.0979)  loss_giou_aux_2: 0.4280 (0.4142)  loss_vfl_aux_3: 0.4751 (0.5113)  loss_bbox_aux_3: 0.0944 (0.0959)  loss_giou_aux_3: 0.4216 (0.4103)  loss_vfl_aux_4: 0.4746 (0.4985)  loss_bbox_aux_4: 0.0953 (0.0962)  loss_giou_aux_4: 0.4175 (0.4113)  loss_vfl_aux_5: 0.5660 (0.5919)  loss_bbox_aux_5: 0.1226 (0.1513)  loss_giou_aux_5: 0.5994 (0.5832)  loss_vfl_dn_0: 0.4300 (0.4321)  loss_bbox_dn_0: 0.1514 (0.1701)  loss_giou_dn_0: 0.6093 (0.6155)  loss_vfl_dn_1: 0.4027 (0.3943)  loss_bbox_dn_1: 0.1041 (0.1262)  loss_giou_dn_1: 0.4662 (0.4706)  loss_vfl_dn_2: 0.3838 (0.3823)  loss_bbox_dn_2: 0.1047 (0.1177)  loss_giou_dn_2: 0.4319 (0.4458)  loss_vfl_dn_3: 0.3798 (0.3783)  loss_bbox_dn_3: 0.1062 (0.1163)  loss_giou_dn_3: 0.4281 (0.4398)  loss_vfl_dn_4: 0.3781 (0.3763)  loss_bbox_dn_4: 0.1073 (0.1165)  loss_giou_dn_4: 0.4289 (0.4393)  loss_vfl_dn_5: 0.3800 (0.3768)  loss_bbox_dn_5: 0.1077 (0.1164)  loss_giou_dn_5: 0.4291 (0.4396)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9199  data: 0.6117  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3840  data: 0.1138  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3961 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.404\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [163]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 13.9408 (13.9408)  loss_vfl: 0.5804 (0.5804)  loss_bbox: 0.0730 (0.0730)  loss_giou: 0.4416 (0.4416)  loss_vfl_aux_0: 0.5855 (0.5855)  loss_bbox_aux_0: 0.0806 (0.0806)  loss_giou_aux_0: 0.4581 (0.4581)  loss_vfl_aux_1: 0.6173 (0.6173)  loss_bbox_aux_1: 0.0781 (0.0781)  loss_giou_aux_1: 0.4540 (0.4540)  loss_vfl_aux_2: 0.6011 (0.6011)  loss_bbox_aux_2: 0.0750 (0.0750)  loss_giou_aux_2: 0.4525 (0.4525)  loss_vfl_aux_3: 0.6133 (0.6133)  loss_bbox_aux_3: 0.0728 (0.0728)  loss_giou_aux_3: 0.4475 (0.4475)  loss_vfl_aux_4: 0.5976 (0.5976)  loss_bbox_aux_4: 0.0725 (0.0725)  loss_giou_aux_4: 0.4433 (0.4433)  loss_vfl_aux_5: 0.6077 (0.6077)  loss_bbox_aux_5: 0.1164 (0.1164)  loss_giou_aux_5: 0.5919 (0.5919)  loss_vfl_dn_0: 0.4335 (0.4335)  loss_bbox_dn_0: 0.1367 (0.1367)  loss_giou_dn_0: 0.5804 (0.5804)  loss_vfl_dn_1: 0.4149 (0.4149)  loss_bbox_dn_1: 0.1027 (0.1027)  loss_giou_dn_1: 0.4486 (0.4486)  loss_vfl_dn_2: 0.4093 (0.4093)  loss_bbox_dn_2: 0.0984 (0.0984)  loss_giou_dn_2: 0.4345 (0.4345)  loss_vfl_dn_3: 0.4080 (0.4080)  loss_bbox_dn_3: 0.0958 (0.0958)  loss_giou_dn_3: 0.4378 (0.4378)  loss_vfl_dn_4: 0.4050 (0.4050)  loss_bbox_dn_4: 0.0956 (0.0956)  loss_giou_dn_4: 0.4374 (0.4374)  loss_vfl_dn_5: 0.4061 (0.4061)  loss_bbox_dn_5: 0.0956 (0.0956)  loss_giou_dn_5: 0.4403 (0.4403)  time: 0.9501  data: 0.5277  max mem: 7790\n",
            "Epoch: [163]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.7371 (13.0411)  loss_vfl: 0.4735 (0.4863)  loss_bbox: 0.0809 (0.0895)  loss_giou: 0.3348 (0.3918)  loss_vfl_aux_0: 0.4926 (0.5188)  loss_bbox_aux_0: 0.0968 (0.1049)  loss_giou_aux_0: 0.3842 (0.4333)  loss_vfl_aux_1: 0.4794 (0.5129)  loss_bbox_aux_1: 0.0871 (0.0940)  loss_giou_aux_1: 0.3566 (0.4038)  loss_vfl_aux_2: 0.4871 (0.5054)  loss_bbox_aux_2: 0.0827 (0.0909)  loss_giou_aux_2: 0.3377 (0.3930)  loss_vfl_aux_3: 0.4847 (0.4957)  loss_bbox_aux_3: 0.0903 (0.0905)  loss_giou_aux_3: 0.3412 (0.3906)  loss_vfl_aux_4: 0.4811 (0.4888)  loss_bbox_aux_4: 0.0812 (0.0894)  loss_giou_aux_4: 0.3378 (0.3903)  loss_vfl_aux_5: 0.5702 (0.5863)  loss_bbox_aux_5: 0.1322 (0.1553)  loss_giou_aux_5: 0.5607 (0.5701)  loss_vfl_dn_0: 0.4461 (0.4413)  loss_bbox_dn_0: 0.1575 (0.1668)  loss_giou_dn_0: 0.5900 (0.5902)  loss_vfl_dn_1: 0.4009 (0.3996)  loss_bbox_dn_1: 0.1036 (0.1188)  loss_giou_dn_1: 0.4015 (0.4385)  loss_vfl_dn_2: 0.3907 (0.3899)  loss_bbox_dn_2: 0.0932 (0.1098)  loss_giou_dn_2: 0.3744 (0.4119)  loss_vfl_dn_3: 0.3837 (0.3857)  loss_bbox_dn_3: 0.0936 (0.1077)  loss_giou_dn_3: 0.3648 (0.4075)  loss_vfl_dn_4: 0.3797 (0.3837)  loss_bbox_dn_4: 0.0950 (0.1072)  loss_giou_dn_4: 0.3617 (0.4057)  loss_vfl_dn_5: 0.3818 (0.3828)  loss_bbox_dn_5: 0.0953 (0.1070)  loss_giou_dn_5: 0.3616 (0.4055)  time: 0.3305  data: 0.0155  max mem: 7790\n",
            "Epoch: [163] Total time: 0:00:11 (0.3497 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.7371 (13.0411)  loss_vfl: 0.4735 (0.4863)  loss_bbox: 0.0809 (0.0895)  loss_giou: 0.3348 (0.3918)  loss_vfl_aux_0: 0.4926 (0.5188)  loss_bbox_aux_0: 0.0968 (0.1049)  loss_giou_aux_0: 0.3842 (0.4333)  loss_vfl_aux_1: 0.4794 (0.5129)  loss_bbox_aux_1: 0.0871 (0.0940)  loss_giou_aux_1: 0.3566 (0.4038)  loss_vfl_aux_2: 0.4871 (0.5054)  loss_bbox_aux_2: 0.0827 (0.0909)  loss_giou_aux_2: 0.3377 (0.3930)  loss_vfl_aux_3: 0.4847 (0.4957)  loss_bbox_aux_3: 0.0903 (0.0905)  loss_giou_aux_3: 0.3412 (0.3906)  loss_vfl_aux_4: 0.4811 (0.4888)  loss_bbox_aux_4: 0.0812 (0.0894)  loss_giou_aux_4: 0.3378 (0.3903)  loss_vfl_aux_5: 0.5702 (0.5863)  loss_bbox_aux_5: 0.1322 (0.1553)  loss_giou_aux_5: 0.5607 (0.5701)  loss_vfl_dn_0: 0.4461 (0.4413)  loss_bbox_dn_0: 0.1575 (0.1668)  loss_giou_dn_0: 0.5900 (0.5902)  loss_vfl_dn_1: 0.4009 (0.3996)  loss_bbox_dn_1: 0.1036 (0.1188)  loss_giou_dn_1: 0.4015 (0.4385)  loss_vfl_dn_2: 0.3907 (0.3899)  loss_bbox_dn_2: 0.0932 (0.1098)  loss_giou_dn_2: 0.3744 (0.4119)  loss_vfl_dn_3: 0.3837 (0.3857)  loss_bbox_dn_3: 0.0936 (0.1077)  loss_giou_dn_3: 0.3648 (0.4075)  loss_vfl_dn_4: 0.3797 (0.3837)  loss_bbox_dn_4: 0.0950 (0.1072)  loss_giou_dn_4: 0.3617 (0.4057)  loss_vfl_dn_5: 0.3818 (0.3828)  loss_bbox_dn_5: 0.0953 (0.1070)  loss_giou_dn_5: 0.3616 (0.4055)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8797  data: 0.5659  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3840  data: 0.1094  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3964 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.667\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [164]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 13.1700 (13.1700)  loss_vfl: 0.4719 (0.4719)  loss_bbox: 0.0736 (0.0736)  loss_giou: 0.3933 (0.3933)  loss_vfl_aux_0: 0.5238 (0.5238)  loss_bbox_aux_0: 0.0824 (0.0824)  loss_giou_aux_0: 0.4400 (0.4400)  loss_vfl_aux_1: 0.4899 (0.4899)  loss_bbox_aux_1: 0.0779 (0.0779)  loss_giou_aux_1: 0.4061 (0.4061)  loss_vfl_aux_2: 0.4833 (0.4833)  loss_bbox_aux_2: 0.0741 (0.0741)  loss_giou_aux_2: 0.4034 (0.4034)  loss_vfl_aux_3: 0.4770 (0.4770)  loss_bbox_aux_3: 0.0715 (0.0715)  loss_giou_aux_3: 0.3935 (0.3935)  loss_vfl_aux_4: 0.4711 (0.4711)  loss_bbox_aux_4: 0.0732 (0.0732)  loss_giou_aux_4: 0.3954 (0.3954)  loss_vfl_aux_5: 0.5485 (0.5485)  loss_bbox_aux_5: 0.1225 (0.1225)  loss_giou_aux_5: 0.5869 (0.5869)  loss_vfl_dn_0: 0.4384 (0.4384)  loss_bbox_dn_0: 0.1517 (0.1517)  loss_giou_dn_0: 0.6427 (0.6427)  loss_vfl_dn_1: 0.4202 (0.4202)  loss_bbox_dn_1: 0.1062 (0.1062)  loss_giou_dn_1: 0.4825 (0.4825)  loss_vfl_dn_2: 0.4231 (0.4231)  loss_bbox_dn_2: 0.0967 (0.0967)  loss_giou_dn_2: 0.4604 (0.4604)  loss_vfl_dn_3: 0.4177 (0.4177)  loss_bbox_dn_3: 0.0953 (0.0953)  loss_giou_dn_3: 0.4487 (0.4487)  loss_vfl_dn_4: 0.4214 (0.4214)  loss_bbox_dn_4: 0.0941 (0.0941)  loss_giou_dn_4: 0.4482 (0.4482)  loss_vfl_dn_5: 0.4226 (0.4226)  loss_bbox_dn_5: 0.0938 (0.0938)  loss_giou_dn_5: 0.4470 (0.4470)  time: 1.0521  data: 0.6280  max mem: 7790\n",
            "Epoch: [164]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.5383 (13.2196)  loss_vfl: 0.4732 (0.4927)  loss_bbox: 0.0785 (0.0854)  loss_giou: 0.3347 (0.3991)  loss_vfl_aux_0: 0.5302 (0.5344)  loss_bbox_aux_0: 0.0948 (0.0978)  loss_giou_aux_0: 0.4095 (0.4465)  loss_vfl_aux_1: 0.5007 (0.5178)  loss_bbox_aux_1: 0.0798 (0.0884)  loss_giou_aux_1: 0.3488 (0.4091)  loss_vfl_aux_2: 0.4988 (0.5125)  loss_bbox_aux_2: 0.0800 (0.0873)  loss_giou_aux_2: 0.3417 (0.4013)  loss_vfl_aux_3: 0.4930 (0.5096)  loss_bbox_aux_3: 0.0787 (0.0846)  loss_giou_aux_3: 0.3421 (0.3963)  loss_vfl_aux_4: 0.4809 (0.4945)  loss_bbox_aux_4: 0.0783 (0.0854)  loss_giou_aux_4: 0.3444 (0.3993)  loss_vfl_aux_5: 0.5769 (0.5910)  loss_bbox_aux_5: 0.1337 (0.1437)  loss_giou_aux_5: 0.5966 (0.5798)  loss_vfl_dn_0: 0.4355 (0.4384)  loss_bbox_dn_0: 0.1383 (0.1599)  loss_giou_dn_0: 0.5736 (0.6122)  loss_vfl_dn_1: 0.3954 (0.4010)  loss_bbox_dn_1: 0.1087 (0.1142)  loss_giou_dn_1: 0.4260 (0.4611)  loss_vfl_dn_2: 0.3858 (0.3891)  loss_bbox_dn_2: 0.0988 (0.1060)  loss_giou_dn_2: 0.4052 (0.4352)  loss_vfl_dn_3: 0.3860 (0.3852)  loss_bbox_dn_3: 0.0946 (0.1035)  loss_giou_dn_3: 0.4011 (0.4274)  loss_vfl_dn_4: 0.3856 (0.3848)  loss_bbox_dn_4: 0.0926 (0.1033)  loss_giou_dn_4: 0.3965 (0.4272)  loss_vfl_dn_5: 0.3864 (0.3843)  loss_bbox_dn_5: 0.0917 (0.1032)  loss_giou_dn_5: 0.3933 (0.4272)  time: 0.3303  data: 0.0144  max mem: 7790\n",
            "Epoch: [164] Total time: 0:00:11 (0.3575 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.5383 (13.2196)  loss_vfl: 0.4732 (0.4927)  loss_bbox: 0.0785 (0.0854)  loss_giou: 0.3347 (0.3991)  loss_vfl_aux_0: 0.5302 (0.5344)  loss_bbox_aux_0: 0.0948 (0.0978)  loss_giou_aux_0: 0.4095 (0.4465)  loss_vfl_aux_1: 0.5007 (0.5178)  loss_bbox_aux_1: 0.0798 (0.0884)  loss_giou_aux_1: 0.3488 (0.4091)  loss_vfl_aux_2: 0.4988 (0.5125)  loss_bbox_aux_2: 0.0800 (0.0873)  loss_giou_aux_2: 0.3417 (0.4013)  loss_vfl_aux_3: 0.4930 (0.5096)  loss_bbox_aux_3: 0.0787 (0.0846)  loss_giou_aux_3: 0.3421 (0.3963)  loss_vfl_aux_4: 0.4809 (0.4945)  loss_bbox_aux_4: 0.0783 (0.0854)  loss_giou_aux_4: 0.3444 (0.3993)  loss_vfl_aux_5: 0.5769 (0.5910)  loss_bbox_aux_5: 0.1337 (0.1437)  loss_giou_aux_5: 0.5966 (0.5798)  loss_vfl_dn_0: 0.4355 (0.4384)  loss_bbox_dn_0: 0.1383 (0.1599)  loss_giou_dn_0: 0.5736 (0.6122)  loss_vfl_dn_1: 0.3954 (0.4010)  loss_bbox_dn_1: 0.1087 (0.1142)  loss_giou_dn_1: 0.4260 (0.4611)  loss_vfl_dn_2: 0.3858 (0.3891)  loss_bbox_dn_2: 0.0988 (0.1060)  loss_giou_dn_2: 0.4052 (0.4352)  loss_vfl_dn_3: 0.3860 (0.3852)  loss_bbox_dn_3: 0.0946 (0.1035)  loss_giou_dn_3: 0.4011 (0.4274)  loss_vfl_dn_4: 0.3856 (0.3848)  loss_bbox_dn_4: 0.0926 (0.1033)  loss_giou_dn_4: 0.3965 (0.4272)  loss_vfl_dn_5: 0.3864 (0.3843)  loss_bbox_dn_5: 0.0917 (0.1032)  loss_giou_dn_5: 0.3933 (0.4272)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8447  data: 0.5325  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4313  data: 0.1098  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4453 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.675\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.578\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [165]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 13.5583 (13.5583)  loss_vfl: 0.4426 (0.4426)  loss_bbox: 0.0868 (0.0868)  loss_giou: 0.4353 (0.4353)  loss_vfl_aux_0: 0.4630 (0.4630)  loss_bbox_aux_0: 0.1155 (0.1155)  loss_giou_aux_0: 0.5229 (0.5229)  loss_vfl_aux_1: 0.4387 (0.4387)  loss_bbox_aux_1: 0.0917 (0.0917)  loss_giou_aux_1: 0.4496 (0.4496)  loss_vfl_aux_2: 0.4479 (0.4479)  loss_bbox_aux_2: 0.0898 (0.0898)  loss_giou_aux_2: 0.4526 (0.4526)  loss_vfl_aux_3: 0.4461 (0.4461)  loss_bbox_aux_3: 0.0862 (0.0862)  loss_giou_aux_3: 0.4348 (0.4348)  loss_vfl_aux_4: 0.4348 (0.4348)  loss_bbox_aux_4: 0.0870 (0.0870)  loss_giou_aux_4: 0.4394 (0.4394)  loss_vfl_aux_5: 0.5149 (0.5149)  loss_bbox_aux_5: 0.1659 (0.1659)  loss_giou_aux_5: 0.6081 (0.6081)  loss_vfl_dn_0: 0.4534 (0.4534)  loss_bbox_dn_0: 0.1687 (0.1687)  loss_giou_dn_0: 0.6461 (0.6461)  loss_vfl_dn_1: 0.4224 (0.4224)  loss_bbox_dn_1: 0.1225 (0.1225)  loss_giou_dn_1: 0.5111 (0.5111)  loss_vfl_dn_2: 0.4109 (0.4109)  loss_bbox_dn_2: 0.1114 (0.1114)  loss_giou_dn_2: 0.4934 (0.4934)  loss_vfl_dn_3: 0.4067 (0.4067)  loss_bbox_dn_3: 0.1072 (0.1072)  loss_giou_dn_3: 0.4824 (0.4824)  loss_vfl_dn_4: 0.4064 (0.4064)  loss_bbox_dn_4: 0.1057 (0.1057)  loss_giou_dn_4: 0.4770 (0.4770)  loss_vfl_dn_5: 0.4037 (0.4037)  loss_bbox_dn_5: 0.1044 (0.1044)  loss_giou_dn_5: 0.4712 (0.4712)  time: 1.0164  data: 0.6404  max mem: 7790\n",
            "Epoch: [165]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 13.2242 (13.0956)  loss_vfl: 0.4574 (0.4775)  loss_bbox: 0.0867 (0.0960)  loss_giou: 0.3690 (0.3781)  loss_vfl_aux_0: 0.5048 (0.5176)  loss_bbox_aux_0: 0.1049 (0.1168)  loss_giou_aux_0: 0.4423 (0.4320)  loss_vfl_aux_1: 0.4942 (0.4936)  loss_bbox_aux_1: 0.0915 (0.1026)  loss_giou_aux_1: 0.3989 (0.3967)  loss_vfl_aux_2: 0.4850 (0.4919)  loss_bbox_aux_2: 0.0856 (0.0971)  loss_giou_aux_2: 0.3692 (0.3835)  loss_vfl_aux_3: 0.4691 (0.4871)  loss_bbox_aux_3: 0.0852 (0.0969)  loss_giou_aux_3: 0.3661 (0.3804)  loss_vfl_aux_4: 0.4618 (0.4802)  loss_bbox_aux_4: 0.0851 (0.0963)  loss_giou_aux_4: 0.3673 (0.3785)  loss_vfl_aux_5: 0.6003 (0.6016)  loss_bbox_aux_5: 0.1663 (0.1645)  loss_giou_aux_5: 0.5557 (0.5657)  loss_vfl_dn_0: 0.4429 (0.4426)  loss_bbox_dn_0: 0.1888 (0.1834)  loss_giou_dn_0: 0.6085 (0.6013)  loss_vfl_dn_1: 0.4100 (0.4041)  loss_bbox_dn_1: 0.1180 (0.1320)  loss_giou_dn_1: 0.4469 (0.4443)  loss_vfl_dn_2: 0.3971 (0.3907)  loss_bbox_dn_2: 0.1015 (0.1212)  loss_giou_dn_2: 0.4100 (0.4146)  loss_vfl_dn_3: 0.3898 (0.3866)  loss_bbox_dn_3: 0.0968 (0.1186)  loss_giou_dn_3: 0.3977 (0.4071)  loss_vfl_dn_4: 0.3897 (0.3843)  loss_bbox_dn_4: 0.0944 (0.1177)  loss_giou_dn_4: 0.4008 (0.4055)  loss_vfl_dn_5: 0.3895 (0.3842)  loss_bbox_dn_5: 0.0936 (0.1174)  loss_giou_dn_5: 0.4012 (0.4050)  time: 0.3276  data: 0.0138  max mem: 7790\n",
            "Epoch: [165] Total time: 0:00:11 (0.3508 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 13.2242 (13.0956)  loss_vfl: 0.4574 (0.4775)  loss_bbox: 0.0867 (0.0960)  loss_giou: 0.3690 (0.3781)  loss_vfl_aux_0: 0.5048 (0.5176)  loss_bbox_aux_0: 0.1049 (0.1168)  loss_giou_aux_0: 0.4423 (0.4320)  loss_vfl_aux_1: 0.4942 (0.4936)  loss_bbox_aux_1: 0.0915 (0.1026)  loss_giou_aux_1: 0.3989 (0.3967)  loss_vfl_aux_2: 0.4850 (0.4919)  loss_bbox_aux_2: 0.0856 (0.0971)  loss_giou_aux_2: 0.3692 (0.3835)  loss_vfl_aux_3: 0.4691 (0.4871)  loss_bbox_aux_3: 0.0852 (0.0969)  loss_giou_aux_3: 0.3661 (0.3804)  loss_vfl_aux_4: 0.4618 (0.4802)  loss_bbox_aux_4: 0.0851 (0.0963)  loss_giou_aux_4: 0.3673 (0.3785)  loss_vfl_aux_5: 0.6003 (0.6016)  loss_bbox_aux_5: 0.1663 (0.1645)  loss_giou_aux_5: 0.5557 (0.5657)  loss_vfl_dn_0: 0.4429 (0.4426)  loss_bbox_dn_0: 0.1888 (0.1834)  loss_giou_dn_0: 0.6085 (0.6013)  loss_vfl_dn_1: 0.4100 (0.4041)  loss_bbox_dn_1: 0.1180 (0.1320)  loss_giou_dn_1: 0.4469 (0.4443)  loss_vfl_dn_2: 0.3971 (0.3907)  loss_bbox_dn_2: 0.1015 (0.1212)  loss_giou_dn_2: 0.4100 (0.4146)  loss_vfl_dn_3: 0.3898 (0.3866)  loss_bbox_dn_3: 0.0968 (0.1186)  loss_giou_dn_3: 0.3977 (0.4071)  loss_vfl_dn_4: 0.3897 (0.3843)  loss_bbox_dn_4: 0.0944 (0.1177)  loss_giou_dn_4: 0.4008 (0.4055)  loss_vfl_dn_5: 0.3895 (0.3842)  loss_bbox_dn_5: 0.0936 (0.1174)  loss_giou_dn_5: 0.4012 (0.4050)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8905  data: 0.5747  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4376  data: 0.1109  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4507 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [166]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 11.4168 (11.4168)  loss_vfl: 0.3942 (0.3942)  loss_bbox: 0.0688 (0.0688)  loss_giou: 0.3659 (0.3659)  loss_vfl_aux_0: 0.4644 (0.4644)  loss_bbox_aux_0: 0.1107 (0.1107)  loss_giou_aux_0: 0.4270 (0.4270)  loss_vfl_aux_1: 0.4136 (0.4136)  loss_bbox_aux_1: 0.0783 (0.0783)  loss_giou_aux_1: 0.3947 (0.3947)  loss_vfl_aux_2: 0.3919 (0.3919)  loss_bbox_aux_2: 0.0739 (0.0739)  loss_giou_aux_2: 0.3714 (0.3714)  loss_vfl_aux_3: 0.3929 (0.3929)  loss_bbox_aux_3: 0.0705 (0.0705)  loss_giou_aux_3: 0.3676 (0.3676)  loss_vfl_aux_4: 0.3922 (0.3922)  loss_bbox_aux_4: 0.0692 (0.0692)  loss_giou_aux_4: 0.3661 (0.3661)  loss_vfl_aux_5: 0.5264 (0.5264)  loss_bbox_aux_5: 0.1217 (0.1217)  loss_giou_aux_5: 0.5293 (0.5293)  loss_vfl_dn_0: 0.4394 (0.4394)  loss_bbox_dn_0: 0.1255 (0.1255)  loss_giou_dn_0: 0.5269 (0.5269)  loss_vfl_dn_1: 0.3801 (0.3801)  loss_bbox_dn_1: 0.0768 (0.0768)  loss_giou_dn_1: 0.3805 (0.3805)  loss_vfl_dn_2: 0.3628 (0.3628)  loss_bbox_dn_2: 0.0679 (0.0679)  loss_giou_dn_2: 0.3482 (0.3482)  loss_vfl_dn_3: 0.3618 (0.3618)  loss_bbox_dn_3: 0.0664 (0.0664)  loss_giou_dn_3: 0.3455 (0.3455)  loss_vfl_dn_4: 0.3606 (0.3606)  loss_bbox_dn_4: 0.0658 (0.0658)  loss_giou_dn_4: 0.3461 (0.3461)  loss_vfl_dn_5: 0.3587 (0.3587)  loss_bbox_dn_5: 0.0656 (0.0656)  loss_giou_dn_5: 0.3478 (0.3478)  time: 0.9938  data: 0.6045  max mem: 7790\n",
            "Epoch: [166]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.5255 (13.3442)  loss_vfl: 0.4573 (0.4793)  loss_bbox: 0.0806 (0.0995)  loss_giou: 0.3926 (0.4010)  loss_vfl_aux_0: 0.4969 (0.5185)  loss_bbox_aux_0: 0.0893 (0.1112)  loss_giou_aux_0: 0.4289 (0.4436)  loss_vfl_aux_1: 0.4825 (0.5073)  loss_bbox_aux_1: 0.0833 (0.1031)  loss_giou_aux_1: 0.4017 (0.4124)  loss_vfl_aux_2: 0.4769 (0.4990)  loss_bbox_aux_2: 0.0842 (0.1000)  loss_giou_aux_2: 0.3917 (0.4060)  loss_vfl_aux_3: 0.4658 (0.4913)  loss_bbox_aux_3: 0.0819 (0.1004)  loss_giou_aux_3: 0.3886 (0.4041)  loss_vfl_aux_4: 0.4590 (0.4814)  loss_bbox_aux_4: 0.0811 (0.0997)  loss_giou_aux_4: 0.3831 (0.4011)  loss_vfl_aux_5: 0.6004 (0.6091)  loss_bbox_aux_5: 0.1207 (0.1567)  loss_giou_aux_5: 0.5421 (0.5597)  loss_vfl_dn_0: 0.4334 (0.4371)  loss_bbox_dn_0: 0.1376 (0.1814)  loss_giou_dn_0: 0.5904 (0.6167)  loss_vfl_dn_1: 0.3989 (0.4002)  loss_bbox_dn_1: 0.1024 (0.1305)  loss_giou_dn_1: 0.4490 (0.4610)  loss_vfl_dn_2: 0.3833 (0.3890)  loss_bbox_dn_2: 0.0945 (0.1212)  loss_giou_dn_2: 0.4143 (0.4356)  loss_vfl_dn_3: 0.3797 (0.3857)  loss_bbox_dn_3: 0.0930 (0.1186)  loss_giou_dn_3: 0.4072 (0.4274)  loss_vfl_dn_4: 0.3799 (0.3849)  loss_bbox_dn_4: 0.0922 (0.1178)  loss_giou_dn_4: 0.4025 (0.4253)  loss_vfl_dn_5: 0.3804 (0.3844)  loss_bbox_dn_5: 0.0921 (0.1175)  loss_giou_dn_5: 0.4019 (0.4254)  time: 0.3294  data: 0.0145  max mem: 7790\n",
            "Epoch: [166] Total time: 0:00:11 (0.3534 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.5255 (13.3442)  loss_vfl: 0.4573 (0.4793)  loss_bbox: 0.0806 (0.0995)  loss_giou: 0.3926 (0.4010)  loss_vfl_aux_0: 0.4969 (0.5185)  loss_bbox_aux_0: 0.0893 (0.1112)  loss_giou_aux_0: 0.4289 (0.4436)  loss_vfl_aux_1: 0.4825 (0.5073)  loss_bbox_aux_1: 0.0833 (0.1031)  loss_giou_aux_1: 0.4017 (0.4124)  loss_vfl_aux_2: 0.4769 (0.4990)  loss_bbox_aux_2: 0.0842 (0.1000)  loss_giou_aux_2: 0.3917 (0.4060)  loss_vfl_aux_3: 0.4658 (0.4913)  loss_bbox_aux_3: 0.0819 (0.1004)  loss_giou_aux_3: 0.3886 (0.4041)  loss_vfl_aux_4: 0.4590 (0.4814)  loss_bbox_aux_4: 0.0811 (0.0997)  loss_giou_aux_4: 0.3831 (0.4011)  loss_vfl_aux_5: 0.6004 (0.6091)  loss_bbox_aux_5: 0.1207 (0.1567)  loss_giou_aux_5: 0.5421 (0.5597)  loss_vfl_dn_0: 0.4334 (0.4371)  loss_bbox_dn_0: 0.1376 (0.1814)  loss_giou_dn_0: 0.5904 (0.6167)  loss_vfl_dn_1: 0.3989 (0.4002)  loss_bbox_dn_1: 0.1024 (0.1305)  loss_giou_dn_1: 0.4490 (0.4610)  loss_vfl_dn_2: 0.3833 (0.3890)  loss_bbox_dn_2: 0.0945 (0.1212)  loss_giou_dn_2: 0.4143 (0.4356)  loss_vfl_dn_3: 0.3797 (0.3857)  loss_bbox_dn_3: 0.0930 (0.1186)  loss_giou_dn_3: 0.4072 (0.4274)  loss_vfl_dn_4: 0.3799 (0.3849)  loss_bbox_dn_4: 0.0922 (0.1178)  loss_giou_dn_4: 0.4025 (0.4253)  loss_vfl_dn_5: 0.3804 (0.3844)  loss_bbox_dn_5: 0.0921 (0.1175)  loss_giou_dn_5: 0.4019 (0.4254)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9194  data: 0.6038  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3879  data: 0.1124  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4025 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.652\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [167]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 10.0851 (10.0851)  loss_vfl: 0.3923 (0.3923)  loss_bbox: 0.0540 (0.0540)  loss_giou: 0.2336 (0.2336)  loss_vfl_aux_0: 0.4423 (0.4423)  loss_bbox_aux_0: 0.0782 (0.0782)  loss_giou_aux_0: 0.3113 (0.3113)  loss_vfl_aux_1: 0.4024 (0.4024)  loss_bbox_aux_1: 0.0592 (0.0592)  loss_giou_aux_1: 0.2446 (0.2446)  loss_vfl_aux_2: 0.3973 (0.3973)  loss_bbox_aux_2: 0.0559 (0.0559)  loss_giou_aux_2: 0.2349 (0.2349)  loss_vfl_aux_3: 0.3831 (0.3831)  loss_bbox_aux_3: 0.0561 (0.0561)  loss_giou_aux_3: 0.2326 (0.2326)  loss_vfl_aux_4: 0.3976 (0.3976)  loss_bbox_aux_4: 0.0542 (0.0542)  loss_giou_aux_4: 0.2343 (0.2343)  loss_vfl_aux_5: 0.5705 (0.5705)  loss_bbox_aux_5: 0.2243 (0.2243)  loss_giou_aux_5: 0.6850 (0.6850)  loss_vfl_dn_0: 0.4313 (0.4313)  loss_bbox_dn_0: 0.1267 (0.1267)  loss_giou_dn_0: 0.5220 (0.5220)  loss_vfl_dn_1: 0.3581 (0.3581)  loss_bbox_dn_1: 0.0731 (0.0731)  loss_giou_dn_1: 0.2899 (0.2899)  loss_vfl_dn_2: 0.3324 (0.3324)  loss_bbox_dn_2: 0.0627 (0.0627)  loss_giou_dn_2: 0.2511 (0.2511)  loss_vfl_dn_3: 0.3271 (0.3271)  loss_bbox_dn_3: 0.0616 (0.0616)  loss_giou_dn_3: 0.2442 (0.2442)  loss_vfl_dn_4: 0.3260 (0.3260)  loss_bbox_dn_4: 0.0606 (0.0606)  loss_giou_dn_4: 0.2436 (0.2436)  loss_vfl_dn_5: 0.3265 (0.3265)  loss_bbox_dn_5: 0.0607 (0.0607)  loss_giou_dn_5: 0.2438 (0.2438)  time: 0.9260  data: 0.5175  max mem: 7790\n",
            "Epoch: [167]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.6618 (13.2392)  loss_vfl: 0.4627 (0.4897)  loss_bbox: 0.0843 (0.0909)  loss_giou: 0.3814 (0.4105)  loss_vfl_aux_0: 0.4900 (0.5175)  loss_bbox_aux_0: 0.0937 (0.1027)  loss_giou_aux_0: 0.4147 (0.4549)  loss_vfl_aux_1: 0.4926 (0.4993)  loss_bbox_aux_1: 0.0872 (0.0939)  loss_giou_aux_1: 0.4011 (0.4219)  loss_vfl_aux_2: 0.4880 (0.4989)  loss_bbox_aux_2: 0.0872 (0.0907)  loss_giou_aux_2: 0.3850 (0.4120)  loss_vfl_aux_3: 0.4799 (0.4891)  loss_bbox_aux_3: 0.0858 (0.0898)  loss_giou_aux_3: 0.3855 (0.4088)  loss_vfl_aux_4: 0.4779 (0.4844)  loss_bbox_aux_4: 0.0857 (0.0915)  loss_giou_aux_4: 0.3823 (0.4115)  loss_vfl_aux_5: 0.5553 (0.5829)  loss_bbox_aux_5: 0.1327 (0.1541)  loss_giou_aux_5: 0.5611 (0.6029)  loss_vfl_dn_0: 0.4338 (0.4372)  loss_bbox_dn_0: 0.1362 (0.1651)  loss_giou_dn_0: 0.5541 (0.6076)  loss_vfl_dn_1: 0.3974 (0.3985)  loss_bbox_dn_1: 0.0934 (0.1168)  loss_giou_dn_1: 0.4189 (0.4586)  loss_vfl_dn_2: 0.3863 (0.3872)  loss_bbox_dn_2: 0.0878 (0.1067)  loss_giou_dn_2: 0.3848 (0.4305)  loss_vfl_dn_3: 0.3834 (0.3823)  loss_bbox_dn_3: 0.0872 (0.1047)  loss_giou_dn_3: 0.3765 (0.4244)  loss_vfl_dn_4: 0.3837 (0.3818)  loss_bbox_dn_4: 0.0877 (0.1046)  loss_giou_dn_4: 0.3761 (0.4242)  loss_vfl_dn_5: 0.3814 (0.3821)  loss_bbox_dn_5: 0.0878 (0.1046)  loss_giou_dn_5: 0.3773 (0.4246)  time: 0.3245  data: 0.0141  max mem: 7790\n",
            "Epoch: [167] Total time: 0:00:11 (0.3557 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.6618 (13.2392)  loss_vfl: 0.4627 (0.4897)  loss_bbox: 0.0843 (0.0909)  loss_giou: 0.3814 (0.4105)  loss_vfl_aux_0: 0.4900 (0.5175)  loss_bbox_aux_0: 0.0937 (0.1027)  loss_giou_aux_0: 0.4147 (0.4549)  loss_vfl_aux_1: 0.4926 (0.4993)  loss_bbox_aux_1: 0.0872 (0.0939)  loss_giou_aux_1: 0.4011 (0.4219)  loss_vfl_aux_2: 0.4880 (0.4989)  loss_bbox_aux_2: 0.0872 (0.0907)  loss_giou_aux_2: 0.3850 (0.4120)  loss_vfl_aux_3: 0.4799 (0.4891)  loss_bbox_aux_3: 0.0858 (0.0898)  loss_giou_aux_3: 0.3855 (0.4088)  loss_vfl_aux_4: 0.4779 (0.4844)  loss_bbox_aux_4: 0.0857 (0.0915)  loss_giou_aux_4: 0.3823 (0.4115)  loss_vfl_aux_5: 0.5553 (0.5829)  loss_bbox_aux_5: 0.1327 (0.1541)  loss_giou_aux_5: 0.5611 (0.6029)  loss_vfl_dn_0: 0.4338 (0.4372)  loss_bbox_dn_0: 0.1362 (0.1651)  loss_giou_dn_0: 0.5541 (0.6076)  loss_vfl_dn_1: 0.3974 (0.3985)  loss_bbox_dn_1: 0.0934 (0.1168)  loss_giou_dn_1: 0.4189 (0.4586)  loss_vfl_dn_2: 0.3863 (0.3872)  loss_bbox_dn_2: 0.0878 (0.1067)  loss_giou_dn_2: 0.3848 (0.4305)  loss_vfl_dn_3: 0.3834 (0.3823)  loss_bbox_dn_3: 0.0872 (0.1047)  loss_giou_dn_3: 0.3765 (0.4244)  loss_vfl_dn_4: 0.3837 (0.3818)  loss_bbox_dn_4: 0.0877 (0.1046)  loss_giou_dn_4: 0.3761 (0.4242)  loss_vfl_dn_5: 0.3814 (0.3821)  loss_bbox_dn_5: 0.0878 (0.1046)  loss_giou_dn_5: 0.3773 (0.4246)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8705  data: 0.5609  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3845  data: 0.1148  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3993 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.669\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.361\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [168]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 11.9405 (11.9405)  loss_vfl: 0.4693 (0.4693)  loss_bbox: 0.1079 (0.1079)  loss_giou: 0.2659 (0.2659)  loss_vfl_aux_0: 0.5204 (0.5204)  loss_bbox_aux_0: 0.1198 (0.1198)  loss_giou_aux_0: 0.3278 (0.3278)  loss_vfl_aux_1: 0.4753 (0.4753)  loss_bbox_aux_1: 0.1049 (0.1049)  loss_giou_aux_1: 0.2916 (0.2916)  loss_vfl_aux_2: 0.4572 (0.4572)  loss_bbox_aux_2: 0.1051 (0.1051)  loss_giou_aux_2: 0.2800 (0.2800)  loss_vfl_aux_3: 0.4585 (0.4585)  loss_bbox_aux_3: 0.1044 (0.1044)  loss_giou_aux_3: 0.2750 (0.2750)  loss_vfl_aux_4: 0.4397 (0.4397)  loss_bbox_aux_4: 0.1058 (0.1058)  loss_giou_aux_4: 0.2747 (0.2747)  loss_vfl_aux_5: 0.7130 (0.7130)  loss_bbox_aux_5: 0.1572 (0.1572)  loss_giou_aux_5: 0.4311 (0.4311)  loss_vfl_dn_0: 0.4343 (0.4343)  loss_bbox_dn_0: 0.2394 (0.2394)  loss_giou_dn_0: 0.5258 (0.5258)  loss_vfl_dn_1: 0.3761 (0.3761)  loss_bbox_dn_1: 0.1697 (0.1697)  loss_giou_dn_1: 0.3715 (0.3715)  loss_vfl_dn_2: 0.3596 (0.3596)  loss_bbox_dn_2: 0.1533 (0.1533)  loss_giou_dn_2: 0.3397 (0.3397)  loss_vfl_dn_3: 0.3581 (0.3581)  loss_bbox_dn_3: 0.1452 (0.1452)  loss_giou_dn_3: 0.3327 (0.3327)  loss_vfl_dn_4: 0.3555 (0.3555)  loss_bbox_dn_4: 0.1424 (0.1424)  loss_giou_dn_4: 0.3292 (0.3292)  loss_vfl_dn_5: 0.3539 (0.3539)  loss_bbox_dn_5: 0.1412 (0.1412)  loss_giou_dn_5: 0.3279 (0.3279)  time: 0.9972  data: 0.5468  max mem: 7790\n",
            "Epoch: [168]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.6393 (12.4569)  loss_vfl: 0.4715 (0.4624)  loss_bbox: 0.0821 (0.0814)  loss_giou: 0.3873 (0.3740)  loss_vfl_aux_0: 0.5079 (0.5050)  loss_bbox_aux_0: 0.0909 (0.0923)  loss_giou_aux_0: 0.4301 (0.4206)  loss_vfl_aux_1: 0.4902 (0.4855)  loss_bbox_aux_1: 0.0838 (0.0840)  loss_giou_aux_1: 0.4027 (0.3859)  loss_vfl_aux_2: 0.4840 (0.4746)  loss_bbox_aux_2: 0.0817 (0.0818)  loss_giou_aux_2: 0.3932 (0.3781)  loss_vfl_aux_3: 0.4782 (0.4716)  loss_bbox_aux_3: 0.0788 (0.0806)  loss_giou_aux_3: 0.3820 (0.3738)  loss_vfl_aux_4: 0.4645 (0.4656)  loss_bbox_aux_4: 0.0805 (0.0808)  loss_giou_aux_4: 0.3838 (0.3739)  loss_vfl_aux_5: 0.5750 (0.5794)  loss_bbox_aux_5: 0.1258 (0.1367)  loss_giou_aux_5: 0.5482 (0.5495)  loss_vfl_dn_0: 0.4371 (0.4381)  loss_bbox_dn_0: 0.1422 (0.1473)  loss_giou_dn_0: 0.5772 (0.5778)  loss_vfl_dn_1: 0.4060 (0.3947)  loss_bbox_dn_1: 0.1005 (0.0991)  loss_giou_dn_1: 0.4292 (0.4218)  loss_vfl_dn_2: 0.3931 (0.3832)  loss_bbox_dn_2: 0.0889 (0.0905)  loss_giou_dn_2: 0.3918 (0.3970)  loss_vfl_dn_3: 0.3928 (0.3802)  loss_bbox_dn_3: 0.0880 (0.0881)  loss_giou_dn_3: 0.3885 (0.3904)  loss_vfl_dn_4: 0.3892 (0.3789)  loss_bbox_dn_4: 0.0878 (0.0877)  loss_giou_dn_4: 0.3894 (0.3894)  loss_vfl_dn_5: 0.3900 (0.3791)  loss_bbox_dn_5: 0.0879 (0.0874)  loss_giou_dn_5: 0.3895 (0.3888)  time: 0.3314  data: 0.0142  max mem: 7790\n",
            "Epoch: [168] Total time: 0:00:11 (0.3553 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.6393 (12.4569)  loss_vfl: 0.4715 (0.4624)  loss_bbox: 0.0821 (0.0814)  loss_giou: 0.3873 (0.3740)  loss_vfl_aux_0: 0.5079 (0.5050)  loss_bbox_aux_0: 0.0909 (0.0923)  loss_giou_aux_0: 0.4301 (0.4206)  loss_vfl_aux_1: 0.4902 (0.4855)  loss_bbox_aux_1: 0.0838 (0.0840)  loss_giou_aux_1: 0.4027 (0.3859)  loss_vfl_aux_2: 0.4840 (0.4746)  loss_bbox_aux_2: 0.0817 (0.0818)  loss_giou_aux_2: 0.3932 (0.3781)  loss_vfl_aux_3: 0.4782 (0.4716)  loss_bbox_aux_3: 0.0788 (0.0806)  loss_giou_aux_3: 0.3820 (0.3738)  loss_vfl_aux_4: 0.4645 (0.4656)  loss_bbox_aux_4: 0.0805 (0.0808)  loss_giou_aux_4: 0.3838 (0.3739)  loss_vfl_aux_5: 0.5750 (0.5794)  loss_bbox_aux_5: 0.1258 (0.1367)  loss_giou_aux_5: 0.5482 (0.5495)  loss_vfl_dn_0: 0.4371 (0.4381)  loss_bbox_dn_0: 0.1422 (0.1473)  loss_giou_dn_0: 0.5772 (0.5778)  loss_vfl_dn_1: 0.4060 (0.3947)  loss_bbox_dn_1: 0.1005 (0.0991)  loss_giou_dn_1: 0.4292 (0.4218)  loss_vfl_dn_2: 0.3931 (0.3832)  loss_bbox_dn_2: 0.0889 (0.0905)  loss_giou_dn_2: 0.3918 (0.3970)  loss_vfl_dn_3: 0.3928 (0.3802)  loss_bbox_dn_3: 0.0880 (0.0881)  loss_giou_dn_3: 0.3885 (0.3904)  loss_vfl_dn_4: 0.3892 (0.3789)  loss_bbox_dn_4: 0.0878 (0.0877)  loss_giou_dn_4: 0.3894 (0.3894)  loss_vfl_dn_5: 0.3900 (0.3791)  loss_bbox_dn_5: 0.0879 (0.0874)  loss_giou_dn_5: 0.3895 (0.3888)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8982  data: 0.5789  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3971  data: 0.1132  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4105 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.668\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [169]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 12.2505 (12.2505)  loss_vfl: 0.6376 (0.6376)  loss_bbox: 0.0877 (0.0877)  loss_giou: 0.2162 (0.2162)  loss_vfl_aux_0: 0.7110 (0.7110)  loss_bbox_aux_0: 0.1295 (0.1295)  loss_giou_aux_0: 0.2695 (0.2695)  loss_vfl_aux_1: 0.6778 (0.6778)  loss_bbox_aux_1: 0.1466 (0.1466)  loss_giou_aux_1: 0.2828 (0.2828)  loss_vfl_aux_2: 0.6561 (0.6561)  loss_bbox_aux_2: 0.1412 (0.1412)  loss_giou_aux_2: 0.2790 (0.2790)  loss_vfl_aux_3: 0.5953 (0.5953)  loss_bbox_aux_3: 0.1397 (0.1397)  loss_giou_aux_3: 0.2777 (0.2777)  loss_vfl_aux_4: 0.6484 (0.6484)  loss_bbox_aux_4: 0.0881 (0.0881)  loss_giou_aux_4: 0.2173 (0.2173)  loss_vfl_aux_5: 0.7289 (0.7289)  loss_bbox_aux_5: 0.2474 (0.2474)  loss_giou_aux_5: 0.5296 (0.5296)  loss_vfl_dn_0: 0.4060 (0.4060)  loss_bbox_dn_0: 0.1975 (0.1975)  loss_giou_dn_0: 0.4076 (0.4076)  loss_vfl_dn_1: 0.3387 (0.3387)  loss_bbox_dn_1: 0.1307 (0.1307)  loss_giou_dn_1: 0.2778 (0.2778)  loss_vfl_dn_2: 0.3281 (0.3281)  loss_bbox_dn_2: 0.1179 (0.1179)  loss_giou_dn_2: 0.2613 (0.2613)  loss_vfl_dn_3: 0.3235 (0.3235)  loss_bbox_dn_3: 0.1149 (0.1149)  loss_giou_dn_3: 0.2554 (0.2554)  loss_vfl_dn_4: 0.3226 (0.3226)  loss_bbox_dn_4: 0.1158 (0.1158)  loss_giou_dn_4: 0.2555 (0.2555)  loss_vfl_dn_5: 0.3204 (0.3204)  loss_bbox_dn_5: 0.1153 (0.1153)  loss_giou_dn_5: 0.2539 (0.2539)  time: 1.0111  data: 0.6223  max mem: 7790\n",
            "Epoch: [169]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.2498 (12.9020)  loss_vfl: 0.4852 (0.5045)  loss_bbox: 0.0865 (0.1017)  loss_giou: 0.3155 (0.3478)  loss_vfl_aux_0: 0.5282 (0.5548)  loss_bbox_aux_0: 0.1065 (0.1195)  loss_giou_aux_0: 0.3605 (0.3945)  loss_vfl_aux_1: 0.5176 (0.5394)  loss_bbox_aux_1: 0.0876 (0.1066)  loss_giou_aux_1: 0.3264 (0.3593)  loss_vfl_aux_2: 0.5238 (0.5261)  loss_bbox_aux_2: 0.0848 (0.1043)  loss_giou_aux_2: 0.3225 (0.3504)  loss_vfl_aux_3: 0.4931 (0.5174)  loss_bbox_aux_3: 0.0870 (0.1035)  loss_giou_aux_3: 0.3173 (0.3499)  loss_vfl_aux_4: 0.4895 (0.5049)  loss_bbox_aux_4: 0.0906 (0.1028)  loss_giou_aux_4: 0.3124 (0.3490)  loss_vfl_aux_5: 0.5934 (0.6231)  loss_bbox_aux_5: 0.1653 (0.1794)  loss_giou_aux_5: 0.5268 (0.5389)  loss_vfl_dn_0: 0.4396 (0.4391)  loss_bbox_dn_0: 0.1916 (0.1973)  loss_giou_dn_0: 0.5108 (0.5477)  loss_vfl_dn_1: 0.3906 (0.3952)  loss_bbox_dn_1: 0.1319 (0.1418)  loss_giou_dn_1: 0.3524 (0.4010)  loss_vfl_dn_2: 0.3730 (0.3818)  loss_bbox_dn_2: 0.1120 (0.1307)  loss_giou_dn_2: 0.3185 (0.3739)  loss_vfl_dn_3: 0.3669 (0.3779)  loss_bbox_dn_3: 0.1095 (0.1285)  loss_giou_dn_3: 0.3188 (0.3686)  loss_vfl_dn_4: 0.3696 (0.3759)  loss_bbox_dn_4: 0.1065 (0.1279)  loss_giou_dn_4: 0.3198 (0.3670)  loss_vfl_dn_5: 0.3686 (0.3754)  loss_bbox_dn_5: 0.1062 (0.1276)  loss_giou_dn_5: 0.3236 (0.3669)  time: 0.3261  data: 0.0144  max mem: 7790\n",
            "Epoch: [169] Total time: 0:00:11 (0.3494 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.2498 (12.9020)  loss_vfl: 0.4852 (0.5045)  loss_bbox: 0.0865 (0.1017)  loss_giou: 0.3155 (0.3478)  loss_vfl_aux_0: 0.5282 (0.5548)  loss_bbox_aux_0: 0.1065 (0.1195)  loss_giou_aux_0: 0.3605 (0.3945)  loss_vfl_aux_1: 0.5176 (0.5394)  loss_bbox_aux_1: 0.0876 (0.1066)  loss_giou_aux_1: 0.3264 (0.3593)  loss_vfl_aux_2: 0.5238 (0.5261)  loss_bbox_aux_2: 0.0848 (0.1043)  loss_giou_aux_2: 0.3225 (0.3504)  loss_vfl_aux_3: 0.4931 (0.5174)  loss_bbox_aux_3: 0.0870 (0.1035)  loss_giou_aux_3: 0.3173 (0.3499)  loss_vfl_aux_4: 0.4895 (0.5049)  loss_bbox_aux_4: 0.0906 (0.1028)  loss_giou_aux_4: 0.3124 (0.3490)  loss_vfl_aux_5: 0.5934 (0.6231)  loss_bbox_aux_5: 0.1653 (0.1794)  loss_giou_aux_5: 0.5268 (0.5389)  loss_vfl_dn_0: 0.4396 (0.4391)  loss_bbox_dn_0: 0.1916 (0.1973)  loss_giou_dn_0: 0.5108 (0.5477)  loss_vfl_dn_1: 0.3906 (0.3952)  loss_bbox_dn_1: 0.1319 (0.1418)  loss_giou_dn_1: 0.3524 (0.4010)  loss_vfl_dn_2: 0.3730 (0.3818)  loss_bbox_dn_2: 0.1120 (0.1307)  loss_giou_dn_2: 0.3185 (0.3739)  loss_vfl_dn_3: 0.3669 (0.3779)  loss_bbox_dn_3: 0.1095 (0.1285)  loss_giou_dn_3: 0.3188 (0.3686)  loss_vfl_dn_4: 0.3696 (0.3759)  loss_bbox_dn_4: 0.1065 (0.1279)  loss_giou_dn_4: 0.3198 (0.3670)  loss_vfl_dn_5: 0.3686 (0.3754)  loss_bbox_dn_5: 0.1062 (0.1276)  loss_giou_dn_5: 0.3236 (0.3669)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9058  data: 0.5925  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3862  data: 0.1133  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3986 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.672\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [170]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 13.5567 (13.5567)  loss_vfl: 0.5541 (0.5541)  loss_bbox: 0.0588 (0.0588)  loss_giou: 0.3773 (0.3773)  loss_vfl_aux_0: 0.6273 (0.6273)  loss_bbox_aux_0: 0.0717 (0.0717)  loss_giou_aux_0: 0.4508 (0.4508)  loss_vfl_aux_1: 0.6133 (0.6133)  loss_bbox_aux_1: 0.0580 (0.0580)  loss_giou_aux_1: 0.4016 (0.4016)  loss_vfl_aux_2: 0.6085 (0.6085)  loss_bbox_aux_2: 0.0559 (0.0559)  loss_giou_aux_2: 0.3865 (0.3865)  loss_vfl_aux_3: 0.5974 (0.5974)  loss_bbox_aux_3: 0.0582 (0.0582)  loss_giou_aux_3: 0.3765 (0.3765)  loss_vfl_aux_4: 0.5637 (0.5637)  loss_bbox_aux_4: 0.0591 (0.0591)  loss_giou_aux_4: 0.3767 (0.3767)  loss_vfl_aux_5: 0.6450 (0.6450)  loss_bbox_aux_5: 0.1166 (0.1166)  loss_giou_aux_5: 0.6345 (0.6345)  loss_vfl_dn_0: 0.4371 (0.4371)  loss_bbox_dn_0: 0.1585 (0.1585)  loss_giou_dn_0: 0.6468 (0.6468)  loss_vfl_dn_1: 0.4121 (0.4121)  loss_bbox_dn_1: 0.1004 (0.1004)  loss_giou_dn_1: 0.4986 (0.4986)  loss_vfl_dn_2: 0.3950 (0.3950)  loss_bbox_dn_2: 0.0803 (0.0803)  loss_giou_dn_2: 0.4498 (0.4498)  loss_vfl_dn_3: 0.3976 (0.3976)  loss_bbox_dn_3: 0.0722 (0.0722)  loss_giou_dn_3: 0.4346 (0.4346)  loss_vfl_dn_4: 0.3936 (0.3936)  loss_bbox_dn_4: 0.0688 (0.0688)  loss_giou_dn_4: 0.4296 (0.4296)  loss_vfl_dn_5: 0.3968 (0.3968)  loss_bbox_dn_5: 0.0676 (0.0676)  loss_giou_dn_5: 0.4260 (0.4260)  time: 0.9510  data: 0.5578  max mem: 7790\n",
            "Epoch: [170]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.9190 (12.6890)  loss_vfl: 0.4843 (0.4834)  loss_bbox: 0.0876 (0.0839)  loss_giou: 0.3427 (0.3648)  loss_vfl_aux_0: 0.5254 (0.5185)  loss_bbox_aux_0: 0.1014 (0.1005)  loss_giou_aux_0: 0.3875 (0.4156)  loss_vfl_aux_1: 0.5034 (0.5012)  loss_bbox_aux_1: 0.0977 (0.0884)  loss_giou_aux_1: 0.3612 (0.3760)  loss_vfl_aux_2: 0.4909 (0.4989)  loss_bbox_aux_2: 0.0920 (0.0842)  loss_giou_aux_2: 0.3513 (0.3661)  loss_vfl_aux_3: 0.4809 (0.4912)  loss_bbox_aux_3: 0.0881 (0.0833)  loss_giou_aux_3: 0.3409 (0.3640)  loss_vfl_aux_4: 0.4754 (0.4795)  loss_bbox_aux_4: 0.0878 (0.0838)  loss_giou_aux_4: 0.3429 (0.3642)  loss_vfl_aux_5: 0.5925 (0.5949)  loss_bbox_aux_5: 0.1547 (0.1497)  loss_giou_aux_5: 0.5594 (0.5573)  loss_vfl_dn_0: 0.4375 (0.4384)  loss_bbox_dn_0: 0.1654 (0.1641)  loss_giou_dn_0: 0.5540 (0.5842)  loss_vfl_dn_1: 0.3980 (0.3940)  loss_bbox_dn_1: 0.1197 (0.1147)  loss_giou_dn_1: 0.4175 (0.4297)  loss_vfl_dn_2: 0.3850 (0.3824)  loss_bbox_dn_2: 0.1089 (0.1054)  loss_giou_dn_2: 0.3916 (0.4026)  loss_vfl_dn_3: 0.3794 (0.3778)  loss_bbox_dn_3: 0.1054 (0.1031)  loss_giou_dn_3: 0.3863 (0.3951)  loss_vfl_dn_4: 0.3725 (0.3768)  loss_bbox_dn_4: 0.1046 (0.1028)  loss_giou_dn_4: 0.3889 (0.3938)  loss_vfl_dn_5: 0.3735 (0.3778)  loss_bbox_dn_5: 0.1045 (0.1027)  loss_giou_dn_5: 0.3929 (0.3941)  time: 0.3256  data: 0.0149  max mem: 7790\n",
            "Epoch: [170] Total time: 0:00:11 (0.3486 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.9190 (12.6890)  loss_vfl: 0.4843 (0.4834)  loss_bbox: 0.0876 (0.0839)  loss_giou: 0.3427 (0.3648)  loss_vfl_aux_0: 0.5254 (0.5185)  loss_bbox_aux_0: 0.1014 (0.1005)  loss_giou_aux_0: 0.3875 (0.4156)  loss_vfl_aux_1: 0.5034 (0.5012)  loss_bbox_aux_1: 0.0977 (0.0884)  loss_giou_aux_1: 0.3612 (0.3760)  loss_vfl_aux_2: 0.4909 (0.4989)  loss_bbox_aux_2: 0.0920 (0.0842)  loss_giou_aux_2: 0.3513 (0.3661)  loss_vfl_aux_3: 0.4809 (0.4912)  loss_bbox_aux_3: 0.0881 (0.0833)  loss_giou_aux_3: 0.3409 (0.3640)  loss_vfl_aux_4: 0.4754 (0.4795)  loss_bbox_aux_4: 0.0878 (0.0838)  loss_giou_aux_4: 0.3429 (0.3642)  loss_vfl_aux_5: 0.5925 (0.5949)  loss_bbox_aux_5: 0.1547 (0.1497)  loss_giou_aux_5: 0.5594 (0.5573)  loss_vfl_dn_0: 0.4375 (0.4384)  loss_bbox_dn_0: 0.1654 (0.1641)  loss_giou_dn_0: 0.5540 (0.5842)  loss_vfl_dn_1: 0.3980 (0.3940)  loss_bbox_dn_1: 0.1197 (0.1147)  loss_giou_dn_1: 0.4175 (0.4297)  loss_vfl_dn_2: 0.3850 (0.3824)  loss_bbox_dn_2: 0.1089 (0.1054)  loss_giou_dn_2: 0.3916 (0.4026)  loss_vfl_dn_3: 0.3794 (0.3778)  loss_bbox_dn_3: 0.1054 (0.1031)  loss_giou_dn_3: 0.3863 (0.3951)  loss_vfl_dn_4: 0.3725 (0.3768)  loss_bbox_dn_4: 0.1046 (0.1028)  loss_giou_dn_4: 0.3889 (0.3938)  loss_vfl_dn_5: 0.3735 (0.3778)  loss_bbox_dn_5: 0.1045 (0.1027)  loss_giou_dn_5: 0.3929 (0.3941)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8974  data: 0.5851  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3852  data: 0.1125  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3983 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.673\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [171]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 14.4222 (14.4222)  loss_vfl: 0.4822 (0.4822)  loss_bbox: 0.1166 (0.1166)  loss_giou: 0.4746 (0.4746)  loss_vfl_aux_0: 0.4804 (0.4804)  loss_bbox_aux_0: 0.1252 (0.1252)  loss_giou_aux_0: 0.5305 (0.5305)  loss_vfl_aux_1: 0.4687 (0.4687)  loss_bbox_aux_1: 0.1196 (0.1196)  loss_giou_aux_1: 0.5004 (0.5004)  loss_vfl_aux_2: 0.4675 (0.4675)  loss_bbox_aux_2: 0.1164 (0.1164)  loss_giou_aux_2: 0.4889 (0.4889)  loss_vfl_aux_3: 0.4659 (0.4659)  loss_bbox_aux_3: 0.1185 (0.1185)  loss_giou_aux_3: 0.4891 (0.4891)  loss_vfl_aux_4: 0.4677 (0.4677)  loss_bbox_aux_4: 0.1168 (0.1168)  loss_giou_aux_4: 0.4763 (0.4763)  loss_vfl_aux_5: 0.4944 (0.4944)  loss_bbox_aux_5: 0.1681 (0.1681)  loss_giou_aux_5: 0.6969 (0.6969)  loss_vfl_dn_0: 0.4776 (0.4776)  loss_bbox_dn_0: 0.1649 (0.1649)  loss_giou_dn_0: 0.6203 (0.6203)  loss_vfl_dn_1: 0.4560 (0.4560)  loss_bbox_dn_1: 0.1320 (0.1320)  loss_giou_dn_1: 0.5041 (0.5041)  loss_vfl_dn_2: 0.4413 (0.4413)  loss_bbox_dn_2: 0.1300 (0.1300)  loss_giou_dn_2: 0.4830 (0.4830)  loss_vfl_dn_3: 0.4362 (0.4362)  loss_bbox_dn_3: 0.1317 (0.1317)  loss_giou_dn_3: 0.4810 (0.4810)  loss_vfl_dn_4: 0.4344 (0.4344)  loss_bbox_dn_4: 0.1333 (0.1333)  loss_giou_dn_4: 0.4828 (0.4828)  loss_vfl_dn_5: 0.4325 (0.4325)  loss_bbox_dn_5: 0.1333 (0.1333)  loss_giou_dn_5: 0.4827 (0.4827)  time: 1.0051  data: 0.6255  max mem: 7790\n",
            "Epoch: [171]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.4851 (12.3669)  loss_vfl: 0.4521 (0.4506)  loss_bbox: 0.0666 (0.0787)  loss_giou: 0.3914 (0.3768)  loss_vfl_aux_0: 0.4951 (0.4934)  loss_bbox_aux_0: 0.0795 (0.0882)  loss_giou_aux_0: 0.4347 (0.4175)  loss_vfl_aux_1: 0.4762 (0.4823)  loss_bbox_aux_1: 0.0697 (0.0797)  loss_giou_aux_1: 0.3819 (0.3873)  loss_vfl_aux_2: 0.4847 (0.4761)  loss_bbox_aux_2: 0.0662 (0.0776)  loss_giou_aux_2: 0.3811 (0.3791)  loss_vfl_aux_3: 0.4692 (0.4668)  loss_bbox_aux_3: 0.0667 (0.0775)  loss_giou_aux_3: 0.3920 (0.3775)  loss_vfl_aux_4: 0.4502 (0.4546)  loss_bbox_aux_4: 0.0671 (0.0786)  loss_giou_aux_4: 0.3919 (0.3770)  loss_vfl_aux_5: 0.5545 (0.5611)  loss_bbox_aux_5: 0.1174 (0.1255)  loss_giou_aux_5: 0.5630 (0.5476)  loss_vfl_dn_0: 0.4305 (0.4362)  loss_bbox_dn_0: 0.1139 (0.1380)  loss_giou_dn_0: 0.5749 (0.5693)  loss_vfl_dn_1: 0.3961 (0.3923)  loss_bbox_dn_1: 0.0785 (0.0968)  loss_giou_dn_1: 0.4120 (0.4243)  loss_vfl_dn_2: 0.3857 (0.3813)  loss_bbox_dn_2: 0.0683 (0.0906)  loss_giou_dn_2: 0.4012 (0.4019)  loss_vfl_dn_3: 0.3819 (0.3774)  loss_bbox_dn_3: 0.0676 (0.0890)  loss_giou_dn_3: 0.4010 (0.3966)  loss_vfl_dn_4: 0.3796 (0.3758)  loss_bbox_dn_4: 0.0679 (0.0887)  loss_giou_dn_4: 0.3985 (0.3959)  loss_vfl_dn_5: 0.3774 (0.3749)  loss_bbox_dn_5: 0.0678 (0.0886)  loss_giou_dn_5: 0.3990 (0.3958)  time: 0.3261  data: 0.0142  max mem: 7790\n",
            "Epoch: [171] Total time: 0:00:11 (0.3493 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.4851 (12.3669)  loss_vfl: 0.4521 (0.4506)  loss_bbox: 0.0666 (0.0787)  loss_giou: 0.3914 (0.3768)  loss_vfl_aux_0: 0.4951 (0.4934)  loss_bbox_aux_0: 0.0795 (0.0882)  loss_giou_aux_0: 0.4347 (0.4175)  loss_vfl_aux_1: 0.4762 (0.4823)  loss_bbox_aux_1: 0.0697 (0.0797)  loss_giou_aux_1: 0.3819 (0.3873)  loss_vfl_aux_2: 0.4847 (0.4761)  loss_bbox_aux_2: 0.0662 (0.0776)  loss_giou_aux_2: 0.3811 (0.3791)  loss_vfl_aux_3: 0.4692 (0.4668)  loss_bbox_aux_3: 0.0667 (0.0775)  loss_giou_aux_3: 0.3920 (0.3775)  loss_vfl_aux_4: 0.4502 (0.4546)  loss_bbox_aux_4: 0.0671 (0.0786)  loss_giou_aux_4: 0.3919 (0.3770)  loss_vfl_aux_5: 0.5545 (0.5611)  loss_bbox_aux_5: 0.1174 (0.1255)  loss_giou_aux_5: 0.5630 (0.5476)  loss_vfl_dn_0: 0.4305 (0.4362)  loss_bbox_dn_0: 0.1139 (0.1380)  loss_giou_dn_0: 0.5749 (0.5693)  loss_vfl_dn_1: 0.3961 (0.3923)  loss_bbox_dn_1: 0.0785 (0.0968)  loss_giou_dn_1: 0.4120 (0.4243)  loss_vfl_dn_2: 0.3857 (0.3813)  loss_bbox_dn_2: 0.0683 (0.0906)  loss_giou_dn_2: 0.4012 (0.4019)  loss_vfl_dn_3: 0.3819 (0.3774)  loss_bbox_dn_3: 0.0676 (0.0890)  loss_giou_dn_3: 0.4010 (0.3966)  loss_vfl_dn_4: 0.3796 (0.3758)  loss_bbox_dn_4: 0.0679 (0.0887)  loss_giou_dn_4: 0.3985 (0.3959)  loss_vfl_dn_5: 0.3774 (0.3749)  loss_bbox_dn_5: 0.0678 (0.0886)  loss_giou_dn_5: 0.3990 (0.3958)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9272  data: 0.6165  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4422  data: 0.1148  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4565 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.324\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [172]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 12.7385 (12.7385)  loss_vfl: 0.4737 (0.4737)  loss_bbox: 0.0733 (0.0733)  loss_giou: 0.4422 (0.4422)  loss_vfl_aux_0: 0.4662 (0.4662)  loss_bbox_aux_0: 0.0727 (0.0727)  loss_giou_aux_0: 0.4655 (0.4655)  loss_vfl_aux_1: 0.4711 (0.4711)  loss_bbox_aux_1: 0.0662 (0.0662)  loss_giou_aux_1: 0.4422 (0.4422)  loss_vfl_aux_2: 0.4705 (0.4705)  loss_bbox_aux_2: 0.0668 (0.0668)  loss_giou_aux_2: 0.4371 (0.4371)  loss_vfl_aux_3: 0.4655 (0.4655)  loss_bbox_aux_3: 0.0711 (0.0711)  loss_giou_aux_3: 0.4349 (0.4349)  loss_vfl_aux_4: 0.4612 (0.4612)  loss_bbox_aux_4: 0.0729 (0.0729)  loss_giou_aux_4: 0.4461 (0.4461)  loss_vfl_aux_5: 0.5421 (0.5421)  loss_bbox_aux_5: 0.0955 (0.0955)  loss_giou_aux_5: 0.5635 (0.5635)  loss_vfl_dn_0: 0.4318 (0.4318)  loss_bbox_dn_0: 0.1218 (0.1218)  loss_giou_dn_0: 0.6173 (0.6173)  loss_vfl_dn_1: 0.3867 (0.3867)  loss_bbox_dn_1: 0.0811 (0.0811)  loss_giou_dn_1: 0.4586 (0.4586)  loss_vfl_dn_2: 0.3724 (0.3724)  loss_bbox_dn_2: 0.0748 (0.0748)  loss_giou_dn_2: 0.4371 (0.4371)  loss_vfl_dn_3: 0.3708 (0.3708)  loss_bbox_dn_3: 0.0758 (0.0758)  loss_giou_dn_3: 0.4398 (0.4398)  loss_vfl_dn_4: 0.3683 (0.3683)  loss_bbox_dn_4: 0.0760 (0.0760)  loss_giou_dn_4: 0.4403 (0.4403)  loss_vfl_dn_5: 0.3692 (0.3692)  loss_bbox_dn_5: 0.0762 (0.0762)  loss_giou_dn_5: 0.4403 (0.4403)  time: 0.9273  data: 0.5326  max mem: 7790\n",
            "Epoch: [172]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.5029 (12.7213)  loss_vfl: 0.4626 (0.4887)  loss_bbox: 0.0793 (0.0814)  loss_giou: 0.3592 (0.3804)  loss_vfl_aux_0: 0.4727 (0.5033)  loss_bbox_aux_0: 0.0983 (0.0967)  loss_giou_aux_0: 0.4092 (0.4290)  loss_vfl_aux_1: 0.4832 (0.5086)  loss_bbox_aux_1: 0.0852 (0.0866)  loss_giou_aux_1: 0.3767 (0.3964)  loss_vfl_aux_2: 0.4618 (0.5018)  loss_bbox_aux_2: 0.0800 (0.0832)  loss_giou_aux_2: 0.3738 (0.3862)  loss_vfl_aux_3: 0.4621 (0.5013)  loss_bbox_aux_3: 0.0782 (0.0817)  loss_giou_aux_3: 0.3745 (0.3826)  loss_vfl_aux_4: 0.4613 (0.4862)  loss_bbox_aux_4: 0.0793 (0.0821)  loss_giou_aux_4: 0.3589 (0.3825)  loss_vfl_aux_5: 0.5440 (0.5745)  loss_bbox_aux_5: 0.1369 (0.1340)  loss_giou_aux_5: 0.5395 (0.5497)  loss_vfl_dn_0: 0.4371 (0.4395)  loss_bbox_dn_0: 0.1426 (0.1492)  loss_giou_dn_0: 0.5402 (0.5727)  loss_vfl_dn_1: 0.3990 (0.3995)  loss_bbox_dn_1: 0.0995 (0.1040)  loss_giou_dn_1: 0.3880 (0.4275)  loss_vfl_dn_2: 0.3862 (0.3893)  loss_bbox_dn_2: 0.0947 (0.0962)  loss_giou_dn_2: 0.3581 (0.4031)  loss_vfl_dn_3: 0.3812 (0.3861)  loss_bbox_dn_3: 0.0924 (0.0940)  loss_giou_dn_3: 0.3494 (0.3971)  loss_vfl_dn_4: 0.3826 (0.3853)  loss_bbox_dn_4: 0.0915 (0.0932)  loss_giou_dn_4: 0.3459 (0.3951)  loss_vfl_dn_5: 0.3770 (0.3848)  loss_bbox_dn_5: 0.0903 (0.0929)  loss_giou_dn_5: 0.3470 (0.3948)  time: 0.3226  data: 0.0141  max mem: 7790\n",
            "Epoch: [172] Total time: 0:00:11 (0.3482 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.5029 (12.7213)  loss_vfl: 0.4626 (0.4887)  loss_bbox: 0.0793 (0.0814)  loss_giou: 0.3592 (0.3804)  loss_vfl_aux_0: 0.4727 (0.5033)  loss_bbox_aux_0: 0.0983 (0.0967)  loss_giou_aux_0: 0.4092 (0.4290)  loss_vfl_aux_1: 0.4832 (0.5086)  loss_bbox_aux_1: 0.0852 (0.0866)  loss_giou_aux_1: 0.3767 (0.3964)  loss_vfl_aux_2: 0.4618 (0.5018)  loss_bbox_aux_2: 0.0800 (0.0832)  loss_giou_aux_2: 0.3738 (0.3862)  loss_vfl_aux_3: 0.4621 (0.5013)  loss_bbox_aux_3: 0.0782 (0.0817)  loss_giou_aux_3: 0.3745 (0.3826)  loss_vfl_aux_4: 0.4613 (0.4862)  loss_bbox_aux_4: 0.0793 (0.0821)  loss_giou_aux_4: 0.3589 (0.3825)  loss_vfl_aux_5: 0.5440 (0.5745)  loss_bbox_aux_5: 0.1369 (0.1340)  loss_giou_aux_5: 0.5395 (0.5497)  loss_vfl_dn_0: 0.4371 (0.4395)  loss_bbox_dn_0: 0.1426 (0.1492)  loss_giou_dn_0: 0.5402 (0.5727)  loss_vfl_dn_1: 0.3990 (0.3995)  loss_bbox_dn_1: 0.0995 (0.1040)  loss_giou_dn_1: 0.3880 (0.4275)  loss_vfl_dn_2: 0.3862 (0.3893)  loss_bbox_dn_2: 0.0947 (0.0962)  loss_giou_dn_2: 0.3581 (0.4031)  loss_vfl_dn_3: 0.3812 (0.3861)  loss_bbox_dn_3: 0.0924 (0.0940)  loss_giou_dn_3: 0.3494 (0.3971)  loss_vfl_dn_4: 0.3826 (0.3853)  loss_bbox_dn_4: 0.0915 (0.0932)  loss_giou_dn_4: 0.3459 (0.3951)  loss_vfl_dn_5: 0.3770 (0.3848)  loss_bbox_dn_5: 0.0903 (0.0929)  loss_giou_dn_5: 0.3470 (0.3948)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9134  data: 0.6051  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4449  data: 0.1193  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4590 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.668\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.404\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [173]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 14.9195 (14.9195)  loss_vfl: 0.6083 (0.6083)  loss_bbox: 0.1023 (0.1023)  loss_giou: 0.4634 (0.4634)  loss_vfl_aux_0: 0.6090 (0.6090)  loss_bbox_aux_0: 0.1122 (0.1122)  loss_giou_aux_0: 0.4849 (0.4849)  loss_vfl_aux_1: 0.6135 (0.6135)  loss_bbox_aux_1: 0.1044 (0.1044)  loss_giou_aux_1: 0.4646 (0.4646)  loss_vfl_aux_2: 0.5861 (0.5861)  loss_bbox_aux_2: 0.1004 (0.1004)  loss_giou_aux_2: 0.4589 (0.4589)  loss_vfl_aux_3: 0.5871 (0.5871)  loss_bbox_aux_3: 0.1041 (0.1041)  loss_giou_aux_3: 0.4651 (0.4651)  loss_vfl_aux_4: 0.6161 (0.6161)  loss_bbox_aux_4: 0.1033 (0.1033)  loss_giou_aux_4: 0.4638 (0.4638)  loss_vfl_aux_5: 0.6358 (0.6358)  loss_bbox_aux_5: 0.1534 (0.1534)  loss_giou_aux_5: 0.6011 (0.6011)  loss_vfl_dn_0: 0.4489 (0.4489)  loss_bbox_dn_0: 0.1957 (0.1957)  loss_giou_dn_0: 0.6514 (0.6514)  loss_vfl_dn_1: 0.4125 (0.4125)  loss_bbox_dn_1: 0.1493 (0.1493)  loss_giou_dn_1: 0.5081 (0.5081)  loss_vfl_dn_2: 0.4040 (0.4040)  loss_bbox_dn_2: 0.1342 (0.1342)  loss_giou_dn_2: 0.4879 (0.4879)  loss_vfl_dn_3: 0.4059 (0.4059)  loss_bbox_dn_3: 0.1370 (0.1370)  loss_giou_dn_3: 0.4833 (0.4833)  loss_vfl_dn_4: 0.4110 (0.4110)  loss_bbox_dn_4: 0.1358 (0.1358)  loss_giou_dn_4: 0.4847 (0.4847)  loss_vfl_dn_5: 0.4107 (0.4107)  loss_bbox_dn_5: 0.1356 (0.1356)  loss_giou_dn_5: 0.4857 (0.4857)  time: 0.9809  data: 0.5786  max mem: 7790\n",
            "Epoch: [173]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.9702 (12.9843)  loss_vfl: 0.4835 (0.5062)  loss_bbox: 0.0743 (0.0894)  loss_giou: 0.3741 (0.3705)  loss_vfl_aux_0: 0.5249 (0.5277)  loss_bbox_aux_0: 0.0850 (0.1055)  loss_giou_aux_0: 0.4110 (0.4219)  loss_vfl_aux_1: 0.5097 (0.5238)  loss_bbox_aux_1: 0.0747 (0.0922)  loss_giou_aux_1: 0.3955 (0.3850)  loss_vfl_aux_2: 0.5200 (0.5258)  loss_bbox_aux_2: 0.0748 (0.0883)  loss_giou_aux_2: 0.3836 (0.3760)  loss_vfl_aux_3: 0.5008 (0.5110)  loss_bbox_aux_3: 0.0762 (0.0913)  loss_giou_aux_3: 0.3785 (0.3776)  loss_vfl_aux_4: 0.4777 (0.5035)  loss_bbox_aux_4: 0.0757 (0.0896)  loss_giou_aux_4: 0.3724 (0.3727)  loss_vfl_aux_5: 0.5806 (0.5905)  loss_bbox_aux_5: 0.1344 (0.1621)  loss_giou_aux_5: 0.5929 (0.5652)  loss_vfl_dn_0: 0.4333 (0.4382)  loss_bbox_dn_0: 0.1403 (0.1739)  loss_giou_dn_0: 0.5761 (0.5797)  loss_vfl_dn_1: 0.3961 (0.3951)  loss_bbox_dn_1: 0.1047 (0.1242)  loss_giou_dn_1: 0.4188 (0.4292)  loss_vfl_dn_2: 0.3839 (0.3822)  loss_bbox_dn_2: 0.0956 (0.1153)  loss_giou_dn_2: 0.3968 (0.4037)  loss_vfl_dn_3: 0.3788 (0.3794)  loss_bbox_dn_3: 0.0941 (0.1134)  loss_giou_dn_3: 0.3893 (0.3978)  loss_vfl_dn_4: 0.3803 (0.3783)  loss_bbox_dn_4: 0.0937 (0.1128)  loss_giou_dn_4: 0.3880 (0.3973)  loss_vfl_dn_5: 0.3795 (0.3777)  loss_bbox_dn_5: 0.0942 (0.1125)  loss_giou_dn_5: 0.3882 (0.3974)  time: 0.3180  data: 0.0150  max mem: 7790\n",
            "Epoch: [173] Total time: 0:00:11 (0.3453 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.9702 (12.9843)  loss_vfl: 0.4835 (0.5062)  loss_bbox: 0.0743 (0.0894)  loss_giou: 0.3741 (0.3705)  loss_vfl_aux_0: 0.5249 (0.5277)  loss_bbox_aux_0: 0.0850 (0.1055)  loss_giou_aux_0: 0.4110 (0.4219)  loss_vfl_aux_1: 0.5097 (0.5238)  loss_bbox_aux_1: 0.0747 (0.0922)  loss_giou_aux_1: 0.3955 (0.3850)  loss_vfl_aux_2: 0.5200 (0.5258)  loss_bbox_aux_2: 0.0748 (0.0883)  loss_giou_aux_2: 0.3836 (0.3760)  loss_vfl_aux_3: 0.5008 (0.5110)  loss_bbox_aux_3: 0.0762 (0.0913)  loss_giou_aux_3: 0.3785 (0.3776)  loss_vfl_aux_4: 0.4777 (0.5035)  loss_bbox_aux_4: 0.0757 (0.0896)  loss_giou_aux_4: 0.3724 (0.3727)  loss_vfl_aux_5: 0.5806 (0.5905)  loss_bbox_aux_5: 0.1344 (0.1621)  loss_giou_aux_5: 0.5929 (0.5652)  loss_vfl_dn_0: 0.4333 (0.4382)  loss_bbox_dn_0: 0.1403 (0.1739)  loss_giou_dn_0: 0.5761 (0.5797)  loss_vfl_dn_1: 0.3961 (0.3951)  loss_bbox_dn_1: 0.1047 (0.1242)  loss_giou_dn_1: 0.4188 (0.4292)  loss_vfl_dn_2: 0.3839 (0.3822)  loss_bbox_dn_2: 0.0956 (0.1153)  loss_giou_dn_2: 0.3968 (0.4037)  loss_vfl_dn_3: 0.3788 (0.3794)  loss_bbox_dn_3: 0.0941 (0.1134)  loss_giou_dn_3: 0.3893 (0.3978)  loss_vfl_dn_4: 0.3803 (0.3783)  loss_bbox_dn_4: 0.0937 (0.1128)  loss_giou_dn_4: 0.3880 (0.3973)  loss_vfl_dn_5: 0.3795 (0.3777)  loss_bbox_dn_5: 0.0942 (0.1125)  loss_giou_dn_5: 0.3882 (0.3974)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8974  data: 0.5704  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3877  data: 0.1102  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4022 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [174]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 11.3864 (11.3864)  loss_vfl: 0.4540 (0.4540)  loss_bbox: 0.0964 (0.0964)  loss_giou: 0.2890 (0.2890)  loss_vfl_aux_0: 0.4753 (0.4753)  loss_bbox_aux_0: 0.1070 (0.1070)  loss_giou_aux_0: 0.3549 (0.3549)  loss_vfl_aux_1: 0.4483 (0.4483)  loss_bbox_aux_1: 0.1003 (0.1003)  loss_giou_aux_1: 0.3119 (0.3119)  loss_vfl_aux_2: 0.4484 (0.4484)  loss_bbox_aux_2: 0.0973 (0.0973)  loss_giou_aux_2: 0.2990 (0.2990)  loss_vfl_aux_3: 0.4437 (0.4437)  loss_bbox_aux_3: 0.0956 (0.0956)  loss_giou_aux_3: 0.2936 (0.2936)  loss_vfl_aux_4: 0.4506 (0.4506)  loss_bbox_aux_4: 0.0961 (0.0961)  loss_giou_aux_4: 0.2923 (0.2923)  loss_vfl_aux_5: 0.5826 (0.5826)  loss_bbox_aux_5: 0.1765 (0.1765)  loss_giou_aux_5: 0.5123 (0.5123)  loss_vfl_dn_0: 0.4221 (0.4221)  loss_bbox_dn_0: 0.1628 (0.1628)  loss_giou_dn_0: 0.4844 (0.4844)  loss_vfl_dn_1: 0.3678 (0.3678)  loss_bbox_dn_1: 0.1151 (0.1151)  loss_giou_dn_1: 0.3522 (0.3522)  loss_vfl_dn_2: 0.3483 (0.3483)  loss_bbox_dn_2: 0.1094 (0.1094)  loss_giou_dn_2: 0.3231 (0.3231)  loss_vfl_dn_3: 0.3438 (0.3438)  loss_bbox_dn_3: 0.1088 (0.1088)  loss_giou_dn_3: 0.3168 (0.3168)  loss_vfl_dn_4: 0.3360 (0.3360)  loss_bbox_dn_4: 0.1073 (0.1073)  loss_giou_dn_4: 0.3124 (0.3124)  loss_vfl_dn_5: 0.3330 (0.3330)  loss_bbox_dn_5: 0.1080 (0.1080)  loss_giou_dn_5: 0.3103 (0.3103)  time: 1.0655  data: 0.6281  max mem: 7790\n",
            "Epoch: [174]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.3105 (12.7373)  loss_vfl: 0.4502 (0.4671)  loss_bbox: 0.0889 (0.0859)  loss_giou: 0.3494 (0.3830)  loss_vfl_aux_0: 0.4824 (0.5085)  loss_bbox_aux_0: 0.1034 (0.1003)  loss_giou_aux_0: 0.4019 (0.4304)  loss_vfl_aux_1: 0.4757 (0.4937)  loss_bbox_aux_1: 0.0998 (0.0905)  loss_giou_aux_1: 0.3654 (0.3956)  loss_vfl_aux_2: 0.4781 (0.4903)  loss_bbox_aux_2: 0.0965 (0.0872)  loss_giou_aux_2: 0.3591 (0.3875)  loss_vfl_aux_3: 0.4662 (0.4807)  loss_bbox_aux_3: 0.0916 (0.0869)  loss_giou_aux_3: 0.3484 (0.3854)  loss_vfl_aux_4: 0.4468 (0.4687)  loss_bbox_aux_4: 0.0893 (0.0868)  loss_giou_aux_4: 0.3469 (0.3850)  loss_vfl_aux_5: 0.5557 (0.5844)  loss_bbox_aux_5: 0.1319 (0.1446)  loss_giou_aux_5: 0.5411 (0.5600)  loss_vfl_dn_0: 0.4289 (0.4327)  loss_bbox_dn_0: 0.1410 (0.1565)  loss_giou_dn_0: 0.5511 (0.5904)  loss_vfl_dn_1: 0.3898 (0.3905)  loss_bbox_dn_1: 0.0925 (0.1104)  loss_giou_dn_1: 0.3951 (0.4378)  loss_vfl_dn_2: 0.3761 (0.3787)  loss_bbox_dn_2: 0.0848 (0.1019)  loss_giou_dn_2: 0.3782 (0.4110)  loss_vfl_dn_3: 0.3706 (0.3732)  loss_bbox_dn_3: 0.0812 (0.0999)  loss_giou_dn_3: 0.3703 (0.4043)  loss_vfl_dn_4: 0.3732 (0.3714)  loss_bbox_dn_4: 0.0805 (0.0994)  loss_giou_dn_4: 0.3704 (0.4031)  loss_vfl_dn_5: 0.3740 (0.3711)  loss_bbox_dn_5: 0.0807 (0.0994)  loss_giou_dn_5: 0.3654 (0.4032)  time: 0.3259  data: 0.0138  max mem: 7790\n",
            "Epoch: [174] Total time: 0:00:11 (0.3628 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.3105 (12.7373)  loss_vfl: 0.4502 (0.4671)  loss_bbox: 0.0889 (0.0859)  loss_giou: 0.3494 (0.3830)  loss_vfl_aux_0: 0.4824 (0.5085)  loss_bbox_aux_0: 0.1034 (0.1003)  loss_giou_aux_0: 0.4019 (0.4304)  loss_vfl_aux_1: 0.4757 (0.4937)  loss_bbox_aux_1: 0.0998 (0.0905)  loss_giou_aux_1: 0.3654 (0.3956)  loss_vfl_aux_2: 0.4781 (0.4903)  loss_bbox_aux_2: 0.0965 (0.0872)  loss_giou_aux_2: 0.3591 (0.3875)  loss_vfl_aux_3: 0.4662 (0.4807)  loss_bbox_aux_3: 0.0916 (0.0869)  loss_giou_aux_3: 0.3484 (0.3854)  loss_vfl_aux_4: 0.4468 (0.4687)  loss_bbox_aux_4: 0.0893 (0.0868)  loss_giou_aux_4: 0.3469 (0.3850)  loss_vfl_aux_5: 0.5557 (0.5844)  loss_bbox_aux_5: 0.1319 (0.1446)  loss_giou_aux_5: 0.5411 (0.5600)  loss_vfl_dn_0: 0.4289 (0.4327)  loss_bbox_dn_0: 0.1410 (0.1565)  loss_giou_dn_0: 0.5511 (0.5904)  loss_vfl_dn_1: 0.3898 (0.3905)  loss_bbox_dn_1: 0.0925 (0.1104)  loss_giou_dn_1: 0.3951 (0.4378)  loss_vfl_dn_2: 0.3761 (0.3787)  loss_bbox_dn_2: 0.0848 (0.1019)  loss_giou_dn_2: 0.3782 (0.4110)  loss_vfl_dn_3: 0.3706 (0.3732)  loss_bbox_dn_3: 0.0812 (0.0999)  loss_giou_dn_3: 0.3703 (0.4043)  loss_vfl_dn_4: 0.3732 (0.3714)  loss_bbox_dn_4: 0.0805 (0.0994)  loss_giou_dn_4: 0.3704 (0.4031)  loss_vfl_dn_5: 0.3740 (0.3711)  loss_bbox_dn_5: 0.0807 (0.0994)  loss_giou_dn_5: 0.3654 (0.4032)\n",
            "Test:  [0/6]  eta: 0:00:26    time: 4.4824  data: 4.1750  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.9854  data: 0.7134  max mem: 7790\n",
            "Test: Total time: 0:00:05 (0.9998 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [175]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 11.2762 (11.2762)  loss_vfl: 0.4354 (0.4354)  loss_bbox: 0.0634 (0.0634)  loss_giou: 0.2994 (0.2994)  loss_vfl_aux_0: 0.5289 (0.5289)  loss_bbox_aux_0: 0.1026 (0.1026)  loss_giou_aux_0: 0.3931 (0.3931)  loss_vfl_aux_1: 0.4479 (0.4479)  loss_bbox_aux_1: 0.0861 (0.0861)  loss_giou_aux_1: 0.3536 (0.3536)  loss_vfl_aux_2: 0.4250 (0.4250)  loss_bbox_aux_2: 0.0801 (0.0801)  loss_giou_aux_2: 0.3312 (0.3312)  loss_vfl_aux_3: 0.4166 (0.4166)  loss_bbox_aux_3: 0.0773 (0.0773)  loss_giou_aux_3: 0.3298 (0.3298)  loss_vfl_aux_4: 0.4368 (0.4368)  loss_bbox_aux_4: 0.0633 (0.0633)  loss_giou_aux_4: 0.3003 (0.3003)  loss_vfl_aux_5: 0.6258 (0.6258)  loss_bbox_aux_5: 0.1405 (0.1405)  loss_giou_aux_5: 0.4802 (0.4802)  loss_vfl_dn_0: 0.4322 (0.4322)  loss_bbox_dn_0: 0.1361 (0.1361)  loss_giou_dn_0: 0.5366 (0.5366)  loss_vfl_dn_1: 0.3776 (0.3776)  loss_bbox_dn_1: 0.0936 (0.0936)  loss_giou_dn_1: 0.3597 (0.3597)  loss_vfl_dn_2: 0.3546 (0.3546)  loss_bbox_dn_2: 0.0839 (0.0839)  loss_giou_dn_2: 0.3083 (0.3083)  loss_vfl_dn_3: 0.3541 (0.3541)  loss_bbox_dn_3: 0.0811 (0.0811)  loss_giou_dn_3: 0.3000 (0.3000)  loss_vfl_dn_4: 0.3495 (0.3495)  loss_bbox_dn_4: 0.0800 (0.0800)  loss_giou_dn_4: 0.2940 (0.2940)  loss_vfl_dn_5: 0.3467 (0.3467)  loss_bbox_dn_5: 0.0796 (0.0796)  loss_giou_dn_5: 0.2915 (0.2915)  time: 1.0306  data: 0.6219  max mem: 7790\n",
            "Epoch: [175]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.5456 (12.4468)  loss_vfl: 0.4440 (0.4636)  loss_bbox: 0.0765 (0.0877)  loss_giou: 0.3695 (0.3660)  loss_vfl_aux_0: 0.4906 (0.5094)  loss_bbox_aux_0: 0.0890 (0.0975)  loss_giou_aux_0: 0.4187 (0.4093)  loss_vfl_aux_1: 0.4733 (0.4961)  loss_bbox_aux_1: 0.0778 (0.0904)  loss_giou_aux_1: 0.3769 (0.3788)  loss_vfl_aux_2: 0.4637 (0.4848)  loss_bbox_aux_2: 0.0759 (0.0884)  loss_giou_aux_2: 0.3734 (0.3698)  loss_vfl_aux_3: 0.4651 (0.4741)  loss_bbox_aux_3: 0.0750 (0.0869)  loss_giou_aux_3: 0.3630 (0.3679)  loss_vfl_aux_4: 0.4480 (0.4597)  loss_bbox_aux_4: 0.0766 (0.0876)  loss_giou_aux_4: 0.3701 (0.3664)  loss_vfl_aux_5: 0.5698 (0.5874)  loss_bbox_aux_5: 0.1250 (0.1366)  loss_giou_aux_5: 0.5158 (0.5262)  loss_vfl_dn_0: 0.4369 (0.4392)  loss_bbox_dn_0: 0.1290 (0.1520)  loss_giou_dn_0: 0.5844 (0.5761)  loss_vfl_dn_1: 0.3956 (0.3940)  loss_bbox_dn_1: 0.0905 (0.1071)  loss_giou_dn_1: 0.4134 (0.4158)  loss_vfl_dn_2: 0.3840 (0.3807)  loss_bbox_dn_2: 0.0837 (0.0992)  loss_giou_dn_2: 0.3960 (0.3871)  loss_vfl_dn_3: 0.3761 (0.3761)  loss_bbox_dn_3: 0.0821 (0.0980)  loss_giou_dn_3: 0.3899 (0.3818)  loss_vfl_dn_4: 0.3778 (0.3738)  loss_bbox_dn_4: 0.0815 (0.0978)  loss_giou_dn_4: 0.3894 (0.3807)  loss_vfl_dn_5: 0.3761 (0.3740)  loss_bbox_dn_5: 0.0808 (0.0978)  loss_giou_dn_5: 0.3907 (0.3808)  time: 0.3258  data: 0.0138  max mem: 7790\n",
            "Epoch: [175] Total time: 0:00:11 (0.3513 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.5456 (12.4468)  loss_vfl: 0.4440 (0.4636)  loss_bbox: 0.0765 (0.0877)  loss_giou: 0.3695 (0.3660)  loss_vfl_aux_0: 0.4906 (0.5094)  loss_bbox_aux_0: 0.0890 (0.0975)  loss_giou_aux_0: 0.4187 (0.4093)  loss_vfl_aux_1: 0.4733 (0.4961)  loss_bbox_aux_1: 0.0778 (0.0904)  loss_giou_aux_1: 0.3769 (0.3788)  loss_vfl_aux_2: 0.4637 (0.4848)  loss_bbox_aux_2: 0.0759 (0.0884)  loss_giou_aux_2: 0.3734 (0.3698)  loss_vfl_aux_3: 0.4651 (0.4741)  loss_bbox_aux_3: 0.0750 (0.0869)  loss_giou_aux_3: 0.3630 (0.3679)  loss_vfl_aux_4: 0.4480 (0.4597)  loss_bbox_aux_4: 0.0766 (0.0876)  loss_giou_aux_4: 0.3701 (0.3664)  loss_vfl_aux_5: 0.5698 (0.5874)  loss_bbox_aux_5: 0.1250 (0.1366)  loss_giou_aux_5: 0.5158 (0.5262)  loss_vfl_dn_0: 0.4369 (0.4392)  loss_bbox_dn_0: 0.1290 (0.1520)  loss_giou_dn_0: 0.5844 (0.5761)  loss_vfl_dn_1: 0.3956 (0.3940)  loss_bbox_dn_1: 0.0905 (0.1071)  loss_giou_dn_1: 0.4134 (0.4158)  loss_vfl_dn_2: 0.3840 (0.3807)  loss_bbox_dn_2: 0.0837 (0.0992)  loss_giou_dn_2: 0.3960 (0.3871)  loss_vfl_dn_3: 0.3761 (0.3761)  loss_bbox_dn_3: 0.0821 (0.0980)  loss_giou_dn_3: 0.3899 (0.3818)  loss_vfl_dn_4: 0.3778 (0.3738)  loss_bbox_dn_4: 0.0815 (0.0978)  loss_giou_dn_4: 0.3894 (0.3807)  loss_vfl_dn_5: 0.3761 (0.3740)  loss_bbox_dn_5: 0.0808 (0.0978)  loss_giou_dn_5: 0.3907 (0.3808)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9207  data: 0.6069  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3882  data: 0.1160  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4013 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.659\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [176]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 11.1514 (11.1514)  loss_vfl: 0.3896 (0.3896)  loss_bbox: 0.0795 (0.0795)  loss_giou: 0.3649 (0.3649)  loss_vfl_aux_0: 0.4431 (0.4431)  loss_bbox_aux_0: 0.0870 (0.0870)  loss_giou_aux_0: 0.3927 (0.3927)  loss_vfl_aux_1: 0.4259 (0.4259)  loss_bbox_aux_1: 0.0736 (0.0736)  loss_giou_aux_1: 0.3561 (0.3561)  loss_vfl_aux_2: 0.4045 (0.4045)  loss_bbox_aux_2: 0.0800 (0.0800)  loss_giou_aux_2: 0.3671 (0.3671)  loss_vfl_aux_3: 0.4080 (0.4080)  loss_bbox_aux_3: 0.0797 (0.0797)  loss_giou_aux_3: 0.3616 (0.3616)  loss_vfl_aux_4: 0.3967 (0.3967)  loss_bbox_aux_4: 0.0792 (0.0792)  loss_giou_aux_4: 0.3624 (0.3624)  loss_vfl_aux_5: 0.5236 (0.5236)  loss_bbox_aux_5: 0.1060 (0.1060)  loss_giou_aux_5: 0.4886 (0.4886)  loss_vfl_dn_0: 0.4283 (0.4283)  loss_bbox_dn_0: 0.1235 (0.1235)  loss_giou_dn_0: 0.5193 (0.5193)  loss_vfl_dn_1: 0.3794 (0.3794)  loss_bbox_dn_1: 0.0762 (0.0762)  loss_giou_dn_1: 0.3585 (0.3585)  loss_vfl_dn_2: 0.3573 (0.3573)  loss_bbox_dn_2: 0.0686 (0.0686)  loss_giou_dn_2: 0.3279 (0.3279)  loss_vfl_dn_3: 0.3552 (0.3552)  loss_bbox_dn_3: 0.0682 (0.0682)  loss_giou_dn_3: 0.3266 (0.3266)  loss_vfl_dn_4: 0.3504 (0.3504)  loss_bbox_dn_4: 0.0685 (0.0685)  loss_giou_dn_4: 0.3271 (0.3271)  loss_vfl_dn_5: 0.3491 (0.3491)  loss_bbox_dn_5: 0.0687 (0.0687)  loss_giou_dn_5: 0.3287 (0.3287)  time: 0.9864  data: 0.5904  max mem: 7790\n",
            "Epoch: [176]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.6006 (12.9446)  loss_vfl: 0.4599 (0.4779)  loss_bbox: 0.0775 (0.0855)  loss_giou: 0.3424 (0.3877)  loss_vfl_aux_0: 0.5134 (0.5271)  loss_bbox_aux_0: 0.0913 (0.0971)  loss_giou_aux_0: 0.3912 (0.4318)  loss_vfl_aux_1: 0.5073 (0.5152)  loss_bbox_aux_1: 0.0816 (0.0880)  loss_giou_aux_1: 0.3654 (0.3994)  loss_vfl_aux_2: 0.5048 (0.5054)  loss_bbox_aux_2: 0.0782 (0.0854)  loss_giou_aux_2: 0.3527 (0.3893)  loss_vfl_aux_3: 0.4886 (0.4918)  loss_bbox_aux_3: 0.0779 (0.0856)  loss_giou_aux_3: 0.3470 (0.3869)  loss_vfl_aux_4: 0.4569 (0.4796)  loss_bbox_aux_4: 0.0802 (0.0857)  loss_giou_aux_4: 0.3436 (0.3883)  loss_vfl_aux_5: 0.5596 (0.5832)  loss_bbox_aux_5: 0.1357 (0.1379)  loss_giou_aux_5: 0.5425 (0.5594)  loss_vfl_dn_0: 0.4328 (0.4363)  loss_bbox_dn_0: 0.1388 (0.1561)  loss_giou_dn_0: 0.5588 (0.5955)  loss_vfl_dn_1: 0.3915 (0.3975)  loss_bbox_dn_1: 0.0956 (0.1125)  loss_giou_dn_1: 0.4083 (0.4486)  loss_vfl_dn_2: 0.3783 (0.3873)  loss_bbox_dn_2: 0.0897 (0.1044)  loss_giou_dn_2: 0.3799 (0.4219)  loss_vfl_dn_3: 0.3715 (0.3838)  loss_bbox_dn_3: 0.0894 (0.1019)  loss_giou_dn_3: 0.3723 (0.4149)  loss_vfl_dn_4: 0.3682 (0.3828)  loss_bbox_dn_4: 0.0896 (0.1014)  loss_giou_dn_4: 0.3704 (0.4136)  loss_vfl_dn_5: 0.3696 (0.3829)  loss_bbox_dn_5: 0.0898 (0.1012)  loss_giou_dn_5: 0.3699 (0.4138)  time: 0.3280  data: 0.0161  max mem: 7790\n",
            "Epoch: [176] Total time: 0:00:11 (0.3489 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.6006 (12.9446)  loss_vfl: 0.4599 (0.4779)  loss_bbox: 0.0775 (0.0855)  loss_giou: 0.3424 (0.3877)  loss_vfl_aux_0: 0.5134 (0.5271)  loss_bbox_aux_0: 0.0913 (0.0971)  loss_giou_aux_0: 0.3912 (0.4318)  loss_vfl_aux_1: 0.5073 (0.5152)  loss_bbox_aux_1: 0.0816 (0.0880)  loss_giou_aux_1: 0.3654 (0.3994)  loss_vfl_aux_2: 0.5048 (0.5054)  loss_bbox_aux_2: 0.0782 (0.0854)  loss_giou_aux_2: 0.3527 (0.3893)  loss_vfl_aux_3: 0.4886 (0.4918)  loss_bbox_aux_3: 0.0779 (0.0856)  loss_giou_aux_3: 0.3470 (0.3869)  loss_vfl_aux_4: 0.4569 (0.4796)  loss_bbox_aux_4: 0.0802 (0.0857)  loss_giou_aux_4: 0.3436 (0.3883)  loss_vfl_aux_5: 0.5596 (0.5832)  loss_bbox_aux_5: 0.1357 (0.1379)  loss_giou_aux_5: 0.5425 (0.5594)  loss_vfl_dn_0: 0.4328 (0.4363)  loss_bbox_dn_0: 0.1388 (0.1561)  loss_giou_dn_0: 0.5588 (0.5955)  loss_vfl_dn_1: 0.3915 (0.3975)  loss_bbox_dn_1: 0.0956 (0.1125)  loss_giou_dn_1: 0.4083 (0.4486)  loss_vfl_dn_2: 0.3783 (0.3873)  loss_bbox_dn_2: 0.0897 (0.1044)  loss_giou_dn_2: 0.3799 (0.4219)  loss_vfl_dn_3: 0.3715 (0.3838)  loss_bbox_dn_3: 0.0894 (0.1019)  loss_giou_dn_3: 0.3723 (0.4149)  loss_vfl_dn_4: 0.3682 (0.3828)  loss_bbox_dn_4: 0.0896 (0.1014)  loss_giou_dn_4: 0.3704 (0.4136)  loss_vfl_dn_5: 0.3696 (0.3829)  loss_bbox_dn_5: 0.0898 (0.1012)  loss_giou_dn_5: 0.3699 (0.4138)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9035  data: 0.5965  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3837  data: 0.1112  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3981 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.653\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [177]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 14.3268 (14.3268)  loss_vfl: 0.4730 (0.4730)  loss_bbox: 0.1075 (0.1075)  loss_giou: 0.5029 (0.5029)  loss_vfl_aux_0: 0.5212 (0.5212)  loss_bbox_aux_0: 0.1164 (0.1164)  loss_giou_aux_0: 0.5339 (0.5339)  loss_vfl_aux_1: 0.5053 (0.5053)  loss_bbox_aux_1: 0.1130 (0.1130)  loss_giou_aux_1: 0.5121 (0.5121)  loss_vfl_aux_2: 0.4778 (0.4778)  loss_bbox_aux_2: 0.1090 (0.1090)  loss_giou_aux_2: 0.5044 (0.5044)  loss_vfl_aux_3: 0.4936 (0.4936)  loss_bbox_aux_3: 0.1079 (0.1079)  loss_giou_aux_3: 0.5014 (0.5014)  loss_vfl_aux_4: 0.4729 (0.4729)  loss_bbox_aux_4: 0.1074 (0.1074)  loss_giou_aux_4: 0.4993 (0.4993)  loss_vfl_aux_5: 0.6159 (0.6159)  loss_bbox_aux_5: 0.1355 (0.1355)  loss_giou_aux_5: 0.6394 (0.6394)  loss_vfl_dn_0: 0.4283 (0.4283)  loss_bbox_dn_0: 0.1830 (0.1830)  loss_giou_dn_0: 0.6330 (0.6330)  loss_vfl_dn_1: 0.3992 (0.3992)  loss_bbox_dn_1: 0.1480 (0.1480)  loss_giou_dn_1: 0.4964 (0.4964)  loss_vfl_dn_2: 0.3884 (0.3884)  loss_bbox_dn_2: 0.1385 (0.1385)  loss_giou_dn_2: 0.4804 (0.4804)  loss_vfl_dn_3: 0.3877 (0.3877)  loss_bbox_dn_3: 0.1343 (0.1343)  loss_giou_dn_3: 0.4771 (0.4771)  loss_vfl_dn_4: 0.3823 (0.3823)  loss_bbox_dn_4: 0.1346 (0.1346)  loss_giou_dn_4: 0.4761 (0.4761)  loss_vfl_dn_5: 0.3814 (0.3814)  loss_bbox_dn_5: 0.1343 (0.1343)  loss_giou_dn_5: 0.4740 (0.4740)  time: 1.0894  data: 0.7196  max mem: 7790\n",
            "Epoch: [177]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.5828 (12.8869)  loss_vfl: 0.4934 (0.4870)  loss_bbox: 0.0748 (0.0871)  loss_giou: 0.3761 (0.3805)  loss_vfl_aux_0: 0.5013 (0.5367)  loss_bbox_aux_0: 0.0879 (0.0965)  loss_giou_aux_0: 0.4123 (0.4149)  loss_vfl_aux_1: 0.4917 (0.5178)  loss_bbox_aux_1: 0.0768 (0.0873)  loss_giou_aux_1: 0.3824 (0.3877)  loss_vfl_aux_2: 0.4889 (0.5098)  loss_bbox_aux_2: 0.0745 (0.0850)  loss_giou_aux_2: 0.3814 (0.3825)  loss_vfl_aux_3: 0.4864 (0.5013)  loss_bbox_aux_3: 0.0732 (0.0850)  loss_giou_aux_3: 0.3762 (0.3812)  loss_vfl_aux_4: 0.4855 (0.4911)  loss_bbox_aux_4: 0.0742 (0.0857)  loss_giou_aux_4: 0.3764 (0.3803)  loss_vfl_aux_5: 0.5720 (0.5970)  loss_bbox_aux_5: 0.1155 (0.1313)  loss_giou_aux_5: 0.5092 (0.5336)  loss_vfl_dn_0: 0.4377 (0.4398)  loss_bbox_dn_0: 0.1504 (0.1688)  loss_giou_dn_0: 0.6236 (0.5848)  loss_vfl_dn_1: 0.4062 (0.3990)  loss_bbox_dn_1: 0.0953 (0.1204)  loss_giou_dn_1: 0.4378 (0.4324)  loss_vfl_dn_2: 0.3953 (0.3869)  loss_bbox_dn_2: 0.0880 (0.1108)  loss_giou_dn_2: 0.4124 (0.4092)  loss_vfl_dn_3: 0.3883 (0.3817)  loss_bbox_dn_3: 0.0862 (0.1083)  loss_giou_dn_3: 0.4159 (0.4037)  loss_vfl_dn_4: 0.3870 (0.3806)  loss_bbox_dn_4: 0.0860 (0.1078)  loss_giou_dn_4: 0.4186 (0.4026)  loss_vfl_dn_5: 0.3892 (0.3805)  loss_bbox_dn_5: 0.0864 (0.1076)  loss_giou_dn_5: 0.4182 (0.4026)  time: 0.3186  data: 0.0136  max mem: 7790\n",
            "Epoch: [177] Total time: 0:00:11 (0.3511 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.5828 (12.8869)  loss_vfl: 0.4934 (0.4870)  loss_bbox: 0.0748 (0.0871)  loss_giou: 0.3761 (0.3805)  loss_vfl_aux_0: 0.5013 (0.5367)  loss_bbox_aux_0: 0.0879 (0.0965)  loss_giou_aux_0: 0.4123 (0.4149)  loss_vfl_aux_1: 0.4917 (0.5178)  loss_bbox_aux_1: 0.0768 (0.0873)  loss_giou_aux_1: 0.3824 (0.3877)  loss_vfl_aux_2: 0.4889 (0.5098)  loss_bbox_aux_2: 0.0745 (0.0850)  loss_giou_aux_2: 0.3814 (0.3825)  loss_vfl_aux_3: 0.4864 (0.5013)  loss_bbox_aux_3: 0.0732 (0.0850)  loss_giou_aux_3: 0.3762 (0.3812)  loss_vfl_aux_4: 0.4855 (0.4911)  loss_bbox_aux_4: 0.0742 (0.0857)  loss_giou_aux_4: 0.3764 (0.3803)  loss_vfl_aux_5: 0.5720 (0.5970)  loss_bbox_aux_5: 0.1155 (0.1313)  loss_giou_aux_5: 0.5092 (0.5336)  loss_vfl_dn_0: 0.4377 (0.4398)  loss_bbox_dn_0: 0.1504 (0.1688)  loss_giou_dn_0: 0.6236 (0.5848)  loss_vfl_dn_1: 0.4062 (0.3990)  loss_bbox_dn_1: 0.0953 (0.1204)  loss_giou_dn_1: 0.4378 (0.4324)  loss_vfl_dn_2: 0.3953 (0.3869)  loss_bbox_dn_2: 0.0880 (0.1108)  loss_giou_dn_2: 0.4124 (0.4092)  loss_vfl_dn_3: 0.3883 (0.3817)  loss_bbox_dn_3: 0.0862 (0.1083)  loss_giou_dn_3: 0.4159 (0.4037)  loss_vfl_dn_4: 0.3870 (0.3806)  loss_bbox_dn_4: 0.0860 (0.1078)  loss_giou_dn_4: 0.4186 (0.4026)  loss_vfl_dn_5: 0.3892 (0.3805)  loss_bbox_dn_5: 0.0864 (0.1076)  loss_giou_dn_5: 0.4182 (0.4026)\n",
            "Test:  [0/6]  eta: 0:00:06    time: 1.1126  data: 0.7950  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4841  data: 0.1489  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4974 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [178]  [ 0/33]  eta: 0:00:31  lr: 0.000001  loss: 11.5554 (11.5554)  loss_vfl: 0.4810 (0.4810)  loss_bbox: 0.1315 (0.1315)  loss_giou: 0.2639 (0.2639)  loss_vfl_aux_0: 0.4947 (0.4947)  loss_bbox_aux_0: 0.1439 (0.1439)  loss_giou_aux_0: 0.3473 (0.3473)  loss_vfl_aux_1: 0.4788 (0.4788)  loss_bbox_aux_1: 0.1339 (0.1339)  loss_giou_aux_1: 0.2874 (0.2874)  loss_vfl_aux_2: 0.4822 (0.4822)  loss_bbox_aux_2: 0.1308 (0.1308)  loss_giou_aux_2: 0.2712 (0.2712)  loss_vfl_aux_3: 0.5082 (0.5082)  loss_bbox_aux_3: 0.1261 (0.1261)  loss_giou_aux_3: 0.2611 (0.2611)  loss_vfl_aux_4: 0.4585 (0.4585)  loss_bbox_aux_4: 0.1337 (0.1337)  loss_giou_aux_4: 0.2639 (0.2639)  loss_vfl_aux_5: 0.5613 (0.5613)  loss_bbox_aux_5: 0.2117 (0.2117)  loss_giou_aux_5: 0.5032 (0.5032)  loss_vfl_dn_0: 0.4370 (0.4370)  loss_bbox_dn_0: 0.1986 (0.1986)  loss_giou_dn_0: 0.4870 (0.4870)  loss_vfl_dn_1: 0.3701 (0.3701)  loss_bbox_dn_1: 0.1397 (0.1397)  loss_giou_dn_1: 0.2950 (0.2950)  loss_vfl_dn_2: 0.3579 (0.3579)  loss_bbox_dn_2: 0.1274 (0.1274)  loss_giou_dn_2: 0.2664 (0.2664)  loss_vfl_dn_3: 0.3555 (0.3555)  loss_bbox_dn_3: 0.1240 (0.1240)  loss_giou_dn_3: 0.2563 (0.2563)  loss_vfl_dn_4: 0.3509 (0.3509)  loss_bbox_dn_4: 0.1240 (0.1240)  loss_giou_dn_4: 0.2565 (0.2565)  loss_vfl_dn_5: 0.3519 (0.3519)  loss_bbox_dn_5: 0.1238 (0.1238)  loss_giou_dn_5: 0.2590 (0.2590)  time: 0.9570  data: 0.5378  max mem: 7790\n",
            "Epoch: [178]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.1736 (12.4169)  loss_vfl: 0.4424 (0.4562)  loss_bbox: 0.0744 (0.0835)  loss_giou: 0.3506 (0.3661)  loss_vfl_aux_0: 0.4956 (0.4990)  loss_bbox_aux_0: 0.0814 (0.0974)  loss_giou_aux_0: 0.3966 (0.4144)  loss_vfl_aux_1: 0.4636 (0.4879)  loss_bbox_aux_1: 0.0776 (0.0878)  loss_giou_aux_1: 0.3663 (0.3810)  loss_vfl_aux_2: 0.4593 (0.4827)  loss_bbox_aux_2: 0.0737 (0.0842)  loss_giou_aux_2: 0.3533 (0.3688)  loss_vfl_aux_3: 0.4640 (0.4781)  loss_bbox_aux_3: 0.0734 (0.0835)  loss_giou_aux_3: 0.3501 (0.3664)  loss_vfl_aux_4: 0.4491 (0.4554)  loss_bbox_aux_4: 0.0745 (0.0838)  loss_giou_aux_4: 0.3522 (0.3666)  loss_vfl_aux_5: 0.5506 (0.5682)  loss_bbox_aux_5: 0.1092 (0.1350)  loss_giou_aux_5: 0.5217 (0.5339)  loss_vfl_dn_0: 0.4391 (0.4371)  loss_bbox_dn_0: 0.1223 (0.1543)  loss_giou_dn_0: 0.5632 (0.5850)  loss_vfl_dn_1: 0.4008 (0.3914)  loss_bbox_dn_1: 0.0843 (0.1064)  loss_giou_dn_1: 0.3976 (0.4226)  loss_vfl_dn_2: 0.3841 (0.3769)  loss_bbox_dn_2: 0.0777 (0.0983)  loss_giou_dn_2: 0.3682 (0.3927)  loss_vfl_dn_3: 0.3800 (0.3757)  loss_bbox_dn_3: 0.0770 (0.0966)  loss_giou_dn_3: 0.3629 (0.3868)  loss_vfl_dn_4: 0.3789 (0.3734)  loss_bbox_dn_4: 0.0776 (0.0965)  loss_giou_dn_4: 0.3609 (0.3862)  loss_vfl_dn_5: 0.3778 (0.3746)  loss_bbox_dn_5: 0.0775 (0.0964)  loss_giou_dn_5: 0.3620 (0.3863)  time: 0.3335  data: 0.0159  max mem: 7790\n",
            "Epoch: [178] Total time: 0:00:11 (0.3531 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.1736 (12.4169)  loss_vfl: 0.4424 (0.4562)  loss_bbox: 0.0744 (0.0835)  loss_giou: 0.3506 (0.3661)  loss_vfl_aux_0: 0.4956 (0.4990)  loss_bbox_aux_0: 0.0814 (0.0974)  loss_giou_aux_0: 0.3966 (0.4144)  loss_vfl_aux_1: 0.4636 (0.4879)  loss_bbox_aux_1: 0.0776 (0.0878)  loss_giou_aux_1: 0.3663 (0.3810)  loss_vfl_aux_2: 0.4593 (0.4827)  loss_bbox_aux_2: 0.0737 (0.0842)  loss_giou_aux_2: 0.3533 (0.3688)  loss_vfl_aux_3: 0.4640 (0.4781)  loss_bbox_aux_3: 0.0734 (0.0835)  loss_giou_aux_3: 0.3501 (0.3664)  loss_vfl_aux_4: 0.4491 (0.4554)  loss_bbox_aux_4: 0.0745 (0.0838)  loss_giou_aux_4: 0.3522 (0.3666)  loss_vfl_aux_5: 0.5506 (0.5682)  loss_bbox_aux_5: 0.1092 (0.1350)  loss_giou_aux_5: 0.5217 (0.5339)  loss_vfl_dn_0: 0.4391 (0.4371)  loss_bbox_dn_0: 0.1223 (0.1543)  loss_giou_dn_0: 0.5632 (0.5850)  loss_vfl_dn_1: 0.4008 (0.3914)  loss_bbox_dn_1: 0.0843 (0.1064)  loss_giou_dn_1: 0.3976 (0.4226)  loss_vfl_dn_2: 0.3841 (0.3769)  loss_bbox_dn_2: 0.0777 (0.0983)  loss_giou_dn_2: 0.3682 (0.3927)  loss_vfl_dn_3: 0.3800 (0.3757)  loss_bbox_dn_3: 0.0770 (0.0966)  loss_giou_dn_3: 0.3629 (0.3868)  loss_vfl_dn_4: 0.3789 (0.3734)  loss_bbox_dn_4: 0.0776 (0.0965)  loss_giou_dn_4: 0.3609 (0.3862)  loss_vfl_dn_5: 0.3778 (0.3746)  loss_bbox_dn_5: 0.0775 (0.0964)  loss_giou_dn_5: 0.3620 (0.3863)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8609  data: 0.5516  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4315  data: 0.1069  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4461 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.337\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [179]  [ 0/33]  eta: 0:00:36  lr: 0.000001  loss: 11.3349 (11.3349)  loss_vfl: 0.4232 (0.4232)  loss_bbox: 0.0579 (0.0579)  loss_giou: 0.3251 (0.3251)  loss_vfl_aux_0: 0.4482 (0.4482)  loss_bbox_aux_0: 0.0670 (0.0670)  loss_giou_aux_0: 0.3752 (0.3752)  loss_vfl_aux_1: 0.4423 (0.4423)  loss_bbox_aux_1: 0.0636 (0.0636)  loss_giou_aux_1: 0.3497 (0.3497)  loss_vfl_aux_2: 0.4380 (0.4380)  loss_bbox_aux_2: 0.0607 (0.0607)  loss_giou_aux_2: 0.3351 (0.3351)  loss_vfl_aux_3: 0.4273 (0.4273)  loss_bbox_aux_3: 0.0589 (0.0589)  loss_giou_aux_3: 0.3270 (0.3270)  loss_vfl_aux_4: 0.4263 (0.4263)  loss_bbox_aux_4: 0.0578 (0.0578)  loss_giou_aux_4: 0.3256 (0.3256)  loss_vfl_aux_5: 0.5322 (0.5322)  loss_bbox_aux_5: 0.0806 (0.0806)  loss_giou_aux_5: 0.4641 (0.4641)  loss_vfl_dn_0: 0.4413 (0.4413)  loss_bbox_dn_0: 0.1045 (0.1045)  loss_giou_dn_0: 0.5469 (0.5469)  loss_vfl_dn_1: 0.4101 (0.4101)  loss_bbox_dn_1: 0.0733 (0.0733)  loss_giou_dn_1: 0.4020 (0.4020)  loss_vfl_dn_2: 0.3969 (0.3969)  loss_bbox_dn_2: 0.0690 (0.0690)  loss_giou_dn_2: 0.3723 (0.3723)  loss_vfl_dn_3: 0.3836 (0.3836)  loss_bbox_dn_3: 0.0667 (0.0667)  loss_giou_dn_3: 0.3590 (0.3590)  loss_vfl_dn_4: 0.3892 (0.3892)  loss_bbox_dn_4: 0.0663 (0.0663)  loss_giou_dn_4: 0.3575 (0.3575)  loss_vfl_dn_5: 0.3879 (0.3879)  loss_bbox_dn_5: 0.0661 (0.0661)  loss_giou_dn_5: 0.3565 (0.3565)  time: 1.0910  data: 0.6980  max mem: 7790\n",
            "Epoch: [179]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.8702 (12.8868)  loss_vfl: 0.4790 (0.4670)  loss_bbox: 0.0819 (0.0878)  loss_giou: 0.3639 (0.3937)  loss_vfl_aux_0: 0.5060 (0.5089)  loss_bbox_aux_0: 0.0933 (0.0988)  loss_giou_aux_0: 0.4169 (0.4436)  loss_vfl_aux_1: 0.4984 (0.4931)  loss_bbox_aux_1: 0.0873 (0.0904)  loss_giou_aux_1: 0.3914 (0.4112)  loss_vfl_aux_2: 0.4935 (0.4953)  loss_bbox_aux_2: 0.0820 (0.0882)  loss_giou_aux_2: 0.3739 (0.3980)  loss_vfl_aux_3: 0.4880 (0.4855)  loss_bbox_aux_3: 0.0743 (0.0879)  loss_giou_aux_3: 0.3739 (0.3949)  loss_vfl_aux_4: 0.4785 (0.4683)  loss_bbox_aux_4: 0.0817 (0.0883)  loss_giou_aux_4: 0.3751 (0.3947)  loss_vfl_aux_5: 0.5759 (0.5696)  loss_bbox_aux_5: 0.1491 (0.1563)  loss_giou_aux_5: 0.6091 (0.6024)  loss_vfl_dn_0: 0.4364 (0.4382)  loss_bbox_dn_0: 0.1436 (0.1525)  loss_giou_dn_0: 0.6021 (0.5866)  loss_vfl_dn_1: 0.4049 (0.3961)  loss_bbox_dn_1: 0.0983 (0.1079)  loss_giou_dn_1: 0.4499 (0.4376)  loss_vfl_dn_2: 0.3900 (0.3838)  loss_bbox_dn_2: 0.0935 (0.1013)  loss_giou_dn_2: 0.4152 (0.4118)  loss_vfl_dn_3: 0.3872 (0.3793)  loss_bbox_dn_3: 0.0914 (0.0996)  loss_giou_dn_3: 0.4084 (0.4059)  loss_vfl_dn_4: 0.3871 (0.3772)  loss_bbox_dn_4: 0.0912 (0.0992)  loss_giou_dn_4: 0.4065 (0.4045)  loss_vfl_dn_5: 0.3880 (0.3778)  loss_bbox_dn_5: 0.0908 (0.0992)  loss_giou_dn_5: 0.4078 (0.4042)  time: 0.3270  data: 0.0137  max mem: 7790\n",
            "Epoch: [179] Total time: 0:00:11 (0.3513 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.8702 (12.8868)  loss_vfl: 0.4790 (0.4670)  loss_bbox: 0.0819 (0.0878)  loss_giou: 0.3639 (0.3937)  loss_vfl_aux_0: 0.5060 (0.5089)  loss_bbox_aux_0: 0.0933 (0.0988)  loss_giou_aux_0: 0.4169 (0.4436)  loss_vfl_aux_1: 0.4984 (0.4931)  loss_bbox_aux_1: 0.0873 (0.0904)  loss_giou_aux_1: 0.3914 (0.4112)  loss_vfl_aux_2: 0.4935 (0.4953)  loss_bbox_aux_2: 0.0820 (0.0882)  loss_giou_aux_2: 0.3739 (0.3980)  loss_vfl_aux_3: 0.4880 (0.4855)  loss_bbox_aux_3: 0.0743 (0.0879)  loss_giou_aux_3: 0.3739 (0.3949)  loss_vfl_aux_4: 0.4785 (0.4683)  loss_bbox_aux_4: 0.0817 (0.0883)  loss_giou_aux_4: 0.3751 (0.3947)  loss_vfl_aux_5: 0.5759 (0.5696)  loss_bbox_aux_5: 0.1491 (0.1563)  loss_giou_aux_5: 0.6091 (0.6024)  loss_vfl_dn_0: 0.4364 (0.4382)  loss_bbox_dn_0: 0.1436 (0.1525)  loss_giou_dn_0: 0.6021 (0.5866)  loss_vfl_dn_1: 0.4049 (0.3961)  loss_bbox_dn_1: 0.0983 (0.1079)  loss_giou_dn_1: 0.4499 (0.4376)  loss_vfl_dn_2: 0.3900 (0.3838)  loss_bbox_dn_2: 0.0935 (0.1013)  loss_giou_dn_2: 0.4152 (0.4118)  loss_vfl_dn_3: 0.3872 (0.3793)  loss_bbox_dn_3: 0.0914 (0.0996)  loss_giou_dn_3: 0.4084 (0.4059)  loss_vfl_dn_4: 0.3871 (0.3772)  loss_bbox_dn_4: 0.0912 (0.0992)  loss_giou_dn_4: 0.4065 (0.4045)  loss_vfl_dn_5: 0.3880 (0.3778)  loss_bbox_dn_5: 0.0908 (0.0992)  loss_giou_dn_5: 0.4078 (0.4042)\n",
            "Test:  [0/6]  eta: 0:00:04    time: 0.8330  data: 0.5243  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.8531  data: 0.5787  max mem: 7790\n",
            "Test: Total time: 0:00:05 (0.8678 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.652\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [180]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 13.0773 (13.0773)  loss_vfl: 0.5344 (0.5344)  loss_bbox: 0.0731 (0.0731)  loss_giou: 0.3631 (0.3631)  loss_vfl_aux_0: 0.5765 (0.5765)  loss_bbox_aux_0: 0.1053 (0.1053)  loss_giou_aux_0: 0.4090 (0.4090)  loss_vfl_aux_1: 0.5578 (0.5578)  loss_bbox_aux_1: 0.0778 (0.0778)  loss_giou_aux_1: 0.3724 (0.3724)  loss_vfl_aux_2: 0.5670 (0.5670)  loss_bbox_aux_2: 0.0751 (0.0751)  loss_giou_aux_2: 0.3696 (0.3696)  loss_vfl_aux_3: 0.5633 (0.5633)  loss_bbox_aux_3: 0.0787 (0.0787)  loss_giou_aux_3: 0.3670 (0.3670)  loss_vfl_aux_4: 0.5335 (0.5335)  loss_bbox_aux_4: 0.0746 (0.0746)  loss_giou_aux_4: 0.3630 (0.3630)  loss_vfl_aux_5: 0.6765 (0.6765)  loss_bbox_aux_5: 0.1294 (0.1294)  loss_giou_aux_5: 0.4824 (0.4824)  loss_vfl_dn_0: 0.4299 (0.4299)  loss_bbox_dn_0: 0.1948 (0.1948)  loss_giou_dn_0: 0.5827 (0.5827)  loss_vfl_dn_1: 0.3868 (0.3868)  loss_bbox_dn_1: 0.1420 (0.1420)  loss_giou_dn_1: 0.4201 (0.4201)  loss_vfl_dn_2: 0.3814 (0.3814)  loss_bbox_dn_2: 0.1274 (0.1274)  loss_giou_dn_2: 0.4031 (0.4031)  loss_vfl_dn_3: 0.3808 (0.3808)  loss_bbox_dn_3: 0.1166 (0.1166)  loss_giou_dn_3: 0.3971 (0.3971)  loss_vfl_dn_4: 0.3783 (0.3783)  loss_bbox_dn_4: 0.1134 (0.1134)  loss_giou_dn_4: 0.3928 (0.3928)  loss_vfl_dn_5: 0.3777 (0.3777)  loss_bbox_dn_5: 0.1116 (0.1116)  loss_giou_dn_5: 0.3913 (0.3913)  time: 1.0892  data: 0.7107  max mem: 7790\n",
            "Epoch: [180]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.0536 (12.7561)  loss_vfl: 0.4597 (0.4665)  loss_bbox: 0.0795 (0.0844)  loss_giou: 0.3592 (0.3901)  loss_vfl_aux_0: 0.4985 (0.5069)  loss_bbox_aux_0: 0.0879 (0.0988)  loss_giou_aux_0: 0.3984 (0.4365)  loss_vfl_aux_1: 0.4806 (0.4956)  loss_bbox_aux_1: 0.0808 (0.0870)  loss_giou_aux_1: 0.3568 (0.4003)  loss_vfl_aux_2: 0.4878 (0.4927)  loss_bbox_aux_2: 0.0802 (0.0842)  loss_giou_aux_2: 0.3524 (0.3909)  loss_vfl_aux_3: 0.4686 (0.4816)  loss_bbox_aux_3: 0.0787 (0.0846)  loss_giou_aux_3: 0.3550 (0.3897)  loss_vfl_aux_4: 0.4596 (0.4696)  loss_bbox_aux_4: 0.0789 (0.0833)  loss_giou_aux_4: 0.3481 (0.3884)  loss_vfl_aux_5: 0.5378 (0.5681)  loss_bbox_aux_5: 0.1209 (0.1351)  loss_giou_aux_5: 0.5226 (0.5602)  loss_vfl_dn_0: 0.4336 (0.4337)  loss_bbox_dn_0: 0.1541 (0.1527)  loss_giou_dn_0: 0.5438 (0.5835)  loss_vfl_dn_1: 0.3855 (0.3926)  loss_bbox_dn_1: 0.0971 (0.1062)  loss_giou_dn_1: 0.3995 (0.4392)  loss_vfl_dn_2: 0.3733 (0.3818)  loss_bbox_dn_2: 0.0959 (0.0989)  loss_giou_dn_2: 0.3819 (0.4161)  loss_vfl_dn_3: 0.3726 (0.3782)  loss_bbox_dn_3: 0.0935 (0.0973)  loss_giou_dn_3: 0.3792 (0.4120)  loss_vfl_dn_4: 0.3746 (0.3765)  loss_bbox_dn_4: 0.0911 (0.0971)  loss_giou_dn_4: 0.3736 (0.4116)  loss_vfl_dn_5: 0.3721 (0.3757)  loss_bbox_dn_5: 0.0905 (0.0970)  loss_giou_dn_5: 0.3729 (0.4118)  time: 0.3275  data: 0.0149  max mem: 7790\n",
            "Epoch: [180] Total time: 0:00:11 (0.3626 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.0536 (12.7561)  loss_vfl: 0.4597 (0.4665)  loss_bbox: 0.0795 (0.0844)  loss_giou: 0.3592 (0.3901)  loss_vfl_aux_0: 0.4985 (0.5069)  loss_bbox_aux_0: 0.0879 (0.0988)  loss_giou_aux_0: 0.3984 (0.4365)  loss_vfl_aux_1: 0.4806 (0.4956)  loss_bbox_aux_1: 0.0808 (0.0870)  loss_giou_aux_1: 0.3568 (0.4003)  loss_vfl_aux_2: 0.4878 (0.4927)  loss_bbox_aux_2: 0.0802 (0.0842)  loss_giou_aux_2: 0.3524 (0.3909)  loss_vfl_aux_3: 0.4686 (0.4816)  loss_bbox_aux_3: 0.0787 (0.0846)  loss_giou_aux_3: 0.3550 (0.3897)  loss_vfl_aux_4: 0.4596 (0.4696)  loss_bbox_aux_4: 0.0789 (0.0833)  loss_giou_aux_4: 0.3481 (0.3884)  loss_vfl_aux_5: 0.5378 (0.5681)  loss_bbox_aux_5: 0.1209 (0.1351)  loss_giou_aux_5: 0.5226 (0.5602)  loss_vfl_dn_0: 0.4336 (0.4337)  loss_bbox_dn_0: 0.1541 (0.1527)  loss_giou_dn_0: 0.5438 (0.5835)  loss_vfl_dn_1: 0.3855 (0.3926)  loss_bbox_dn_1: 0.0971 (0.1062)  loss_giou_dn_1: 0.3995 (0.4392)  loss_vfl_dn_2: 0.3733 (0.3818)  loss_bbox_dn_2: 0.0959 (0.0989)  loss_giou_dn_2: 0.3819 (0.4161)  loss_vfl_dn_3: 0.3726 (0.3782)  loss_bbox_dn_3: 0.0935 (0.0973)  loss_giou_dn_3: 0.3792 (0.4120)  loss_vfl_dn_4: 0.3746 (0.3765)  loss_bbox_dn_4: 0.0911 (0.0971)  loss_giou_dn_4: 0.3736 (0.4116)  loss_vfl_dn_5: 0.3721 (0.3757)  loss_bbox_dn_5: 0.0905 (0.0970)  loss_giou_dn_5: 0.3729 (0.4118)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8507  data: 0.5279  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3893  data: 0.1106  max mem: 7790\n",
            "Test: Total time: 0:00:04 (0.6978 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [181]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 9.9920 (9.9920)  loss_vfl: 0.3407 (0.3407)  loss_bbox: 0.0464 (0.0464)  loss_giou: 0.2594 (0.2594)  loss_vfl_aux_0: 0.4214 (0.4214)  loss_bbox_aux_0: 0.0660 (0.0660)  loss_giou_aux_0: 0.3181 (0.3181)  loss_vfl_aux_1: 0.3894 (0.3894)  loss_bbox_aux_1: 0.0547 (0.0547)  loss_giou_aux_1: 0.2825 (0.2825)  loss_vfl_aux_2: 0.3726 (0.3726)  loss_bbox_aux_2: 0.0495 (0.0495)  loss_giou_aux_2: 0.2696 (0.2696)  loss_vfl_aux_3: 0.3573 (0.3573)  loss_bbox_aux_3: 0.0479 (0.0479)  loss_giou_aux_3: 0.2647 (0.2647)  loss_vfl_aux_4: 0.3437 (0.3437)  loss_bbox_aux_4: 0.0469 (0.0469)  loss_giou_aux_4: 0.2620 (0.2620)  loss_vfl_aux_5: 0.5385 (0.5385)  loss_bbox_aux_5: 0.0924 (0.0924)  loss_giou_aux_5: 0.3932 (0.3932)  loss_vfl_dn_0: 0.4348 (0.4348)  loss_bbox_dn_0: 0.1360 (0.1360)  loss_giou_dn_0: 0.5083 (0.5083)  loss_vfl_dn_1: 0.3670 (0.3670)  loss_bbox_dn_1: 0.0850 (0.0850)  loss_giou_dn_1: 0.3422 (0.3422)  loss_vfl_dn_2: 0.3520 (0.3520)  loss_bbox_dn_2: 0.0742 (0.0742)  loss_giou_dn_2: 0.3129 (0.3129)  loss_vfl_dn_3: 0.3459 (0.3459)  loss_bbox_dn_3: 0.0728 (0.0728)  loss_giou_dn_3: 0.3065 (0.3065)  loss_vfl_dn_4: 0.3426 (0.3426)  loss_bbox_dn_4: 0.0724 (0.0724)  loss_giou_dn_4: 0.3057 (0.3057)  loss_vfl_dn_5: 0.3406 (0.3406)  loss_bbox_dn_5: 0.0720 (0.0720)  loss_giou_dn_5: 0.3045 (0.3045)  time: 1.0095  data: 0.6229  max mem: 7790\n",
            "Epoch: [181]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.3062 (12.5366)  loss_vfl: 0.4332 (0.4565)  loss_bbox: 0.0756 (0.0813)  loss_giou: 0.3616 (0.3754)  loss_vfl_aux_0: 0.4879 (0.5041)  loss_bbox_aux_0: 0.0899 (0.0944)  loss_giou_aux_0: 0.3952 (0.4171)  loss_vfl_aux_1: 0.4678 (0.4864)  loss_bbox_aux_1: 0.0788 (0.0842)  loss_giou_aux_1: 0.3737 (0.3848)  loss_vfl_aux_2: 0.4699 (0.4840)  loss_bbox_aux_2: 0.0747 (0.0818)  loss_giou_aux_2: 0.3633 (0.3769)  loss_vfl_aux_3: 0.4501 (0.4731)  loss_bbox_aux_3: 0.0757 (0.0811)  loss_giou_aux_3: 0.3595 (0.3748)  loss_vfl_aux_4: 0.4470 (0.4611)  loss_bbox_aux_4: 0.0741 (0.0805)  loss_giou_aux_4: 0.3605 (0.3755)  loss_vfl_aux_5: 0.5766 (0.5828)  loss_bbox_aux_5: 0.1352 (0.1404)  loss_giou_aux_5: 0.5462 (0.5506)  loss_vfl_dn_0: 0.4321 (0.4312)  loss_bbox_dn_0: 0.1285 (0.1503)  loss_giou_dn_0: 0.5778 (0.5760)  loss_vfl_dn_1: 0.3825 (0.3892)  loss_bbox_dn_1: 0.0917 (0.1086)  loss_giou_dn_1: 0.4225 (0.4315)  loss_vfl_dn_2: 0.3675 (0.3782)  loss_bbox_dn_2: 0.0849 (0.1008)  loss_giou_dn_2: 0.3944 (0.4071)  loss_vfl_dn_3: 0.3622 (0.3722)  loss_bbox_dn_3: 0.0813 (0.0992)  loss_giou_dn_3: 0.3862 (0.4024)  loss_vfl_dn_4: 0.3597 (0.3712)  loss_bbox_dn_4: 0.0808 (0.0991)  loss_giou_dn_4: 0.3847 (0.4015)  loss_vfl_dn_5: 0.3599 (0.3712)  loss_bbox_dn_5: 0.0807 (0.0989)  loss_giou_dn_5: 0.3839 (0.4013)  time: 0.3442  data: 0.0150  max mem: 7790\n",
            "Epoch: [181] Total time: 0:00:11 (0.3574 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.3062 (12.5366)  loss_vfl: 0.4332 (0.4565)  loss_bbox: 0.0756 (0.0813)  loss_giou: 0.3616 (0.3754)  loss_vfl_aux_0: 0.4879 (0.5041)  loss_bbox_aux_0: 0.0899 (0.0944)  loss_giou_aux_0: 0.3952 (0.4171)  loss_vfl_aux_1: 0.4678 (0.4864)  loss_bbox_aux_1: 0.0788 (0.0842)  loss_giou_aux_1: 0.3737 (0.3848)  loss_vfl_aux_2: 0.4699 (0.4840)  loss_bbox_aux_2: 0.0747 (0.0818)  loss_giou_aux_2: 0.3633 (0.3769)  loss_vfl_aux_3: 0.4501 (0.4731)  loss_bbox_aux_3: 0.0757 (0.0811)  loss_giou_aux_3: 0.3595 (0.3748)  loss_vfl_aux_4: 0.4470 (0.4611)  loss_bbox_aux_4: 0.0741 (0.0805)  loss_giou_aux_4: 0.3605 (0.3755)  loss_vfl_aux_5: 0.5766 (0.5828)  loss_bbox_aux_5: 0.1352 (0.1404)  loss_giou_aux_5: 0.5462 (0.5506)  loss_vfl_dn_0: 0.4321 (0.4312)  loss_bbox_dn_0: 0.1285 (0.1503)  loss_giou_dn_0: 0.5778 (0.5760)  loss_vfl_dn_1: 0.3825 (0.3892)  loss_bbox_dn_1: 0.0917 (0.1086)  loss_giou_dn_1: 0.4225 (0.4315)  loss_vfl_dn_2: 0.3675 (0.3782)  loss_bbox_dn_2: 0.0849 (0.1008)  loss_giou_dn_2: 0.3944 (0.4071)  loss_vfl_dn_3: 0.3622 (0.3722)  loss_bbox_dn_3: 0.0813 (0.0992)  loss_giou_dn_3: 0.3862 (0.4024)  loss_vfl_dn_4: 0.3597 (0.3712)  loss_bbox_dn_4: 0.0808 (0.0991)  loss_giou_dn_4: 0.3847 (0.4015)  loss_vfl_dn_5: 0.3599 (0.3712)  loss_bbox_dn_5: 0.0807 (0.0989)  loss_giou_dn_5: 0.3839 (0.4013)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8988  data: 0.5693  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4010  data: 0.1146  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4152 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.645\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.317\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [182]  [ 0/33]  eta: 0:00:30  lr: 0.000001  loss: 10.9258 (10.9258)  loss_vfl: 0.4007 (0.4007)  loss_bbox: 0.0718 (0.0718)  loss_giou: 0.2541 (0.2541)  loss_vfl_aux_0: 0.5064 (0.5064)  loss_bbox_aux_0: 0.0866 (0.0866)  loss_giou_aux_0: 0.2843 (0.2843)  loss_vfl_aux_1: 0.4565 (0.4565)  loss_bbox_aux_1: 0.0758 (0.0758)  loss_giou_aux_1: 0.2625 (0.2625)  loss_vfl_aux_2: 0.4527 (0.4527)  loss_bbox_aux_2: 0.0741 (0.0741)  loss_giou_aux_2: 0.2544 (0.2544)  loss_vfl_aux_3: 0.4231 (0.4231)  loss_bbox_aux_3: 0.0711 (0.0711)  loss_giou_aux_3: 0.2541 (0.2541)  loss_vfl_aux_4: 0.3946 (0.3946)  loss_bbox_aux_4: 0.0727 (0.0727)  loss_giou_aux_4: 0.2550 (0.2550)  loss_vfl_aux_5: 0.6066 (0.6066)  loss_bbox_aux_5: 0.1685 (0.1685)  loss_giou_aux_5: 0.5005 (0.5005)  loss_vfl_dn_0: 0.4322 (0.4322)  loss_bbox_dn_0: 0.1625 (0.1625)  loss_giou_dn_0: 0.4783 (0.4783)  loss_vfl_dn_1: 0.3826 (0.3826)  loss_bbox_dn_1: 0.1096 (0.1096)  loss_giou_dn_1: 0.3262 (0.3262)  loss_vfl_dn_2: 0.3780 (0.3780)  loss_bbox_dn_2: 0.1041 (0.1041)  loss_giou_dn_2: 0.3083 (0.3083)  loss_vfl_dn_3: 0.3740 (0.3740)  loss_bbox_dn_3: 0.0984 (0.0984)  loss_giou_dn_3: 0.3022 (0.3022)  loss_vfl_dn_4: 0.3762 (0.3762)  loss_bbox_dn_4: 0.0972 (0.0972)  loss_giou_dn_4: 0.2988 (0.2988)  loss_vfl_dn_5: 0.3766 (0.3766)  loss_bbox_dn_5: 0.0967 (0.0967)  loss_giou_dn_5: 0.2977 (0.2977)  time: 0.9201  data: 0.5540  max mem: 7790\n",
            "Epoch: [182]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.2402 (12.8682)  loss_vfl: 0.4488 (0.4704)  loss_bbox: 0.0781 (0.0826)  loss_giou: 0.3634 (0.4009)  loss_vfl_aux_0: 0.4960 (0.5082)  loss_bbox_aux_0: 0.0889 (0.0947)  loss_giou_aux_0: 0.4063 (0.4424)  loss_vfl_aux_1: 0.4842 (0.5004)  loss_bbox_aux_1: 0.0779 (0.0852)  loss_giou_aux_1: 0.3758 (0.4110)  loss_vfl_aux_2: 0.4738 (0.4974)  loss_bbox_aux_2: 0.0758 (0.0830)  loss_giou_aux_2: 0.3665 (0.4025)  loss_vfl_aux_3: 0.4623 (0.4838)  loss_bbox_aux_3: 0.0772 (0.0830)  loss_giou_aux_3: 0.3643 (0.4011)  loss_vfl_aux_4: 0.4498 (0.4667)  loss_bbox_aux_4: 0.0781 (0.0823)  loss_giou_aux_4: 0.3638 (0.4008)  loss_vfl_aux_5: 0.5758 (0.5840)  loss_bbox_aux_5: 0.1128 (0.1318)  loss_giou_aux_5: 0.5206 (0.5611)  loss_vfl_dn_0: 0.4332 (0.4377)  loss_bbox_dn_0: 0.1274 (0.1431)  loss_giou_dn_0: 0.5494 (0.5838)  loss_vfl_dn_1: 0.3989 (0.3961)  loss_bbox_dn_1: 0.0848 (0.1041)  loss_giou_dn_1: 0.4101 (0.4441)  loss_vfl_dn_2: 0.3888 (0.3861)  loss_bbox_dn_2: 0.0811 (0.0978)  loss_giou_dn_2: 0.3830 (0.4221)  loss_vfl_dn_3: 0.3851 (0.3822)  loss_bbox_dn_3: 0.0807 (0.0962)  loss_giou_dn_3: 0.3793 (0.4172)  loss_vfl_dn_4: 0.3790 (0.3795)  loss_bbox_dn_4: 0.0801 (0.0958)  loss_giou_dn_4: 0.3783 (0.4161)  loss_vfl_dn_5: 0.3839 (0.3805)  loss_bbox_dn_5: 0.0798 (0.0958)  loss_giou_dn_5: 0.3798 (0.4167)  time: 0.3258  data: 0.0141  max mem: 7790\n",
            "Epoch: [182] Total time: 0:00:11 (0.3512 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.2402 (12.8682)  loss_vfl: 0.4488 (0.4704)  loss_bbox: 0.0781 (0.0826)  loss_giou: 0.3634 (0.4009)  loss_vfl_aux_0: 0.4960 (0.5082)  loss_bbox_aux_0: 0.0889 (0.0947)  loss_giou_aux_0: 0.4063 (0.4424)  loss_vfl_aux_1: 0.4842 (0.5004)  loss_bbox_aux_1: 0.0779 (0.0852)  loss_giou_aux_1: 0.3758 (0.4110)  loss_vfl_aux_2: 0.4738 (0.4974)  loss_bbox_aux_2: 0.0758 (0.0830)  loss_giou_aux_2: 0.3665 (0.4025)  loss_vfl_aux_3: 0.4623 (0.4838)  loss_bbox_aux_3: 0.0772 (0.0830)  loss_giou_aux_3: 0.3643 (0.4011)  loss_vfl_aux_4: 0.4498 (0.4667)  loss_bbox_aux_4: 0.0781 (0.0823)  loss_giou_aux_4: 0.3638 (0.4008)  loss_vfl_aux_5: 0.5758 (0.5840)  loss_bbox_aux_5: 0.1128 (0.1318)  loss_giou_aux_5: 0.5206 (0.5611)  loss_vfl_dn_0: 0.4332 (0.4377)  loss_bbox_dn_0: 0.1274 (0.1431)  loss_giou_dn_0: 0.5494 (0.5838)  loss_vfl_dn_1: 0.3989 (0.3961)  loss_bbox_dn_1: 0.0848 (0.1041)  loss_giou_dn_1: 0.4101 (0.4441)  loss_vfl_dn_2: 0.3888 (0.3861)  loss_bbox_dn_2: 0.0811 (0.0978)  loss_giou_dn_2: 0.3830 (0.4221)  loss_vfl_dn_3: 0.3851 (0.3822)  loss_bbox_dn_3: 0.0807 (0.0962)  loss_giou_dn_3: 0.3793 (0.4172)  loss_vfl_dn_4: 0.3790 (0.3795)  loss_bbox_dn_4: 0.0801 (0.0958)  loss_giou_dn_4: 0.3783 (0.4161)  loss_vfl_dn_5: 0.3839 (0.3805)  loss_bbox_dn_5: 0.0798 (0.0958)  loss_giou_dn_5: 0.3798 (0.4167)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9339  data: 0.6255  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3898  data: 0.1164  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4032 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.655\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [183]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 15.8447 (15.8447)  loss_vfl: 0.5814 (0.5814)  loss_bbox: 0.1296 (0.1296)  loss_giou: 0.4908 (0.4908)  loss_vfl_aux_0: 0.6095 (0.6095)  loss_bbox_aux_0: 0.1750 (0.1750)  loss_giou_aux_0: 0.5713 (0.5713)  loss_vfl_aux_1: 0.6729 (0.6729)  loss_bbox_aux_1: 0.1111 (0.1111)  loss_giou_aux_1: 0.4992 (0.4992)  loss_vfl_aux_2: 0.6566 (0.6566)  loss_bbox_aux_2: 0.0998 (0.0998)  loss_giou_aux_2: 0.4732 (0.4732)  loss_vfl_aux_3: 0.6530 (0.6530)  loss_bbox_aux_3: 0.1016 (0.1016)  loss_giou_aux_3: 0.4627 (0.4627)  loss_vfl_aux_4: 0.6138 (0.6138)  loss_bbox_aux_4: 0.1162 (0.1162)  loss_giou_aux_4: 0.4688 (0.4688)  loss_vfl_aux_5: 0.6806 (0.6806)  loss_bbox_aux_5: 0.1980 (0.1980)  loss_giou_aux_5: 0.6522 (0.6522)  loss_vfl_dn_0: 0.4435 (0.4435)  loss_bbox_dn_0: 0.2328 (0.2328)  loss_giou_dn_0: 0.6389 (0.6389)  loss_vfl_dn_1: 0.4291 (0.4291)  loss_bbox_dn_1: 0.1902 (0.1902)  loss_giou_dn_1: 0.5109 (0.5109)  loss_vfl_dn_2: 0.4326 (0.4326)  loss_bbox_dn_2: 0.1827 (0.1827)  loss_giou_dn_2: 0.4879 (0.4879)  loss_vfl_dn_3: 0.4303 (0.4303)  loss_bbox_dn_3: 0.1862 (0.1862)  loss_giou_dn_3: 0.4838 (0.4838)  loss_vfl_dn_4: 0.4218 (0.4218)  loss_bbox_dn_4: 0.1845 (0.1845)  loss_giou_dn_4: 0.4811 (0.4811)  loss_vfl_dn_5: 0.4251 (0.4251)  loss_bbox_dn_5: 0.1843 (0.1843)  loss_giou_dn_5: 0.4817 (0.4817)  time: 1.0819  data: 0.6881  max mem: 7790\n",
            "Epoch: [183]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 11.6823 (12.4262)  loss_vfl: 0.4116 (0.4462)  loss_bbox: 0.0674 (0.0795)  loss_giou: 0.3268 (0.3810)  loss_vfl_aux_0: 0.4525 (0.4905)  loss_bbox_aux_0: 0.0722 (0.0940)  loss_giou_aux_0: 0.3772 (0.4246)  loss_vfl_aux_1: 0.4441 (0.4837)  loss_bbox_aux_1: 0.0697 (0.0811)  loss_giou_aux_1: 0.3424 (0.3898)  loss_vfl_aux_2: 0.4399 (0.4721)  loss_bbox_aux_2: 0.0687 (0.0796)  loss_giou_aux_2: 0.3433 (0.3835)  loss_vfl_aux_3: 0.4318 (0.4669)  loss_bbox_aux_3: 0.0671 (0.0778)  loss_giou_aux_3: 0.3277 (0.3802)  loss_vfl_aux_4: 0.4156 (0.4489)  loss_bbox_aux_4: 0.0678 (0.0803)  loss_giou_aux_4: 0.3305 (0.3834)  loss_vfl_aux_5: 0.5476 (0.5750)  loss_bbox_aux_5: 0.1003 (0.1299)  loss_giou_aux_5: 0.4756 (0.5416)  loss_vfl_dn_0: 0.4296 (0.4322)  loss_bbox_dn_0: 0.1189 (0.1487)  loss_giou_dn_0: 0.5474 (0.5696)  loss_vfl_dn_1: 0.3819 (0.3868)  loss_bbox_dn_1: 0.0810 (0.1058)  loss_giou_dn_1: 0.3988 (0.4258)  loss_vfl_dn_2: 0.3740 (0.3766)  loss_bbox_dn_2: 0.0787 (0.0983)  loss_giou_dn_2: 0.3799 (0.4024)  loss_vfl_dn_3: 0.3692 (0.3724)  loss_bbox_dn_3: 0.0781 (0.0969)  loss_giou_dn_3: 0.3707 (0.3972)  loss_vfl_dn_4: 0.3671 (0.3697)  loss_bbox_dn_4: 0.0777 (0.0965)  loss_giou_dn_4: 0.3691 (0.3963)  loss_vfl_dn_5: 0.3654 (0.3692)  loss_bbox_dn_5: 0.0777 (0.0963)  loss_giou_dn_5: 0.3676 (0.3961)  time: 0.3371  data: 0.0149  max mem: 7790\n",
            "Epoch: [183] Total time: 0:00:11 (0.3578 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 11.6823 (12.4262)  loss_vfl: 0.4116 (0.4462)  loss_bbox: 0.0674 (0.0795)  loss_giou: 0.3268 (0.3810)  loss_vfl_aux_0: 0.4525 (0.4905)  loss_bbox_aux_0: 0.0722 (0.0940)  loss_giou_aux_0: 0.3772 (0.4246)  loss_vfl_aux_1: 0.4441 (0.4837)  loss_bbox_aux_1: 0.0697 (0.0811)  loss_giou_aux_1: 0.3424 (0.3898)  loss_vfl_aux_2: 0.4399 (0.4721)  loss_bbox_aux_2: 0.0687 (0.0796)  loss_giou_aux_2: 0.3433 (0.3835)  loss_vfl_aux_3: 0.4318 (0.4669)  loss_bbox_aux_3: 0.0671 (0.0778)  loss_giou_aux_3: 0.3277 (0.3802)  loss_vfl_aux_4: 0.4156 (0.4489)  loss_bbox_aux_4: 0.0678 (0.0803)  loss_giou_aux_4: 0.3305 (0.3834)  loss_vfl_aux_5: 0.5476 (0.5750)  loss_bbox_aux_5: 0.1003 (0.1299)  loss_giou_aux_5: 0.4756 (0.5416)  loss_vfl_dn_0: 0.4296 (0.4322)  loss_bbox_dn_0: 0.1189 (0.1487)  loss_giou_dn_0: 0.5474 (0.5696)  loss_vfl_dn_1: 0.3819 (0.3868)  loss_bbox_dn_1: 0.0810 (0.1058)  loss_giou_dn_1: 0.3988 (0.4258)  loss_vfl_dn_2: 0.3740 (0.3766)  loss_bbox_dn_2: 0.0787 (0.0983)  loss_giou_dn_2: 0.3799 (0.4024)  loss_vfl_dn_3: 0.3692 (0.3724)  loss_bbox_dn_3: 0.0781 (0.0969)  loss_giou_dn_3: 0.3707 (0.3972)  loss_vfl_dn_4: 0.3671 (0.3697)  loss_bbox_dn_4: 0.0777 (0.0965)  loss_giou_dn_4: 0.3691 (0.3963)  loss_vfl_dn_5: 0.3654 (0.3692)  loss_bbox_dn_5: 0.0777 (0.0963)  loss_giou_dn_5: 0.3676 (0.3961)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9352  data: 0.6049  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3901  data: 0.1127  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4034 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [184]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 12.2961 (12.2961)  loss_vfl: 0.4104 (0.4104)  loss_bbox: 0.0661 (0.0661)  loss_giou: 0.3646 (0.3646)  loss_vfl_aux_0: 0.4854 (0.4854)  loss_bbox_aux_0: 0.0722 (0.0722)  loss_giou_aux_0: 0.3917 (0.3917)  loss_vfl_aux_1: 0.4634 (0.4634)  loss_bbox_aux_1: 0.0684 (0.0684)  loss_giou_aux_1: 0.3766 (0.3766)  loss_vfl_aux_2: 0.4472 (0.4472)  loss_bbox_aux_2: 0.0668 (0.0668)  loss_giou_aux_2: 0.3644 (0.3644)  loss_vfl_aux_3: 0.4440 (0.4440)  loss_bbox_aux_3: 0.0671 (0.0671)  loss_giou_aux_3: 0.3629 (0.3629)  loss_vfl_aux_4: 0.4130 (0.4130)  loss_bbox_aux_4: 0.0662 (0.0662)  loss_giou_aux_4: 0.3616 (0.3616)  loss_vfl_aux_5: 0.5598 (0.5598)  loss_bbox_aux_5: 0.1004 (0.1004)  loss_giou_aux_5: 0.5763 (0.5763)  loss_vfl_dn_0: 0.4310 (0.4310)  loss_bbox_dn_0: 0.1203 (0.1203)  loss_giou_dn_0: 0.6281 (0.6281)  loss_vfl_dn_1: 0.3954 (0.3954)  loss_bbox_dn_1: 0.0869 (0.0869)  loss_giou_dn_1: 0.4875 (0.4875)  loss_vfl_dn_2: 0.3795 (0.3795)  loss_bbox_dn_2: 0.0810 (0.0810)  loss_giou_dn_2: 0.4527 (0.4527)  loss_vfl_dn_3: 0.3804 (0.3804)  loss_bbox_dn_3: 0.0809 (0.0809)  loss_giou_dn_3: 0.4483 (0.4483)  loss_vfl_dn_4: 0.3695 (0.3695)  loss_bbox_dn_4: 0.0807 (0.0807)  loss_giou_dn_4: 0.4463 (0.4463)  loss_vfl_dn_5: 0.3720 (0.3720)  loss_bbox_dn_5: 0.0807 (0.0807)  loss_giou_dn_5: 0.4464 (0.4464)  time: 0.9703  data: 0.5782  max mem: 7790\n",
            "Epoch: [184]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.5896 (12.5827)  loss_vfl: 0.4476 (0.4480)  loss_bbox: 0.0826 (0.1014)  loss_giou: 0.3790 (0.3668)  loss_vfl_aux_0: 0.5001 (0.4990)  loss_bbox_aux_0: 0.0949 (0.1174)  loss_giou_aux_0: 0.4290 (0.4046)  loss_vfl_aux_1: 0.4971 (0.4801)  loss_bbox_aux_1: 0.0798 (0.1055)  loss_giou_aux_1: 0.3853 (0.3769)  loss_vfl_aux_2: 0.4720 (0.4780)  loss_bbox_aux_2: 0.0743 (0.1027)  loss_giou_aux_2: 0.3907 (0.3677)  loss_vfl_aux_3: 0.4613 (0.4699)  loss_bbox_aux_3: 0.0769 (0.1021)  loss_giou_aux_3: 0.3830 (0.3676)  loss_vfl_aux_4: 0.4618 (0.4521)  loss_bbox_aux_4: 0.0828 (0.1024)  loss_giou_aux_4: 0.3934 (0.3672)  loss_vfl_aux_5: 0.5910 (0.5954)  loss_bbox_aux_5: 0.1347 (0.1623)  loss_giou_aux_5: 0.5404 (0.5312)  loss_vfl_dn_0: 0.4320 (0.4342)  loss_bbox_dn_0: 0.1358 (0.1812)  loss_giou_dn_0: 0.5642 (0.5523)  loss_vfl_dn_1: 0.3954 (0.3877)  loss_bbox_dn_1: 0.0994 (0.1303)  loss_giou_dn_1: 0.4323 (0.4077)  loss_vfl_dn_2: 0.3881 (0.3767)  loss_bbox_dn_2: 0.0977 (0.1213)  loss_giou_dn_2: 0.3976 (0.3836)  loss_vfl_dn_3: 0.3885 (0.3748)  loss_bbox_dn_3: 0.0976 (0.1191)  loss_giou_dn_3: 0.3881 (0.3794)  loss_vfl_dn_4: 0.3826 (0.3719)  loss_bbox_dn_4: 0.0974 (0.1187)  loss_giou_dn_4: 0.3814 (0.3780)  loss_vfl_dn_5: 0.3798 (0.3712)  loss_bbox_dn_5: 0.0970 (0.1186)  loss_giou_dn_5: 0.3788 (0.3779)  time: 0.3231  data: 0.0142  max mem: 7790\n",
            "Epoch: [184] Total time: 0:00:11 (0.3481 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.5896 (12.5827)  loss_vfl: 0.4476 (0.4480)  loss_bbox: 0.0826 (0.1014)  loss_giou: 0.3790 (0.3668)  loss_vfl_aux_0: 0.5001 (0.4990)  loss_bbox_aux_0: 0.0949 (0.1174)  loss_giou_aux_0: 0.4290 (0.4046)  loss_vfl_aux_1: 0.4971 (0.4801)  loss_bbox_aux_1: 0.0798 (0.1055)  loss_giou_aux_1: 0.3853 (0.3769)  loss_vfl_aux_2: 0.4720 (0.4780)  loss_bbox_aux_2: 0.0743 (0.1027)  loss_giou_aux_2: 0.3907 (0.3677)  loss_vfl_aux_3: 0.4613 (0.4699)  loss_bbox_aux_3: 0.0769 (0.1021)  loss_giou_aux_3: 0.3830 (0.3676)  loss_vfl_aux_4: 0.4618 (0.4521)  loss_bbox_aux_4: 0.0828 (0.1024)  loss_giou_aux_4: 0.3934 (0.3672)  loss_vfl_aux_5: 0.5910 (0.5954)  loss_bbox_aux_5: 0.1347 (0.1623)  loss_giou_aux_5: 0.5404 (0.5312)  loss_vfl_dn_0: 0.4320 (0.4342)  loss_bbox_dn_0: 0.1358 (0.1812)  loss_giou_dn_0: 0.5642 (0.5523)  loss_vfl_dn_1: 0.3954 (0.3877)  loss_bbox_dn_1: 0.0994 (0.1303)  loss_giou_dn_1: 0.4323 (0.4077)  loss_vfl_dn_2: 0.3881 (0.3767)  loss_bbox_dn_2: 0.0977 (0.1213)  loss_giou_dn_2: 0.3976 (0.3836)  loss_vfl_dn_3: 0.3885 (0.3748)  loss_bbox_dn_3: 0.0976 (0.1191)  loss_giou_dn_3: 0.3881 (0.3794)  loss_vfl_dn_4: 0.3826 (0.3719)  loss_bbox_dn_4: 0.0974 (0.1187)  loss_giou_dn_4: 0.3814 (0.3780)  loss_vfl_dn_5: 0.3798 (0.3712)  loss_bbox_dn_5: 0.0970 (0.1186)  loss_giou_dn_5: 0.3788 (0.3779)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9056  data: 0.5974  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4372  data: 0.1118  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4508 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.670\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [185]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 13.2100 (13.2100)  loss_vfl: 0.4453 (0.4453)  loss_bbox: 0.0909 (0.0909)  loss_giou: 0.4523 (0.4523)  loss_vfl_aux_0: 0.4921 (0.4921)  loss_bbox_aux_0: 0.0913 (0.0913)  loss_giou_aux_0: 0.4701 (0.4701)  loss_vfl_aux_1: 0.4754 (0.4754)  loss_bbox_aux_1: 0.0903 (0.0903)  loss_giou_aux_1: 0.4564 (0.4564)  loss_vfl_aux_2: 0.4605 (0.4605)  loss_bbox_aux_2: 0.0905 (0.0905)  loss_giou_aux_2: 0.4534 (0.4534)  loss_vfl_aux_3: 0.4696 (0.4696)  loss_bbox_aux_3: 0.0913 (0.0913)  loss_giou_aux_3: 0.4487 (0.4487)  loss_vfl_aux_4: 0.4447 (0.4447)  loss_bbox_aux_4: 0.0920 (0.0920)  loss_giou_aux_4: 0.4539 (0.4539)  loss_vfl_aux_5: 0.5307 (0.5307)  loss_bbox_aux_5: 0.1399 (0.1399)  loss_giou_aux_5: 0.6084 (0.6084)  loss_vfl_dn_0: 0.4299 (0.4299)  loss_bbox_dn_0: 0.1389 (0.1389)  loss_giou_dn_0: 0.6059 (0.6059)  loss_vfl_dn_1: 0.3926 (0.3926)  loss_bbox_dn_1: 0.1025 (0.1025)  loss_giou_dn_1: 0.4822 (0.4822)  loss_vfl_dn_2: 0.3862 (0.3862)  loss_bbox_dn_2: 0.0939 (0.0939)  loss_giou_dn_2: 0.4583 (0.4583)  loss_vfl_dn_3: 0.3794 (0.3794)  loss_bbox_dn_3: 0.0918 (0.0918)  loss_giou_dn_3: 0.4549 (0.4549)  loss_vfl_dn_4: 0.3756 (0.3756)  loss_bbox_dn_4: 0.0910 (0.0910)  loss_giou_dn_4: 0.4548 (0.4548)  loss_vfl_dn_5: 0.3768 (0.3768)  loss_bbox_dn_5: 0.0909 (0.0909)  loss_giou_dn_5: 0.4572 (0.4572)  time: 0.9959  data: 0.6163  max mem: 7790\n",
            "Epoch: [185]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 11.9046 (12.4678)  loss_vfl: 0.4420 (0.4527)  loss_bbox: 0.0772 (0.0753)  loss_giou: 0.3131 (0.3798)  loss_vfl_aux_0: 0.4821 (0.4920)  loss_bbox_aux_0: 0.0886 (0.0868)  loss_giou_aux_0: 0.3916 (0.4219)  loss_vfl_aux_1: 0.4771 (0.4812)  loss_bbox_aux_1: 0.0738 (0.0786)  loss_giou_aux_1: 0.3309 (0.3905)  loss_vfl_aux_2: 0.4735 (0.4772)  loss_bbox_aux_2: 0.0751 (0.0768)  loss_giou_aux_2: 0.3252 (0.3828)  loss_vfl_aux_3: 0.4572 (0.4684)  loss_bbox_aux_3: 0.0798 (0.0762)  loss_giou_aux_3: 0.3301 (0.3815)  loss_vfl_aux_4: 0.4413 (0.4527)  loss_bbox_aux_4: 0.0759 (0.0757)  loss_giou_aux_4: 0.3188 (0.3808)  loss_vfl_aux_5: 0.5633 (0.5600)  loss_bbox_aux_5: 0.1210 (0.1268)  loss_giou_aux_5: 0.4943 (0.5492)  loss_vfl_dn_0: 0.4327 (0.4333)  loss_bbox_dn_0: 0.1429 (0.1390)  loss_giou_dn_0: 0.5378 (0.5779)  loss_vfl_dn_1: 0.3817 (0.3904)  loss_bbox_dn_1: 0.0972 (0.0992)  loss_giou_dn_1: 0.3873 (0.4362)  loss_vfl_dn_2: 0.3709 (0.3820)  loss_bbox_dn_2: 0.0841 (0.0931)  loss_giou_dn_2: 0.3662 (0.4157)  loss_vfl_dn_3: 0.3702 (0.3775)  loss_bbox_dn_3: 0.0793 (0.0918)  loss_giou_dn_3: 0.3600 (0.4116)  loss_vfl_dn_4: 0.3682 (0.3743)  loss_bbox_dn_4: 0.0782 (0.0917)  loss_giou_dn_4: 0.3606 (0.4107)  loss_vfl_dn_5: 0.3695 (0.3748)  loss_bbox_dn_5: 0.0783 (0.0916)  loss_giou_dn_5: 0.3625 (0.4105)  time: 0.3272  data: 0.0147  max mem: 7790\n",
            "Epoch: [185] Total time: 0:00:11 (0.3508 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 11.9046 (12.4678)  loss_vfl: 0.4420 (0.4527)  loss_bbox: 0.0772 (0.0753)  loss_giou: 0.3131 (0.3798)  loss_vfl_aux_0: 0.4821 (0.4920)  loss_bbox_aux_0: 0.0886 (0.0868)  loss_giou_aux_0: 0.3916 (0.4219)  loss_vfl_aux_1: 0.4771 (0.4812)  loss_bbox_aux_1: 0.0738 (0.0786)  loss_giou_aux_1: 0.3309 (0.3905)  loss_vfl_aux_2: 0.4735 (0.4772)  loss_bbox_aux_2: 0.0751 (0.0768)  loss_giou_aux_2: 0.3252 (0.3828)  loss_vfl_aux_3: 0.4572 (0.4684)  loss_bbox_aux_3: 0.0798 (0.0762)  loss_giou_aux_3: 0.3301 (0.3815)  loss_vfl_aux_4: 0.4413 (0.4527)  loss_bbox_aux_4: 0.0759 (0.0757)  loss_giou_aux_4: 0.3188 (0.3808)  loss_vfl_aux_5: 0.5633 (0.5600)  loss_bbox_aux_5: 0.1210 (0.1268)  loss_giou_aux_5: 0.4943 (0.5492)  loss_vfl_dn_0: 0.4327 (0.4333)  loss_bbox_dn_0: 0.1429 (0.1390)  loss_giou_dn_0: 0.5378 (0.5779)  loss_vfl_dn_1: 0.3817 (0.3904)  loss_bbox_dn_1: 0.0972 (0.0992)  loss_giou_dn_1: 0.3873 (0.4362)  loss_vfl_dn_2: 0.3709 (0.3820)  loss_bbox_dn_2: 0.0841 (0.0931)  loss_giou_dn_2: 0.3662 (0.4157)  loss_vfl_dn_3: 0.3702 (0.3775)  loss_bbox_dn_3: 0.0793 (0.0918)  loss_giou_dn_3: 0.3600 (0.4116)  loss_vfl_dn_4: 0.3682 (0.3743)  loss_bbox_dn_4: 0.0782 (0.0917)  loss_giou_dn_4: 0.3606 (0.4107)  loss_vfl_dn_5: 0.3695 (0.3748)  loss_bbox_dn_5: 0.0783 (0.0916)  loss_giou_dn_5: 0.3625 (0.4105)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8769  data: 0.5622  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3833  data: 0.1087  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3979 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.667\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.593\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [186]  [ 0/33]  eta: 0:00:57  lr: 0.000001  loss: 12.5316 (12.5316)  loss_vfl: 0.4196 (0.4196)  loss_bbox: 0.0587 (0.0587)  loss_giou: 0.4577 (0.4577)  loss_vfl_aux_0: 0.4622 (0.4622)  loss_bbox_aux_0: 0.0684 (0.0684)  loss_giou_aux_0: 0.4989 (0.4989)  loss_vfl_aux_1: 0.4577 (0.4577)  loss_bbox_aux_1: 0.0614 (0.0614)  loss_giou_aux_1: 0.4683 (0.4683)  loss_vfl_aux_2: 0.4324 (0.4324)  loss_bbox_aux_2: 0.0585 (0.0585)  loss_giou_aux_2: 0.4620 (0.4620)  loss_vfl_aux_3: 0.4428 (0.4428)  loss_bbox_aux_3: 0.0588 (0.0588)  loss_giou_aux_3: 0.4608 (0.4608)  loss_vfl_aux_4: 0.4130 (0.4130)  loss_bbox_aux_4: 0.0582 (0.0582)  loss_giou_aux_4: 0.4593 (0.4593)  loss_vfl_aux_5: 0.5071 (0.5071)  loss_bbox_aux_5: 0.0923 (0.0923)  loss_giou_aux_5: 0.5821 (0.5821)  loss_vfl_dn_0: 0.4409 (0.4409)  loss_bbox_dn_0: 0.1103 (0.1103)  loss_giou_dn_0: 0.5984 (0.5984)  loss_vfl_dn_1: 0.4034 (0.4034)  loss_bbox_dn_1: 0.0715 (0.0715)  loss_giou_dn_1: 0.4539 (0.4539)  loss_vfl_dn_2: 0.3826 (0.3826)  loss_bbox_dn_2: 0.0646 (0.0646)  loss_giou_dn_2: 0.4344 (0.4344)  loss_vfl_dn_3: 0.3763 (0.3763)  loss_bbox_dn_3: 0.0641 (0.0641)  loss_giou_dn_3: 0.4291 (0.4291)  loss_vfl_dn_4: 0.3719 (0.3719)  loss_bbox_dn_4: 0.0635 (0.0635)  loss_giou_dn_4: 0.4263 (0.4263)  loss_vfl_dn_5: 0.3710 (0.3710)  loss_bbox_dn_5: 0.0639 (0.0639)  loss_giou_dn_5: 0.4253 (0.4253)  time: 1.7308  data: 1.3452  max mem: 7790\n",
            "Epoch: [186]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.0268 (12.6657)  loss_vfl: 0.4479 (0.4612)  loss_bbox: 0.0702 (0.0827)  loss_giou: 0.3035 (0.3785)  loss_vfl_aux_0: 0.4922 (0.5121)  loss_bbox_aux_0: 0.0864 (0.0984)  loss_giou_aux_0: 0.4025 (0.4224)  loss_vfl_aux_1: 0.4584 (0.4916)  loss_bbox_aux_1: 0.0715 (0.0871)  loss_giou_aux_1: 0.3233 (0.3905)  loss_vfl_aux_2: 0.4728 (0.4899)  loss_bbox_aux_2: 0.0703 (0.0844)  loss_giou_aux_2: 0.3070 (0.3806)  loss_vfl_aux_3: 0.4469 (0.4779)  loss_bbox_aux_3: 0.0702 (0.0829)  loss_giou_aux_3: 0.3012 (0.3777)  loss_vfl_aux_4: 0.4534 (0.4665)  loss_bbox_aux_4: 0.0699 (0.0830)  loss_giou_aux_4: 0.3051 (0.3786)  loss_vfl_aux_5: 0.5670 (0.5824)  loss_bbox_aux_5: 0.1261 (0.1370)  loss_giou_aux_5: 0.5530 (0.5449)  loss_vfl_dn_0: 0.4353 (0.4350)  loss_bbox_dn_0: 0.1347 (0.1557)  loss_giou_dn_0: 0.5428 (0.5817)  loss_vfl_dn_1: 0.4035 (0.3931)  loss_bbox_dn_1: 0.1007 (0.1121)  loss_giou_dn_1: 0.3878 (0.4363)  loss_vfl_dn_2: 0.3879 (0.3810)  loss_bbox_dn_2: 0.0942 (0.1044)  loss_giou_dn_2: 0.3521 (0.4120)  loss_vfl_dn_3: 0.3847 (0.3754)  loss_bbox_dn_3: 0.0939 (0.1022)  loss_giou_dn_3: 0.3469 (0.4060)  loss_vfl_dn_4: 0.3818 (0.3744)  loss_bbox_dn_4: 0.0932 (0.1019)  loss_giou_dn_4: 0.3434 (0.4050)  loss_vfl_dn_5: 0.3824 (0.3726)  loss_bbox_dn_5: 0.0930 (0.1018)  loss_giou_dn_5: 0.3397 (0.4050)  time: 0.3269  data: 0.0138  max mem: 7790\n",
            "Epoch: [186] Total time: 0:00:12 (0.3723 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.0268 (12.6657)  loss_vfl: 0.4479 (0.4612)  loss_bbox: 0.0702 (0.0827)  loss_giou: 0.3035 (0.3785)  loss_vfl_aux_0: 0.4922 (0.5121)  loss_bbox_aux_0: 0.0864 (0.0984)  loss_giou_aux_0: 0.4025 (0.4224)  loss_vfl_aux_1: 0.4584 (0.4916)  loss_bbox_aux_1: 0.0715 (0.0871)  loss_giou_aux_1: 0.3233 (0.3905)  loss_vfl_aux_2: 0.4728 (0.4899)  loss_bbox_aux_2: 0.0703 (0.0844)  loss_giou_aux_2: 0.3070 (0.3806)  loss_vfl_aux_3: 0.4469 (0.4779)  loss_bbox_aux_3: 0.0702 (0.0829)  loss_giou_aux_3: 0.3012 (0.3777)  loss_vfl_aux_4: 0.4534 (0.4665)  loss_bbox_aux_4: 0.0699 (0.0830)  loss_giou_aux_4: 0.3051 (0.3786)  loss_vfl_aux_5: 0.5670 (0.5824)  loss_bbox_aux_5: 0.1261 (0.1370)  loss_giou_aux_5: 0.5530 (0.5449)  loss_vfl_dn_0: 0.4353 (0.4350)  loss_bbox_dn_0: 0.1347 (0.1557)  loss_giou_dn_0: 0.5428 (0.5817)  loss_vfl_dn_1: 0.4035 (0.3931)  loss_bbox_dn_1: 0.1007 (0.1121)  loss_giou_dn_1: 0.3878 (0.4363)  loss_vfl_dn_2: 0.3879 (0.3810)  loss_bbox_dn_2: 0.0942 (0.1044)  loss_giou_dn_2: 0.3521 (0.4120)  loss_vfl_dn_3: 0.3847 (0.3754)  loss_bbox_dn_3: 0.0939 (0.1022)  loss_giou_dn_3: 0.3469 (0.4060)  loss_vfl_dn_4: 0.3818 (0.3744)  loss_bbox_dn_4: 0.0932 (0.1019)  loss_giou_dn_4: 0.3434 (0.4050)  loss_vfl_dn_5: 0.3824 (0.3726)  loss_bbox_dn_5: 0.0930 (0.1018)  loss_giou_dn_5: 0.3397 (0.4050)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9010  data: 0.5628  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4027  data: 0.1155  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4157 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.314\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [187]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 9.6413 (9.6413)  loss_vfl: 0.3172 (0.3172)  loss_bbox: 0.0557 (0.0557)  loss_giou: 0.2725 (0.2725)  loss_vfl_aux_0: 0.3941 (0.3941)  loss_bbox_aux_0: 0.0709 (0.0709)  loss_giou_aux_0: 0.3090 (0.3090)  loss_vfl_aux_1: 0.3495 (0.3495)  loss_bbox_aux_1: 0.0572 (0.0572)  loss_giou_aux_1: 0.2821 (0.2821)  loss_vfl_aux_2: 0.3354 (0.3354)  loss_bbox_aux_2: 0.0555 (0.0555)  loss_giou_aux_2: 0.2771 (0.2771)  loss_vfl_aux_3: 0.3272 (0.3272)  loss_bbox_aux_3: 0.0556 (0.0556)  loss_giou_aux_3: 0.2747 (0.2747)  loss_vfl_aux_4: 0.3284 (0.3284)  loss_bbox_aux_4: 0.0552 (0.0552)  loss_giou_aux_4: 0.2715 (0.2715)  loss_vfl_aux_5: 0.5436 (0.5436)  loss_bbox_aux_5: 0.1284 (0.1284)  loss_giou_aux_5: 0.4406 (0.4406)  loss_vfl_dn_0: 0.4201 (0.4201)  loss_bbox_dn_0: 0.1214 (0.1214)  loss_giou_dn_0: 0.4754 (0.4754)  loss_vfl_dn_1: 0.3538 (0.3538)  loss_bbox_dn_1: 0.0716 (0.0716)  loss_giou_dn_1: 0.3238 (0.3238)  loss_vfl_dn_2: 0.3319 (0.3319)  loss_bbox_dn_2: 0.0605 (0.0605)  loss_giou_dn_2: 0.2933 (0.2933)  loss_vfl_dn_3: 0.3204 (0.3204)  loss_bbox_dn_3: 0.0585 (0.0585)  loss_giou_dn_3: 0.2867 (0.2867)  loss_vfl_dn_4: 0.3162 (0.3162)  loss_bbox_dn_4: 0.0586 (0.0586)  loss_giou_dn_4: 0.2854 (0.2854)  loss_vfl_dn_5: 0.3173 (0.3173)  loss_bbox_dn_5: 0.0592 (0.0592)  loss_giou_dn_5: 0.2858 (0.2858)  time: 0.9961  data: 0.5799  max mem: 7790\n",
            "Epoch: [187]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.7108 (12.7318)  loss_vfl: 0.4709 (0.4483)  loss_bbox: 0.0896 (0.0933)  loss_giou: 0.3612 (0.3833)  loss_vfl_aux_0: 0.4924 (0.4840)  loss_bbox_aux_0: 0.1115 (0.1086)  loss_giou_aux_0: 0.4069 (0.4336)  loss_vfl_aux_1: 0.4850 (0.4763)  loss_bbox_aux_1: 0.0976 (0.0959)  loss_giou_aux_1: 0.3894 (0.3959)  loss_vfl_aux_2: 0.4788 (0.4740)  loss_bbox_aux_2: 0.0873 (0.0932)  loss_giou_aux_2: 0.3530 (0.3840)  loss_vfl_aux_3: 0.4763 (0.4618)  loss_bbox_aux_3: 0.0867 (0.0924)  loss_giou_aux_3: 0.3583 (0.3829)  loss_vfl_aux_4: 0.4649 (0.4505)  loss_bbox_aux_4: 0.0890 (0.0934)  loss_giou_aux_4: 0.3635 (0.3840)  loss_vfl_aux_5: 0.5634 (0.5737)  loss_bbox_aux_5: 0.1579 (0.1652)  loss_giou_aux_5: 0.5771 (0.5809)  loss_vfl_dn_0: 0.4391 (0.4375)  loss_bbox_dn_0: 0.1614 (0.1662)  loss_giou_dn_0: 0.5820 (0.5776)  loss_vfl_dn_1: 0.4009 (0.3931)  loss_bbox_dn_1: 0.1058 (0.1174)  loss_giou_dn_1: 0.4095 (0.4307)  loss_vfl_dn_2: 0.3942 (0.3818)  loss_bbox_dn_2: 0.0941 (0.1091)  loss_giou_dn_2: 0.4049 (0.4079)  loss_vfl_dn_3: 0.3882 (0.3772)  loss_bbox_dn_3: 0.0906 (0.1067)  loss_giou_dn_3: 0.4009 (0.4025)  loss_vfl_dn_4: 0.3917 (0.3773)  loss_bbox_dn_4: 0.0899 (0.1064)  loss_giou_dn_4: 0.4015 (0.4014)  loss_vfl_dn_5: 0.3882 (0.3757)  loss_bbox_dn_5: 0.0899 (0.1064)  loss_giou_dn_5: 0.4014 (0.4014)  time: 0.3450  data: 0.0144  max mem: 7790\n",
            "Epoch: [187] Total time: 0:00:11 (0.3634 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.7108 (12.7318)  loss_vfl: 0.4709 (0.4483)  loss_bbox: 0.0896 (0.0933)  loss_giou: 0.3612 (0.3833)  loss_vfl_aux_0: 0.4924 (0.4840)  loss_bbox_aux_0: 0.1115 (0.1086)  loss_giou_aux_0: 0.4069 (0.4336)  loss_vfl_aux_1: 0.4850 (0.4763)  loss_bbox_aux_1: 0.0976 (0.0959)  loss_giou_aux_1: 0.3894 (0.3959)  loss_vfl_aux_2: 0.4788 (0.4740)  loss_bbox_aux_2: 0.0873 (0.0932)  loss_giou_aux_2: 0.3530 (0.3840)  loss_vfl_aux_3: 0.4763 (0.4618)  loss_bbox_aux_3: 0.0867 (0.0924)  loss_giou_aux_3: 0.3583 (0.3829)  loss_vfl_aux_4: 0.4649 (0.4505)  loss_bbox_aux_4: 0.0890 (0.0934)  loss_giou_aux_4: 0.3635 (0.3840)  loss_vfl_aux_5: 0.5634 (0.5737)  loss_bbox_aux_5: 0.1579 (0.1652)  loss_giou_aux_5: 0.5771 (0.5809)  loss_vfl_dn_0: 0.4391 (0.4375)  loss_bbox_dn_0: 0.1614 (0.1662)  loss_giou_dn_0: 0.5820 (0.5776)  loss_vfl_dn_1: 0.4009 (0.3931)  loss_bbox_dn_1: 0.1058 (0.1174)  loss_giou_dn_1: 0.4095 (0.4307)  loss_vfl_dn_2: 0.3942 (0.3818)  loss_bbox_dn_2: 0.0941 (0.1091)  loss_giou_dn_2: 0.4049 (0.4079)  loss_vfl_dn_3: 0.3882 (0.3772)  loss_bbox_dn_3: 0.0906 (0.1067)  loss_giou_dn_3: 0.4009 (0.4025)  loss_vfl_dn_4: 0.3917 (0.3773)  loss_bbox_dn_4: 0.0899 (0.1064)  loss_giou_dn_4: 0.4015 (0.4014)  loss_vfl_dn_5: 0.3882 (0.3757)  loss_bbox_dn_5: 0.0899 (0.1064)  loss_giou_dn_5: 0.4014 (0.4014)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8807  data: 0.5558  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3961  data: 0.1112  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4085 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [188]  [ 0/33]  eta: 0:00:37  lr: 0.000001  loss: 11.0471 (11.0471)  loss_vfl: 0.3959 (0.3959)  loss_bbox: 0.1031 (0.1031)  loss_giou: 0.2714 (0.2714)  loss_vfl_aux_0: 0.4563 (0.4563)  loss_bbox_aux_0: 0.0890 (0.0890)  loss_giou_aux_0: 0.3245 (0.3245)  loss_vfl_aux_1: 0.4422 (0.4422)  loss_bbox_aux_1: 0.0844 (0.0844)  loss_giou_aux_1: 0.2734 (0.2734)  loss_vfl_aux_2: 0.4367 (0.4367)  loss_bbox_aux_2: 0.0825 (0.0825)  loss_giou_aux_2: 0.2650 (0.2650)  loss_vfl_aux_3: 0.4087 (0.4087)  loss_bbox_aux_3: 0.1009 (0.1009)  loss_giou_aux_3: 0.2702 (0.2702)  loss_vfl_aux_4: 0.3960 (0.3960)  loss_bbox_aux_4: 0.1034 (0.1034)  loss_giou_aux_4: 0.2725 (0.2725)  loss_vfl_aux_5: 0.5909 (0.5909)  loss_bbox_aux_5: 0.1282 (0.1282)  loss_giou_aux_5: 0.4907 (0.4907)  loss_vfl_dn_0: 0.4297 (0.4297)  loss_bbox_dn_0: 0.1862 (0.1862)  loss_giou_dn_0: 0.5187 (0.5187)  loss_vfl_dn_1: 0.3720 (0.3720)  loss_bbox_dn_1: 0.1379 (0.1379)  loss_giou_dn_1: 0.3458 (0.3458)  loss_vfl_dn_2: 0.3454 (0.3454)  loss_bbox_dn_2: 0.1255 (0.1255)  loss_giou_dn_2: 0.3121 (0.3121)  loss_vfl_dn_3: 0.3385 (0.3385)  loss_bbox_dn_3: 0.1245 (0.1245)  loss_giou_dn_3: 0.3021 (0.3021)  loss_vfl_dn_4: 0.3352 (0.3352)  loss_bbox_dn_4: 0.1256 (0.1256)  loss_giou_dn_4: 0.3019 (0.3019)  loss_vfl_dn_5: 0.3342 (0.3342)  loss_bbox_dn_5: 0.1258 (0.1258)  loss_giou_dn_5: 0.3003 (0.3003)  time: 1.1502  data: 0.7488  max mem: 7790\n",
            "Epoch: [188]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.0777 (12.9734)  loss_vfl: 0.4379 (0.4641)  loss_bbox: 0.0713 (0.0948)  loss_giou: 0.3663 (0.3879)  loss_vfl_aux_0: 0.4943 (0.5108)  loss_bbox_aux_0: 0.0827 (0.1106)  loss_giou_aux_0: 0.4038 (0.4298)  loss_vfl_aux_1: 0.4844 (0.5048)  loss_bbox_aux_1: 0.0754 (0.0987)  loss_giou_aux_1: 0.3726 (0.3975)  loss_vfl_aux_2: 0.4854 (0.5026)  loss_bbox_aux_2: 0.0715 (0.0949)  loss_giou_aux_2: 0.3555 (0.3872)  loss_vfl_aux_3: 0.4691 (0.4889)  loss_bbox_aux_3: 0.0704 (0.0950)  loss_giou_aux_3: 0.3661 (0.3881)  loss_vfl_aux_4: 0.4520 (0.4681)  loss_bbox_aux_4: 0.0710 (0.0934)  loss_giou_aux_4: 0.3659 (0.3869)  loss_vfl_aux_5: 0.5747 (0.5921)  loss_bbox_aux_5: 0.1124 (0.1463)  loss_giou_aux_5: 0.5073 (0.5541)  loss_vfl_dn_0: 0.4276 (0.4319)  loss_bbox_dn_0: 0.1168 (0.1798)  loss_giou_dn_0: 0.5654 (0.5841)  loss_vfl_dn_1: 0.3846 (0.3914)  loss_bbox_dn_1: 0.0851 (0.1333)  loss_giou_dn_1: 0.4127 (0.4373)  loss_vfl_dn_2: 0.3682 (0.3800)  loss_bbox_dn_2: 0.0805 (0.1244)  loss_giou_dn_2: 0.3786 (0.4120)  loss_vfl_dn_3: 0.3699 (0.3765)  loss_bbox_dn_3: 0.0800 (0.1220)  loss_giou_dn_3: 0.3706 (0.4059)  loss_vfl_dn_4: 0.3630 (0.3738)  loss_bbox_dn_4: 0.0794 (0.1213)  loss_giou_dn_4: 0.3731 (0.4046)  loss_vfl_dn_5: 0.3641 (0.3726)  loss_bbox_dn_5: 0.0794 (0.1211)  loss_giou_dn_5: 0.3728 (0.4048)  time: 0.3271  data: 0.0145  max mem: 7790\n",
            "Epoch: [188] Total time: 0:00:11 (0.3556 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.0777 (12.9734)  loss_vfl: 0.4379 (0.4641)  loss_bbox: 0.0713 (0.0948)  loss_giou: 0.3663 (0.3879)  loss_vfl_aux_0: 0.4943 (0.5108)  loss_bbox_aux_0: 0.0827 (0.1106)  loss_giou_aux_0: 0.4038 (0.4298)  loss_vfl_aux_1: 0.4844 (0.5048)  loss_bbox_aux_1: 0.0754 (0.0987)  loss_giou_aux_1: 0.3726 (0.3975)  loss_vfl_aux_2: 0.4854 (0.5026)  loss_bbox_aux_2: 0.0715 (0.0949)  loss_giou_aux_2: 0.3555 (0.3872)  loss_vfl_aux_3: 0.4691 (0.4889)  loss_bbox_aux_3: 0.0704 (0.0950)  loss_giou_aux_3: 0.3661 (0.3881)  loss_vfl_aux_4: 0.4520 (0.4681)  loss_bbox_aux_4: 0.0710 (0.0934)  loss_giou_aux_4: 0.3659 (0.3869)  loss_vfl_aux_5: 0.5747 (0.5921)  loss_bbox_aux_5: 0.1124 (0.1463)  loss_giou_aux_5: 0.5073 (0.5541)  loss_vfl_dn_0: 0.4276 (0.4319)  loss_bbox_dn_0: 0.1168 (0.1798)  loss_giou_dn_0: 0.5654 (0.5841)  loss_vfl_dn_1: 0.3846 (0.3914)  loss_bbox_dn_1: 0.0851 (0.1333)  loss_giou_dn_1: 0.4127 (0.4373)  loss_vfl_dn_2: 0.3682 (0.3800)  loss_bbox_dn_2: 0.0805 (0.1244)  loss_giou_dn_2: 0.3786 (0.4120)  loss_vfl_dn_3: 0.3699 (0.3765)  loss_bbox_dn_3: 0.0800 (0.1220)  loss_giou_dn_3: 0.3706 (0.4059)  loss_vfl_dn_4: 0.3630 (0.3738)  loss_bbox_dn_4: 0.0794 (0.1213)  loss_giou_dn_4: 0.3731 (0.4046)  loss_vfl_dn_5: 0.3641 (0.3726)  loss_bbox_dn_5: 0.0794 (0.1211)  loss_giou_dn_5: 0.3728 (0.4048)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9407  data: 0.6312  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3908  data: 0.1174  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4039 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.659\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [189]  [ 0/33]  eta: 0:00:37  lr: 0.000001  loss: 12.7414 (12.7414)  loss_vfl: 0.4999 (0.4999)  loss_bbox: 0.0703 (0.0703)  loss_giou: 0.3661 (0.3661)  loss_vfl_aux_0: 0.5339 (0.5339)  loss_bbox_aux_0: 0.0872 (0.0872)  loss_giou_aux_0: 0.4223 (0.4223)  loss_vfl_aux_1: 0.5192 (0.5192)  loss_bbox_aux_1: 0.0754 (0.0754)  loss_giou_aux_1: 0.3775 (0.3775)  loss_vfl_aux_2: 0.5068 (0.5068)  loss_bbox_aux_2: 0.0736 (0.0736)  loss_giou_aux_2: 0.3777 (0.3777)  loss_vfl_aux_3: 0.5232 (0.5232)  loss_bbox_aux_3: 0.0700 (0.0700)  loss_giou_aux_3: 0.3667 (0.3667)  loss_vfl_aux_4: 0.4932 (0.4932)  loss_bbox_aux_4: 0.0717 (0.0717)  loss_giou_aux_4: 0.3708 (0.3708)  loss_vfl_aux_5: 0.6105 (0.6105)  loss_bbox_aux_5: 0.1312 (0.1312)  loss_giou_aux_5: 0.5649 (0.5649)  loss_vfl_dn_0: 0.4296 (0.4296)  loss_bbox_dn_0: 0.1337 (0.1337)  loss_giou_dn_0: 0.6053 (0.6053)  loss_vfl_dn_1: 0.3898 (0.3898)  loss_bbox_dn_1: 0.0978 (0.0978)  loss_giou_dn_1: 0.4379 (0.4379)  loss_vfl_dn_2: 0.3780 (0.3780)  loss_bbox_dn_2: 0.0955 (0.0955)  loss_giou_dn_2: 0.4150 (0.4150)  loss_vfl_dn_3: 0.3739 (0.3739)  loss_bbox_dn_3: 0.0957 (0.0957)  loss_giou_dn_3: 0.4120 (0.4120)  loss_vfl_dn_4: 0.3759 (0.3759)  loss_bbox_dn_4: 0.0954 (0.0954)  loss_giou_dn_4: 0.4132 (0.4132)  loss_vfl_dn_5: 0.3726 (0.3726)  loss_bbox_dn_5: 0.0952 (0.0952)  loss_giou_dn_5: 0.4125 (0.4125)  time: 1.1439  data: 0.7112  max mem: 7790\n",
            "Epoch: [189]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.0551 (12.4003)  loss_vfl: 0.4240 (0.4463)  loss_bbox: 0.0651 (0.0787)  loss_giou: 0.3524 (0.3763)  loss_vfl_aux_0: 0.4603 (0.4896)  loss_bbox_aux_0: 0.0748 (0.0926)  loss_giou_aux_0: 0.3988 (0.4174)  loss_vfl_aux_1: 0.4517 (0.4870)  loss_bbox_aux_1: 0.0693 (0.0818)  loss_giou_aux_1: 0.3540 (0.3840)  loss_vfl_aux_2: 0.4496 (0.4807)  loss_bbox_aux_2: 0.0662 (0.0791)  loss_giou_aux_2: 0.3380 (0.3757)  loss_vfl_aux_3: 0.4548 (0.4718)  loss_bbox_aux_3: 0.0652 (0.0781)  loss_giou_aux_3: 0.3510 (0.3750)  loss_vfl_aux_4: 0.4245 (0.4529)  loss_bbox_aux_4: 0.0643 (0.0782)  loss_giou_aux_4: 0.3554 (0.3760)  loss_vfl_aux_5: 0.5562 (0.5700)  loss_bbox_aux_5: 0.1165 (0.1288)  loss_giou_aux_5: 0.5165 (0.5358)  loss_vfl_dn_0: 0.4273 (0.4325)  loss_bbox_dn_0: 0.1281 (0.1426)  loss_giou_dn_0: 0.5738 (0.5751)  loss_vfl_dn_1: 0.3848 (0.3910)  loss_bbox_dn_1: 0.0794 (0.0997)  loss_giou_dn_1: 0.4229 (0.4288)  loss_vfl_dn_2: 0.3714 (0.3802)  loss_bbox_dn_2: 0.0733 (0.0932)  loss_giou_dn_2: 0.3969 (0.4050)  loss_vfl_dn_3: 0.3693 (0.3770)  loss_bbox_dn_3: 0.0732 (0.0920)  loss_giou_dn_3: 0.3930 (0.4001)  loss_vfl_dn_4: 0.3664 (0.3730)  loss_bbox_dn_4: 0.0729 (0.0917)  loss_giou_dn_4: 0.3942 (0.3995)  loss_vfl_dn_5: 0.3657 (0.3722)  loss_bbox_dn_5: 0.0730 (0.0916)  loss_giou_dn_5: 0.3953 (0.3995)  time: 0.3284  data: 0.0159  max mem: 7790\n",
            "Epoch: [189] Total time: 0:00:11 (0.3550 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.0551 (12.4003)  loss_vfl: 0.4240 (0.4463)  loss_bbox: 0.0651 (0.0787)  loss_giou: 0.3524 (0.3763)  loss_vfl_aux_0: 0.4603 (0.4896)  loss_bbox_aux_0: 0.0748 (0.0926)  loss_giou_aux_0: 0.3988 (0.4174)  loss_vfl_aux_1: 0.4517 (0.4870)  loss_bbox_aux_1: 0.0693 (0.0818)  loss_giou_aux_1: 0.3540 (0.3840)  loss_vfl_aux_2: 0.4496 (0.4807)  loss_bbox_aux_2: 0.0662 (0.0791)  loss_giou_aux_2: 0.3380 (0.3757)  loss_vfl_aux_3: 0.4548 (0.4718)  loss_bbox_aux_3: 0.0652 (0.0781)  loss_giou_aux_3: 0.3510 (0.3750)  loss_vfl_aux_4: 0.4245 (0.4529)  loss_bbox_aux_4: 0.0643 (0.0782)  loss_giou_aux_4: 0.3554 (0.3760)  loss_vfl_aux_5: 0.5562 (0.5700)  loss_bbox_aux_5: 0.1165 (0.1288)  loss_giou_aux_5: 0.5165 (0.5358)  loss_vfl_dn_0: 0.4273 (0.4325)  loss_bbox_dn_0: 0.1281 (0.1426)  loss_giou_dn_0: 0.5738 (0.5751)  loss_vfl_dn_1: 0.3848 (0.3910)  loss_bbox_dn_1: 0.0794 (0.0997)  loss_giou_dn_1: 0.4229 (0.4288)  loss_vfl_dn_2: 0.3714 (0.3802)  loss_bbox_dn_2: 0.0733 (0.0932)  loss_giou_dn_2: 0.3969 (0.4050)  loss_vfl_dn_3: 0.3693 (0.3770)  loss_bbox_dn_3: 0.0732 (0.0920)  loss_giou_dn_3: 0.3930 (0.4001)  loss_vfl_dn_4: 0.3664 (0.3730)  loss_bbox_dn_4: 0.0729 (0.0917)  loss_giou_dn_4: 0.3942 (0.3995)  loss_vfl_dn_5: 0.3657 (0.3722)  loss_bbox_dn_5: 0.0730 (0.0916)  loss_giou_dn_5: 0.3953 (0.3995)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8393  data: 0.5272  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3845  data: 0.1102  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3986 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [190]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 12.0952 (12.0952)  loss_vfl: 0.4794 (0.4794)  loss_bbox: 0.0999 (0.0999)  loss_giou: 0.2372 (0.2372)  loss_vfl_aux_0: 0.5110 (0.5110)  loss_bbox_aux_0: 0.1496 (0.1496)  loss_giou_aux_0: 0.3297 (0.3297)  loss_vfl_aux_1: 0.5079 (0.5079)  loss_bbox_aux_1: 0.1246 (0.1246)  loss_giou_aux_1: 0.2756 (0.2756)  loss_vfl_aux_2: 0.4929 (0.4929)  loss_bbox_aux_2: 0.1193 (0.1193)  loss_giou_aux_2: 0.2652 (0.2652)  loss_vfl_aux_3: 0.4857 (0.4857)  loss_bbox_aux_3: 0.1119 (0.1119)  loss_giou_aux_3: 0.2561 (0.2561)  loss_vfl_aux_4: 0.4875 (0.4875)  loss_bbox_aux_4: 0.1027 (0.1027)  loss_giou_aux_4: 0.2415 (0.2415)  loss_vfl_aux_5: 0.6101 (0.6101)  loss_bbox_aux_5: 0.3062 (0.3062)  loss_giou_aux_5: 0.5433 (0.5433)  loss_vfl_dn_0: 0.4395 (0.4395)  loss_bbox_dn_0: 0.2722 (0.2722)  loss_giou_dn_0: 0.4889 (0.4889)  loss_vfl_dn_1: 0.3679 (0.3679)  loss_bbox_dn_1: 0.1828 (0.1828)  loss_giou_dn_1: 0.3370 (0.3370)  loss_vfl_dn_2: 0.3533 (0.3533)  loss_bbox_dn_2: 0.1736 (0.1736)  loss_giou_dn_2: 0.3170 (0.3170)  loss_vfl_dn_3: 0.3410 (0.3410)  loss_bbox_dn_3: 0.1700 (0.1700)  loss_giou_dn_3: 0.3063 (0.3063)  loss_vfl_dn_4: 0.3340 (0.3340)  loss_bbox_dn_4: 0.1693 (0.1693)  loss_giou_dn_4: 0.3043 (0.3043)  loss_vfl_dn_5: 0.3319 (0.3319)  loss_bbox_dn_5: 0.1665 (0.1665)  loss_giou_dn_5: 0.3023 (0.3023)  time: 0.9806  data: 0.5930  max mem: 7790\n",
            "Epoch: [190]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.1509 (12.1781)  loss_vfl: 0.4385 (0.4500)  loss_bbox: 0.0807 (0.0824)  loss_giou: 0.3312 (0.3514)  loss_vfl_aux_0: 0.4875 (0.4970)  loss_bbox_aux_0: 0.0888 (0.0978)  loss_giou_aux_0: 0.3934 (0.3925)  loss_vfl_aux_1: 0.4645 (0.4826)  loss_bbox_aux_1: 0.0803 (0.0856)  loss_giou_aux_1: 0.3353 (0.3591)  loss_vfl_aux_2: 0.4488 (0.4730)  loss_bbox_aux_2: 0.0835 (0.0834)  loss_giou_aux_2: 0.3268 (0.3548)  loss_vfl_aux_3: 0.4525 (0.4718)  loss_bbox_aux_3: 0.0826 (0.0829)  loss_giou_aux_3: 0.3392 (0.3523)  loss_vfl_aux_4: 0.4395 (0.4532)  loss_bbox_aux_4: 0.0810 (0.0826)  loss_giou_aux_4: 0.3305 (0.3526)  loss_vfl_aux_5: 0.5439 (0.5720)  loss_bbox_aux_5: 0.1330 (0.1525)  loss_giou_aux_5: 0.5549 (0.5394)  loss_vfl_dn_0: 0.4353 (0.4378)  loss_bbox_dn_0: 0.1317 (0.1578)  loss_giou_dn_0: 0.5633 (0.5570)  loss_vfl_dn_1: 0.3901 (0.3900)  loss_bbox_dn_1: 0.0857 (0.1084)  loss_giou_dn_1: 0.3940 (0.4011)  loss_vfl_dn_2: 0.3739 (0.3777)  loss_bbox_dn_2: 0.0789 (0.0999)  loss_giou_dn_2: 0.3597 (0.3745)  loss_vfl_dn_3: 0.3671 (0.3723)  loss_bbox_dn_3: 0.0778 (0.0975)  loss_giou_dn_3: 0.3507 (0.3682)  loss_vfl_dn_4: 0.3661 (0.3704)  loss_bbox_dn_4: 0.0776 (0.0970)  loss_giou_dn_4: 0.3480 (0.3669)  loss_vfl_dn_5: 0.3676 (0.3692)  loss_bbox_dn_5: 0.0779 (0.0967)  loss_giou_dn_5: 0.3494 (0.3669)  time: 0.3236  data: 0.0139  max mem: 7790\n",
            "Epoch: [190] Total time: 0:00:11 (0.3494 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.1509 (12.1781)  loss_vfl: 0.4385 (0.4500)  loss_bbox: 0.0807 (0.0824)  loss_giou: 0.3312 (0.3514)  loss_vfl_aux_0: 0.4875 (0.4970)  loss_bbox_aux_0: 0.0888 (0.0978)  loss_giou_aux_0: 0.3934 (0.3925)  loss_vfl_aux_1: 0.4645 (0.4826)  loss_bbox_aux_1: 0.0803 (0.0856)  loss_giou_aux_1: 0.3353 (0.3591)  loss_vfl_aux_2: 0.4488 (0.4730)  loss_bbox_aux_2: 0.0835 (0.0834)  loss_giou_aux_2: 0.3268 (0.3548)  loss_vfl_aux_3: 0.4525 (0.4718)  loss_bbox_aux_3: 0.0826 (0.0829)  loss_giou_aux_3: 0.3392 (0.3523)  loss_vfl_aux_4: 0.4395 (0.4532)  loss_bbox_aux_4: 0.0810 (0.0826)  loss_giou_aux_4: 0.3305 (0.3526)  loss_vfl_aux_5: 0.5439 (0.5720)  loss_bbox_aux_5: 0.1330 (0.1525)  loss_giou_aux_5: 0.5549 (0.5394)  loss_vfl_dn_0: 0.4353 (0.4378)  loss_bbox_dn_0: 0.1317 (0.1578)  loss_giou_dn_0: 0.5633 (0.5570)  loss_vfl_dn_1: 0.3901 (0.3900)  loss_bbox_dn_1: 0.0857 (0.1084)  loss_giou_dn_1: 0.3940 (0.4011)  loss_vfl_dn_2: 0.3739 (0.3777)  loss_bbox_dn_2: 0.0789 (0.0999)  loss_giou_dn_2: 0.3597 (0.3745)  loss_vfl_dn_3: 0.3671 (0.3723)  loss_bbox_dn_3: 0.0778 (0.0975)  loss_giou_dn_3: 0.3507 (0.3682)  loss_vfl_dn_4: 0.3661 (0.3704)  loss_bbox_dn_4: 0.0776 (0.0970)  loss_giou_dn_4: 0.3480 (0.3669)  loss_vfl_dn_5: 0.3676 (0.3692)  loss_bbox_dn_5: 0.0779 (0.0967)  loss_giou_dn_5: 0.3494 (0.3669)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9119  data: 0.5901  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4501  data: 0.1109  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4646 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.659\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [191]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 13.9507 (13.9507)  loss_vfl: 0.5092 (0.5092)  loss_bbox: 0.0611 (0.0611)  loss_giou: 0.5203 (0.5203)  loss_vfl_aux_0: 0.5480 (0.5480)  loss_bbox_aux_0: 0.0652 (0.0652)  loss_giou_aux_0: 0.5270 (0.5270)  loss_vfl_aux_1: 0.5328 (0.5328)  loss_bbox_aux_1: 0.0622 (0.0622)  loss_giou_aux_1: 0.5036 (0.5036)  loss_vfl_aux_2: 0.5257 (0.5257)  loss_bbox_aux_2: 0.0605 (0.0605)  loss_giou_aux_2: 0.5037 (0.5037)  loss_vfl_aux_3: 0.5012 (0.5012)  loss_bbox_aux_3: 0.0615 (0.0615)  loss_giou_aux_3: 0.5132 (0.5132)  loss_vfl_aux_4: 0.5274 (0.5274)  loss_bbox_aux_4: 0.0613 (0.0613)  loss_giou_aux_4: 0.5100 (0.5100)  loss_vfl_aux_5: 0.5943 (0.5943)  loss_bbox_aux_5: 0.0765 (0.0765)  loss_giou_aux_5: 0.5750 (0.5750)  loss_vfl_dn_0: 0.4268 (0.4268)  loss_bbox_dn_0: 0.0868 (0.0868)  loss_giou_dn_0: 0.6821 (0.6821)  loss_vfl_dn_1: 0.3993 (0.3993)  loss_bbox_dn_1: 0.0634 (0.0634)  loss_giou_dn_1: 0.5422 (0.5422)  loss_vfl_dn_2: 0.3921 (0.3921)  loss_bbox_dn_2: 0.0611 (0.0611)  loss_giou_dn_2: 0.5322 (0.5322)  loss_vfl_dn_3: 0.3882 (0.3882)  loss_bbox_dn_3: 0.0601 (0.0601)  loss_giou_dn_3: 0.5230 (0.5230)  loss_vfl_dn_4: 0.3954 (0.3954)  loss_bbox_dn_4: 0.0605 (0.0605)  loss_giou_dn_4: 0.5217 (0.5217)  loss_vfl_dn_5: 0.3937 (0.3937)  loss_bbox_dn_5: 0.0606 (0.0606)  loss_giou_dn_5: 0.5216 (0.5216)  time: 1.0026  data: 0.6106  max mem: 7790\n",
            "Epoch: [191]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 11.6097 (12.1418)  loss_vfl: 0.4251 (0.4351)  loss_bbox: 0.0724 (0.0798)  loss_giou: 0.3375 (0.3711)  loss_vfl_aux_0: 0.4525 (0.4859)  loss_bbox_aux_0: 0.0878 (0.0948)  loss_giou_aux_0: 0.3768 (0.4097)  loss_vfl_aux_1: 0.4439 (0.4668)  loss_bbox_aux_1: 0.0799 (0.0835)  loss_giou_aux_1: 0.3352 (0.3792)  loss_vfl_aux_2: 0.4343 (0.4560)  loss_bbox_aux_2: 0.0740 (0.0817)  loss_giou_aux_2: 0.3268 (0.3722)  loss_vfl_aux_3: 0.4246 (0.4497)  loss_bbox_aux_3: 0.0744 (0.0808)  loss_giou_aux_3: 0.3258 (0.3699)  loss_vfl_aux_4: 0.4231 (0.4364)  loss_bbox_aux_4: 0.0677 (0.0800)  loss_giou_aux_4: 0.3352 (0.3693)  loss_vfl_aux_5: 0.5528 (0.5644)  loss_bbox_aux_5: 0.1269 (0.1332)  loss_giou_aux_5: 0.5163 (0.5364)  loss_vfl_dn_0: 0.4306 (0.4315)  loss_bbox_dn_0: 0.1301 (0.1464)  loss_giou_dn_0: 0.5531 (0.5628)  loss_vfl_dn_1: 0.3734 (0.3802)  loss_bbox_dn_1: 0.0925 (0.1039)  loss_giou_dn_1: 0.3969 (0.4120)  loss_vfl_dn_2: 0.3680 (0.3681)  loss_bbox_dn_2: 0.0878 (0.0969)  loss_giou_dn_2: 0.3725 (0.3881)  loss_vfl_dn_3: 0.3648 (0.3634)  loss_bbox_dn_3: 0.0873 (0.0949)  loss_giou_dn_3: 0.3663 (0.3832)  loss_vfl_dn_4: 0.3577 (0.3612)  loss_bbox_dn_4: 0.0861 (0.0946)  loss_giou_dn_4: 0.3627 (0.3820)  loss_vfl_dn_5: 0.3593 (0.3606)  loss_bbox_dn_5: 0.0866 (0.0945)  loss_giou_dn_5: 0.3603 (0.3818)  time: 0.3323  data: 0.0144  max mem: 7790\n",
            "Epoch: [191] Total time: 0:00:11 (0.3583 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 11.6097 (12.1418)  loss_vfl: 0.4251 (0.4351)  loss_bbox: 0.0724 (0.0798)  loss_giou: 0.3375 (0.3711)  loss_vfl_aux_0: 0.4525 (0.4859)  loss_bbox_aux_0: 0.0878 (0.0948)  loss_giou_aux_0: 0.3768 (0.4097)  loss_vfl_aux_1: 0.4439 (0.4668)  loss_bbox_aux_1: 0.0799 (0.0835)  loss_giou_aux_1: 0.3352 (0.3792)  loss_vfl_aux_2: 0.4343 (0.4560)  loss_bbox_aux_2: 0.0740 (0.0817)  loss_giou_aux_2: 0.3268 (0.3722)  loss_vfl_aux_3: 0.4246 (0.4497)  loss_bbox_aux_3: 0.0744 (0.0808)  loss_giou_aux_3: 0.3258 (0.3699)  loss_vfl_aux_4: 0.4231 (0.4364)  loss_bbox_aux_4: 0.0677 (0.0800)  loss_giou_aux_4: 0.3352 (0.3693)  loss_vfl_aux_5: 0.5528 (0.5644)  loss_bbox_aux_5: 0.1269 (0.1332)  loss_giou_aux_5: 0.5163 (0.5364)  loss_vfl_dn_0: 0.4306 (0.4315)  loss_bbox_dn_0: 0.1301 (0.1464)  loss_giou_dn_0: 0.5531 (0.5628)  loss_vfl_dn_1: 0.3734 (0.3802)  loss_bbox_dn_1: 0.0925 (0.1039)  loss_giou_dn_1: 0.3969 (0.4120)  loss_vfl_dn_2: 0.3680 (0.3681)  loss_bbox_dn_2: 0.0878 (0.0969)  loss_giou_dn_2: 0.3725 (0.3881)  loss_vfl_dn_3: 0.3648 (0.3634)  loss_bbox_dn_3: 0.0873 (0.0949)  loss_giou_dn_3: 0.3663 (0.3832)  loss_vfl_dn_4: 0.3577 (0.3612)  loss_bbox_dn_4: 0.0861 (0.0946)  loss_giou_dn_4: 0.3627 (0.3820)  loss_vfl_dn_5: 0.3593 (0.3606)  loss_bbox_dn_5: 0.0866 (0.0945)  loss_giou_dn_5: 0.3603 (0.3818)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8368  data: 0.5204  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3847  data: 0.1094  max mem: 7790\n",
            "Test: Total time: 0:00:04 (0.6921 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.669\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [192]  [ 0/33]  eta: 0:00:46  lr: 0.000001  loss: 11.7118 (11.7118)  loss_vfl: 0.4496 (0.4496)  loss_bbox: 0.0567 (0.0567)  loss_giou: 0.3432 (0.3432)  loss_vfl_aux_0: 0.4721 (0.4721)  loss_bbox_aux_0: 0.0753 (0.0753)  loss_giou_aux_0: 0.4103 (0.4103)  loss_vfl_aux_1: 0.4598 (0.4598)  loss_bbox_aux_1: 0.0618 (0.0618)  loss_giou_aux_1: 0.3646 (0.3646)  loss_vfl_aux_2: 0.4573 (0.4573)  loss_bbox_aux_2: 0.0583 (0.0583)  loss_giou_aux_2: 0.3511 (0.3511)  loss_vfl_aux_3: 0.4475 (0.4475)  loss_bbox_aux_3: 0.0571 (0.0571)  loss_giou_aux_3: 0.3469 (0.3469)  loss_vfl_aux_4: 0.4496 (0.4496)  loss_bbox_aux_4: 0.0560 (0.0560)  loss_giou_aux_4: 0.3434 (0.3434)  loss_vfl_aux_5: 0.5332 (0.5332)  loss_bbox_aux_5: 0.1086 (0.1086)  loss_giou_aux_5: 0.5554 (0.5554)  loss_vfl_dn_0: 0.4196 (0.4196)  loss_bbox_dn_0: 0.1278 (0.1278)  loss_giou_dn_0: 0.5674 (0.5674)  loss_vfl_dn_1: 0.3645 (0.3645)  loss_bbox_dn_1: 0.0811 (0.0811)  loss_giou_dn_1: 0.4288 (0.4288)  loss_vfl_dn_2: 0.3519 (0.3519)  loss_bbox_dn_2: 0.0741 (0.0741)  loss_giou_dn_2: 0.4063 (0.4063)  loss_vfl_dn_3: 0.3498 (0.3498)  loss_bbox_dn_3: 0.0718 (0.0718)  loss_giou_dn_3: 0.3973 (0.3973)  loss_vfl_dn_4: 0.3447 (0.3447)  loss_bbox_dn_4: 0.0692 (0.0692)  loss_giou_dn_4: 0.3929 (0.3929)  loss_vfl_dn_5: 0.3464 (0.3464)  loss_bbox_dn_5: 0.0690 (0.0690)  loss_giou_dn_5: 0.3912 (0.3912)  time: 1.4020  data: 0.7080  max mem: 7790\n",
            "Epoch: [192]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.7428 (12.6436)  loss_vfl: 0.4369 (0.4446)  loss_bbox: 0.0828 (0.0863)  loss_giou: 0.3956 (0.3932)  loss_vfl_aux_0: 0.4692 (0.4893)  loss_bbox_aux_0: 0.0840 (0.0983)  loss_giou_aux_0: 0.4195 (0.4366)  loss_vfl_aux_1: 0.4777 (0.4859)  loss_bbox_aux_1: 0.0787 (0.0870)  loss_giou_aux_1: 0.3890 (0.4011)  loss_vfl_aux_2: 0.4688 (0.4748)  loss_bbox_aux_2: 0.0818 (0.0866)  loss_giou_aux_2: 0.3927 (0.3951)  loss_vfl_aux_3: 0.4561 (0.4665)  loss_bbox_aux_3: 0.0830 (0.0858)  loss_giou_aux_3: 0.3901 (0.3923)  loss_vfl_aux_4: 0.4467 (0.4498)  loss_bbox_aux_4: 0.0827 (0.0860)  loss_giou_aux_4: 0.3866 (0.3921)  loss_vfl_aux_5: 0.5411 (0.5540)  loss_bbox_aux_5: 0.1262 (0.1348)  loss_giou_aux_5: 0.5876 (0.5588)  loss_vfl_dn_0: 0.4292 (0.4350)  loss_bbox_dn_0: 0.1408 (0.1473)  loss_giou_dn_0: 0.5902 (0.5808)  loss_vfl_dn_1: 0.3893 (0.3903)  loss_bbox_dn_1: 0.0949 (0.1054)  loss_giou_dn_1: 0.4401 (0.4414)  loss_vfl_dn_2: 0.3784 (0.3795)  loss_bbox_dn_2: 0.0877 (0.0978)  loss_giou_dn_2: 0.4061 (0.4193)  loss_vfl_dn_3: 0.3730 (0.3759)  loss_bbox_dn_3: 0.0868 (0.0961)  loss_giou_dn_3: 0.4028 (0.4132)  loss_vfl_dn_4: 0.3703 (0.3731)  loss_bbox_dn_4: 0.0871 (0.0960)  loss_giou_dn_4: 0.4013 (0.4122)  loss_vfl_dn_5: 0.3723 (0.3727)  loss_bbox_dn_5: 0.0872 (0.0960)  loss_giou_dn_5: 0.4012 (0.4127)  time: 0.3220  data: 0.0144  max mem: 7790\n",
            "Epoch: [192] Total time: 0:00:11 (0.3582 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.7428 (12.6436)  loss_vfl: 0.4369 (0.4446)  loss_bbox: 0.0828 (0.0863)  loss_giou: 0.3956 (0.3932)  loss_vfl_aux_0: 0.4692 (0.4893)  loss_bbox_aux_0: 0.0840 (0.0983)  loss_giou_aux_0: 0.4195 (0.4366)  loss_vfl_aux_1: 0.4777 (0.4859)  loss_bbox_aux_1: 0.0787 (0.0870)  loss_giou_aux_1: 0.3890 (0.4011)  loss_vfl_aux_2: 0.4688 (0.4748)  loss_bbox_aux_2: 0.0818 (0.0866)  loss_giou_aux_2: 0.3927 (0.3951)  loss_vfl_aux_3: 0.4561 (0.4665)  loss_bbox_aux_3: 0.0830 (0.0858)  loss_giou_aux_3: 0.3901 (0.3923)  loss_vfl_aux_4: 0.4467 (0.4498)  loss_bbox_aux_4: 0.0827 (0.0860)  loss_giou_aux_4: 0.3866 (0.3921)  loss_vfl_aux_5: 0.5411 (0.5540)  loss_bbox_aux_5: 0.1262 (0.1348)  loss_giou_aux_5: 0.5876 (0.5588)  loss_vfl_dn_0: 0.4292 (0.4350)  loss_bbox_dn_0: 0.1408 (0.1473)  loss_giou_dn_0: 0.5902 (0.5808)  loss_vfl_dn_1: 0.3893 (0.3903)  loss_bbox_dn_1: 0.0949 (0.1054)  loss_giou_dn_1: 0.4401 (0.4414)  loss_vfl_dn_2: 0.3784 (0.3795)  loss_bbox_dn_2: 0.0877 (0.0978)  loss_giou_dn_2: 0.4061 (0.4193)  loss_vfl_dn_3: 0.3730 (0.3759)  loss_bbox_dn_3: 0.0868 (0.0961)  loss_giou_dn_3: 0.4028 (0.4132)  loss_vfl_dn_4: 0.3703 (0.3731)  loss_bbox_dn_4: 0.0871 (0.0960)  loss_giou_dn_4: 0.4013 (0.4122)  loss_vfl_dn_5: 0.3723 (0.3727)  loss_bbox_dn_5: 0.0872 (0.0960)  loss_giou_dn_5: 0.4012 (0.4127)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8895  data: 0.5784  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3883  data: 0.1148  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4010 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [193]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 12.2022 (12.2022)  loss_vfl: 0.4026 (0.4026)  loss_bbox: 0.0776 (0.0776)  loss_giou: 0.3803 (0.3803)  loss_vfl_aux_0: 0.4634 (0.4634)  loss_bbox_aux_0: 0.0779 (0.0779)  loss_giou_aux_0: 0.4000 (0.4000)  loss_vfl_aux_1: 0.4618 (0.4618)  loss_bbox_aux_1: 0.0719 (0.0719)  loss_giou_aux_1: 0.3805 (0.3805)  loss_vfl_aux_2: 0.4407 (0.4407)  loss_bbox_aux_2: 0.0756 (0.0756)  loss_giou_aux_2: 0.3805 (0.3805)  loss_vfl_aux_3: 0.4574 (0.4574)  loss_bbox_aux_3: 0.0755 (0.0755)  loss_giou_aux_3: 0.3746 (0.3746)  loss_vfl_aux_4: 0.4180 (0.4180)  loss_bbox_aux_4: 0.0743 (0.0743)  loss_giou_aux_4: 0.3738 (0.3738)  loss_vfl_aux_5: 0.5415 (0.5415)  loss_bbox_aux_5: 0.1072 (0.1072)  loss_giou_aux_5: 0.5152 (0.5152)  loss_vfl_dn_0: 0.4422 (0.4422)  loss_bbox_dn_0: 0.1206 (0.1206)  loss_giou_dn_0: 0.5779 (0.5779)  loss_vfl_dn_1: 0.4107 (0.4107)  loss_bbox_dn_1: 0.0875 (0.0875)  loss_giou_dn_1: 0.4328 (0.4328)  loss_vfl_dn_2: 0.4015 (0.4015)  loss_bbox_dn_2: 0.0847 (0.0847)  loss_giou_dn_2: 0.4166 (0.4166)  loss_vfl_dn_3: 0.4016 (0.4016)  loss_bbox_dn_3: 0.0860 (0.0860)  loss_giou_dn_3: 0.4149 (0.4149)  loss_vfl_dn_4: 0.3887 (0.3887)  loss_bbox_dn_4: 0.0857 (0.0857)  loss_giou_dn_4: 0.4126 (0.4126)  loss_vfl_dn_5: 0.3894 (0.3894)  loss_bbox_dn_5: 0.0857 (0.0857)  loss_giou_dn_5: 0.4129 (0.4129)  time: 1.0724  data: 0.6495  max mem: 7790\n",
            "Epoch: [193]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.0600 (12.2969)  loss_vfl: 0.4043 (0.4306)  loss_bbox: 0.0852 (0.0864)  loss_giou: 0.3441 (0.3755)  loss_vfl_aux_0: 0.4730 (0.4796)  loss_bbox_aux_0: 0.0989 (0.1020)  loss_giou_aux_0: 0.3838 (0.4157)  loss_vfl_aux_1: 0.4253 (0.4602)  loss_bbox_aux_1: 0.0890 (0.0902)  loss_giou_aux_1: 0.3653 (0.3846)  loss_vfl_aux_2: 0.4330 (0.4511)  loss_bbox_aux_2: 0.0852 (0.0871)  loss_giou_aux_2: 0.3245 (0.3759)  loss_vfl_aux_3: 0.4182 (0.4445)  loss_bbox_aux_3: 0.0859 (0.0859)  loss_giou_aux_3: 0.3410 (0.3751)  loss_vfl_aux_4: 0.4093 (0.4315)  loss_bbox_aux_4: 0.0857 (0.0867)  loss_giou_aux_4: 0.3400 (0.3757)  loss_vfl_aux_5: 0.5395 (0.5664)  loss_bbox_aux_5: 0.1443 (0.1421)  loss_giou_aux_5: 0.5236 (0.5510)  loss_vfl_dn_0: 0.4352 (0.4342)  loss_bbox_dn_0: 0.1478 (0.1500)  loss_giou_dn_0: 0.5418 (0.5569)  loss_vfl_dn_1: 0.3812 (0.3876)  loss_bbox_dn_1: 0.1047 (0.1062)  loss_giou_dn_1: 0.3960 (0.4158)  loss_vfl_dn_2: 0.3719 (0.3761)  loss_bbox_dn_2: 0.0971 (0.1008)  loss_giou_dn_2: 0.3665 (0.3931)  loss_vfl_dn_3: 0.3713 (0.3729)  loss_bbox_dn_3: 0.0965 (0.1003)  loss_giou_dn_3: 0.3717 (0.3890)  loss_vfl_dn_4: 0.3675 (0.3697)  loss_bbox_dn_4: 0.0961 (0.1003)  loss_giou_dn_4: 0.3730 (0.3881)  loss_vfl_dn_5: 0.3680 (0.3698)  loss_bbox_dn_5: 0.0961 (0.1003)  loss_giou_dn_5: 0.3741 (0.3881)  time: 0.3405  data: 0.0150  max mem: 7790\n",
            "Epoch: [193] Total time: 0:00:12 (0.3638 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.0600 (12.2969)  loss_vfl: 0.4043 (0.4306)  loss_bbox: 0.0852 (0.0864)  loss_giou: 0.3441 (0.3755)  loss_vfl_aux_0: 0.4730 (0.4796)  loss_bbox_aux_0: 0.0989 (0.1020)  loss_giou_aux_0: 0.3838 (0.4157)  loss_vfl_aux_1: 0.4253 (0.4602)  loss_bbox_aux_1: 0.0890 (0.0902)  loss_giou_aux_1: 0.3653 (0.3846)  loss_vfl_aux_2: 0.4330 (0.4511)  loss_bbox_aux_2: 0.0852 (0.0871)  loss_giou_aux_2: 0.3245 (0.3759)  loss_vfl_aux_3: 0.4182 (0.4445)  loss_bbox_aux_3: 0.0859 (0.0859)  loss_giou_aux_3: 0.3410 (0.3751)  loss_vfl_aux_4: 0.4093 (0.4315)  loss_bbox_aux_4: 0.0857 (0.0867)  loss_giou_aux_4: 0.3400 (0.3757)  loss_vfl_aux_5: 0.5395 (0.5664)  loss_bbox_aux_5: 0.1443 (0.1421)  loss_giou_aux_5: 0.5236 (0.5510)  loss_vfl_dn_0: 0.4352 (0.4342)  loss_bbox_dn_0: 0.1478 (0.1500)  loss_giou_dn_0: 0.5418 (0.5569)  loss_vfl_dn_1: 0.3812 (0.3876)  loss_bbox_dn_1: 0.1047 (0.1062)  loss_giou_dn_1: 0.3960 (0.4158)  loss_vfl_dn_2: 0.3719 (0.3761)  loss_bbox_dn_2: 0.0971 (0.1008)  loss_giou_dn_2: 0.3665 (0.3931)  loss_vfl_dn_3: 0.3713 (0.3729)  loss_bbox_dn_3: 0.0965 (0.1003)  loss_giou_dn_3: 0.3717 (0.3890)  loss_vfl_dn_4: 0.3675 (0.3697)  loss_bbox_dn_4: 0.0961 (0.1003)  loss_giou_dn_4: 0.3730 (0.3881)  loss_vfl_dn_5: 0.3680 (0.3698)  loss_bbox_dn_5: 0.0961 (0.1003)  loss_giou_dn_5: 0.3741 (0.3881)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9043  data: 0.5800  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3939  data: 0.1162  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4067 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [194]  [ 0/33]  eta: 0:00:34  lr: 0.000001  loss: 15.2333 (15.2333)  loss_vfl: 0.3636 (0.3636)  loss_bbox: 0.0773 (0.0773)  loss_giou: 0.6861 (0.6861)  loss_vfl_aux_0: 0.3853 (0.3853)  loss_bbox_aux_0: 0.1019 (0.1019)  loss_giou_aux_0: 0.7930 (0.7930)  loss_vfl_aux_1: 0.3670 (0.3670)  loss_bbox_aux_1: 0.0883 (0.0883)  loss_giou_aux_1: 0.7437 (0.7437)  loss_vfl_aux_2: 0.3656 (0.3656)  loss_bbox_aux_2: 0.0858 (0.0858)  loss_giou_aux_2: 0.7309 (0.7309)  loss_vfl_aux_3: 0.3720 (0.3720)  loss_bbox_aux_3: 0.0852 (0.0852)  loss_giou_aux_3: 0.7075 (0.7075)  loss_vfl_aux_4: 0.3626 (0.3626)  loss_bbox_aux_4: 0.0777 (0.0777)  loss_giou_aux_4: 0.6894 (0.6894)  loss_vfl_aux_5: 0.4434 (0.4434)  loss_bbox_aux_5: 0.1229 (0.1229)  loss_giou_aux_5: 0.8315 (0.8315)  loss_vfl_dn_0: 0.4052 (0.4052)  loss_bbox_dn_0: 0.1153 (0.1153)  loss_giou_dn_0: 0.7669 (0.7669)  loss_vfl_dn_1: 0.3769 (0.3769)  loss_bbox_dn_1: 0.0835 (0.0835)  loss_giou_dn_1: 0.6644 (0.6644)  loss_vfl_dn_2: 0.3679 (0.3679)  loss_bbox_dn_2: 0.0770 (0.0770)  loss_giou_dn_2: 0.6466 (0.6466)  loss_vfl_dn_3: 0.3640 (0.3640)  loss_bbox_dn_3: 0.0764 (0.0764)  loss_giou_dn_3: 0.6442 (0.6442)  loss_vfl_dn_4: 0.3568 (0.3568)  loss_bbox_dn_4: 0.0764 (0.0764)  loss_giou_dn_4: 0.6464 (0.6464)  loss_vfl_dn_5: 0.3609 (0.3609)  loss_bbox_dn_5: 0.0763 (0.0763)  loss_giou_dn_5: 0.6473 (0.6473)  time: 1.0312  data: 0.6549  max mem: 7790\n",
            "Epoch: [194]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.4317 (12.5446)  loss_vfl: 0.4309 (0.4433)  loss_bbox: 0.0854 (0.0805)  loss_giou: 0.3751 (0.3868)  loss_vfl_aux_0: 0.5064 (0.4987)  loss_bbox_aux_0: 0.0936 (0.0939)  loss_giou_aux_0: 0.3976 (0.4343)  loss_vfl_aux_1: 0.5010 (0.4893)  loss_bbox_aux_1: 0.0873 (0.0833)  loss_giou_aux_1: 0.3817 (0.3969)  loss_vfl_aux_2: 0.4858 (0.4792)  loss_bbox_aux_2: 0.0830 (0.0826)  loss_giou_aux_2: 0.3745 (0.3904)  loss_vfl_aux_3: 0.4686 (0.4678)  loss_bbox_aux_3: 0.0855 (0.0816)  loss_giou_aux_3: 0.3744 (0.3886)  loss_vfl_aux_4: 0.4438 (0.4497)  loss_bbox_aux_4: 0.0838 (0.0802)  loss_giou_aux_4: 0.3733 (0.3865)  loss_vfl_aux_5: 0.5838 (0.5723)  loss_bbox_aux_5: 0.1298 (0.1374)  loss_giou_aux_5: 0.5306 (0.5565)  loss_vfl_dn_0: 0.4358 (0.4332)  loss_bbox_dn_0: 0.1576 (0.1472)  loss_giou_dn_0: 0.5607 (0.5704)  loss_vfl_dn_1: 0.3924 (0.3895)  loss_bbox_dn_1: 0.1102 (0.1045)  loss_giou_dn_1: 0.4265 (0.4279)  loss_vfl_dn_2: 0.3828 (0.3802)  loss_bbox_dn_2: 0.1029 (0.0975)  loss_giou_dn_2: 0.4018 (0.4063)  loss_vfl_dn_3: 0.3831 (0.3769)  loss_bbox_dn_3: 0.0982 (0.0956)  loss_giou_dn_3: 0.3966 (0.4001)  loss_vfl_dn_4: 0.3783 (0.3734)  loss_bbox_dn_4: 0.0957 (0.0952)  loss_giou_dn_4: 0.3978 (0.3998)  loss_vfl_dn_5: 0.3792 (0.3727)  loss_bbox_dn_5: 0.0957 (0.0950)  loss_giou_dn_5: 0.3969 (0.3996)  time: 0.3192  data: 0.0146  max mem: 7790\n",
            "Epoch: [194] Total time: 0:00:11 (0.3465 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.4317 (12.5446)  loss_vfl: 0.4309 (0.4433)  loss_bbox: 0.0854 (0.0805)  loss_giou: 0.3751 (0.3868)  loss_vfl_aux_0: 0.5064 (0.4987)  loss_bbox_aux_0: 0.0936 (0.0939)  loss_giou_aux_0: 0.3976 (0.4343)  loss_vfl_aux_1: 0.5010 (0.4893)  loss_bbox_aux_1: 0.0873 (0.0833)  loss_giou_aux_1: 0.3817 (0.3969)  loss_vfl_aux_2: 0.4858 (0.4792)  loss_bbox_aux_2: 0.0830 (0.0826)  loss_giou_aux_2: 0.3745 (0.3904)  loss_vfl_aux_3: 0.4686 (0.4678)  loss_bbox_aux_3: 0.0855 (0.0816)  loss_giou_aux_3: 0.3744 (0.3886)  loss_vfl_aux_4: 0.4438 (0.4497)  loss_bbox_aux_4: 0.0838 (0.0802)  loss_giou_aux_4: 0.3733 (0.3865)  loss_vfl_aux_5: 0.5838 (0.5723)  loss_bbox_aux_5: 0.1298 (0.1374)  loss_giou_aux_5: 0.5306 (0.5565)  loss_vfl_dn_0: 0.4358 (0.4332)  loss_bbox_dn_0: 0.1576 (0.1472)  loss_giou_dn_0: 0.5607 (0.5704)  loss_vfl_dn_1: 0.3924 (0.3895)  loss_bbox_dn_1: 0.1102 (0.1045)  loss_giou_dn_1: 0.4265 (0.4279)  loss_vfl_dn_2: 0.3828 (0.3802)  loss_bbox_dn_2: 0.1029 (0.0975)  loss_giou_dn_2: 0.4018 (0.4063)  loss_vfl_dn_3: 0.3831 (0.3769)  loss_bbox_dn_3: 0.0982 (0.0956)  loss_giou_dn_3: 0.3966 (0.4001)  loss_vfl_dn_4: 0.3783 (0.3734)  loss_bbox_dn_4: 0.0957 (0.0952)  loss_giou_dn_4: 0.3978 (0.3998)  loss_vfl_dn_5: 0.3792 (0.3727)  loss_bbox_dn_5: 0.0957 (0.0950)  loss_giou_dn_5: 0.3969 (0.3996)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8402  data: 0.5284  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3800  data: 0.1091  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3932 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.675\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.314\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762\n",
            "best_stat:  {'epoch': 158, 'coco_eval_bbox': 0.355712335907113}\n",
            "Epoch: [195]  [ 0/33]  eta: 0:00:39  lr: 0.000001  loss: 13.0456 (13.0456)  loss_vfl: 0.4338 (0.4338)  loss_bbox: 0.0516 (0.0516)  loss_giou: 0.5253 (0.5253)  loss_vfl_aux_0: 0.4823 (0.4823)  loss_bbox_aux_0: 0.0548 (0.0548)  loss_giou_aux_0: 0.5060 (0.5060)  loss_vfl_aux_1: 0.4728 (0.4728)  loss_bbox_aux_1: 0.0526 (0.0526)  loss_giou_aux_1: 0.4979 (0.4979)  loss_vfl_aux_2: 0.4587 (0.4587)  loss_bbox_aux_2: 0.0520 (0.0520)  loss_giou_aux_2: 0.5160 (0.5160)  loss_vfl_aux_3: 0.4377 (0.4377)  loss_bbox_aux_3: 0.0520 (0.0520)  loss_giou_aux_3: 0.5284 (0.5284)  loss_vfl_aux_4: 0.4323 (0.4323)  loss_bbox_aux_4: 0.0513 (0.0513)  loss_giou_aux_4: 0.5259 (0.5259)  loss_vfl_aux_5: 0.5642 (0.5642)  loss_bbox_aux_5: 0.0709 (0.0709)  loss_giou_aux_5: 0.6455 (0.6455)  loss_vfl_dn_0: 0.4343 (0.4343)  loss_bbox_dn_0: 0.0715 (0.0715)  loss_giou_dn_0: 0.6234 (0.6234)  loss_vfl_dn_1: 0.4026 (0.4026)  loss_bbox_dn_1: 0.0510 (0.0510)  loss_giou_dn_1: 0.4767 (0.4767)  loss_vfl_dn_2: 0.3957 (0.3957)  loss_bbox_dn_2: 0.0482 (0.0482)  loss_giou_dn_2: 0.4568 (0.4568)  loss_vfl_dn_3: 0.3969 (0.3969)  loss_bbox_dn_3: 0.0474 (0.0474)  loss_giou_dn_3: 0.4519 (0.4519)  loss_vfl_dn_4: 0.3918 (0.3918)  loss_bbox_dn_4: 0.0472 (0.0472)  loss_giou_dn_4: 0.4497 (0.4497)  loss_vfl_dn_5: 0.3914 (0.3914)  loss_bbox_dn_5: 0.0473 (0.0473)  loss_giou_dn_5: 0.4499 (0.4499)  time: 1.2024  data: 0.7995  max mem: 7790\n",
            "Epoch: [195]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 11.9561 (12.6695)  loss_vfl: 0.4395 (0.4693)  loss_bbox: 0.0721 (0.0899)  loss_giou: 0.3273 (0.3634)  loss_vfl_aux_0: 0.4987 (0.5296)  loss_bbox_aux_0: 0.0964 (0.1090)  loss_giou_aux_0: 0.3718 (0.4066)  loss_vfl_aux_1: 0.4919 (0.5114)  loss_bbox_aux_1: 0.0720 (0.0952)  loss_giou_aux_1: 0.3348 (0.3729)  loss_vfl_aux_2: 0.4815 (0.5079)  loss_bbox_aux_2: 0.0704 (0.0920)  loss_giou_aux_2: 0.3294 (0.3648)  loss_vfl_aux_3: 0.4503 (0.4873)  loss_bbox_aux_3: 0.0720 (0.0922)  loss_giou_aux_3: 0.3290 (0.3652)  loss_vfl_aux_4: 0.4339 (0.4695)  loss_bbox_aux_4: 0.0721 (0.0916)  loss_giou_aux_4: 0.3261 (0.3637)  loss_vfl_aux_5: 0.5722 (0.6190)  loss_bbox_aux_5: 0.1288 (0.1540)  loss_giou_aux_5: 0.5221 (0.5339)  loss_vfl_dn_0: 0.4278 (0.4387)  loss_bbox_dn_0: 0.1511 (0.1752)  loss_giou_dn_0: 0.5405 (0.5631)  loss_vfl_dn_1: 0.3837 (0.3931)  loss_bbox_dn_1: 0.1031 (0.1233)  loss_giou_dn_1: 0.3808 (0.4129)  loss_vfl_dn_2: 0.3685 (0.3801)  loss_bbox_dn_2: 0.0942 (0.1134)  loss_giou_dn_2: 0.3557 (0.3865)  loss_vfl_dn_3: 0.3637 (0.3767)  loss_bbox_dn_3: 0.0927 (0.1107)  loss_giou_dn_3: 0.3539 (0.3809)  loss_vfl_dn_4: 0.3666 (0.3739)  loss_bbox_dn_4: 0.0925 (0.1100)  loss_giou_dn_4: 0.3528 (0.3799)  loss_vfl_dn_5: 0.3619 (0.3731)  loss_bbox_dn_5: 0.0931 (0.1098)  loss_giou_dn_5: 0.3538 (0.3799)  time: 0.3256  data: 0.0151  max mem: 7790\n",
            "Epoch: [195] Total time: 0:00:11 (0.3556 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 11.9561 (12.6695)  loss_vfl: 0.4395 (0.4693)  loss_bbox: 0.0721 (0.0899)  loss_giou: 0.3273 (0.3634)  loss_vfl_aux_0: 0.4987 (0.5296)  loss_bbox_aux_0: 0.0964 (0.1090)  loss_giou_aux_0: 0.3718 (0.4066)  loss_vfl_aux_1: 0.4919 (0.5114)  loss_bbox_aux_1: 0.0720 (0.0952)  loss_giou_aux_1: 0.3348 (0.3729)  loss_vfl_aux_2: 0.4815 (0.5079)  loss_bbox_aux_2: 0.0704 (0.0920)  loss_giou_aux_2: 0.3294 (0.3648)  loss_vfl_aux_3: 0.4503 (0.4873)  loss_bbox_aux_3: 0.0720 (0.0922)  loss_giou_aux_3: 0.3290 (0.3652)  loss_vfl_aux_4: 0.4339 (0.4695)  loss_bbox_aux_4: 0.0721 (0.0916)  loss_giou_aux_4: 0.3261 (0.3637)  loss_vfl_aux_5: 0.5722 (0.6190)  loss_bbox_aux_5: 0.1288 (0.1540)  loss_giou_aux_5: 0.5221 (0.5339)  loss_vfl_dn_0: 0.4278 (0.4387)  loss_bbox_dn_0: 0.1511 (0.1752)  loss_giou_dn_0: 0.5405 (0.5631)  loss_vfl_dn_1: 0.3837 (0.3931)  loss_bbox_dn_1: 0.1031 (0.1233)  loss_giou_dn_1: 0.3808 (0.4129)  loss_vfl_dn_2: 0.3685 (0.3801)  loss_bbox_dn_2: 0.0942 (0.1134)  loss_giou_dn_2: 0.3557 (0.3865)  loss_vfl_dn_3: 0.3637 (0.3767)  loss_bbox_dn_3: 0.0927 (0.1107)  loss_giou_dn_3: 0.3539 (0.3809)  loss_vfl_dn_4: 0.3666 (0.3739)  loss_bbox_dn_4: 0.0925 (0.1100)  loss_giou_dn_4: 0.3528 (0.3799)  loss_vfl_dn_5: 0.3619 (0.3731)  loss_bbox_dn_5: 0.0931 (0.1098)  loss_giou_dn_5: 0.3538 (0.3799)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.9018  data: 0.5846  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3926  data: 0.1158  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4069 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.677\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            "best_stat:  {'epoch': 195, 'coco_eval_bbox': 0.35723378790708515}\n",
            "Epoch: [196]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 14.8044 (14.8044)  loss_vfl: 0.6322 (0.6322)  loss_bbox: 0.1104 (0.1104)  loss_giou: 0.3947 (0.3947)  loss_vfl_aux_0: 0.6892 (0.6892)  loss_bbox_aux_0: 0.1012 (0.1012)  loss_giou_aux_0: 0.4657 (0.4657)  loss_vfl_aux_1: 0.6806 (0.6806)  loss_bbox_aux_1: 0.0945 (0.0945)  loss_giou_aux_1: 0.4109 (0.4109)  loss_vfl_aux_2: 0.6865 (0.6865)  loss_bbox_aux_2: 0.1020 (0.1020)  loss_giou_aux_2: 0.3840 (0.3840)  loss_vfl_aux_3: 0.6738 (0.6738)  loss_bbox_aux_3: 0.1043 (0.1043)  loss_giou_aux_3: 0.3924 (0.3924)  loss_vfl_aux_4: 0.6322 (0.6322)  loss_bbox_aux_4: 0.1087 (0.1087)  loss_giou_aux_4: 0.3921 (0.3921)  loss_vfl_aux_5: 0.6292 (0.6292)  loss_bbox_aux_5: 0.1374 (0.1374)  loss_giou_aux_5: 0.6477 (0.6477)  loss_vfl_dn_0: 0.4412 (0.4412)  loss_bbox_dn_0: 0.1779 (0.1779)  loss_giou_dn_0: 0.6326 (0.6326)  loss_vfl_dn_1: 0.4051 (0.4051)  loss_bbox_dn_1: 0.1337 (0.1337)  loss_giou_dn_1: 0.5038 (0.5038)  loss_vfl_dn_2: 0.3981 (0.3981)  loss_bbox_dn_2: 0.1281 (0.1281)  loss_giou_dn_2: 0.4887 (0.4887)  loss_vfl_dn_3: 0.3946 (0.3946)  loss_bbox_dn_3: 0.1290 (0.1290)  loss_giou_dn_3: 0.4887 (0.4887)  loss_vfl_dn_4: 0.3902 (0.3902)  loss_bbox_dn_4: 0.1298 (0.1298)  loss_giou_dn_4: 0.4867 (0.4867)  loss_vfl_dn_5: 0.3899 (0.3899)  loss_bbox_dn_5: 0.1295 (0.1295)  loss_giou_dn_5: 0.4872 (0.4872)  time: 1.0771  data: 0.6721  max mem: 7790\n",
            "Epoch: [196]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.2113 (12.6262)  loss_vfl: 0.4784 (0.4724)  loss_bbox: 0.0778 (0.0821)  loss_giou: 0.3225 (0.3781)  loss_vfl_aux_0: 0.4990 (0.5120)  loss_bbox_aux_0: 0.0938 (0.0957)  loss_giou_aux_0: 0.4029 (0.4264)  loss_vfl_aux_1: 0.4987 (0.5008)  loss_bbox_aux_1: 0.0823 (0.0874)  loss_giou_aux_1: 0.3648 (0.3940)  loss_vfl_aux_2: 0.4952 (0.5022)  loss_bbox_aux_2: 0.0781 (0.0829)  loss_giou_aux_2: 0.3530 (0.3810)  loss_vfl_aux_3: 0.4956 (0.4945)  loss_bbox_aux_3: 0.0770 (0.0818)  loss_giou_aux_3: 0.3268 (0.3769)  loss_vfl_aux_4: 0.4763 (0.4728)  loss_bbox_aux_4: 0.0782 (0.0824)  loss_giou_aux_4: 0.3211 (0.3780)  loss_vfl_aux_5: 0.5655 (0.5712)  loss_bbox_aux_5: 0.1308 (0.1314)  loss_giou_aux_5: 0.5104 (0.5470)  loss_vfl_dn_0: 0.4277 (0.4326)  loss_bbox_dn_0: 0.1419 (0.1461)  loss_giou_dn_0: 0.5542 (0.5716)  loss_vfl_dn_1: 0.3845 (0.3906)  loss_bbox_dn_1: 0.0986 (0.1055)  loss_giou_dn_1: 0.3925 (0.4294)  loss_vfl_dn_2: 0.3738 (0.3791)  loss_bbox_dn_2: 0.0905 (0.0992)  loss_giou_dn_2: 0.3631 (0.4085)  loss_vfl_dn_3: 0.3685 (0.3735)  loss_bbox_dn_3: 0.0897 (0.0974)  loss_giou_dn_3: 0.3555 (0.4030)  loss_vfl_dn_4: 0.3630 (0.3707)  loss_bbox_dn_4: 0.0891 (0.0973)  loss_giou_dn_4: 0.3541 (0.4020)  loss_vfl_dn_5: 0.3617 (0.3700)  loss_bbox_dn_5: 0.0887 (0.0971)  loss_giou_dn_5: 0.3539 (0.4017)  time: 0.3347  data: 0.0140  max mem: 7790\n",
            "Epoch: [196] Total time: 0:00:11 (0.3585 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.2113 (12.6262)  loss_vfl: 0.4784 (0.4724)  loss_bbox: 0.0778 (0.0821)  loss_giou: 0.3225 (0.3781)  loss_vfl_aux_0: 0.4990 (0.5120)  loss_bbox_aux_0: 0.0938 (0.0957)  loss_giou_aux_0: 0.4029 (0.4264)  loss_vfl_aux_1: 0.4987 (0.5008)  loss_bbox_aux_1: 0.0823 (0.0874)  loss_giou_aux_1: 0.3648 (0.3940)  loss_vfl_aux_2: 0.4952 (0.5022)  loss_bbox_aux_2: 0.0781 (0.0829)  loss_giou_aux_2: 0.3530 (0.3810)  loss_vfl_aux_3: 0.4956 (0.4945)  loss_bbox_aux_3: 0.0770 (0.0818)  loss_giou_aux_3: 0.3268 (0.3769)  loss_vfl_aux_4: 0.4763 (0.4728)  loss_bbox_aux_4: 0.0782 (0.0824)  loss_giou_aux_4: 0.3211 (0.3780)  loss_vfl_aux_5: 0.5655 (0.5712)  loss_bbox_aux_5: 0.1308 (0.1314)  loss_giou_aux_5: 0.5104 (0.5470)  loss_vfl_dn_0: 0.4277 (0.4326)  loss_bbox_dn_0: 0.1419 (0.1461)  loss_giou_dn_0: 0.5542 (0.5716)  loss_vfl_dn_1: 0.3845 (0.3906)  loss_bbox_dn_1: 0.0986 (0.1055)  loss_giou_dn_1: 0.3925 (0.4294)  loss_vfl_dn_2: 0.3738 (0.3791)  loss_bbox_dn_2: 0.0905 (0.0992)  loss_giou_dn_2: 0.3631 (0.4085)  loss_vfl_dn_3: 0.3685 (0.3735)  loss_bbox_dn_3: 0.0897 (0.0974)  loss_giou_dn_3: 0.3555 (0.4030)  loss_vfl_dn_4: 0.3630 (0.3707)  loss_bbox_dn_4: 0.0891 (0.0973)  loss_giou_dn_4: 0.3541 (0.4020)  loss_vfl_dn_5: 0.3617 (0.3700)  loss_bbox_dn_5: 0.0887 (0.0971)  loss_giou_dn_5: 0.3539 (0.4017)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8945  data: 0.5862  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4332  data: 0.1096  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4457 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "best_stat:  {'epoch': 195, 'coco_eval_bbox': 0.35723378790708515}\n",
            "Epoch: [197]  [ 0/33]  eta: 0:00:36  lr: 0.000001  loss: 12.2390 (12.2390)  loss_vfl: 0.4732 (0.4732)  loss_bbox: 0.0647 (0.0647)  loss_giou: 0.3516 (0.3516)  loss_vfl_aux_0: 0.4935 (0.4935)  loss_bbox_aux_0: 0.0796 (0.0796)  loss_giou_aux_0: 0.3976 (0.3976)  loss_vfl_aux_1: 0.5246 (0.5246)  loss_bbox_aux_1: 0.0653 (0.0653)  loss_giou_aux_1: 0.3670 (0.3670)  loss_vfl_aux_2: 0.5063 (0.5063)  loss_bbox_aux_2: 0.0656 (0.0656)  loss_giou_aux_2: 0.3594 (0.3594)  loss_vfl_aux_3: 0.5074 (0.5074)  loss_bbox_aux_3: 0.0645 (0.0645)  loss_giou_aux_3: 0.3507 (0.3507)  loss_vfl_aux_4: 0.4631 (0.4631)  loss_bbox_aux_4: 0.0642 (0.0642)  loss_giou_aux_4: 0.3495 (0.3495)  loss_vfl_aux_5: 0.5570 (0.5570)  loss_bbox_aux_5: 0.1284 (0.1284)  loss_giou_aux_5: 0.5057 (0.5057)  loss_vfl_dn_0: 0.4262 (0.4262)  loss_bbox_dn_0: 0.1398 (0.1398)  loss_giou_dn_0: 0.5658 (0.5658)  loss_vfl_dn_1: 0.3772 (0.3772)  loss_bbox_dn_1: 0.0994 (0.0994)  loss_giou_dn_1: 0.4331 (0.4331)  loss_vfl_dn_2: 0.3706 (0.3706)  loss_bbox_dn_2: 0.0905 (0.0905)  loss_giou_dn_2: 0.4077 (0.4077)  loss_vfl_dn_3: 0.3683 (0.3683)  loss_bbox_dn_3: 0.0901 (0.0901)  loss_giou_dn_3: 0.4045 (0.4045)  loss_vfl_dn_4: 0.3675 (0.3675)  loss_bbox_dn_4: 0.0902 (0.0902)  loss_giou_dn_4: 0.4043 (0.4043)  loss_vfl_dn_5: 0.3697 (0.3697)  loss_bbox_dn_5: 0.0904 (0.0904)  loss_giou_dn_5: 0.4048 (0.4048)  time: 1.1205  data: 0.7408  max mem: 7790\n",
            "Epoch: [197]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 11.9722 (12.1590)  loss_vfl: 0.4514 (0.4578)  loss_bbox: 0.0636 (0.0799)  loss_giou: 0.3255 (0.3466)  loss_vfl_aux_0: 0.4933 (0.4993)  loss_bbox_aux_0: 0.0736 (0.0955)  loss_giou_aux_0: 0.3906 (0.3945)  loss_vfl_aux_1: 0.4805 (0.4917)  loss_bbox_aux_1: 0.0666 (0.0842)  loss_giou_aux_1: 0.3295 (0.3610)  loss_vfl_aux_2: 0.4716 (0.4872)  loss_bbox_aux_2: 0.0671 (0.0819)  loss_giou_aux_2: 0.3304 (0.3520)  loss_vfl_aux_3: 0.4624 (0.4730)  loss_bbox_aux_3: 0.0675 (0.0807)  loss_giou_aux_3: 0.3264 (0.3477)  loss_vfl_aux_4: 0.4483 (0.4592)  loss_bbox_aux_4: 0.0664 (0.0815)  loss_giou_aux_4: 0.3251 (0.3476)  loss_vfl_aux_5: 0.5603 (0.5951)  loss_bbox_aux_5: 0.1243 (0.1469)  loss_giou_aux_5: 0.5303 (0.5394)  loss_vfl_dn_0: 0.4328 (0.4346)  loss_bbox_dn_0: 0.1307 (0.1531)  loss_giou_dn_0: 0.5380 (0.5481)  loss_vfl_dn_1: 0.3744 (0.3859)  loss_bbox_dn_1: 0.0856 (0.1051)  loss_giou_dn_1: 0.4040 (0.4001)  loss_vfl_dn_2: 0.3615 (0.3735)  loss_bbox_dn_2: 0.0778 (0.0959)  loss_giou_dn_2: 0.3908 (0.3732)  loss_vfl_dn_3: 0.3590 (0.3689)  loss_bbox_dn_3: 0.0772 (0.0936)  loss_giou_dn_3: 0.3862 (0.3684)  loss_vfl_dn_4: 0.3543 (0.3679)  loss_bbox_dn_4: 0.0770 (0.0933)  loss_giou_dn_4: 0.3889 (0.3675)  loss_vfl_dn_5: 0.3535 (0.3658)  loss_bbox_dn_5: 0.0755 (0.0933)  loss_giou_dn_5: 0.3900 (0.3679)  time: 0.3284  data: 0.0149  max mem: 7790\n",
            "Epoch: [197] Total time: 0:00:11 (0.3583 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 11.9722 (12.1590)  loss_vfl: 0.4514 (0.4578)  loss_bbox: 0.0636 (0.0799)  loss_giou: 0.3255 (0.3466)  loss_vfl_aux_0: 0.4933 (0.4993)  loss_bbox_aux_0: 0.0736 (0.0955)  loss_giou_aux_0: 0.3906 (0.3945)  loss_vfl_aux_1: 0.4805 (0.4917)  loss_bbox_aux_1: 0.0666 (0.0842)  loss_giou_aux_1: 0.3295 (0.3610)  loss_vfl_aux_2: 0.4716 (0.4872)  loss_bbox_aux_2: 0.0671 (0.0819)  loss_giou_aux_2: 0.3304 (0.3520)  loss_vfl_aux_3: 0.4624 (0.4730)  loss_bbox_aux_3: 0.0675 (0.0807)  loss_giou_aux_3: 0.3264 (0.3477)  loss_vfl_aux_4: 0.4483 (0.4592)  loss_bbox_aux_4: 0.0664 (0.0815)  loss_giou_aux_4: 0.3251 (0.3476)  loss_vfl_aux_5: 0.5603 (0.5951)  loss_bbox_aux_5: 0.1243 (0.1469)  loss_giou_aux_5: 0.5303 (0.5394)  loss_vfl_dn_0: 0.4328 (0.4346)  loss_bbox_dn_0: 0.1307 (0.1531)  loss_giou_dn_0: 0.5380 (0.5481)  loss_vfl_dn_1: 0.3744 (0.3859)  loss_bbox_dn_1: 0.0856 (0.1051)  loss_giou_dn_1: 0.4040 (0.4001)  loss_vfl_dn_2: 0.3615 (0.3735)  loss_bbox_dn_2: 0.0778 (0.0959)  loss_giou_dn_2: 0.3908 (0.3732)  loss_vfl_dn_3: 0.3590 (0.3689)  loss_bbox_dn_3: 0.0772 (0.0936)  loss_giou_dn_3: 0.3862 (0.3684)  loss_vfl_dn_4: 0.3543 (0.3679)  loss_bbox_dn_4: 0.0770 (0.0933)  loss_giou_dn_4: 0.3889 (0.3675)  loss_vfl_dn_5: 0.3535 (0.3658)  loss_bbox_dn_5: 0.0755 (0.0933)  loss_giou_dn_5: 0.3900 (0.3679)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8494  data: 0.5392  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.4526  data: 0.1133  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4673 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.662\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "best_stat:  {'epoch': 195, 'coco_eval_bbox': 0.35723378790708515}\n",
            "Epoch: [198]  [ 0/33]  eta: 0:00:33  lr: 0.000001  loss: 12.7682 (12.7682)  loss_vfl: 0.3855 (0.3855)  loss_bbox: 0.0799 (0.0799)  loss_giou: 0.4955 (0.4955)  loss_vfl_aux_0: 0.3996 (0.3996)  loss_bbox_aux_0: 0.0883 (0.0883)  loss_giou_aux_0: 0.5397 (0.5397)  loss_vfl_aux_1: 0.4040 (0.4040)  loss_bbox_aux_1: 0.0862 (0.0862)  loss_giou_aux_1: 0.5173 (0.5173)  loss_vfl_aux_2: 0.4001 (0.4001)  loss_bbox_aux_2: 0.0820 (0.0820)  loss_giou_aux_2: 0.5056 (0.5056)  loss_vfl_aux_3: 0.3967 (0.3967)  loss_bbox_aux_3: 0.0804 (0.0804)  loss_giou_aux_3: 0.4976 (0.4976)  loss_vfl_aux_4: 0.3860 (0.3860)  loss_bbox_aux_4: 0.0803 (0.0803)  loss_giou_aux_4: 0.4964 (0.4964)  loss_vfl_aux_5: 0.4865 (0.4865)  loss_bbox_aux_5: 0.1144 (0.1144)  loss_giou_aux_5: 0.6274 (0.6274)  loss_vfl_dn_0: 0.4149 (0.4149)  loss_bbox_dn_0: 0.1246 (0.1246)  loss_giou_dn_0: 0.6182 (0.6182)  loss_vfl_dn_1: 0.3648 (0.3648)  loss_bbox_dn_1: 0.0860 (0.0860)  loss_giou_dn_1: 0.4844 (0.4844)  loss_vfl_dn_2: 0.3542 (0.3542)  loss_bbox_dn_2: 0.0770 (0.0770)  loss_giou_dn_2: 0.4572 (0.4572)  loss_vfl_dn_3: 0.3503 (0.3503)  loss_bbox_dn_3: 0.0752 (0.0752)  loss_giou_dn_3: 0.4516 (0.4516)  loss_vfl_dn_4: 0.3540 (0.3540)  loss_bbox_dn_4: 0.0758 (0.0758)  loss_giou_dn_4: 0.4518 (0.4518)  loss_vfl_dn_5: 0.3510 (0.3510)  loss_bbox_dn_5: 0.0756 (0.0756)  loss_giou_dn_5: 0.4527 (0.4527)  time: 1.0102  data: 0.5649  max mem: 7790\n",
            "Epoch: [198]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.4893 (12.5980)  loss_vfl: 0.4478 (0.4582)  loss_bbox: 0.0751 (0.0815)  loss_giou: 0.3499 (0.3718)  loss_vfl_aux_0: 0.4984 (0.5102)  loss_bbox_aux_0: 0.0815 (0.1002)  loss_giou_aux_0: 0.4070 (0.4206)  loss_vfl_aux_1: 0.4800 (0.5047)  loss_bbox_aux_1: 0.0757 (0.0874)  loss_giou_aux_1: 0.3695 (0.3849)  loss_vfl_aux_2: 0.4802 (0.4993)  loss_bbox_aux_2: 0.0744 (0.0840)  loss_giou_aux_2: 0.3587 (0.3757)  loss_vfl_aux_3: 0.4666 (0.4873)  loss_bbox_aux_3: 0.0756 (0.0826)  loss_giou_aux_3: 0.3459 (0.3714)  loss_vfl_aux_4: 0.4526 (0.4611)  loss_bbox_aux_4: 0.0757 (0.0817)  loss_giou_aux_4: 0.3514 (0.3711)  loss_vfl_aux_5: 0.5730 (0.5863)  loss_bbox_aux_5: 0.1221 (0.1429)  loss_giou_aux_5: 0.5157 (0.5486)  loss_vfl_dn_0: 0.4331 (0.4344)  loss_bbox_dn_0: 0.1476 (0.1575)  loss_giou_dn_0: 0.5756 (0.5761)  loss_vfl_dn_1: 0.3912 (0.3932)  loss_bbox_dn_1: 0.0994 (0.1083)  loss_giou_dn_1: 0.4257 (0.4243)  loss_vfl_dn_2: 0.3853 (0.3829)  loss_bbox_dn_2: 0.0876 (0.1005)  loss_giou_dn_2: 0.4007 (0.3999)  loss_vfl_dn_3: 0.3797 (0.3802)  loss_bbox_dn_3: 0.0868 (0.0987)  loss_giou_dn_3: 0.3949 (0.3950)  loss_vfl_dn_4: 0.3772 (0.3755)  loss_bbox_dn_4: 0.0849 (0.0986)  loss_giou_dn_4: 0.3925 (0.3942)  loss_vfl_dn_5: 0.3757 (0.3747)  loss_bbox_dn_5: 0.0847 (0.0984)  loss_giou_dn_5: 0.3915 (0.3941)  time: 0.3194  data: 0.0141  max mem: 7790\n",
            "Epoch: [198] Total time: 0:00:11 (0.3463 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.4893 (12.5980)  loss_vfl: 0.4478 (0.4582)  loss_bbox: 0.0751 (0.0815)  loss_giou: 0.3499 (0.3718)  loss_vfl_aux_0: 0.4984 (0.5102)  loss_bbox_aux_0: 0.0815 (0.1002)  loss_giou_aux_0: 0.4070 (0.4206)  loss_vfl_aux_1: 0.4800 (0.5047)  loss_bbox_aux_1: 0.0757 (0.0874)  loss_giou_aux_1: 0.3695 (0.3849)  loss_vfl_aux_2: 0.4802 (0.4993)  loss_bbox_aux_2: 0.0744 (0.0840)  loss_giou_aux_2: 0.3587 (0.3757)  loss_vfl_aux_3: 0.4666 (0.4873)  loss_bbox_aux_3: 0.0756 (0.0826)  loss_giou_aux_3: 0.3459 (0.3714)  loss_vfl_aux_4: 0.4526 (0.4611)  loss_bbox_aux_4: 0.0757 (0.0817)  loss_giou_aux_4: 0.3514 (0.3711)  loss_vfl_aux_5: 0.5730 (0.5863)  loss_bbox_aux_5: 0.1221 (0.1429)  loss_giou_aux_5: 0.5157 (0.5486)  loss_vfl_dn_0: 0.4331 (0.4344)  loss_bbox_dn_0: 0.1476 (0.1575)  loss_giou_dn_0: 0.5756 (0.5761)  loss_vfl_dn_1: 0.3912 (0.3932)  loss_bbox_dn_1: 0.0994 (0.1083)  loss_giou_dn_1: 0.4257 (0.4243)  loss_vfl_dn_2: 0.3853 (0.3829)  loss_bbox_dn_2: 0.0876 (0.1005)  loss_giou_dn_2: 0.4007 (0.3999)  loss_vfl_dn_3: 0.3797 (0.3802)  loss_bbox_dn_3: 0.0868 (0.0987)  loss_giou_dn_3: 0.3949 (0.3950)  loss_vfl_dn_4: 0.3772 (0.3755)  loss_bbox_dn_4: 0.0849 (0.0986)  loss_giou_dn_4: 0.3925 (0.3942)  loss_vfl_dn_5: 0.3757 (0.3747)  loss_bbox_dn_5: 0.0847 (0.0984)  loss_giou_dn_5: 0.3915 (0.3941)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8965  data: 0.5889  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3841  data: 0.1131  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.3988 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.672\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741\n",
            "best_stat:  {'epoch': 195, 'coco_eval_bbox': 0.35723378790708515}\n",
            "Epoch: [199]  [ 0/33]  eta: 0:00:32  lr: 0.000001  loss: 12.6171 (12.6171)  loss_vfl: 0.5393 (0.5393)  loss_bbox: 0.0938 (0.0938)  loss_giou: 0.3199 (0.3199)  loss_vfl_aux_0: 0.4783 (0.4783)  loss_bbox_aux_0: 0.1305 (0.1305)  loss_giou_aux_0: 0.3862 (0.3862)  loss_vfl_aux_1: 0.5370 (0.5370)  loss_bbox_aux_1: 0.0946 (0.0946)  loss_giou_aux_1: 0.3341 (0.3341)  loss_vfl_aux_2: 0.5355 (0.5355)  loss_bbox_aux_2: 0.0962 (0.0962)  loss_giou_aux_2: 0.3269 (0.3269)  loss_vfl_aux_3: 0.5512 (0.5512)  loss_bbox_aux_3: 0.0936 (0.0936)  loss_giou_aux_3: 0.3247 (0.3247)  loss_vfl_aux_4: 0.5253 (0.5253)  loss_bbox_aux_4: 0.0939 (0.0939)  loss_giou_aux_4: 0.3224 (0.3224)  loss_vfl_aux_5: 0.5884 (0.5884)  loss_bbox_aux_5: 0.1539 (0.1539)  loss_giou_aux_5: 0.4956 (0.4956)  loss_vfl_dn_0: 0.4276 (0.4276)  loss_bbox_dn_0: 0.2180 (0.2180)  loss_giou_dn_0: 0.5344 (0.5344)  loss_vfl_dn_1: 0.3841 (0.3841)  loss_bbox_dn_1: 0.1566 (0.1566)  loss_giou_dn_1: 0.3826 (0.3826)  loss_vfl_dn_2: 0.3651 (0.3651)  loss_bbox_dn_2: 0.1505 (0.1505)  loss_giou_dn_2: 0.3571 (0.3571)  loss_vfl_dn_3: 0.3644 (0.3644)  loss_bbox_dn_3: 0.1534 (0.1534)  loss_giou_dn_3: 0.3583 (0.3583)  loss_vfl_dn_4: 0.3592 (0.3592)  loss_bbox_dn_4: 0.1532 (0.1532)  loss_giou_dn_4: 0.3560 (0.3560)  loss_vfl_dn_5: 0.3626 (0.3626)  loss_bbox_dn_5: 0.1549 (0.1549)  loss_giou_dn_5: 0.3578 (0.3578)  time: 0.9729  data: 0.5864  max mem: 7790\n",
            "Epoch: [199]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 12.3456 (12.4762)  loss_vfl: 0.4300 (0.4497)  loss_bbox: 0.0732 (0.0808)  loss_giou: 0.3628 (0.3762)  loss_vfl_aux_0: 0.4721 (0.4875)  loss_bbox_aux_0: 0.0888 (0.0985)  loss_giou_aux_0: 0.3987 (0.4249)  loss_vfl_aux_1: 0.4831 (0.4853)  loss_bbox_aux_1: 0.0783 (0.0848)  loss_giou_aux_1: 0.3768 (0.3886)  loss_vfl_aux_2: 0.4794 (0.4775)  loss_bbox_aux_2: 0.0761 (0.0835)  loss_giou_aux_2: 0.3664 (0.3803)  loss_vfl_aux_3: 0.4426 (0.4749)  loss_bbox_aux_3: 0.0744 (0.0818)  loss_giou_aux_3: 0.3643 (0.3774)  loss_vfl_aux_4: 0.4441 (0.4535)  loss_bbox_aux_4: 0.0735 (0.0808)  loss_giou_aux_4: 0.3695 (0.3756)  loss_vfl_aux_5: 0.5600 (0.5756)  loss_bbox_aux_5: 0.1207 (0.1357)  loss_giou_aux_5: 0.5335 (0.5480)  loss_vfl_dn_0: 0.4348 (0.4346)  loss_bbox_dn_0: 0.1423 (0.1515)  loss_giou_dn_0: 0.5612 (0.5799)  loss_vfl_dn_1: 0.3939 (0.3916)  loss_bbox_dn_1: 0.0849 (0.1038)  loss_giou_dn_1: 0.4001 (0.4275)  loss_vfl_dn_2: 0.3851 (0.3781)  loss_bbox_dn_2: 0.0766 (0.0963)  loss_giou_dn_2: 0.3867 (0.4026)  loss_vfl_dn_3: 0.3731 (0.3758)  loss_bbox_dn_3: 0.0746 (0.0949)  loss_giou_dn_3: 0.3723 (0.3972)  loss_vfl_dn_4: 0.3713 (0.3708)  loss_bbox_dn_4: 0.0742 (0.0945)  loss_giou_dn_4: 0.3670 (0.3957)  loss_vfl_dn_5: 0.3710 (0.3703)  loss_bbox_dn_5: 0.0741 (0.0945)  loss_giou_dn_5: 0.3658 (0.3961)  time: 0.3409  data: 0.0139  max mem: 7790\n",
            "Epoch: [199] Total time: 0:00:11 (0.3548 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 12.3456 (12.4762)  loss_vfl: 0.4300 (0.4497)  loss_bbox: 0.0732 (0.0808)  loss_giou: 0.3628 (0.3762)  loss_vfl_aux_0: 0.4721 (0.4875)  loss_bbox_aux_0: 0.0888 (0.0985)  loss_giou_aux_0: 0.3987 (0.4249)  loss_vfl_aux_1: 0.4831 (0.4853)  loss_bbox_aux_1: 0.0783 (0.0848)  loss_giou_aux_1: 0.3768 (0.3886)  loss_vfl_aux_2: 0.4794 (0.4775)  loss_bbox_aux_2: 0.0761 (0.0835)  loss_giou_aux_2: 0.3664 (0.3803)  loss_vfl_aux_3: 0.4426 (0.4749)  loss_bbox_aux_3: 0.0744 (0.0818)  loss_giou_aux_3: 0.3643 (0.3774)  loss_vfl_aux_4: 0.4441 (0.4535)  loss_bbox_aux_4: 0.0735 (0.0808)  loss_giou_aux_4: 0.3695 (0.3756)  loss_vfl_aux_5: 0.5600 (0.5756)  loss_bbox_aux_5: 0.1207 (0.1357)  loss_giou_aux_5: 0.5335 (0.5480)  loss_vfl_dn_0: 0.4348 (0.4346)  loss_bbox_dn_0: 0.1423 (0.1515)  loss_giou_dn_0: 0.5612 (0.5799)  loss_vfl_dn_1: 0.3939 (0.3916)  loss_bbox_dn_1: 0.0849 (0.1038)  loss_giou_dn_1: 0.4001 (0.4275)  loss_vfl_dn_2: 0.3851 (0.3781)  loss_bbox_dn_2: 0.0766 (0.0963)  loss_giou_dn_2: 0.3867 (0.4026)  loss_vfl_dn_3: 0.3731 (0.3758)  loss_bbox_dn_3: 0.0746 (0.0949)  loss_giou_dn_3: 0.3723 (0.3972)  loss_vfl_dn_4: 0.3713 (0.3708)  loss_bbox_dn_4: 0.0742 (0.0945)  loss_giou_dn_4: 0.3670 (0.3957)  loss_vfl_dn_5: 0.3710 (0.3703)  loss_bbox_dn_5: 0.0741 (0.0945)  loss_giou_dn_5: 0.3658 (0.3961)\n",
            "Test:  [0/6]  eta: 0:00:05    time: 0.8559  data: 0.5425  max mem: 7790\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.3868  data: 0.1115  max mem: 7790\n",
            "Test: Total time: 0:00:02 (0.4007 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.671\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            "best_stat:  {'epoch': 195, 'coco_eval_bbox': 0.35723378790708515}\n",
            "Training time 1:03:21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/RT-DETR/rtdetr_pytorch/tools/train.py -c /content/RT-DETR/rtdetr_pytorch/configs/rtdetr/rtdetr_r101vd_6x_coco.yml -r /content/logs/checkpoint0195.pth --test-only\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emdhm6IIWf7n",
        "outputId": "647edbfd-e0c7-4e67-8cdd-0f2387224e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-14 15:43:22.781511: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-14 15:43:22.804236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-14 15:43:22.827129: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-14 15:43:22.833824: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-14 15:43:22.850535: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-14 15:43:24.227320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Not init distributed mode.\n",
            "Load PResNet50 state_dict\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "resume from /content/output/rtdetr_r50vd_6x_coco/checkpoint0185.pth\n",
            "Loading last_epoch\n",
            "Loading model.state_dict\n",
            "Loading ema.state_dict\n",
            "Test:  [0/6]  eta: 0:00:12    time: 2.1158  data: 0.5216  max mem: 1469\n",
            "Test:  [5/6]  eta: 0:00:00    time: 0.5870  data: 0.1026  max mem: 1477\n",
            "Test: Total time: 0:00:03 (0.5978 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python  /content/RT-DETR/rtdetr_pytorch/tools/infer.py -c /content/RT-DETR/rtdetr_pytorch/configs/rtdetr/rtdetr_r101vd_6x_coco.yml -r /content/logs/checkpoint0195.pth -d cuda -f /content/RT-DETR/rtdetrv2_pytorch/configs/dataset/individual_urban_tree_crown_detection/test/104.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-45PExMSABr",
        "outputId": "6b84655b-1620-4e00-bd5b-9c1947b277e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-15 15:02:40.124004: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-15 15:02:40.144478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-15 15:02:40.167744: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-15 15:02:40.174453: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-15 15:02:40.190387: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-15 15:02:41.335503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Load PResNet101 state_dict\n"
          ]
        }
      ]
    }
  ]
}